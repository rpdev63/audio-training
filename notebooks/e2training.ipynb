{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHeo90WTngrE",
        "outputId": "9aaece19-b488-4084-a992-25eb37e2889c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Apr 20 15:51:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwZZx6MzniLC",
        "outputId": "20519d5f-681b-4c11-dce0-058da59e0de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'audio-training'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 23 (delta 8), reused 22 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (23/23), 108.73 KiB | 4.73 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "--2024-04-20 15:51:39--  https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.103.159, 188.185.79.172, 188.184.98.238, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1203745/files/UrbanSound8K.tar.gz [following]\n",
            "--2024-04-20 15:51:39--  https://zenodo.org/records/1203745/files/UrbanSound8K.tar.gz\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6023741708 (5.6G) [application/octet-stream]\n",
            "Saving to: ‘urban8k.tgz’\n",
            "\n",
            "urban8k.tgz         100%[===================>]   5.61G   166MB/s    in 38s     \n",
            "\n",
            "2024-04-20 15:52:18 (149 MB/s) - ‘urban8k.tgz’ saved [6023741708/6023741708]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rpdev63/audio-training\n",
        "\n",
        "import os\n",
        "os.chdir(\"audio-training\")\n",
        "!wget https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz -O urban8k.tgz\n",
        "!tar -xzf urban8k.tgz\n",
        "!rm urban8k.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DVPGK5XTsyg",
        "outputId": "7b6bcaa2-a1d2-414b-a71a-16d339b5e037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7IeZ0Zan66T",
        "outputId": "c1d80e2a-80df-4650-fb49-87e86dba099d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max Padding =  174\n",
            "Creating output folder:  features_mfcc\n",
            "Saving features in  features_mfcc\n",
            " 41% 3552/8732 [01:26<01:52, 45.94it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
            "  warnings.warn(\n",
            " 95% 8323/8732 [03:06<00:06, 66.04it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
            "  warnings.warn(\n",
            "100% 8732/8732 [03:14<00:00, 44.92it/s]\n",
            "Temps d'éxécution : 194.380486803 s\n",
            "\n",
            "Reshaping and saving complete.\n"
          ]
        }
      ],
      "source": [
        "!python extract.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZElVyGSpvTe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications import VGG16\n",
        "from keras.layers import Dense, Flatten, Dropout, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import plotly.graph_objects as go\n",
        "from joblib import dump, load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44QITBCnoq5q"
      },
      "outputs": [],
      "source": [
        "def get_data(csv_file_path, random_state = 1, reshaped=False):\n",
        "  df = pd.read_csv(csv_file_path)\n",
        "  df['features'] = [np.asarray(np.load(feature_path))\n",
        "                    for feature_path in tqdm(df['reshaped_path'] if reshaped else df['mfcc_features_path'])]\n",
        "  num_classes = 10\n",
        "  df['labels_categorical'] = df['classID'].apply(\n",
        "      lambda x: np.eye(num_classes)[x])\n",
        "\n",
        "  # Add one dimension for the channel\n",
        "  X = np.array(df['features'].tolist())\n",
        "  X = X.reshape(X.shape + (1,))\n",
        "  y = np.array(df['labels_categorical'].tolist())\n",
        "\n",
        "  # As there is unbalance for some classes I am going to stratify it so we have the same proportion in train/test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                      y,\n",
        "                                                      test_size=0.30,\n",
        "                                                      random_state=random_state,\n",
        "                                                      stratify=y)\n",
        "  # Create validation and test\n",
        "  X_test, X_val, y_test, y_val = train_test_split(X_test,\n",
        "                                                  y_test,\n",
        "                                                  test_size=0.5,\n",
        "                                                  random_state=random_state,\n",
        "                                                  stratify=y_test)\n",
        "  return X_train, X_test, X_val, y_train, y_test, y_val\n",
        "\n",
        "def schedule(epoch, lr):\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "        lr = lr * 0.95\n",
        "    return lr\n",
        "\n",
        "def launch_training(model, X_train, y_train, X_val, y_val, lr=0.001, bs=256, epochs=100, patience=10, decay=1, optimizer=\"Adam\", verbose=0):\n",
        "  if verbose > 0:\n",
        "    model.summary()\n",
        "\n",
        "  if optimizer == \"Adam\":\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "  elif optimizer == \"RMSprop\":\n",
        "    optimizer = RMSprop(learning_rate=lr)\n",
        "  elif optimizer == \"SGD\":\n",
        "    optimizer = SGD(learning_rate=lr)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  early_stopping = EarlyStopping(\n",
        "      monitor='val_accuracy', patience=patience, restore_best_weights=True)\n",
        "  checkpointer = ModelCheckpoint(\n",
        "      filepath='saved_models/best_fcn.keras', monitor='val_accuracy', verbose=verbose, save_best_only=True)\n",
        "  callbacks=[checkpointer, early_stopping]\n",
        "  if decay < 1:\n",
        "    lr_scheduler = LearningRateScheduler(schedule)\n",
        "    callbacks.append(lr_scheduler)\n",
        "  # Train the model\n",
        "  history = model.fit(X_train,\n",
        "                      y_train,\n",
        "                      epochs=epochs,\n",
        "                      batch_size=bs,\n",
        "                      validation_data=(X_val, y_val),\n",
        "                      callbacks=callbacks,\n",
        "                      verbose=verbose\n",
        "                      )\n",
        "  return model, history\n",
        "\n",
        "def get_eval(model, history, X_test, y_test, matrix=True):\n",
        "  # Plot training and validation loss\n",
        "  plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.show()\n",
        "  # Print best validation accuracy\n",
        "  best_val_accuracy = round(max(history.history['val_accuracy']), 3)\n",
        "  print(f\"Best Validation Accuracy: {best_val_accuracy}\")\n",
        "\n",
        "  # Calculate test accuracy\n",
        "  y_pred_probs = model.predict(X_test)\n",
        "  y_pred = np.round(y_pred_probs)\n",
        "  accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
        "  print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "  # Convert multilabel indicators to class labels\n",
        "  y_test_labels = np.argmax(y_test, axis=1)\n",
        "  y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "  if matrix :\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "    plt.xlabel('Predicted labels')\n",
        "    plt.ylabel('True labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def get_cv_eval(cv_scores, random_states):\n",
        "  rounded_accuracy_scores = [round(score, 2) for score in cv_scores]\n",
        "  # Plot bar chart\n",
        "  fig = go.Figure(data=[go.Bar(\n",
        "      x=random_states,\n",
        "      y=rounded_accuracy_scores,\n",
        "      marker=dict(color=['blue', 'purple']*5)  # Alternate colors between blue and purple\n",
        "  )])\n",
        "  # Layout\n",
        "  fig.update_layout(\n",
        "      title=f\"Mean Accuracy: {round(np.mean(cv_scores),3)}\",\n",
        "      xaxis_title=\"<b>Random State</b>\",\n",
        "      title_x=0.5,  # Center the title horizontally\n",
        "      yaxis_title=\"<b>Accuracy</b>\",\n",
        "      yaxis=dict(range=[0.7, 1.0]),  # Set y-axis range from 0.7 to 1.0\n",
        "      xaxis=dict(\n",
        "          tickmode='array',  # Set tick mode to 'array'\n",
        "          tickvals=random_states)  # Provide all values for ticks\n",
        "  )\n",
        "  fig.update_layout(\n",
        "      height=400,  # Set height\n",
        "      width=600   # Set width\n",
        "  )\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq4YZEztqFJV"
      },
      "outputs": [],
      "source": [
        "def transfert_model(keep_weights = True, num_classes = 10):\n",
        "  base_model = VGG16(weights='imagenet' if keep_weights else None, include_top=False, input_shape=(224, 224, 3) if keep_weights  else (39,174,1))\n",
        "  # Freeze convolutional base\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "  # Add new fully connected layers\n",
        "  x = Flatten()(base_model.output)\n",
        "  output = Dense(num_classes, activation='softmax')(x)  # num_classes is the number of classes in your dataset\n",
        "  # Create the new model\n",
        "  model = Model(inputs=base_model.input, outputs=output)\n",
        "  return model\n",
        "\n",
        "\n",
        "def base_model(num_classes=10, input_shape=None, dropout_ratio=None):\n",
        "    model = Sequential()\n",
        "    if input_shape is None:\n",
        "        model.add(Input(shape=(None, None, 1)))\n",
        "    else:\n",
        "        model.add(Input(shape=input_shape))\n",
        "    model.add(Conv2D(filters=16, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 3)))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    if dropout_ratio is not None:\n",
        "        model.add(Dropout(dropout_ratio))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "def improved_model(num_classes=10, input_shape=None, dropout_ratio=0.25):\n",
        "    model = Sequential()\n",
        "    if input_shape is None:\n",
        "        model.add(Input(shape=(None, None, 1)))\n",
        "    else:\n",
        "        model.add(Input(shape=input_shape))\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dropout(dropout_ratio))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def reimproved_model(num_classes=10, input_shape=None, dropout_ratio=0.2):\n",
        "    model = Sequential()\n",
        "    if input_shape is None:\n",
        "        model.add(Input(shape=(None, None, 1)))\n",
        "    else:\n",
        "        model.add(Input(shape=input_shape))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    # model.add(Dropout(dropout_ratio))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dropout(dropout_ratio))\n",
        "    # Dense(128, activation='relu'),\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccCJAI_6MbE0"
      },
      "source": [
        "**EVALUATION DU MODEL DE BASE PAR VALIDATION CROISEE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmps30XQNvnl",
        "outputId": "da51d7bc-cb3f-4c76-efb1-ea1d39d6e0e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:01<00:00, 8164.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:1, test_accuracy:0.895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:01<00:00, 7212.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:2, test_accuracy:0.911\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 9215.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:3, test_accuracy:0.903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 9869.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:4, test_accuracy:0.905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 10283.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:5, test_accuracy:0.895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 10150.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:6, test_accuracy:0.897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 10460.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:7, test_accuracy:0.909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 9915.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:8, test_accuracy:0.893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 9967.81it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:9, test_accuracy:0.903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 10033.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n",
            "random_state:10, test_accuracy:0.914\n",
            "Mean CV Accuracy: 0.902\n"
          ]
        }
      ],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 200\n",
        "PATIENCE = 100\n",
        "DROPOUT = 0.5\n",
        "DECAY = 1\n",
        "RS = [1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "cv_scores = []\n",
        "for rs in RS:\n",
        "  X_train, X_test, X_val, y_train, y_test, y_val = get_data(\"extracted.csv\", random_state = rs)\n",
        "  model = base_model(input_shape=X_train.shape[1:], dropout_ratio=DROPOUT)\n",
        "  _ = model(X_train[:1])\n",
        "  trained_model, history = launch_training(model, X_train, y_train, X_val, y_val, lr = LEARNING_RATE, bs = BATCH_SIZE, epochs = EPOCHS, patience = PATIENCE, decay=DECAY)\n",
        "  # Make predictions on the test data\n",
        "  y_pred_probs = model.predict(X_test)\n",
        "  y_pred = np.round(y_pred_probs)\n",
        "  # Calculate accuracy score for this fold\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"random_state:{rs}, test_accuracy:{round(accuracy,3)}\")\n",
        "  cv_scores.append(accuracy)\n",
        "print('Mean CV Accuracy:', round(np.mean(cv_scores),3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "kRn6uT5IN1Fk",
        "outputId": "04516036-3874-4c6e-ce0a-e699e994e2fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"6b0b17a1-24c3-4aaf-af57-62ac21d0d3a9\" class=\"plotly-graph-div\" style=\"height:400px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b0b17a1-24c3-4aaf-af57-62ac21d0d3a9\")) {                    Plotly.newPlot(                        \"6b0b17a1-24c3-4aaf-af57-62ac21d0d3a9\",                        [{\"marker\":{\"color\":[\"blue\",\"purple\",\"blue\",\"purple\",\"blue\",\"purple\",\"blue\",\"purple\",\"blue\",\"purple\"]},\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.9,0.91,0.9,0.9,0.89,0.9,0.91,0.89,0.9,0.91],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Mean Accuracy: 0.902\",\"x\":0.5},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eAccuracy\\u003c\\u002fb\\u003e\"},\"range\":[0.7,1.0]},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eRandom State\\u003c\\u002fb\\u003e\"},\"tickmode\":\"array\",\"tickvals\":[1,2,3,4,5,6,7,8,9,10]},\"height\":400,\"width\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6b0b17a1-24c3-4aaf-af57-62ac21d0d3a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "get_cv_eval(cv_scores, RS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMoOBBWULqMw"
      },
      "source": [
        "## MODEL DE BASE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "6XsunDMMiKKM",
        "outputId": "6b322118-2160-4a37-8fe9-83b01e8e96d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 10154.59it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Accuracy: 0.919\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 0.912\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['results/history_base.joblib']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 200\n",
        "PATIENCE = 200\n",
        "DROPOUT = 0.5\n",
        "DECAY = 0.97\n",
        "RS = 1\n",
        "\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = get_data(\"extracted.csv\", random_state = RS)\n",
        "model = base_model(input_shape=X_train.shape[1:], dropout_ratio=DROPOUT)\n",
        "_ = model(X_train[:1])\n",
        "trained_model, history = launch_training(model, X_train, y_train, X_val, y_val, lr = LEARNING_RATE, bs = BATCH_SIZE, epochs = EPOCHS, patience = PATIENCE, decay=DECAY,  verbose=0)\n",
        "get_eval(trained_model, history, X_test, y_test, matrix=False)\n",
        "if not os.path.exists(\"results\"):\n",
        "  os.mkdir(\"results\")\n",
        "dump(history.history, os.path.join(\"results\",\"history_base.joblib\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvV21FGONl-q"
      },
      "source": [
        "## MODEL AMELIORÉ\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "hVi5yhLnrKLa",
        "outputId": "f5c6791e-73cc-4321-9ff0-5c3d804b8de3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 10014.92it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Accuracy: 0.936\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 0.931\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['results/history_improved.joblib']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 200\n",
        "PATIENCE = 200\n",
        "DROPOUT = 0.5\n",
        "DECAY = 0.97\n",
        "RS = 1\n",
        "\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = get_data(\"extracted.csv\", random_state = RS)\n",
        "model = improved_model(input_shape=X_train.shape[1:], dropout_ratio=DROPOUT)\n",
        "_ = model(X_train[:1])\n",
        "trained_model, history = launch_training(model, X_train, y_train, X_val, y_val, lr = LEARNING_RATE, bs = BATCH_SIZE, epochs = EPOCHS, patience = PATIENCE, decay=DECAY, verbose=0)\n",
        "get_eval(trained_model, history, X_test, y_test, matrix=False)\n",
        "if not os.path.exists(\"results\"):\n",
        "  os.mkdir(\"results\")\n",
        "dump(history.history, os.path.join(\"results\",\"history_improved.joblib\" ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy63ZDQHyZBZ"
      },
      "source": [
        "## MODEL AMELIORÉ V2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "B9NJ2aDurBaZ",
        "outputId": "65d18ae8-4027-4507-8b94-5e9c3593b974"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [00:00<00:00, 9879.54it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Accuracy: 0.949\n",
            "41/41 [==============================] - 0s 9ms/step\n",
            "Test Accuracy: 0.934\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['results/history_improved2.joblib']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 200\n",
        "PATIENCE = 200\n",
        "DROPOUT = 0.5\n",
        "DECAY = 0.97\n",
        "RS = 1\n",
        "\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = get_data(\"extracted.csv\", random_state = RS)\n",
        "model = reimproved_model(input_shape=X_train.shape[1:], dropout_ratio=DROPOUT)\n",
        "_ = model(X_train[:1])\n",
        "trained_model, history = launch_training(model, X_train, y_train, X_val, y_val, lr = LEARNING_RATE, bs = BATCH_SIZE, epochs = EPOCHS, patience = PATIENCE, decay=DECAY, verbose=0)\n",
        "get_eval(trained_model, history, X_test, y_test, matrix=False)\n",
        "if not os.path.exists(\"results\"):\n",
        "  os.mkdir(\"results\")\n",
        "dump(history.history, os.path.join(\"results\",\"history_improved2.joblib\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S0inSsz6I0m"
      },
      "source": [
        "# DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzgzQdA25Wc0",
        "outputId": "514301d0-9a66-4239-c6cc-b84dfd557abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "UrbanSound8K/audio/fold10/178261-7-3-1.wav\n",
            "UrbanSound8K/audio/fold10/189985-0-0-5.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-2.wav\n",
            "UrbanSound8K/audio/fold10/157207-6-7-0.wav\n",
            "UrbanSound8K/audio/fold10/59513-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-4.wav\n",
            "UrbanSound8K/audio/fold10/202334-9-0-137.wav\n",
            "UrbanSound8K/audio/fold10/117889-9-0-36.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-16.wav\n",
            "UrbanSound8K/audio/fold10/196127-3-0-4.wav\n",
            "UrbanSound8K/audio/fold10/195063-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/34050-7-2-0.wav\n",
            "UrbanSound8K/audio/fold10/189985-0-0-2.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-0.wav\n",
            "UrbanSound8K/audio/fold10/203424-9-0-4.wav\n",
            "UrbanSound8K/audio/fold10/178826-2-0-12.wav\n",
            "UrbanSound8K/audio/fold10/155262-2-0-58.wav\n",
            "UrbanSound8K/audio/fold10/155280-2-0-7.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-12-4.wav\n",
            "UrbanSound8K/audio/fold10/138017-9-0-9.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-11.wav\n",
            "UrbanSound8K/audio/fold10/115241-9-0-9.wav\n",
            "UrbanSound8K/audio/fold10/157207-6-9-0.wav\n",
            "UrbanSound8K/audio/fold10/187110-2-0-34.wav\n",
            "UrbanSound8K/audio/fold10/147491-9-0-5.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-4.wav\n",
            "UrbanSound8K/audio/fold10/85574-3-0-12.wav\n",
            "UrbanSound8K/audio/fold10/72538-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/200786-5-1-2.wav\n",
            "UrbanSound8K/audio/fold10/157207-6-6-0.wav\n",
            "UrbanSound8K/audio/fold10/197554-2-0-69.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-25.wav\n",
            "UrbanSound8K/audio/fold10/207213-2-0-85.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-8-6.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-0.wav\n",
            "UrbanSound8K/audio/fold10/83195-9-0-6.wav\n",
            "UrbanSound8K/audio/fold10/84249-9-0-11.wav\n",
            "UrbanSound8K/audio/fold10/197554-2-0-23.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-3-0.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-11.wav\n",
            "UrbanSound8K/audio/fold10/200786-5-1-5.wav\n",
            "UrbanSound8K/audio/fold10/83191-9-0-13.wav\n",
            "UrbanSound8K/audio/fold10/164377-9-1-43.wav\n",
            "UrbanSound8K/audio/fold10/83195-9-0-11.wav\n",
            "UrbanSound8K/audio/fold10/118558-5-2-3.wav\n",
            "UrbanSound8K/audio/fold10/202334-9-0-202.wav\n",
            "UrbanSound8K/audio/fold10/172519-9-0-10.wav\n",
            "UrbanSound8K/audio/fold10/106014-5-0-2.wav\n",
            "UrbanSound8K/audio/fold10/128470-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-17.wav\n",
            "UrbanSound8K/audio/fold10/14468-3-5-0.wav\n",
            "UrbanSound8K/audio/fold10/34050-7-5-0.wav\n",
            "UrbanSound8K/audio/fold10/164194-2-0-10.wav\n",
            "UrbanSound8K/audio/fold10/74922-4-0-5.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-6.wav\n",
            "UrbanSound8K/audio/fold10/117889-9-0-40.wav\n",
            "UrbanSound8K/audio/fold10/188497-2-0-8.wav\n",
            "UrbanSound8K/audio/fold10/155280-2-0-13.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-13.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-30.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-2-0.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-3.wav\n",
            "UrbanSound8K/audio/fold10/77927-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/165166-8-0-0.wav\n",
            "UrbanSound8K/audio/fold10/72220-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-0.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-33.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-22.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-14.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-4-0.wav\n",
            "UrbanSound8K/audio/fold10/196084-2-0-1.wav\n",
            "UrbanSound8K/audio/fold10/165640-4-0-2.wav\n",
            "UrbanSound8K/audio/fold10/164194-2-0-7.wav\n",
            "UrbanSound8K/audio/fold10/129750-2-0-3.wav\n",
            "UrbanSound8K/audio/fold10/100795-3-1-0.wav\n",
            "UrbanSound8K/audio/fold10/188497-2-0-17.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-10.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-8.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-16.wav\n",
            "UrbanSound8K/audio/fold10/197554-2-0-60.wav\n",
            "UrbanSound8K/audio/fold10/27070-2-0-3.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-17.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-10.wav\n",
            "UrbanSound8K/audio/fold10/165166-8-0-7.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-8.wav\n",
            "UrbanSound8K/audio/fold10/69661-3-0-14.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-8-0.wav\n",
            "UrbanSound8K/audio/fold10/164377-9-1-92.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-17.wav\n",
            "UrbanSound8K/audio/fold10/200460-6-0-0.wav\n",
            "UrbanSound8K/audio/fold10/84249-9-0-6.wav\n",
            "UrbanSound8K/audio/fold10/174292-6-0-0.wav\n",
            "UrbanSound8K/audio/fold10/128240-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-54.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-23.wav\n",
            "UrbanSound8K/audio/fold10/81791-3-1-0.wav\n",
            "UrbanSound8K/audio/fold10/196084-2-0-2.wav\n",
            "UrbanSound8K/audio/fold10/187863-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-8.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-13.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-11.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-5.wav\n",
            "UrbanSound8K/audio/fold10/85574-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/197554-2-0-82.wav\n",
            "UrbanSound8K/audio/fold10/84249-9-0-8.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-48.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-1.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-12.wav\n",
            "UrbanSound8K/audio/fold10/26255-3-13-1.wav\n",
            "UrbanSound8K/audio/fold10/71312-3-0-5.wav\n",
            "UrbanSound8K/audio/fold10/74922-4-0-7.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-14.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/136558-9-1-26.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-3-0.wav\n",
            "UrbanSound8K/audio/fold10/174289-6-0-0.wav\n",
            "UrbanSound8K/audio/fold10/81791-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-19.wav\n",
            "UrbanSound8K/audio/fold10/88121-8-0-0.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-38.wav\n",
            "UrbanSound8K/audio/fold10/178826-2-0-17.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-9-0.wav\n",
            "UrbanSound8K/audio/fold10/187110-2-0-1.wav\n",
            "UrbanSound8K/audio/fold10/35628-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/207213-2-0-73.wav\n",
            "UrbanSound8K/audio/fold10/164377-9-0-16.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-23.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-1.wav\n",
            "UrbanSound8K/audio/fold10/155241-9-0-56.wav\n",
            "UrbanSound8K/audio/fold10/83195-9-0-2.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-13.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-3.wav\n",
            "UrbanSound8K/audio/fold10/51024-3-0-16.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-4.wav\n",
            "UrbanSound8K/audio/fold10/101382-2-0-20.wav\n",
            "UrbanSound8K/audio/fold10/7913-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-4.wav\n",
            "UrbanSound8K/audio/fold10/118558-5-2-2.wav\n",
            "UrbanSound8K/audio/fold10/155262-2-0-2.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-2-0.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-0.wav\n",
            "UrbanSound8K/audio/fold10/203424-9-0-18.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-98.wav\n",
            "UrbanSound8K/audio/fold10/72220-3-2-2.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-8.wav\n",
            "UrbanSound8K/audio/fold10/115241-9-0-20.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-101.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-20.wav\n",
            "UrbanSound8K/audio/fold10/157207-6-1-0.wav\n",
            "UrbanSound8K/audio/fold10/164377-9-1-15.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-9-3.wav\n",
            "UrbanSound8K/audio/fold10/172519-9-0-13.wav\n",
            "UrbanSound8K/audio/fold10/72538-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-4.wav\n",
            "UrbanSound8K/audio/fold10/165640-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/196127-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/26344-4-1-0.wav\n",
            "UrbanSound8K/audio/fold10/155280-2-0-6.wav\n",
            "UrbanSound8K/audio/fold10/101382-2-0-12.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-11.wav\n",
            "UrbanSound8K/audio/fold10/164377-9-1-36.wav\n",
            "UrbanSound8K/audio/fold10/77901-9-0-4.wav\n",
            "UrbanSound8K/audio/fold10/196127-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/84249-9-0-10.wav\n",
            "UrbanSound8K/audio/fold10/165166-8-0-4.wav\n",
            "UrbanSound8K/audio/fold10/187110-2-0-30.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-7.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-4.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-13-0.wav\n",
            "UrbanSound8K/audio/fold10/66115-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-13-1.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-8.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-20.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-11-2.wav\n",
            "UrbanSound8K/audio/fold10/7965-3-11-0.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-137.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-13.wav\n",
            "UrbanSound8K/audio/fold10/14468-3-0-3.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-13-3.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-47.wav\n",
            "UrbanSound8K/audio/fold10/74922-4-0-2.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-43.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-7-0.wav\n",
            "UrbanSound8K/audio/fold10/66115-1-0-1.wav\n",
            "UrbanSound8K/audio/fold10/172519-9-0-8.wav\n",
            "UrbanSound8K/audio/fold10/147491-9-2-10.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-1-1.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-8-4.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-5-0.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-19.wav\n",
            "UrbanSound8K/audio/fold10/155262-2-0-63.wav\n",
            "UrbanSound8K/audio/fold10/72538-3-0-4.wav\n",
            "UrbanSound8K/audio/fold10/187110-2-0-10.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-1.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-12.wav\n",
            "UrbanSound8K/audio/fold10/164194-2-0-24.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-18.wav\n",
            "UrbanSound8K/audio/fold10/30344-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/188497-2-0-11.wav\n",
            "UrbanSound8K/audio/fold10/17486-3-1-0.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-30.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-8.wav\n",
            "UrbanSound8K/audio/fold10/117889-9-0-20.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-23.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-0-2.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-7.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-12.wav\n",
            "UrbanSound8K/audio/fold10/174289-6-3-0.wav\n",
            "UrbanSound8K/audio/fold10/85665-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-9.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-0.wav\n",
            "UrbanSound8K/audio/fold10/72220-3-2-4.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-13.wav\n",
            "UrbanSound8K/audio/fold10/83195-9-0-3.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-10-3.wav\n",
            "UrbanSound8K/audio/fold10/178826-2-0-20.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-26.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-3.wav\n",
            "UrbanSound8K/audio/fold10/30344-3-0-3.wav\n",
            "UrbanSound8K/audio/fold10/136558-9-1-39.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-11.wav\n",
            "UrbanSound8K/audio/fold10/14470-2-0-72.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-12-2.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-33.wav\n",
            "UrbanSound8K/audio/fold10/22973-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-12.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-4.wav\n",
            "UrbanSound8K/audio/fold10/155280-2-0-10.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-10-1.wav\n",
            "UrbanSound8K/audio/fold10/165166-8-0-2.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-3-3.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-74.wav\n",
            "UrbanSound8K/audio/fold10/101382-2-0-21.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-19.wav\n",
            "UrbanSound8K/audio/fold10/200460-6-2-0.wav\n",
            "UrbanSound8K/audio/fold10/115241-9-0-6.wav\n",
            "UrbanSound8K/audio/fold10/14468-3-1-0.wav\n",
            "UrbanSound8K/audio/fold10/102103-3-1-0.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-39.wav\n",
            "UrbanSound8K/audio/fold10/84249-9-0-3.wav\n",
            "UrbanSound8K/audio/fold10/188497-2-0-1.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-7.wav\n",
            "UrbanSound8K/audio/fold10/100795-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-9.wav\n",
            "UrbanSound8K/audio/fold10/171478-9-0-57.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-18.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-1-0.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-5.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-11.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-19.wav\n",
            "UrbanSound8K/audio/fold10/14470-2-0-4.wav\n",
            "UrbanSound8K/audio/fold10/164194-2-0-14.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-127.wav\n",
            "UrbanSound8K/audio/fold10/71312-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-13-0.wav\n",
            "UrbanSound8K/audio/fold10/155241-9-0-69.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-4.wav\n",
            "UrbanSound8K/audio/fold10/178402-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/74922-4-0-1.wav\n",
            "UrbanSound8K/audio/fold10/167750-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/7965-3-22-0.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-6.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-24.wav\n",
            "UrbanSound8K/audio/fold10/27070-2-0-2.wav\n",
            "UrbanSound8K/audio/fold10/115418-9-0-6.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-10.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-11.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-8.wav\n",
            "UrbanSound8K/audio/fold10/101382-2-0-42.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-9.wav\n",
            "UrbanSound8K/audio/fold10/155280-2-0-3.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-17.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-5.wav\n",
            "UrbanSound8K/audio/fold10/187863-4-0-1.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-1-0.wav\n",
            "UrbanSound8K/audio/fold10/128470-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-41.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-11.wav\n",
            "UrbanSound8K/audio/fold10/17486-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-6.wav\n",
            "UrbanSound8K/audio/fold10/59513-3-0-3.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-45.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-6.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-114.wav\n",
            "UrbanSound8K/audio/fold10/195063-4-1-0.wav\n",
            "UrbanSound8K/audio/fold10/209672-3-6-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-4-0.wav\n",
            "UrbanSound8K/audio/fold10/69661-3-0-23.wav\n",
            "UrbanSound8K/audio/fold10/100795-3-1-1.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-28.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-36.wav\n",
            "UrbanSound8K/audio/fold10/196127-3-0-3.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-15-0.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-2.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-9-1.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-13-4.wav\n",
            "UrbanSound8K/audio/fold10/165166-8-0-5.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-15-2.wav\n",
            "UrbanSound8K/audio/fold10/118558-5-1-0.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-11-0.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-6.wav\n",
            "UrbanSound8K/audio/fold10/178826-2-0-28.wav\n",
            "UrbanSound8K/audio/fold10/162148-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/77927-3-1-1.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-12.wav\n",
            "UrbanSound8K/audio/fold10/59513-3-0-4.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-11.wav\n",
            "UrbanSound8K/audio/fold10/199261-3-0-4.wav\n",
            "UrbanSound8K/audio/fold10/129750-2-0-48.wav\n",
            "UrbanSound8K/audio/fold10/209672-3-8-0.wav\n",
            "UrbanSound8K/audio/fold10/157207-6-0-0.wav\n",
            "UrbanSound8K/audio/fold10/117889-9-0-12.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-0.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-0-0.wav\n",
            "UrbanSound8K/audio/fold10/157207-6-4-0.wav\n",
            "UrbanSound8K/audio/fold10/41306-3-0-13.wav\n",
            "UrbanSound8K/audio/fold10/175850-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/17486-3-2-0.wav\n",
            "UrbanSound8K/audio/fold10/24076-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/167750-4-1-0.wav\n",
            "UrbanSound8K/audio/fold10/138017-9-0-2.wav\n",
            "UrbanSound8K/audio/fold10/129750-2-0-4.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-15.wav\n",
            "UrbanSound8K/audio/fold10/175842-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/14470-2-0-10.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-7.wav\n",
            "UrbanSound8K/audio/fold10/85574-3-0-2.wav\n",
            "UrbanSound8K/audio/fold10/14470-2-0-21.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-12.wav\n",
            "UrbanSound8K/audio/fold10/189985-0-0-6.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-25.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-54.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-17.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-10-3.wav\n",
            "UrbanSound8K/audio/fold10/14470-2-0-56.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-10-2.wav\n",
            "UrbanSound8K/audio/fold10/172519-9-0-67.wav\n",
            "UrbanSound8K/audio/fold10/189985-0-0-4.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-6.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-12.wav\n",
            "UrbanSound8K/audio/fold10/27070-2-0-4.wav\n",
            "UrbanSound8K/audio/fold10/118558-5-0-1.wav\n",
            "UrbanSound8K/audio/fold10/167750-4-3-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-8-0.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-7.wav\n",
            "UrbanSound8K/audio/fold10/187863-4-0-4.wav\n",
            "UrbanSound8K/audio/fold10/171478-9-0-55.wav\n",
            "UrbanSound8K/audio/fold10/165640-4-0-1.wav\n",
            "UrbanSound8K/audio/fold10/164646-6-0-0.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-105.wav\n",
            "UrbanSound8K/audio/fold10/54086-1-1-0.wav\n",
            "UrbanSound8K/audio/fold10/203424-9-0-46.wav\n",
            "UrbanSound8K/audio/fold10/88121-8-2-0.wav\n",
            "UrbanSound8K/audio/fold10/117889-9-0-39.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-26.wav\n",
            "UrbanSound8K/audio/fold10/138017-9-1-10.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-35.wav\n",
            "UrbanSound8K/audio/fold10/188497-2-0-0.wav\n",
            "UrbanSound8K/audio/fold10/77901-9-0-0.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-27.wav\n",
            "UrbanSound8K/audio/fold10/103438-5-0-1.wav\n",
            "UrbanSound8K/audio/fold10/187863-4-0-3.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-14.wav\n",
            "UrbanSound8K/audio/fold10/165166-8-0-8.wav\n",
            "UrbanSound8K/audio/fold10/54086-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-4.wav\n",
            "UrbanSound8K/audio/fold10/155280-2-0-11.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-19.wav\n",
            "UrbanSound8K/audio/fold10/83191-9-0-4.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-63.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-7-0.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-3.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-0-1.wav\n",
            "UrbanSound8K/audio/fold10/165166-8-0-3.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-21.wav\n",
            "UrbanSound8K/audio/fold10/83191-9-0-17.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-6.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-2.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-3.wav\n",
            "UrbanSound8K/audio/fold10/74922-4-0-3.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-6.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-15-1.wav\n",
            "UrbanSound8K/audio/fold10/178826-2-0-16.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-9.wav\n",
            "UrbanSound8K/audio/fold10/200786-5-1-1.wav\n",
            "UrbanSound8K/audio/fold10/115241-9-0-8.wav\n",
            "UrbanSound8K/audio/fold10/199261-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/172519-9-0-49.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-2.wav\n",
            "UrbanSound8K/audio/fold10/188497-2-0-23.wav\n",
            "UrbanSound8K/audio/fold10/27070-2-0-5.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-3.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-99.wav\n",
            "UrbanSound8K/audio/fold10/129750-2-0-37.wav\n",
            "UrbanSound8K/audio/fold10/171478-9-0-4.wav\n",
            "UrbanSound8K/audio/fold10/41306-3-0-4.wav\n",
            "UrbanSound8K/audio/fold10/157207-6-2-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-9-4.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-6.wav\n",
            "UrbanSound8K/audio/fold10/27070-2-0-0.wav\n",
            "UrbanSound8K/audio/fold10/200786-5-1-4.wav\n",
            "UrbanSound8K/audio/fold10/34050-7-0-0.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-16.wav\n",
            "UrbanSound8K/audio/fold10/147491-9-2-25.wav\n",
            "UrbanSound8K/audio/fold10/115418-9-0-20.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-2.wav\n",
            "UrbanSound8K/audio/fold10/22973-3-0-2.wav\n",
            "UrbanSound8K/audio/fold10/26255-3-8-0.wav\n",
            "UrbanSound8K/audio/fold10/155262-2-0-48.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-11-4.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-9.wav\n",
            "UrbanSound8K/audio/fold10/187863-4-0-5.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-18.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-7.wav\n",
            "UrbanSound8K/audio/fold10/72538-3-0-3.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-20.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-1.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-5.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-23.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-24.wav\n",
            "UrbanSound8K/audio/fold10/88121-8-0-2.wav\n",
            "UrbanSound8K/audio/fold10/77927-3-0-2.wav\n",
            "UrbanSound8K/audio/fold10/100795-3-1-2.wav\n",
            "UrbanSound8K/audio/fold10/174289-6-2-0.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-12.wav\n",
            "UrbanSound8K/audio/fold10/115418-9-0-15.wav\n",
            "UrbanSound8K/audio/fold10/83195-9-0-7.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-14-0.wav\n",
            "UrbanSound8K/audio/fold10/197554-2-0-74.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-9-0.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-20.wav\n",
            "UrbanSound8K/audio/fold10/155280-2-0-5.wav\n",
            "UrbanSound8K/audio/fold10/208652-8-4-0.wav\n",
            "UrbanSound8K/audio/fold10/7913-3-1-0.wav\n",
            "UrbanSound8K/audio/fold10/51024-3-0-23.wav\n",
            "UrbanSound8K/audio/fold10/200786-5-1-0.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-10.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-3.wav\n",
            "UrbanSound8K/audio/fold10/189985-0-0-0.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-21.wav\n",
            "UrbanSound8K/audio/fold10/14468-3-0-2.wav\n",
            "UrbanSound8K/audio/fold10/207213-2-0-109.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-11-3.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-11.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-92.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-1-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-9-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-17-2.wav\n",
            "UrbanSound8K/audio/fold10/115418-9-0-29.wav\n",
            "UrbanSound8K/audio/fold10/208652-8-2-0.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-15.wav\n",
            "UrbanSound8K/audio/fold10/115418-9-0-11.wav\n",
            "UrbanSound8K/audio/fold10/171478-9-0-26.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-13.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-3-0.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-3-0.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-3-6.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-52.wav\n",
            "UrbanSound8K/audio/fold10/179868-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/207213-2-0-81.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-7-1.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-52.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-5.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-8-0.wav\n",
            "UrbanSound8K/audio/fold10/203424-9-0-26.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-10-1.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-1.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-12-3.wav\n",
            "UrbanSound8K/audio/fold10/155262-2-0-101.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-11-6.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-17.wav\n",
            "UrbanSound8K/audio/fold10/178826-2-0-14.wav\n",
            "UrbanSound8K/audio/fold10/118278-4-0-6.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-10.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-10.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-1-0.wav\n",
            "UrbanSound8K/audio/fold10/157800-6-0-0.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-3-2.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-15.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-10.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-40.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-5.wav\n",
            "UrbanSound8K/audio/fold10/115241-9-0-1.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-14-1.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-17-4.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-23.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-14-2.wav\n",
            "UrbanSound8K/audio/fold10/136558-9-0-1.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-5.wav\n",
            "UrbanSound8K/audio/fold10/25037-6-1-0.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-5.wav\n",
            "UrbanSound8K/audio/fold10/11722-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/74922-4-0-4.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-1.wav\n",
            "UrbanSound8K/audio/fold10/174292-6-2-0.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-6.wav\n",
            "UrbanSound8K/audio/fold10/118558-5-2-0.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-2-0.wav\n",
            "UrbanSound8K/audio/fold10/188497-2-0-2.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-2.wav\n",
            "UrbanSound8K/audio/fold10/118558-5-1-1.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-12-1.wav\n",
            "UrbanSound8K/audio/fold10/174292-6-1-0.wav\n",
            "UrbanSound8K/audio/fold10/128240-3-0-39.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-6-0.wav\n",
            "UrbanSound8K/audio/fold10/164194-2-0-11.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-15.wav\n",
            "UrbanSound8K/audio/fold10/165166-8-0-1.wav\n",
            "UrbanSound8K/audio/fold10/207213-2-0-52.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-30.wav\n",
            "UrbanSound8K/audio/fold10/196086-2-0-0.wav\n",
            "UrbanSound8K/audio/fold10/83191-9-0-11.wav\n",
            "UrbanSound8K/audio/fold10/141240-5-0-0.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-7.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-10-0.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-18.wav\n",
            "UrbanSound8K/audio/fold10/51024-3-0-2.wav\n",
            "UrbanSound8K/audio/fold10/88121-8-0-3.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-12.wav\n",
            "UrbanSound8K/audio/fold10/77901-9-0-3.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-7.wav\n",
            "UrbanSound8K/audio/fold10/77901-9-0-6.wav\n",
            "UrbanSound8K/audio/fold10/71312-3-0-2.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-10-0.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-0-0.wav\n",
            "UrbanSound8K/audio/fold10/199261-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-1.wav\n",
            "UrbanSound8K/audio/fold10/208652-8-0-0.wav\n",
            "UrbanSound8K/audio/fold10/200786-5-1-3.wav\n",
            "UrbanSound8K/audio/fold10/100648-1-4-0.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-44.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-133.wav\n",
            "UrbanSound8K/audio/fold10/14470-2-0-70.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-6.wav\n",
            "UrbanSound8K/audio/fold10/136558-9-1-21.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-4.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-8.wav\n",
            "UrbanSound8K/audio/fold10/171478-9-0-58.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-17-1.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-18.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-0-0.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-53.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-113.wav\n",
            "UrbanSound8K/audio/fold10/171478-9-0-38.wav\n",
            "UrbanSound8K/audio/fold10/119067-0-0-2.wav\n",
            "UrbanSound8K/audio/fold10/30344-3-0-4.wav\n",
            "UrbanSound8K/audio/fold10/7913-3-3-0.wav\n",
            "UrbanSound8K/audio/fold10/20571-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-1-0.wav\n",
            "UrbanSound8K/audio/fold10/11722-3-1-0.wav\n",
            "UrbanSound8K/audio/fold10/136558-9-1-10.wav\n",
            "UrbanSound8K/audio/fold10/200460-6-1-0.wav\n",
            "UrbanSound8K/audio/fold10/155262-2-0-21.wav\n",
            "UrbanSound8K/audio/fold10/100648-1-1-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-10-2.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-9-2.wav\n",
            "UrbanSound8K/audio/fold10/88121-8-1-0.wav\n",
            "UrbanSound8K/audio/fold10/83195-9-0-14.wav\n",
            "UrbanSound8K/audio/fold10/129750-2-0-45.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-27.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-4-0.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-3.wav\n",
            "UrbanSound8K/audio/fold10/202334-9-0-88.wav\n",
            "UrbanSound8K/audio/fold10/197554-2-0-3.wav\n",
            "UrbanSound8K/audio/fold10/100648-1-3-0.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-17.wav\n",
            "UrbanSound8K/audio/fold10/207213-2-0-130.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-4.wav\n",
            "UrbanSound8K/audio/fold10/106014-5-0-0.wav\n",
            "UrbanSound8K/audio/fold10/138017-9-1-4.wav\n",
            "UrbanSound8K/audio/fold10/141240-5-1-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-5-0.wav\n",
            "UrbanSound8K/audio/fold10/187110-2-0-8.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-3.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-27.wav\n",
            "UrbanSound8K/audio/fold10/155241-9-0-8.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-42.wav\n",
            "UrbanSound8K/audio/fold10/174289-6-1-0.wav\n",
            "UrbanSound8K/audio/fold10/102103-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/164194-2-0-26.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-3.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-1.wav\n",
            "UrbanSound8K/audio/fold10/27070-2-0-8.wav\n",
            "UrbanSound8K/audio/fold10/142641-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-16.wav\n",
            "UrbanSound8K/audio/fold10/147491-9-0-0.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-8.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-1.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-8-5.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-0.wav\n",
            "UrbanSound8K/audio/fold10/83191-9-0-6.wav\n",
            "UrbanSound8K/audio/fold10/146244-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-16.wav\n",
            "UrbanSound8K/audio/fold10/26173-8-0-0.wav\n",
            "UrbanSound8K/audio/fold10/129750-2-0-36.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-24.wav\n",
            "UrbanSound8K/audio/fold10/7965-3-16-0.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-4.wav\n",
            "UrbanSound8K/audio/fold10/157207-6-8-0.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-5-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-13-2.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-12.wav\n",
            "UrbanSound8K/audio/fold10/196069-2-0-0.wav\n",
            "UrbanSound8K/audio/fold10/180127-4-0-10.wav\n",
            "UrbanSound8K/audio/fold10/26344-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-7-0.wav\n",
            "UrbanSound8K/audio/fold10/20571-3-1-0.wav\n",
            "UrbanSound8K/audio/fold10/115241-9-0-2.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-24.wav\n",
            "UrbanSound8K/audio/fold10/100648-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/155280-2-0-15.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-28.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-2.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-7.wav\n",
            "UrbanSound8K/audio/fold10/41306-3-0-10.wav\n",
            "UrbanSound8K/audio/fold10/84249-9-0-7.wav\n",
            "UrbanSound8K/audio/fold10/178826-2-0-10.wav\n",
            "UrbanSound8K/audio/fold10/147491-9-2-6.wav\n",
            "UrbanSound8K/audio/fold10/17124-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-2.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-8-1.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-11.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-5.wav\n",
            "UrbanSound8K/audio/fold10/39847-5-0-12.wav\n",
            "UrbanSound8K/audio/fold10/129750-2-0-34.wav\n",
            "UrbanSound8K/audio/fold10/115418-9-0-12.wav\n",
            "UrbanSound8K/audio/fold10/7913-3-2-0.wav\n",
            "UrbanSound8K/audio/fold10/138017-9-1-16.wav\n",
            "UrbanSound8K/audio/fold10/119067-0-0-1.wav\n",
            "UrbanSound8K/audio/fold10/155241-9-0-79.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-1-0.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-73.wav\n",
            "UrbanSound8K/audio/fold10/171478-9-0-28.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-1.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-17.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-49.wav\n",
            "UrbanSound8K/audio/fold10/163459-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/164194-2-0-18.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-9.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-13.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-22.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-8.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-8-2.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-13.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-128.wav\n",
            "UrbanSound8K/audio/fold10/106014-5-0-4.wav\n",
            "UrbanSound8K/audio/fold10/54086-1-2-0.wav\n",
            "UrbanSound8K/audio/fold10/69661-3-0-29.wav\n",
            "UrbanSound8K/audio/fold10/200460-6-3-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-17-0.wav\n",
            "UrbanSound8K/audio/fold10/74922-4-0-6.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-15-3.wav\n",
            "UrbanSound8K/audio/fold10/200786-5-0-0.wav\n",
            "UrbanSound8K/audio/fold10/14470-2-0-14.wav\n",
            "UrbanSound8K/audio/fold10/208652-8-6-0.wav\n",
            "UrbanSound8K/audio/fold10/159709-6-0-0.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-21.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-15.wav\n",
            "UrbanSound8K/audio/fold10/101382-2-0-33.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/7965-3-3-0.wav\n",
            "UrbanSound8K/audio/fold10/17074-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/7062-6-0-0.wav\n",
            "UrbanSound8K/audio/fold10/200460-6-5-0.wav\n",
            "UrbanSound8K/audio/fold10/197554-2-0-28.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-0.wav\n",
            "UrbanSound8K/audio/fold10/59513-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/28808-1-0-8.wav\n",
            "UrbanSound8K/audio/fold10/187863-4-0-2.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-11-0.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-14.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-19.wav\n",
            "UrbanSound8K/audio/fold10/115241-9-0-14.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-18.wav\n",
            "UrbanSound8K/audio/fold10/97756-3-0-0.wav\n",
            "UrbanSound8K/audio/fold10/138017-9-1-6.wav\n",
            "UrbanSound8K/audio/fold10/34050-7-6-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-11-1.wav\n",
            "UrbanSound8K/audio/fold10/117889-9-0-30.wav\n",
            "UrbanSound8K/audio/fold10/99192-4-0-32.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-0-0.wav\n",
            "UrbanSound8K/audio/fold10/15544-5-0-2.wav\n",
            "UrbanSound8K/audio/fold10/83191-9-0-0.wav\n",
            "UrbanSound8K/audio/fold10/74364-8-1-15.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-13.wav\n",
            "UrbanSound8K/audio/fold10/30344-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/71312-3-0-4.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-9.wav\n",
            "UrbanSound8K/audio/fold10/181624-4-6-0.wav\n",
            "UrbanSound8K/audio/fold10/197554-2-0-26.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-16-0.wav\n",
            "UrbanSound8K/audio/fold10/83502-0-0-9.wav\n",
            "UrbanSound8K/audio/fold10/202334-9-0-63.wav\n",
            "UrbanSound8K/audio/fold10/119067-0-0-0.wav\n",
            "UrbanSound8K/audio/fold10/187110-2-0-6.wav\n",
            "UrbanSound8K/audio/fold10/178826-2-0-39.wav\n",
            "UrbanSound8K/audio/fold10/101382-2-0-29.wav\n",
            "UrbanSound8K/audio/fold10/203424-9-0-15.wav\n",
            "UrbanSound8K/audio/fold10/103438-5-0-0.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-6-0.wav\n",
            "UrbanSound8K/audio/fold10/189982-0-0-28.wav\n",
            "UrbanSound8K/audio/fold10/159742-8-0-5.wav\n",
            "UrbanSound8K/audio/fold10/27070-2-0-7.wav\n",
            "UrbanSound8K/audio/fold10/34050-7-4-0.wav\n",
            "UrbanSound8K/audio/fold10/85574-3-0-8.wav\n",
            "UrbanSound8K/audio/fold10/118558-5-2-1.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-7.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-3-4.wav\n",
            "UrbanSound8K/audio/fold10/167750-4-2-0.wav\n",
            "UrbanSound8K/audio/fold10/77927-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/73524-0-0-126.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-2-0.wav\n",
            "UrbanSound8K/audio/fold10/93567-8-0-19.wav\n",
            "UrbanSound8K/audio/fold10/188813-7-11-1.wav\n",
            "UrbanSound8K/audio/fold10/199261-3-0-2.wav\n",
            "UrbanSound8K/audio/fold10/2937-1-0-0.wav\n",
            "UrbanSound8K/audio/fold10/34050-7-1-0.wav\n",
            "UrbanSound8K/audio/fold10/118558-5-1-2.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-9.wav\n",
            "UrbanSound8K/audio/fold10/155262-2-0-15.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-12-0.wav\n",
            "UrbanSound8K/audio/fold10/14470-2-0-65.wav\n",
            "UrbanSound8K/audio/fold10/102857-5-0-29.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-10-0.wav\n",
            "UrbanSound8K/audio/fold10/162134-7-8-7.wav\n",
            "UrbanSound8K/audio/fold10/167464-0-0-14.wav\n",
            "UrbanSound8K/audio/fold10/81791-3-0-1.wav\n",
            "UrbanSound8K/audio/fold10/178261-7-3-5.wav\n",
            "UrbanSound8K/audio/fold3/15356-2-0-2.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-3-0.wav\n",
            "UrbanSound8K/audio/fold3/162431-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-4.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-6-1.wav\n",
            "UrbanSound8K/audio/fold3/88569-2-0-14.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-4.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-3.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-36.wav\n",
            "UrbanSound8K/audio/fold3/186334-2-0-36.wav\n",
            "UrbanSound8K/audio/fold3/77769-9-0-0.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-72.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-11.wav\n",
            "UrbanSound8K/audio/fold3/123399-2-0-91.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-11.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-25.wav\n",
            "UrbanSound8K/audio/fold3/18594-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-2-0.wav\n",
            "UrbanSound8K/audio/fold3/151149-2-0-3.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-49.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-7.wav\n",
            "UrbanSound8K/audio/fold3/138473-9-0-38.wav\n",
            "UrbanSound8K/audio/fold3/9223-2-0-10.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-13.wav\n",
            "UrbanSound8K/audio/fold3/42097-7-0-2.wav\n",
            "UrbanSound8K/audio/fold3/72537-3-0-2.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-4.wav\n",
            "UrbanSound8K/audio/fold3/117072-3-0-19.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-3-0.wav\n",
            "UrbanSound8K/audio/fold3/185373-9-1-70.wav\n",
            "UrbanSound8K/audio/fold3/169044-2-0-25.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-11.wav\n",
            "UrbanSound8K/audio/fold3/34708-6-2-0.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-8.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-2.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-31.wav\n",
            "UrbanSound8K/audio/fold3/61791-9-1-42.wav\n",
            "UrbanSound8K/audio/fold3/161195-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/76221-2-0-5.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-0.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-1.wav\n",
            "UrbanSound8K/audio/fold3/54067-2-0-60.wav\n",
            "UrbanSound8K/audio/fold3/34708-6-5-0.wav\n",
            "UrbanSound8K/audio/fold3/176783-3-1-0.wav\n",
            "UrbanSound8K/audio/fold3/155263-2-0-57.wav\n",
            "UrbanSound8K/audio/fold3/9223-2-0-9.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-1.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-211.wav\n",
            "UrbanSound8K/audio/fold3/93065-9-0-7.wav\n",
            "UrbanSound8K/audio/fold3/186334-2-0-35.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-7.wav\n",
            "UrbanSound8K/audio/fold3/180057-9-0-7.wav\n",
            "UrbanSound8K/audio/fold3/184623-8-0-2.wav\n",
            "UrbanSound8K/audio/fold3/17973-2-0-22.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-26.wav\n",
            "UrbanSound8K/audio/fold3/160093-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/95562-4-1-0.wav\n",
            "UrbanSound8K/audio/fold3/116400-3-1-1.wav\n",
            "UrbanSound8K/audio/fold3/34708-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-8.wav\n",
            "UrbanSound8K/audio/fold3/20841-3-3-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-8-1.wav\n",
            "UrbanSound8K/audio/fold3/165786-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/207124-3-1-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-5-0.wav\n",
            "UrbanSound8K/audio/fold3/170015-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-9-0.wav\n",
            "UrbanSound8K/audio/fold3/49769-5-1-0.wav\n",
            "UrbanSound8K/audio/fold3/200161-3-7-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-11.wav\n",
            "UrbanSound8K/audio/fold3/77769-9-0-2.wav\n",
            "UrbanSound8K/audio/fold3/49809-3-3-0.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-3.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-4.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-2.wav\n",
            "UrbanSound8K/audio/fold3/179386-3-0-2.wav\n",
            "UrbanSound8K/audio/fold3/132855-2-0-41.wav\n",
            "UrbanSound8K/audio/fold3/76221-2-0-4.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-53.wav\n",
            "UrbanSound8K/audio/fold3/107228-5-0-1.wav\n",
            "UrbanSound8K/audio/fold3/61791-9-1-46.wav\n",
            "UrbanSound8K/audio/fold3/125523-3-0-3.wav\n",
            "UrbanSound8K/audio/fold3/33696-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/18594-1-3-0.wav\n",
            "UrbanSound8K/audio/fold3/123399-2-0-5.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-8.wav\n",
            "UrbanSound8K/audio/fold3/94631-9-1-2.wav\n",
            "UrbanSound8K/audio/fold3/176783-3-0-3.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-6-0.wav\n",
            "UrbanSound8K/audio/fold3/76221-2-0-0.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-80.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-25.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-46.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-9-0.wav\n",
            "UrbanSound8K/audio/fold3/19496-3-1-1.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-13.wav\n",
            "UrbanSound8K/audio/fold3/93065-9-0-17.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-1.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-8.wav\n",
            "UrbanSound8K/audio/fold3/180057-9-0-5.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-22.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-34.wav\n",
            "UrbanSound8K/audio/fold3/95562-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/90014-8-0-4.wav\n",
            "UrbanSound8K/audio/fold3/184725-3-0-5.wav\n",
            "UrbanSound8K/audio/fold3/174840-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/18594-1-4-0.wav\n",
            "UrbanSound8K/audio/fold3/42937-4-0-1.wav\n",
            "UrbanSound8K/audio/fold3/9223-2-0-4.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-55.wav\n",
            "UrbanSound8K/audio/fold3/58857-2-0-16.wav\n",
            "UrbanSound8K/audio/fold3/93065-9-0-12.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-53.wav\n",
            "UrbanSound8K/audio/fold3/172315-9-0-203.wav\n",
            "UrbanSound8K/audio/fold3/90014-8-0-2.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-4.wav\n",
            "UrbanSound8K/audio/fold3/78326-9-0-6.wav\n",
            "UrbanSound8K/audio/fold3/93065-9-0-4.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-0-3.wav\n",
            "UrbanSound8K/audio/fold3/72537-3-0-6.wav\n",
            "UrbanSound8K/audio/fold3/41372-3-0-39.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-2-1.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-12.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-1-4.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-12.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-4.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-20.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-5.wav\n",
            "UrbanSound8K/audio/fold3/123399-2-0-54.wav\n",
            "UrbanSound8K/audio/fold3/88569-2-0-36.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-5.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-6.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-8.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-39.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-15-0.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-2-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-1-0.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-4-0.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-43.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-17-1.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-4-0.wav\n",
            "UrbanSound8K/audio/fold3/82811-3-0-2.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-6.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-20.wav\n",
            "UrbanSound8K/audio/fold3/107228-5-0-7.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-6.wav\n",
            "UrbanSound8K/audio/fold3/200161-3-6-0.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-6-0.wav\n",
            "UrbanSound8K/audio/fold3/78776-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/9674-1-0-1.wav\n",
            "UrbanSound8K/audio/fold3/132855-2-0-90.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-27.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-2.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-14.wav\n",
            "UrbanSound8K/audio/fold3/180057-9-0-36.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-2-3.wav\n",
            "UrbanSound8K/audio/fold3/186339-9-0-1.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-2.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-15.wav\n",
            "UrbanSound8K/audio/fold3/37560-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-7.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-6-1.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-1.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-0-2.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-2.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-2.wav\n",
            "UrbanSound8K/audio/fold3/155263-2-0-34.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/155263-2-0-12.wav\n",
            "UrbanSound8K/audio/fold3/176783-3-0-11.wav\n",
            "UrbanSound8K/audio/fold3/41372-3-0-36.wav\n",
            "UrbanSound8K/audio/fold3/197074-3-0-6.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-4.wav\n",
            "UrbanSound8K/audio/fold3/6988-5-0-5.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-29.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-6.wav\n",
            "UrbanSound8K/audio/fold3/151149-2-0-56.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-5-1.wav\n",
            "UrbanSound8K/audio/fold3/73373-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-32.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-52.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-5.wav\n",
            "UrbanSound8K/audio/fold3/148838-6-1-0.wav\n",
            "UrbanSound8K/audio/fold3/162431-6-3-0.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-10.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-7.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-2.wav\n",
            "UrbanSound8K/audio/fold3/18594-1-2-0.wav\n",
            "UrbanSound8K/audio/fold3/132855-2-0-113.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-3.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-204.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-10.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-17.wav\n",
            "UrbanSound8K/audio/fold3/117048-3-0-25.wav\n",
            "UrbanSound8K/audio/fold3/132855-2-0-77.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-12-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-5-1.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-16.wav\n",
            "UrbanSound8K/audio/fold3/74810-9-0-32.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-53.wav\n",
            "UrbanSound8K/audio/fold3/17973-2-0-17.wav\n",
            "UrbanSound8K/audio/fold3/155227-9-0-23.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-9.wav\n",
            "UrbanSound8K/audio/fold3/180057-9-0-11.wav\n",
            "UrbanSound8K/audio/fold3/180960-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-3.wav\n",
            "UrbanSound8K/audio/fold3/123399-2-0-83.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-9.wav\n",
            "UrbanSound8K/audio/fold3/78326-9-0-5.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-24.wav\n",
            "UrbanSound8K/audio/fold3/93065-9-0-14.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-1.wav\n",
            "UrbanSound8K/audio/fold3/58806-0-0-0.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-2.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-12-0.wav\n",
            "UrbanSound8K/audio/fold3/33696-3-4-1.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-14.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-4.wav\n",
            "UrbanSound8K/audio/fold3/117072-3-0-8.wav\n",
            "UrbanSound8K/audio/fold3/42937-4-0-2.wav\n",
            "UrbanSound8K/audio/fold3/54067-2-0-48.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-23.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-3.wav\n",
            "UrbanSound8K/audio/fold3/49485-9-0-24.wav\n",
            "UrbanSound8K/audio/fold3/132855-2-0-88.wav\n",
            "UrbanSound8K/audio/fold3/54067-2-0-80.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-7.wav\n",
            "UrbanSound8K/audio/fold3/156418-3-1-0.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-1.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-1-1.wav\n",
            "UrbanSound8K/audio/fold3/78326-9-0-7.wav\n",
            "UrbanSound8K/audio/fold3/185801-4-0-1.wav\n",
            "UrbanSound8K/audio/fold3/6988-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-7-0.wav\n",
            "UrbanSound8K/audio/fold3/148838-6-2-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-49.wav\n",
            "UrbanSound8K/audio/fold3/172315-9-0-105.wav\n",
            "UrbanSound8K/audio/fold3/61791-9-1-1.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-12.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-28.wav\n",
            "UrbanSound8K/audio/fold3/156418-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-8.wav\n",
            "UrbanSound8K/audio/fold3/58857-2-0-10.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-11-0.wav\n",
            "UrbanSound8K/audio/fold3/153261-0-0-0.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-15.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-41.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-6-0.wav\n",
            "UrbanSound8K/audio/fold3/93065-9-0-2.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-36.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-8-0.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-4.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-5-0.wav\n",
            "UrbanSound8K/audio/fold3/98681-9-0-0.wav\n",
            "UrbanSound8K/audio/fold3/175854-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/88569-2-0-85.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-12.wav\n",
            "UrbanSound8K/audio/fold3/58857-2-0-12.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-33.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-3.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-7-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-38.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-40.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-17.wav\n",
            "UrbanSound8K/audio/fold3/17973-2-0-9.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-12.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-8.wav\n",
            "UrbanSound8K/audio/fold3/155227-9-0-20.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-14.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-35.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-20.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-10.wav\n",
            "UrbanSound8K/audio/fold3/65750-3-3-68.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-33.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-27.wav\n",
            "UrbanSound8K/audio/fold3/172315-9-0-211.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-5.wav\n",
            "UrbanSound8K/audio/fold3/144885-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-9.wav\n",
            "UrbanSound8K/audio/fold3/20841-3-2-0.wav\n",
            "UrbanSound8K/audio/fold3/17973-2-0-31.wav\n",
            "UrbanSound8K/audio/fold3/6988-5-0-2.wav\n",
            "UrbanSound8K/audio/fold3/118070-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-5.wav\n",
            "UrbanSound8K/audio/fold3/116400-3-1-2.wav\n",
            "UrbanSound8K/audio/fold3/138473-9-0-12.wav\n",
            "UrbanSound8K/audio/fold3/9223-2-0-15.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-164.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-13.wav\n",
            "UrbanSound8K/audio/fold3/117048-3-0-35.wav\n",
            "UrbanSound8K/audio/fold3/74810-9-0-27.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-178.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-9.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-33.wav\n",
            "UrbanSound8K/audio/fold3/156418-3-2-0.wav\n",
            "UrbanSound8K/audio/fold3/19338-5-3-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-14-0.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-3.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-69.wav\n",
            "UrbanSound8K/audio/fold3/78326-9-0-0.wav\n",
            "UrbanSound8K/audio/fold3/186334-2-0-20.wav\n",
            "UrbanSound8K/audio/fold3/37560-4-0-2.wav\n",
            "UrbanSound8K/audio/fold3/121528-8-1-1.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-8.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-51.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-17.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-0.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-58.wav\n",
            "UrbanSound8K/audio/fold3/32318-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-7.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-9-0.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-19.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-8.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-55.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-6.wav\n",
            "UrbanSound8K/audio/fold3/52077-3-0-17.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-7-2.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-10-1.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-9.wav\n",
            "UrbanSound8K/audio/fold3/117072-3-0-14.wav\n",
            "UrbanSound8K/audio/fold3/179863-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-0-1.wav\n",
            "UrbanSound8K/audio/fold3/17615-3-0-4.wav\n",
            "UrbanSound8K/audio/fold3/123399-2-0-22.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-0-6.wav\n",
            "UrbanSound8K/audio/fold3/95562-4-3-1.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-46.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-35.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-10.wav\n",
            "UrbanSound8K/audio/fold3/155309-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-0.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-1.wav\n",
            "UrbanSound8K/audio/fold3/94631-9-0-16.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-34.wav\n",
            "UrbanSound8K/audio/fold3/32417-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/184725-3-0-4.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-8-2.wav\n",
            "UrbanSound8K/audio/fold3/9223-2-0-17.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-5.wav\n",
            "UrbanSound8K/audio/fold3/34708-6-3-0.wav\n",
            "UrbanSound8K/audio/fold3/65750-3-0-5.wav\n",
            "UrbanSound8K/audio/fold3/186334-2-0-44.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-3.wav\n",
            "UrbanSound8K/audio/fold3/17615-3-0-3.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-23.wav\n",
            "UrbanSound8K/audio/fold3/169044-2-0-13.wav\n",
            "UrbanSound8K/audio/fold3/6988-5-0-1.wav\n",
            "UrbanSound8K/audio/fold3/185801-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-10.wav\n",
            "UrbanSound8K/audio/fold3/186339-9-0-12.wav\n",
            "UrbanSound8K/audio/fold3/37560-4-0-1.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-44.wav\n",
            "UrbanSound8K/audio/fold3/110622-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-1.wav\n",
            "UrbanSound8K/audio/fold3/155227-9-0-27.wav\n",
            "UrbanSound8K/audio/fold3/179386-3-0-1.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-10.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-45.wav\n",
            "UrbanSound8K/audio/fold3/9674-1-0-2.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-14.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-1-0.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-111.wav\n",
            "UrbanSound8K/audio/fold3/153261-0-0-1.wav\n",
            "UrbanSound8K/audio/fold3/155263-2-0-61.wav\n",
            "UrbanSound8K/audio/fold3/76094-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-8.wav\n",
            "UrbanSound8K/audio/fold3/44831-3-1-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-2-0.wav\n",
            "UrbanSound8K/audio/fold3/58857-2-0-7.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-39.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-11.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-8-0.wav\n",
            "UrbanSound8K/audio/fold3/185801-4-0-2.wav\n",
            "UrbanSound8K/audio/fold3/9674-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-7-0.wav\n",
            "UrbanSound8K/audio/fold3/17615-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/186334-2-0-1.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-6.wav\n",
            "UrbanSound8K/audio/fold3/33696-3-6-1.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-29.wav\n",
            "UrbanSound8K/audio/fold3/41372-3-0-25.wav\n",
            "UrbanSound8K/audio/fold3/15356-2-0-4.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-2-1.wav\n",
            "UrbanSound8K/audio/fold3/186336-9-0-2.wav\n",
            "UrbanSound8K/audio/fold3/17615-3-0-6.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-4.wav\n",
            "UrbanSound8K/audio/fold3/49769-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-10.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-47.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-27.wav\n",
            "UrbanSound8K/audio/fold3/185375-9-0-61.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-5.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-62.wav\n",
            "UrbanSound8K/audio/fold3/49485-9-0-138.wav\n",
            "UrbanSound8K/audio/fold3/185375-9-0-23.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-10.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-14.wav\n",
            "UrbanSound8K/audio/fold3/176783-3-0-5.wav\n",
            "UrbanSound8K/audio/fold3/20841-3-6-0.wav\n",
            "UrbanSound8K/audio/fold3/196083-2-0-0.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-5.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-3.wav\n",
            "UrbanSound8K/audio/fold3/19338-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-20.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-1.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-14.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-13.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-7.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-0.wav\n",
            "UrbanSound8K/audio/fold3/76221-2-0-3.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-4-0.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-10-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-4.wav\n",
            "UrbanSound8K/audio/fold3/90846-8-0-0.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-6.wav\n",
            "UrbanSound8K/audio/fold3/186336-9-0-4.wav\n",
            "UrbanSound8K/audio/fold3/14115-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-1-0.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-18.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-6-0.wav\n",
            "UrbanSound8K/audio/fold3/94631-9-1-16.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-16.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-64.wav\n",
            "UrbanSound8K/audio/fold3/112075-5-0-1.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-13-0.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-149.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-21.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-33.wav\n",
            "UrbanSound8K/audio/fold3/58857-2-0-25.wav\n",
            "UrbanSound8K/audio/fold3/18594-1-5-0.wav\n",
            "UrbanSound8K/audio/fold3/185373-9-0-21.wav\n",
            "UrbanSound8K/audio/fold3/118961-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/90014-8-0-0.wav\n",
            "UrbanSound8K/audio/fold3/125523-3-0-1.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-17.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-31.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-15.wav\n",
            "UrbanSound8K/audio/fold3/200161-3-6-3.wav\n",
            "UrbanSound8K/audio/fold3/49485-9-0-28.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-14.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-18.wav\n",
            "UrbanSound8K/audio/fold3/90014-8-0-3.wav\n",
            "UrbanSound8K/audio/fold3/138473-9-0-6.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-15.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-12.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-4-0.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-99.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-5.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-81.wav\n",
            "UrbanSound8K/audio/fold3/58857-2-0-8.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-9.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-3.wav\n",
            "UrbanSound8K/audio/fold3/155263-2-0-22.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-1.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-29.wav\n",
            "UrbanSound8K/audio/fold3/94631-9-1-3.wav\n",
            "UrbanSound8K/audio/fold3/180057-9-0-34.wav\n",
            "UrbanSound8K/audio/fold3/94631-9-1-25.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-28.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-0.wav\n",
            "UrbanSound8K/audio/fold3/37560-4-0-4.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-84.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-1-0.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-17.wav\n",
            "UrbanSound8K/audio/fold3/52077-3-0-3.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-11-0.wav\n",
            "UrbanSound8K/audio/fold3/184623-8-0-1.wav\n",
            "UrbanSound8K/audio/fold3/95562-4-3-0.wav\n",
            "UrbanSound8K/audio/fold3/185373-9-1-7.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-16.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-5-2.wav\n",
            "UrbanSound8K/audio/fold3/82811-3-3-0.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-8.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-61.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-18.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-12.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-0-1.wav\n",
            "UrbanSound8K/audio/fold3/172315-9-0-212.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-6.wav\n",
            "UrbanSound8K/audio/fold3/186339-9-0-3.wav\n",
            "UrbanSound8K/audio/fold3/77769-9-0-8.wav\n",
            "UrbanSound8K/audio/fold3/98681-9-0-11.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-10.wav\n",
            "UrbanSound8K/audio/fold3/155263-2-0-50.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-84.wav\n",
            "UrbanSound8K/audio/fold3/151359-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-7.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-1-0.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-1-2.wav\n",
            "UrbanSound8K/audio/fold3/63292-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-27.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-1-0.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-11-0.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-58.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-10-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-42.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-37.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-16.wav\n",
            "UrbanSound8K/audio/fold3/196073-2-0-0.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-7.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-9.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-73.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-44.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-14.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-2.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-6.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-2.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-27.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-2-1.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-1-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-8.wav\n",
            "UrbanSound8K/audio/fold3/107228-5-0-5.wav\n",
            "UrbanSound8K/audio/fold3/12647-3-1-0.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-2-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-4-1.wav\n",
            "UrbanSound8K/audio/fold3/162436-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-27.wav\n",
            "UrbanSound8K/audio/fold3/185373-9-1-46.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-73.wav\n",
            "UrbanSound8K/audio/fold3/12647-3-2-0.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-19.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-28.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-8-0.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-1.wav\n",
            "UrbanSound8K/audio/fold3/98681-9-0-12.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-50.wav\n",
            "UrbanSound8K/audio/fold3/54067-2-0-23.wav\n",
            "UrbanSound8K/audio/fold3/76221-2-0-6.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-161.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-11.wav\n",
            "UrbanSound8K/audio/fold3/58857-2-0-13.wav\n",
            "UrbanSound8K/audio/fold3/184725-3-0-2.wav\n",
            "UrbanSound8K/audio/fold3/151359-1-1-0.wav\n",
            "UrbanSound8K/audio/fold3/58857-2-0-14.wav\n",
            "UrbanSound8K/audio/fold3/98681-9-0-6.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-19.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-24.wav\n",
            "UrbanSound8K/audio/fold3/20841-3-4-0.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-19.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-10-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-2.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-5.wav\n",
            "UrbanSound8K/audio/fold3/117072-3-0-11.wav\n",
            "UrbanSound8K/audio/fold3/182103-9-0-47.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-49.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-16.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-16.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/148838-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-4.wav\n",
            "UrbanSound8K/audio/fold3/78326-9-0-1.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-45.wav\n",
            "UrbanSound8K/audio/fold3/34708-6-4-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-48.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-54.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-3.wav\n",
            "UrbanSound8K/audio/fold3/153261-0-0-2.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-6.wav\n",
            "UrbanSound8K/audio/fold3/151149-2-0-4.wav\n",
            "UrbanSound8K/audio/fold3/32318-3-0-1.wav\n",
            "UrbanSound8K/audio/fold3/184623-8-1-0.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-13.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-8-0.wav\n",
            "UrbanSound8K/audio/fold3/179386-3-0-3.wav\n",
            "UrbanSound8K/audio/fold3/186336-9-0-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-5-0.wav\n",
            "UrbanSound8K/audio/fold3/44831-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-1.wav\n",
            "UrbanSound8K/audio/fold3/132855-2-0-58.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-41.wav\n",
            "UrbanSound8K/audio/fold3/186339-9-0-7.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-7.wav\n",
            "UrbanSound8K/audio/fold3/186336-9-0-3.wav\n",
            "UrbanSound8K/audio/fold3/88569-2-0-67.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/77769-9-0-17.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-11.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-20.wav\n",
            "UrbanSound8K/audio/fold3/6988-5-0-3.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-5.wav\n",
            "UrbanSound8K/audio/fold3/17973-2-0-8.wav\n",
            "UrbanSound8K/audio/fold3/74810-9-0-5.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-18.wav\n",
            "UrbanSound8K/audio/fold3/76221-2-0-2.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-14.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-15.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-12.wav\n",
            "UrbanSound8K/audio/fold3/200161-3-6-4.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-11.wav\n",
            "UrbanSound8K/audio/fold3/172315-9-0-224.wav\n",
            "UrbanSound8K/audio/fold3/169044-2-0-10.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-18.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-9.wav\n",
            "UrbanSound8K/audio/fold3/132855-2-0-70.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-6.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-21.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-12.wav\n",
            "UrbanSound8K/audio/fold3/155263-2-0-43.wav\n",
            "UrbanSound8K/audio/fold3/185375-9-0-26.wav\n",
            "UrbanSound8K/audio/fold3/123399-2-0-13.wav\n",
            "UrbanSound8K/audio/fold3/90014-8-0-5.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-15.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-41.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-65.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-54.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-196.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-5.wav\n",
            "UrbanSound8K/audio/fold3/162431-6-2-0.wav\n",
            "UrbanSound8K/audio/fold3/88569-2-0-21.wav\n",
            "UrbanSound8K/audio/fold3/34708-6-1-0.wav\n",
            "UrbanSound8K/audio/fold3/185373-9-1-17.wav\n",
            "UrbanSound8K/audio/fold3/121528-8-1-0.wav\n",
            "UrbanSound8K/audio/fold3/185375-9-0-33.wav\n",
            "UrbanSound8K/audio/fold3/155263-2-0-23.wav\n",
            "UrbanSound8K/audio/fold3/175847-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/196060-2-0-0.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-3-0.wav\n",
            "UrbanSound8K/audio/fold3/182103-9-0-8.wav\n",
            "UrbanSound8K/audio/fold3/54067-2-0-70.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-5.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-18.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-5-0.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-17.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-4.wav\n",
            "UrbanSound8K/audio/fold3/151149-2-0-54.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-30.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-6.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-6.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-13.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-13.wav\n",
            "UrbanSound8K/audio/fold3/78326-9-0-3.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-0-3.wav\n",
            "UrbanSound8K/audio/fold3/103357-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-214.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-38.wav\n",
            "UrbanSound8K/audio/fold3/76221-2-0-1.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-3-0.wav\n",
            "UrbanSound8K/audio/fold3/155227-9-0-24.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-21.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-56.wav\n",
            "UrbanSound8K/audio/fold3/151149-2-0-12.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-13-0.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-1.wav\n",
            "UrbanSound8K/audio/fold3/186339-9-0-18.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-3.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-22.wav\n",
            "UrbanSound8K/audio/fold3/42097-7-0-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-16-0.wav\n",
            "UrbanSound8K/audio/fold3/63292-3-0-1.wav\n",
            "UrbanSound8K/audio/fold3/19496-3-1-0.wav\n",
            "UrbanSound8K/audio/fold3/169044-2-0-5.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-10.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-4.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-1-0.wav\n",
            "UrbanSound8K/audio/fold3/138473-9-0-35.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-63.wav\n",
            "UrbanSound8K/audio/fold3/88569-2-0-54.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-8.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-13.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-22.wav\n",
            "UrbanSound8K/audio/fold3/19338-5-2-0.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-12-1.wav\n",
            "UrbanSound8K/audio/fold3/77769-9-0-12.wav\n",
            "UrbanSound8K/audio/fold3/107228-5-0-2.wav\n",
            "UrbanSound8K/audio/fold3/17973-2-0-21.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-4.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-17.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-16.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-3.wav\n",
            "UrbanSound8K/audio/fold3/12647-3-3-0.wav\n",
            "UrbanSound8K/audio/fold3/180057-9-0-20.wav\n",
            "UrbanSound8K/audio/fold3/52077-3-0-8.wav\n",
            "UrbanSound8K/audio/fold3/6988-5-0-4.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-8.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-9.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-35.wav\n",
            "UrbanSound8K/audio/fold3/151149-2-0-22.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-9-0.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-12.wav\n",
            "UrbanSound8K/audio/fold3/179386-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-0-5.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-2.wav\n",
            "UrbanSound8K/audio/fold3/185375-9-0-84.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-51.wav\n",
            "UrbanSound8K/audio/fold3/37560-4-0-5.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-6-0.wav\n",
            "UrbanSound8K/audio/fold3/169044-2-0-18.wav\n",
            "UrbanSound8K/audio/fold3/151149-2-0-15.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-22.wav\n",
            "UrbanSound8K/audio/fold3/44831-3-2-0.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-7.wav\n",
            "UrbanSound8K/audio/fold3/76221-2-0-10.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-3.wav\n",
            "UrbanSound8K/audio/fold3/90014-8-0-6.wav\n",
            "UrbanSound8K/audio/fold3/94631-9-0-12.wav\n",
            "UrbanSound8K/audio/fold3/186334-2-0-37.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-1-3.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-6.wav\n",
            "UrbanSound8K/audio/fold3/156418-3-0-1.wav\n",
            "UrbanSound8K/audio/fold3/49809-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-56.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-9.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-36.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-32.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-5.wav\n",
            "UrbanSound8K/audio/fold3/172315-9-0-113.wav\n",
            "UrbanSound8K/audio/fold3/41372-3-0-51.wav\n",
            "UrbanSound8K/audio/fold3/151359-1-3-0.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-67.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/179865-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/162431-6-1-0.wav\n",
            "UrbanSound8K/audio/fold3/82811-3-4-0.wav\n",
            "UrbanSound8K/audio/fold3/61791-9-1-41.wav\n",
            "UrbanSound8K/audio/fold3/49485-9-0-142.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-3.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-4.wav\n",
            "UrbanSound8K/audio/fold3/107228-5-0-6.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-12.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-2-4.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-1-7.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-16.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-7.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-21.wav\n",
            "UrbanSound8K/audio/fold3/107228-5-0-4.wav\n",
            "UrbanSound8K/audio/fold3/95562-4-2-0.wav\n",
            "UrbanSound8K/audio/fold3/182103-9-0-53.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-13.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-50.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-4-2.wav\n",
            "UrbanSound8K/audio/fold3/102105-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/9223-2-0-2.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-2.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-9.wav\n",
            "UrbanSound8K/audio/fold3/18594-1-6-0.wav\n",
            "UrbanSound8K/audio/fold3/207124-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-3.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-4-0.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-11.wav\n",
            "UrbanSound8K/audio/fold3/90014-8-0-1.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/98681-9-0-7.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-18.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-26.wav\n",
            "UrbanSound8K/audio/fold3/103357-4-0-1.wav\n",
            "UrbanSound8K/audio/fold3/61791-9-1-40.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-2-0.wav\n",
            "UrbanSound8K/audio/fold3/182103-9-0-22.wav\n",
            "UrbanSound8K/audio/fold3/169044-2-0-21.wav\n",
            "UrbanSound8K/audio/fold3/54067-2-0-71.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-8.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-6.wav\n",
            "UrbanSound8K/audio/fold3/54067-2-0-33.wav\n",
            "UrbanSound8K/audio/fold3/107228-5-0-3.wav\n",
            "UrbanSound8K/audio/fold3/98681-9-0-5.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-21.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-0-4.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-1.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-202.wav\n",
            "UrbanSound8K/audio/fold3/52077-3-0-13.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-8.wav\n",
            "UrbanSound8K/audio/fold3/186339-9-0-17.wav\n",
            "UrbanSound8K/audio/fold3/65750-3-3-74.wav\n",
            "UrbanSound8K/audio/fold3/128030-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/186334-2-0-33.wav\n",
            "UrbanSound8K/audio/fold3/159761-0-0-0.wav\n",
            "UrbanSound8K/audio/fold3/17973-2-0-32.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-3-0.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-45.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-23.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-15-1.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-7.wav\n",
            "UrbanSound8K/audio/fold3/66622-4-0-5.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-3-0.wav\n",
            "UrbanSound8K/audio/fold3/186336-9-0-1.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-18.wav\n",
            "UrbanSound8K/audio/fold3/76094-6-1-0.wav\n",
            "UrbanSound8K/audio/fold3/197074-3-0-4.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-7.wav\n",
            "UrbanSound8K/audio/fold3/49809-3-4-0.wav\n",
            "UrbanSound8K/audio/fold3/30204-0-0-0.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-9.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-0-3.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-0-0.wav\n",
            "UrbanSound8K/audio/fold3/61791-9-1-44.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-11.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-5-0.wav\n",
            "UrbanSound8K/audio/fold3/128030-3-1-0.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-10.wav\n",
            "UrbanSound8K/audio/fold3/115536-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/74810-9-1-5.wav\n",
            "UrbanSound8K/audio/fold3/15356-2-0-3.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-43.wav\n",
            "UrbanSound8K/audio/fold3/29721-4-0-9.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-22.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-20.wav\n",
            "UrbanSound8K/audio/fold3/184725-3-0-1.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-13.wav\n",
            "UrbanSound8K/audio/fold3/182103-9-0-0.wav\n",
            "UrbanSound8K/audio/fold3/49485-9-0-91.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-11.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-26.wav\n",
            "UrbanSound8K/audio/fold3/116400-3-0-2.wav\n",
            "UrbanSound8K/audio/fold3/184623-8-0-0.wav\n",
            "UrbanSound8K/audio/fold3/15356-2-0-0.wav\n",
            "UrbanSound8K/audio/fold3/54898-8-0-2.wav\n",
            "UrbanSound8K/audio/fold3/151359-1-2-0.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-18.wav\n",
            "UrbanSound8K/audio/fold3/112075-5-0-2.wav\n",
            "UrbanSound8K/audio/fold3/82811-3-0-1.wav\n",
            "UrbanSound8K/audio/fold3/15356-2-0-1.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-28.wav\n",
            "UrbanSound8K/audio/fold3/19338-5-1-0.wav\n",
            "UrbanSound8K/audio/fold3/49485-9-0-154.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-0-2.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-102.wav\n",
            "UrbanSound8K/audio/fold3/19496-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/185373-9-0-6.wav\n",
            "UrbanSound8K/audio/fold3/135526-6-7-0.wav\n",
            "UrbanSound8K/audio/fold3/12647-3-0-0.wav\n",
            "UrbanSound8K/audio/fold3/151071-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/123399-2-0-74.wav\n",
            "UrbanSound8K/audio/fold3/169044-2-0-3.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-2.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-6.wav\n",
            "UrbanSound8K/audio/fold3/31884-7-0-0.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-37.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-18.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-17.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-14.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-0-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-21.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-17.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-205.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-30.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-79.wav\n",
            "UrbanSound8K/audio/fold3/186334-2-0-11.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-28.wav\n",
            "UrbanSound8K/audio/fold3/42937-4-0-0.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-11.wav\n",
            "UrbanSound8K/audio/fold3/184623-8-0-3.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-2.wav\n",
            "UrbanSound8K/audio/fold3/197074-3-0-5.wav\n",
            "UrbanSound8K/audio/fold3/9223-2-0-5.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-7.wav\n",
            "UrbanSound8K/audio/fold3/138473-9-0-29.wav\n",
            "UrbanSound8K/audio/fold3/118496-1-1-0.wav\n",
            "UrbanSound8K/audio/fold3/185375-9-0-60.wav\n",
            "UrbanSound8K/audio/fold3/42117-8-0-10.wav\n",
            "UrbanSound8K/audio/fold3/125523-3-0-11.wav\n",
            "UrbanSound8K/audio/fold3/155227-9-0-3.wav\n",
            "UrbanSound8K/audio/fold3/94636-8-0-8.wav\n",
            "UrbanSound8K/audio/fold3/138473-9-0-5.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-13.wav\n",
            "UrbanSound8K/audio/fold3/207124-3-2-0.wav\n",
            "UrbanSound8K/audio/fold3/18594-1-1-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-4.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-15.wav\n",
            "UrbanSound8K/audio/fold3/88569-2-0-77.wav\n",
            "UrbanSound8K/audio/fold3/107228-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/95077-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/117048-3-0-23.wav\n",
            "UrbanSound8K/audio/fold3/72537-3-0-8.wav\n",
            "UrbanSound8K/audio/fold3/42097-7-0-1.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-1-24.wav\n",
            "UrbanSound8K/audio/fold3/74810-9-1-12.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-14.wav\n",
            "UrbanSound8K/audio/fold3/63095-4-0-6.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-24.wav\n",
            "UrbanSound8K/audio/fold3/182103-9-0-26.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-9.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-26.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-1.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-3.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-1-0.wav\n",
            "UrbanSound8K/audio/fold3/22601-8-0-6.wav\n",
            "UrbanSound8K/audio/fold3/33696-3-4-0.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-10.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-21.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-47.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-1.wav\n",
            "UrbanSound8K/audio/fold3/165039-7-17-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-7.wav\n",
            "UrbanSound8K/audio/fold3/199769-1-0-3.wav\n",
            "UrbanSound8K/audio/fold3/188824-7-12-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-6.wav\n",
            "UrbanSound8K/audio/fold3/13230-0-0-20.wav\n",
            "UrbanSound8K/audio/fold3/146714-0-0-49.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-165.wav\n",
            "UrbanSound8K/audio/fold3/103199-4-2-10.wav\n",
            "UrbanSound8K/audio/fold3/62837-7-0-31.wav\n",
            "UrbanSound8K/audio/fold3/17973-2-0-29.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-15.wav\n",
            "UrbanSound8K/audio/fold3/195451-5-0-19.wav\n",
            "UrbanSound8K/audio/fold3/155227-9-0-2.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-5.wav\n",
            "UrbanSound8K/audio/fold3/77769-9-0-4.wav\n",
            "UrbanSound8K/audio/fold3/118496-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/112075-5-0-0.wav\n",
            "UrbanSound8K/audio/fold3/177742-0-0-203.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-0.wav\n",
            "UrbanSound8K/audio/fold3/151149-2-0-11.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-12.wav\n",
            "UrbanSound8K/audio/fold3/166101-5-2-2.wav\n",
            "UrbanSound8K/audio/fold3/176631-1-0-0.wav\n",
            "UrbanSound8K/audio/fold3/52357-6-0-0.wav\n",
            "UrbanSound8K/audio/fold3/117048-3-0-17.wav\n",
            "UrbanSound8K/audio/fold3/153261-0-0-3.wav\n",
            "UrbanSound8K/audio/fold3/37560-4-0-3.wav\n",
            "UrbanSound8K/audio/fold3/17853-5-0-2.wav\n",
            "UrbanSound8K/audio/fold3/132855-2-0-99.wav\n",
            "UrbanSound8K/audio/fold3/123399-2-0-19.wav\n",
            "UrbanSound8K/audio/fold3/65750-3-3-48.wav\n",
            "UrbanSound8K/audio/fold3/69598-4-2-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-4.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-4-1.wav\n",
            "UrbanSound8K/audio/fold3/116400-3-1-0.wav\n",
            "UrbanSound8K/audio/fold3/144068-5-0-10.wav\n",
            "UrbanSound8K/audio/fold3/128030-3-2-0.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-3.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-0-2.wav\n",
            "UrbanSound8K/audio/fold6/196076-2-0-0.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-6.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/34643-4-1-1.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-30.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-20.wav\n",
            "UrbanSound8K/audio/fold6/29932-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/190680-3-4-0.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-7.wav\n",
            "UrbanSound8K/audio/fold6/155127-9-1-24.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-2-1.wav\n",
            "UrbanSound8K/audio/fold6/14358-3-0-7.wav\n",
            "UrbanSound8K/audio/fold6/129356-2-0-115.wav\n",
            "UrbanSound8K/audio/fold6/160575-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-11-0.wav\n",
            "UrbanSound8K/audio/fold6/160575-3-7-0.wav\n",
            "UrbanSound8K/audio/fold6/128891-3-0-4.wav\n",
            "UrbanSound8K/audio/fold6/39884-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/115243-9-0-46.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-22.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-1.wav\n",
            "UrbanSound8K/audio/fold6/98263-9-0-24.wav\n",
            "UrbanSound8K/audio/fold6/128891-3-0-5.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-2.wav\n",
            "UrbanSound8K/audio/fold6/122738-9-0-5.wav\n",
            "UrbanSound8K/audio/fold6/98680-9-0-5.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-34.wav\n",
            "UrbanSound8K/audio/fold6/162434-6-1-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-9.wav\n",
            "UrbanSound8K/audio/fold6/82368-2-0-17.wav\n",
            "UrbanSound8K/audio/fold6/116423-2-0-2.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-4.wav\n",
            "UrbanSound8K/audio/fold6/14114-4-0-1.wav\n",
            "UrbanSound8K/audio/fold6/104327-2-0-3.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-15.wav\n",
            "UrbanSound8K/audio/fold6/108638-9-0-1.wav\n",
            "UrbanSound8K/audio/fold6/82368-2-0-23.wav\n",
            "UrbanSound8K/audio/fold6/143115-1-3-0.wav\n",
            "UrbanSound8K/audio/fold6/129356-2-0-48.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-14.wav\n",
            "UrbanSound8K/audio/fold6/137969-2-0-4.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-30.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-57.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-19.wav\n",
            "UrbanSound8K/audio/fold6/194753-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-16.wav\n",
            "UrbanSound8K/audio/fold6/95536-3-0-2.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-27.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-1-0.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-10.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-13.wav\n",
            "UrbanSound8K/audio/fold6/52882-2-0-11.wav\n",
            "UrbanSound8K/audio/fold6/155488-3-3-1.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-5.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-36.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-10.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-34.wav\n",
            "UrbanSound8K/audio/fold6/39854-5-1-2.wav\n",
            "UrbanSound8K/audio/fold6/194753-3-2-0.wav\n",
            "UrbanSound8K/audio/fold6/89442-9-0-6.wav\n",
            "UrbanSound8K/audio/fold6/159702-6-2-0.wav\n",
            "UrbanSound8K/audio/fold6/161922-3-1-4.wav\n",
            "UrbanSound8K/audio/fold6/137969-2-0-56.wav\n",
            "UrbanSound8K/audio/fold6/155488-3-3-0.wav\n",
            "UrbanSound8K/audio/fold6/89442-9-0-14.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-90.wav\n",
            "UrbanSound8K/audio/fold6/115243-9-0-16.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-7.wav\n",
            "UrbanSound8K/audio/fold6/42955-9-0-14.wav\n",
            "UrbanSound8K/audio/fold6/193697-2-0-90.wav\n",
            "UrbanSound8K/audio/fold6/44325-9-0-18.wav\n",
            "UrbanSound8K/audio/fold6/39854-5-1-3.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-54.wav\n",
            "UrbanSound8K/audio/fold6/169045-2-0-16.wav\n",
            "UrbanSound8K/audio/fold6/66000-9-0-1.wav\n",
            "UrbanSound8K/audio/fold6/166489-3-0-1.wav\n",
            "UrbanSound8K/audio/fold6/111048-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-3-0.wav\n",
            "UrbanSound8K/audio/fold6/98263-9-0-1.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-8.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-11.wav\n",
            "UrbanSound8K/audio/fold6/133494-2-0-22.wav\n",
            "UrbanSound8K/audio/fold6/188004-8-0-2.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-4.wav\n",
            "UrbanSound8K/audio/fold6/82368-2-0-30.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-74.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-4.wav\n",
            "UrbanSound8K/audio/fold6/175917-3-2-2.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-11.wav\n",
            "UrbanSound8K/audio/fold6/98263-9-0-35.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-19.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-48.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-6-0.wav\n",
            "UrbanSound8K/audio/fold6/39854-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-28.wav\n",
            "UrbanSound8K/audio/fold6/193697-2-0-103.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-4-0.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-6.wav\n",
            "UrbanSound8K/audio/fold6/89442-9-0-5.wav\n",
            "UrbanSound8K/audio/fold6/68657-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-30.wav\n",
            "UrbanSound8K/audio/fold6/89442-9-0-7.wav\n",
            "UrbanSound8K/audio/fold6/109233-3-0-5.wav\n",
            "UrbanSound8K/audio/fold6/35548-9-1-14.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-2.wav\n",
            "UrbanSound8K/audio/fold6/85249-2-0-79.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-55.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-9.wav\n",
            "UrbanSound8K/audio/fold6/155127-9-1-25.wav\n",
            "UrbanSound8K/audio/fold6/159702-6-4-0.wav\n",
            "UrbanSound8K/audio/fold6/99710-9-0-12.wav\n",
            "UrbanSound8K/audio/fold6/133797-6-2-0.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-16-0.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-10.wav\n",
            "UrbanSound8K/audio/fold6/39884-5-0-7.wav\n",
            "UrbanSound8K/audio/fold6/34952-8-0-2.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-6.wav\n",
            "UrbanSound8K/audio/fold6/66623-4-0-6.wav\n",
            "UrbanSound8K/audio/fold6/52882-2-0-6.wav\n",
            "UrbanSound8K/audio/fold6/133797-6-1-0.wav\n",
            "UrbanSound8K/audio/fold6/161922-3-1-6.wav\n",
            "UrbanSound8K/audio/fold6/39884-5-0-2.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-2.wav\n",
            "UrbanSound8K/audio/fold6/46299-2-0-16.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-101.wav\n",
            "UrbanSound8K/audio/fold6/122738-9-0-2.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-7.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-6-3.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-63.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-6.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-24.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-1.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-2-0.wav\n",
            "UrbanSound8K/audio/fold6/18933-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-3-1.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-17.wav\n",
            "UrbanSound8K/audio/fold6/39884-5-0-6.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-10.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-6-2.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-0.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-5.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-11-0.wav\n",
            "UrbanSound8K/audio/fold6/52882-2-0-8.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-7-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-7.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-13.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-4.wav\n",
            "UrbanSound8K/audio/fold6/104327-2-0-26.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-5.wav\n",
            "UrbanSound8K/audio/fold6/204919-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-2-3.wav\n",
            "UrbanSound8K/audio/fold6/31973-9-0-56.wav\n",
            "UrbanSound8K/audio/fold6/117271-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/75490-8-1-1.wav\n",
            "UrbanSound8K/audio/fold6/132162-9-1-68.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-25.wav\n",
            "UrbanSound8K/audio/fold6/129356-2-0-118.wav\n",
            "UrbanSound8K/audio/fold6/85249-2-0-25.wav\n",
            "UrbanSound8K/audio/fold6/155127-9-1-2.wav\n",
            "UrbanSound8K/audio/fold6/148835-6-2-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-26.wav\n",
            "UrbanSound8K/audio/fold6/35548-9-0-23.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-6.wav\n",
            "UrbanSound8K/audio/fold6/83680-5-0-2.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-11.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-9.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-49.wav\n",
            "UrbanSound8K/audio/fold6/69962-2-0-16.wav\n",
            "UrbanSound8K/audio/fold6/85249-2-0-14.wav\n",
            "UrbanSound8K/audio/fold6/104327-2-0-4.wav\n",
            "UrbanSound8K/audio/fold6/14114-4-0-3.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-2-0.wav\n",
            "UrbanSound8K/audio/fold6/143115-1-4-0.wav\n",
            "UrbanSound8K/audio/fold6/34643-4-1-0.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-1.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-103.wav\n",
            "UrbanSound8K/audio/fold6/137969-2-0-41.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-2.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-3.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-1-4.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-15.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-8.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-21.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-4.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-2-2.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-17.wav\n",
            "UrbanSound8K/audio/fold6/110868-9-0-8.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-76.wav\n",
            "UrbanSound8K/audio/fold6/110868-9-0-6.wav\n",
            "UrbanSound8K/audio/fold6/115243-9-0-4.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-3.wav\n",
            "UrbanSound8K/audio/fold6/66623-4-0-1.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-11.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-29.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-4.wav\n",
            "UrbanSound8K/audio/fold6/46299-2-0-48.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-17.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-1.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-2-1.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-13.wav\n",
            "UrbanSound8K/audio/fold6/85249-2-0-29.wav\n",
            "UrbanSound8K/audio/fold6/110868-9-0-13.wav\n",
            "UrbanSound8K/audio/fold6/133797-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/155127-9-1-23.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-9.wav\n",
            "UrbanSound8K/audio/fold6/148835-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-47.wav\n",
            "UrbanSound8K/audio/fold6/39854-5-1-0.wav\n",
            "UrbanSound8K/audio/fold6/194753-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/194753-3-3-0.wav\n",
            "UrbanSound8K/audio/fold6/182474-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-2.wav\n",
            "UrbanSound8K/audio/fold6/129356-2-0-98.wav\n",
            "UrbanSound8K/audio/fold6/105319-3-0-29.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-0-6.wav\n",
            "UrbanSound8K/audio/fold6/115243-9-0-0.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-12.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-68.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-0.wav\n",
            "UrbanSound8K/audio/fold6/34952-8-0-3.wav\n",
            "UrbanSound8K/audio/fold6/104327-2-0-28.wav\n",
            "UrbanSound8K/audio/fold6/66000-9-0-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-7.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-10.wav\n",
            "UrbanSound8K/audio/fold6/95536-3-0-1.wav\n",
            "UrbanSound8K/audio/fold6/34643-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/137969-2-0-37.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-0-7.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-58.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-1.wav\n",
            "UrbanSound8K/audio/fold6/31973-9-0-43.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-26.wav\n",
            "UrbanSound8K/audio/fold6/39852-5-0-1.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-5-0.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-4-0.wav\n",
            "UrbanSound8K/audio/fold6/165641-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-8.wav\n",
            "UrbanSound8K/audio/fold6/69962-2-0-2.wav\n",
            "UrbanSound8K/audio/fold6/133494-2-0-37.wav\n",
            "UrbanSound8K/audio/fold6/197075-3-1-1.wav\n",
            "UrbanSound8K/audio/fold6/204919-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/44325-9-0-35.wav\n",
            "UrbanSound8K/audio/fold6/34643-4-2-1.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-9-0.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-12.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-7.wav\n",
            "UrbanSound8K/audio/fold6/66623-4-0-5.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-2.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-10.wav\n",
            "UrbanSound8K/audio/fold6/105319-3-0-39.wav\n",
            "UrbanSound8K/audio/fold6/196077-2-0-0.wav\n",
            "UrbanSound8K/audio/fold6/104327-2-0-30.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-28.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-0.wav\n",
            "UrbanSound8K/audio/fold6/169045-2-0-0.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-99.wav\n",
            "UrbanSound8K/audio/fold6/54697-7-0-1.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-16.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-30.wav\n",
            "UrbanSound8K/audio/fold6/160575-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/155212-9-1-88.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-10.wav\n",
            "UrbanSound8K/audio/fold6/169045-2-0-3.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-1-5.wav\n",
            "UrbanSound8K/audio/fold6/42955-9-0-22.wav\n",
            "UrbanSound8K/audio/fold6/89442-9-0-17.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-13.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-16.wav\n",
            "UrbanSound8K/audio/fold6/197075-3-7-5.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-8.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-4.wav\n",
            "UrbanSound8K/audio/fold6/69962-2-0-22.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-1-1.wav\n",
            "UrbanSound8K/audio/fold6/66623-4-0-3.wav\n",
            "UrbanSound8K/audio/fold6/66000-9-0-8.wav\n",
            "UrbanSound8K/audio/fold6/160575-3-4-0.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-13.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-18.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-7.wav\n",
            "UrbanSound8K/audio/fold6/155212-9-1-14.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-61.wav\n",
            "UrbanSound8K/audio/fold6/98263-9-0-33.wav\n",
            "UrbanSound8K/audio/fold6/34952-8-0-4.wav\n",
            "UrbanSound8K/audio/fold6/35548-9-2-9.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-8.wav\n",
            "UrbanSound8K/audio/fold6/204919-3-3-0.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-9.wav\n",
            "UrbanSound8K/audio/fold6/42955-9-0-18.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-0-3.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-8.wav\n",
            "UrbanSound8K/audio/fold6/159704-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/161922-3-2-0.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-121.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-14-0.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-1-2.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-34.wav\n",
            "UrbanSound8K/audio/fold6/133494-2-0-18.wav\n",
            "UrbanSound8K/audio/fold6/51027-3-1-4.wav\n",
            "UrbanSound8K/audio/fold6/133494-2-0-31.wav\n",
            "UrbanSound8K/audio/fold6/75490-8-0-0.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-9.wav\n",
            "UrbanSound8K/audio/fold6/109233-3-0-4.wav\n",
            "UrbanSound8K/audio/fold6/194321-9-0-150.wav\n",
            "UrbanSound8K/audio/fold6/166489-3-0-4.wav\n",
            "UrbanSound8K/audio/fold6/36403-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-1.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-7.wav\n",
            "UrbanSound8K/audio/fold6/75490-8-0-2.wav\n",
            "UrbanSound8K/audio/fold6/162434-6-2-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-14.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-4.wav\n",
            "UrbanSound8K/audio/fold6/197075-3-4-1.wav\n",
            "UrbanSound8K/audio/fold6/157322-3-0-3.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-6.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-3.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-13.wav\n",
            "UrbanSound8K/audio/fold6/143115-1-1-0.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-6.wav\n",
            "UrbanSound8K/audio/fold6/39852-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/97331-2-0-17.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-77.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-7-0.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-4.wav\n",
            "UrbanSound8K/audio/fold6/108638-9-0-4.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-0-1.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-6.wav\n",
            "UrbanSound8K/audio/fold6/99710-9-0-6.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-2.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-1-6.wav\n",
            "UrbanSound8K/audio/fold6/42955-9-0-19.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-14.wav\n",
            "UrbanSound8K/audio/fold6/179725-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/122738-9-0-9.wav\n",
            "UrbanSound8K/audio/fold6/194321-9-0-61.wav\n",
            "UrbanSound8K/audio/fold6/188004-8-0-1.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-14.wav\n",
            "UrbanSound8K/audio/fold6/83680-5-0-1.wav\n",
            "UrbanSound8K/audio/fold6/108638-9-0-5.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-1.wav\n",
            "UrbanSound8K/audio/fold6/71088-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-27.wav\n",
            "UrbanSound8K/audio/fold6/42955-9-0-12.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-15.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-15.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-6.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-14.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-0-5.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-3-2.wav\n",
            "UrbanSound8K/audio/fold6/34952-8-0-7.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-25.wav\n",
            "UrbanSound8K/audio/fold6/34952-8-0-6.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-2-8.wav\n",
            "UrbanSound8K/audio/fold6/70740-8-0-0.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-19-0.wav\n",
            "UrbanSound8K/audio/fold6/128891-3-0-2.wav\n",
            "UrbanSound8K/audio/fold6/66000-9-0-3.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-2.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-2-0.wav\n",
            "UrbanSound8K/audio/fold6/52882-2-0-4.wav\n",
            "UrbanSound8K/audio/fold6/35548-9-0-21.wav\n",
            "UrbanSound8K/audio/fold6/46299-2-0-22.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-0.wav\n",
            "UrbanSound8K/audio/fold6/69962-2-0-15.wav\n",
            "UrbanSound8K/audio/fold6/108638-9-0-6.wav\n",
            "UrbanSound8K/audio/fold6/89442-9-0-34.wav\n",
            "UrbanSound8K/audio/fold6/98680-9-0-14.wav\n",
            "UrbanSound8K/audio/fold6/155317-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/46299-2-0-9.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-0-1.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-3.wav\n",
            "UrbanSound8K/audio/fold6/109233-3-0-6.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-0.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-2.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-9.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-16.wav\n",
            "UrbanSound8K/audio/fold6/116423-2-0-3.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-11.wav\n",
            "UrbanSound8K/audio/fold6/101281-3-0-14.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-17.wav\n",
            "UrbanSound8K/audio/fold6/31973-9-0-64.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/179860-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/43802-1-2-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-8.wav\n",
            "UrbanSound8K/audio/fold6/46299-2-0-8.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-28.wav\n",
            "UrbanSound8K/audio/fold6/95536-3-0-5.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-2-5.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-11.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-2-2.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-40.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-26.wav\n",
            "UrbanSound8K/audio/fold6/129356-2-0-199.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-5.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-11.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-14.wav\n",
            "UrbanSound8K/audio/fold6/47160-0-0-3.wav\n",
            "UrbanSound8K/audio/fold6/36902-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/85249-2-0-61.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-14.wav\n",
            "UrbanSound8K/audio/fold6/133494-2-0-25.wav\n",
            "UrbanSound8K/audio/fold6/117271-3-0-3.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-1-0.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-7.wav\n",
            "UrbanSound8K/audio/fold6/97331-2-0-20.wav\n",
            "UrbanSound8K/audio/fold6/159702-6-1-0.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-14.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-4.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-7.wav\n",
            "UrbanSound8K/audio/fold6/57607-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/85249-2-0-62.wav\n",
            "UrbanSound8K/audio/fold6/14358-3-0-26.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-1.wav\n",
            "UrbanSound8K/audio/fold6/129356-2-0-129.wav\n",
            "UrbanSound8K/audio/fold6/4912-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-23.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-6.wav\n",
            "UrbanSound8K/audio/fold6/193697-2-0-107.wav\n",
            "UrbanSound8K/audio/fold6/97331-2-0-98.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-32.wav\n",
            "UrbanSound8K/audio/fold6/148833-6-1-0.wav\n",
            "UrbanSound8K/audio/fold6/208030-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/133494-2-0-26.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-3.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-34.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-2.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-2-4.wav\n",
            "UrbanSound8K/audio/fold6/162702-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-16.wav\n",
            "UrbanSound8K/audio/fold6/44325-9-0-67.wav\n",
            "UrbanSound8K/audio/fold6/155127-9-0-2.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-6.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-10-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-33.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-3.wav\n",
            "UrbanSound8K/audio/fold6/188004-8-0-0.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-11.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-26.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-5.wav\n",
            "UrbanSound8K/audio/fold6/155212-9-0-13.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-7.wav\n",
            "UrbanSound8K/audio/fold6/117271-3-0-2.wav\n",
            "UrbanSound8K/audio/fold6/71088-4-1-0.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-5-0.wav\n",
            "UrbanSound8K/audio/fold6/157322-3-0-4.wav\n",
            "UrbanSound8K/audio/fold6/129356-2-0-101.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-3.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-0.wav\n",
            "UrbanSound8K/audio/fold6/104327-2-0-15.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-6-0.wav\n",
            "UrbanSound8K/audio/fold6/98263-9-0-22.wav\n",
            "UrbanSound8K/audio/fold6/101281-3-0-5.wav\n",
            "UrbanSound8K/audio/fold6/83680-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/99710-9-0-11.wav\n",
            "UrbanSound8K/audio/fold6/39854-5-1-1.wav\n",
            "UrbanSound8K/audio/fold6/14114-4-0-2.wav\n",
            "UrbanSound8K/audio/fold6/66000-9-0-6.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-5.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-14.wav\n",
            "UrbanSound8K/audio/fold6/159702-6-5-0.wav\n",
            "UrbanSound8K/audio/fold6/39854-5-1-4.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-11.wav\n",
            "UrbanSound8K/audio/fold6/36902-3-2-0.wav\n",
            "UrbanSound8K/audio/fold6/169045-2-0-1.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-1-0.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-13-0.wav\n",
            "UrbanSound8K/audio/fold6/66000-9-0-2.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-12-0.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-13.wav\n",
            "UrbanSound8K/audio/fold6/97331-2-0-59.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-5.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-40.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-9.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-0-2.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-45.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-27.wav\n",
            "UrbanSound8K/audio/fold6/164311-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-8.wav\n",
            "UrbanSound8K/audio/fold6/197075-3-6-0.wav\n",
            "UrbanSound8K/audio/fold6/175917-3-0-3.wav\n",
            "UrbanSound8K/audio/fold6/157322-3-0-5.wav\n",
            "UrbanSound8K/audio/fold6/47160-0-0-4.wav\n",
            "UrbanSound8K/audio/fold6/115243-9-0-81.wav\n",
            "UrbanSound8K/audio/fold6/125554-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/122738-9-0-11.wav\n",
            "UrbanSound8K/audio/fold6/104327-2-0-34.wav\n",
            "UrbanSound8K/audio/fold6/64346-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/106486-5-0-1.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-51.wav\n",
            "UrbanSound8K/audio/fold6/95536-3-0-4.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-3-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-31.wav\n",
            "UrbanSound8K/audio/fold6/148835-6-1-0.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-0-4.wav\n",
            "UrbanSound8K/audio/fold6/110868-9-0-14.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-8.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-38.wav\n",
            "UrbanSound8K/audio/fold6/39884-5-0-3.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-18.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-9.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-9.wav\n",
            "UrbanSound8K/audio/fold6/194321-9-0-6.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-31.wav\n",
            "UrbanSound8K/audio/fold6/175917-3-4-1.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-2.wav\n",
            "UrbanSound8K/audio/fold6/4912-3-2-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-18.wav\n",
            "UrbanSound8K/audio/fold6/190680-3-6-0.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-15-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-15.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-4-0.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-8.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-4.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/99710-9-0-5.wav\n",
            "UrbanSound8K/audio/fold6/196088-2-0-0.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-44.wav\n",
            "UrbanSound8K/audio/fold6/98680-9-0-11.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-12.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-8.wav\n",
            "UrbanSound8K/audio/fold6/143115-1-2-0.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-2-3.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-9.wav\n",
            "UrbanSound8K/audio/fold6/165641-4-0-1.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-9.wav\n",
            "UrbanSound8K/audio/fold6/193697-2-0-135.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-22.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-19.wav\n",
            "UrbanSound8K/audio/fold6/82368-2-0-25.wav\n",
            "UrbanSound8K/audio/fold6/159702-6-6-0.wav\n",
            "UrbanSound8K/audio/fold6/39884-5-0-1.wav\n",
            "UrbanSound8K/audio/fold6/82368-2-0-1.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-18-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-5.wav\n",
            "UrbanSound8K/audio/fold6/34643-4-2-0.wav\n",
            "UrbanSound8K/audio/fold6/34952-8-0-1.wav\n",
            "UrbanSound8K/audio/fold6/47160-0-0-0.wav\n",
            "UrbanSound8K/audio/fold6/162434-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/75490-8-1-0.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-1-2.wav\n",
            "UrbanSound8K/audio/fold6/158979-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-11.wav\n",
            "UrbanSound8K/audio/fold6/54697-7-0-3.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-10.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-17.wav\n",
            "UrbanSound8K/audio/fold6/175848-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/116423-2-0-4.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-4.wav\n",
            "UrbanSound8K/audio/fold6/155127-9-1-27.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-6.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-81.wav\n",
            "UrbanSound8K/audio/fold6/132162-9-1-67.wav\n",
            "UrbanSound8K/audio/fold6/166489-3-0-2.wav\n",
            "UrbanSound8K/audio/fold6/143115-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-29.wav\n",
            "UrbanSound8K/audio/fold6/132162-9-1-58.wav\n",
            "UrbanSound8K/audio/fold6/4910-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-41.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-8.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-39.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-1-0.wav\n",
            "UrbanSound8K/audio/fold6/14358-3-0-90.wav\n",
            "UrbanSound8K/audio/fold6/148834-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/161922-3-1-5.wav\n",
            "UrbanSound8K/audio/fold6/14358-3-0-85.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-2.wav\n",
            "UrbanSound8K/audio/fold6/85249-2-0-68.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-2-12.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-13.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-2-0.wav\n",
            "UrbanSound8K/audio/fold6/44325-9-0-72.wav\n",
            "UrbanSound8K/audio/fold6/97331-2-0-35.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-3-0.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-0.wav\n",
            "UrbanSound8K/audio/fold6/31973-9-0-71.wav\n",
            "UrbanSound8K/audio/fold6/31973-9-0-51.wav\n",
            "UrbanSound8K/audio/fold6/9032-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-12.wav\n",
            "UrbanSound8K/audio/fold6/115243-9-0-94.wav\n",
            "UrbanSound8K/audio/fold6/161923-3-0-5.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-1.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-5.wav\n",
            "UrbanSound8K/audio/fold6/44325-9-0-78.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-32.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-12.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-15.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-15.wav\n",
            "UrbanSound8K/audio/fold6/28284-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-2-7.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-51.wav\n",
            "UrbanSound8K/audio/fold6/75490-8-0-1.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-5.wav\n",
            "UrbanSound8K/audio/fold6/148835-6-4-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-2.wav\n",
            "UrbanSound8K/audio/fold6/46299-2-0-21.wav\n",
            "UrbanSound8K/audio/fold6/52882-2-0-7.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-5.wav\n",
            "UrbanSound8K/audio/fold6/162702-1-1-0.wav\n",
            "UrbanSound8K/audio/fold6/116423-2-0-0.wav\n",
            "UrbanSound8K/audio/fold6/4912-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/43802-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-11.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-6.wav\n",
            "UrbanSound8K/audio/fold6/14114-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/54697-7-0-4.wav\n",
            "UrbanSound8K/audio/fold6/47160-0-0-1.wav\n",
            "UrbanSound8K/audio/fold6/122738-9-0-3.wav\n",
            "UrbanSound8K/audio/fold6/132162-9-1-73.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-4-3.wav\n",
            "UrbanSound8K/audio/fold6/137969-2-0-55.wav\n",
            "UrbanSound8K/audio/fold6/157322-3-0-6.wav\n",
            "UrbanSound8K/audio/fold6/105319-3-0-22.wav\n",
            "UrbanSound8K/audio/fold6/4912-3-3-0.wav\n",
            "UrbanSound8K/audio/fold6/203355-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-23.wav\n",
            "UrbanSound8K/audio/fold6/34952-8-0-0.wav\n",
            "UrbanSound8K/audio/fold6/107842-4-2-4.wav\n",
            "UrbanSound8K/audio/fold6/137969-2-0-18.wav\n",
            "UrbanSound8K/audio/fold6/99710-9-0-2.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-16.wav\n",
            "UrbanSound8K/audio/fold6/69962-2-0-17.wav\n",
            "UrbanSound8K/audio/fold6/208030-3-4-0.wav\n",
            "UrbanSound8K/audio/fold6/82317-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/106486-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-7.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-12.wav\n",
            "UrbanSound8K/audio/fold6/155212-9-1-85.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-6.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-32.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-0.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-7.wav\n",
            "UrbanSound8K/audio/fold6/133494-2-0-19.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-35.wav\n",
            "UrbanSound8K/audio/fold6/148833-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-33.wav\n",
            "UrbanSound8K/audio/fold6/38121-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/117271-3-0-1.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-63.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-9.wav\n",
            "UrbanSound8K/audio/fold6/208030-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-8.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-10.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-0.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-13.wav\n",
            "UrbanSound8K/audio/fold6/116423-2-0-1.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-12.wav\n",
            "UrbanSound8K/audio/fold6/82368-2-0-0.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-9.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-64.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-0.wav\n",
            "UrbanSound8K/audio/fold6/47160-0-0-2.wav\n",
            "UrbanSound8K/audio/fold6/50455-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/97392-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-28.wav\n",
            "UrbanSound8K/audio/fold6/169045-2-0-14.wav\n",
            "UrbanSound8K/audio/fold6/194321-9-0-241.wav\n",
            "UrbanSound8K/audio/fold6/69962-2-0-25.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-1.wav\n",
            "UrbanSound8K/audio/fold6/175917-3-1-1.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-32.wav\n",
            "UrbanSound8K/audio/fold6/108638-9-0-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-25.wav\n",
            "UrbanSound8K/audio/fold6/122738-9-0-12.wav\n",
            "UrbanSound8K/audio/fold6/155488-3-2-0.wav\n",
            "UrbanSound8K/audio/fold6/95532-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/69962-2-0-20.wav\n",
            "UrbanSound8K/audio/fold6/125574-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/82368-2-0-7.wav\n",
            "UrbanSound8K/audio/fold6/98263-9-0-10.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-8-0.wav\n",
            "UrbanSound8K/audio/fold6/208030-3-2-0.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-16.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-20.wav\n",
            "UrbanSound8K/audio/fold6/169045-2-0-20.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-4.wav\n",
            "UrbanSound8K/audio/fold6/164311-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/104327-2-0-19.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-13.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-3.wav\n",
            "UrbanSound8K/audio/fold6/169045-2-0-8.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-2-0.wav\n",
            "UrbanSound8K/audio/fold6/155488-3-0-6.wav\n",
            "UrbanSound8K/audio/fold6/99710-9-0-16.wav\n",
            "UrbanSound8K/audio/fold6/155212-9-1-49.wav\n",
            "UrbanSound8K/audio/fold6/133494-2-0-45.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-2.wav\n",
            "UrbanSound8K/audio/fold6/39884-5-0-4.wav\n",
            "UrbanSound8K/audio/fold6/106486-5-0-2.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-3.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-10.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-45.wav\n",
            "UrbanSound8K/audio/fold6/46299-2-0-36.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-34.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-5.wav\n",
            "UrbanSound8K/audio/fold6/194321-9-0-126.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-70.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-9-0.wav\n",
            "UrbanSound8K/audio/fold6/9032-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/9032-3-2-0.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-12.wav\n",
            "UrbanSound8K/audio/fold6/148835-6-3-0.wav\n",
            "UrbanSound8K/audio/fold6/71079-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-75.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-3.wav\n",
            "UrbanSound8K/audio/fold6/161923-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/189986-0-0-0.wav\n",
            "UrbanSound8K/audio/fold6/155212-9-1-75.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-3.wav\n",
            "UrbanSound8K/audio/fold6/190680-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-23.wav\n",
            "UrbanSound8K/audio/fold6/193697-2-0-99.wav\n",
            "UrbanSound8K/audio/fold6/97331-2-0-13.wav\n",
            "UrbanSound8K/audio/fold6/28284-3-1-0.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-1.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-10.wav\n",
            "UrbanSound8K/audio/fold6/29932-1-1-0.wav\n",
            "UrbanSound8K/audio/fold6/118072-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-2.wav\n",
            "UrbanSound8K/audio/fold6/110868-9-0-11.wav\n",
            "UrbanSound8K/audio/fold6/24364-4-0-6.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-0-0.wav\n",
            "UrbanSound8K/audio/fold6/51027-3-0-9.wav\n",
            "UrbanSound8K/audio/fold6/128465-1-0-0.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-23.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-5.wav\n",
            "UrbanSound8K/audio/fold6/101281-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/97331-2-0-55.wav\n",
            "UrbanSound8K/audio/fold6/159702-6-0-0.wav\n",
            "UrbanSound8K/audio/fold6/62564-5-0-2.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-1-0.wav\n",
            "UrbanSound8K/audio/fold6/109233-3-0-3.wav\n",
            "UrbanSound8K/audio/fold6/204919-3-4-0.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-2-3.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-0-1.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-17-0.wav\n",
            "UrbanSound8K/audio/fold6/58005-4-0-24.wav\n",
            "UrbanSound8K/audio/fold6/44325-9-0-21.wav\n",
            "UrbanSound8K/audio/fold6/110868-9-0-15.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-21.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-10-0.wav\n",
            "UrbanSound8K/audio/fold6/132162-9-1-63.wav\n",
            "UrbanSound8K/audio/fold6/111386-5-1-13.wav\n",
            "UrbanSound8K/audio/fold6/161923-3-0-19.wav\n",
            "UrbanSound8K/audio/fold6/98680-9-0-3.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-4-2.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-29.wav\n",
            "UrbanSound8K/audio/fold6/159702-6-3-0.wav\n",
            "UrbanSound8K/audio/fold6/83680-5-0-3.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-1.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-12.wav\n",
            "UrbanSound8K/audio/fold6/35548-9-0-10.wav\n",
            "UrbanSound8K/audio/fold6/85249-2-0-10.wav\n",
            "UrbanSound8K/audio/fold6/52882-2-0-3.wav\n",
            "UrbanSound8K/audio/fold6/196077-2-0-1.wav\n",
            "UrbanSound8K/audio/fold6/28284-3-0-1.wav\n",
            "UrbanSound8K/audio/fold6/34952-8-0-5.wav\n",
            "UrbanSound8K/audio/fold6/43802-1-1-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-37.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-2.wav\n",
            "UrbanSound8K/audio/fold6/135544-6-12-0.wav\n",
            "UrbanSound8K/audio/fold6/166931-4-2-13.wav\n",
            "UrbanSound8K/audio/fold6/35548-9-2-7.wav\n",
            "UrbanSound8K/audio/fold6/69962-2-0-11.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-7.wav\n",
            "UrbanSound8K/audio/fold6/193697-2-0-110.wav\n",
            "UrbanSound8K/audio/fold6/97331-2-0-50.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-9-1.wav\n",
            "UrbanSound8K/audio/fold6/131918-7-0-4.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-8.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-0-31.wav\n",
            "UrbanSound8K/audio/fold6/71079-4-1-0.wav\n",
            "UrbanSound8K/audio/fold6/39884-5-0-5.wav\n",
            "UrbanSound8K/audio/fold6/63724-0-0-3.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-88.wav\n",
            "UrbanSound8K/audio/fold6/34643-4-2-2.wav\n",
            "UrbanSound8K/audio/fold6/31973-9-0-57.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-17.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-27.wav\n",
            "UrbanSound8K/audio/fold6/203355-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-6-4.wav\n",
            "UrbanSound8K/audio/fold6/36902-3-0-0.wav\n",
            "UrbanSound8K/audio/fold6/82368-2-0-10.wav\n",
            "UrbanSound8K/audio/fold6/54697-7-0-2.wav\n",
            "UrbanSound8K/audio/fold6/51027-3-0-7.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-7.wav\n",
            "UrbanSound8K/audio/fold6/132021-7-0-1.wav\n",
            "UrbanSound8K/audio/fold6/66623-4-0-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-33.wav\n",
            "UrbanSound8K/audio/fold6/193697-2-0-5.wav\n",
            "UrbanSound8K/audio/fold6/52882-2-0-0.wav\n",
            "UrbanSound8K/audio/fold6/71088-4-2-0.wav\n",
            "UrbanSound8K/audio/fold6/137969-2-0-20.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-112.wav\n",
            "UrbanSound8K/audio/fold6/108638-9-0-2.wav\n",
            "UrbanSound8K/audio/fold6/124389-8-1-1.wav\n",
            "UrbanSound8K/audio/fold6/66623-4-0-2.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-82.wav\n",
            "UrbanSound8K/audio/fold6/66623-4-0-4.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-21.wav\n",
            "UrbanSound8K/audio/fold6/184805-0-0-104.wav\n",
            "UrbanSound8K/audio/fold6/54697-7-0-0.wav\n",
            "UrbanSound8K/audio/fold6/74726-8-0-5.wav\n",
            "UrbanSound8K/audio/fold6/46299-2-0-0.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-22.wav\n",
            "UrbanSound8K/audio/fold6/161923-3-0-12.wav\n",
            "UrbanSound8K/audio/fold6/51027-3-1-1.wav\n",
            "UrbanSound8K/audio/fold6/30206-7-0-35.wav\n",
            "UrbanSound8K/audio/fold6/194321-9-0-100.wav\n",
            "UrbanSound8K/audio/fold6/167701-4-6-1.wav\n",
            "UrbanSound8K/audio/fold6/94632-5-1-18.wav\n",
            "UrbanSound8K/audio/fold6/121285-0-0-8.wav\n",
            "UrbanSound8K/audio/fold6/204240-0-0-10.wav\n",
            "UrbanSound8K/audio/fold6/135160-8-0-3.wav\n",
            "UrbanSound8K/audio/fold6/78651-5-0-5.wav\n",
            "UrbanSound8K/audio/fold6/98680-9-0-2.wav\n",
            "UrbanSound8K/audio/fold6/132162-9-1-3.wav\n",
            "UrbanSound8K/audio/fold9/207211-2-0-72.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-1.wav\n",
            "UrbanSound8K/audio/fold9/159726-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159735-2-0-121.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-4.wav\n",
            "UrbanSound8K/audio/fold9/174786-2-0-60.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-13-0.wav\n",
            "UrbanSound8K/audio/fold9/99500-2-0-50.wav\n",
            "UrbanSound8K/audio/fold9/81722-3-0-22.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-7.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-5.wav\n",
            "UrbanSound8K/audio/fold9/145390-9-0-7.wav\n",
            "UrbanSound8K/audio/fold9/14111-4-0-1.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-135.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-2-1.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-3.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-5-0.wav\n",
            "UrbanSound8K/audio/fold9/39532-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/177620-3-0-20.wav\n",
            "UrbanSound8K/audio/fold9/59800-3-2-0.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-9.wav\n",
            "UrbanSound8K/audio/fold9/119449-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/168906-9-0-95.wav\n",
            "UrbanSound8K/audio/fold9/119449-5-0-3.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-0-1.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-1-0.wav\n",
            "UrbanSound8K/audio/fold9/157801-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/171406-9-0-183.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-6.wav\n",
            "UrbanSound8K/audio/fold9/171406-9-0-57.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-24.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-16.wav\n",
            "UrbanSound8K/audio/fold9/14527-9-0-7.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-3-4.wav\n",
            "UrbanSound8K/audio/fold9/116483-3-0-1.wav\n",
            "UrbanSound8K/audio/fold9/26185-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-9.wav\n",
            "UrbanSound8K/audio/fold9/149255-9-0-0.wav\n",
            "UrbanSound8K/audio/fold9/42101-1-1-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-9.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-20.wav\n",
            "UrbanSound8K/audio/fold9/7063-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/149929-9-0-0.wav\n",
            "UrbanSound8K/audio/fold9/18592-5-0-4.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-5.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-20.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-16.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-3.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-6.wav\n",
            "UrbanSound8K/audio/fold9/110389-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-0.wav\n",
            "UrbanSound8K/audio/fold9/52411-9-0-52.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-27.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-9.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-18.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-1-0.wav\n",
            "UrbanSound8K/audio/fold9/152588-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-138.wav\n",
            "UrbanSound8K/audio/fold9/189988-0-0-3.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-10.wav\n",
            "UrbanSound8K/audio/fold9/207211-2-0-89.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-0-2.wav\n",
            "UrbanSound8K/audio/fold9/18592-5-0-3.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-9.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-1-2.wav\n",
            "UrbanSound8K/audio/fold9/174786-2-0-75.wav\n",
            "UrbanSound8K/audio/fold9/174287-6-1-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-63.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-9.wav\n",
            "UrbanSound8K/audio/fold9/66601-8-0-3.wav\n",
            "UrbanSound8K/audio/fold9/149255-9-0-13.wav\n",
            "UrbanSound8K/audio/fold9/174786-2-0-89.wav\n",
            "UrbanSound8K/audio/fold9/189989-0-0-1.wav\n",
            "UrbanSound8K/audio/fold9/184449-2-0-12.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-7.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-3.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-3.wav\n",
            "UrbanSound8K/audio/fold9/42953-9-0-28.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-1.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-2.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-0-0.wav\n",
            "UrbanSound8K/audio/fold9/96921-9-0-18.wav\n",
            "UrbanSound8K/audio/fold9/81117-4-0-1.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-8-0.wav\n",
            "UrbanSound8K/audio/fold9/119809-7-0-0.wav\n",
            "UrbanSound8K/audio/fold9/119449-5-0-6.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-10.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-21.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-23.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-3-2.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-37.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-5-2.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-0-19.wav\n",
            "UrbanSound8K/audio/fold9/96921-9-0-4.wav\n",
            "UrbanSound8K/audio/fold9/14385-9-0-10.wav\n",
            "UrbanSound8K/audio/fold9/14527-9-0-4.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-7.wav\n",
            "UrbanSound8K/audio/fold9/81117-4-0-3.wav\n",
            "UrbanSound8K/audio/fold9/81722-3-0-21.wav\n",
            "UrbanSound8K/audio/fold9/159755-8-0-1.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-0-20.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-136.wav\n",
            "UrbanSound8K/audio/fold9/76640-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/149929-9-1-1.wav\n",
            "UrbanSound8K/audio/fold9/190894-2-0-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-56.wav\n",
            "UrbanSound8K/audio/fold9/50223-3-0-1.wav\n",
            "UrbanSound8K/audio/fold9/161005-2-0-6.wav\n",
            "UrbanSound8K/audio/fold9/155242-9-0-35.wav\n",
            "UrbanSound8K/audio/fold9/185374-9-0-35.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-2.wav\n",
            "UrbanSound8K/audio/fold9/94182-9-0-25.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-22.wav\n",
            "UrbanSound8K/audio/fold9/119449-5-0-2.wav\n",
            "UrbanSound8K/audio/fold9/159735-2-0-22.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-2.wav\n",
            "UrbanSound8K/audio/fold9/57105-3-4-4.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-10-0.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-2-0.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-5-4.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-5.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-3.wav\n",
            "UrbanSound8K/audio/fold9/12812-5-0-1.wav\n",
            "UrbanSound8K/audio/fold9/155044-9-0-38.wav\n",
            "UrbanSound8K/audio/fold9/85661-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/155044-9-0-19.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-6-0.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-3-9.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-4-1.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-1-0.wav\n",
            "UrbanSound8K/audio/fold9/18592-5-0-2.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-2.wav\n",
            "UrbanSound8K/audio/fold9/99500-2-0-11.wav\n",
            "UrbanSound8K/audio/fold9/18592-5-0-1.wav\n",
            "UrbanSound8K/audio/fold9/159707-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/152588-3-2-0.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-26.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-15.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-1-12.wav\n",
            "UrbanSound8K/audio/fold9/184449-2-0-28.wav\n",
            "UrbanSound8K/audio/fold9/149255-9-0-7.wav\n",
            "UrbanSound8K/audio/fold9/13579-2-0-48.wav\n",
            "UrbanSound8K/audio/fold9/119809-7-0-4.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-1-1.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-1.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-4.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-0-0.wav\n",
            "UrbanSound8K/audio/fold9/94182-9-0-20.wav\n",
            "UrbanSound8K/audio/fold9/94182-9-0-10.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-0-13.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-3-6.wav\n",
            "UrbanSound8K/audio/fold9/81722-3-0-28.wav\n",
            "UrbanSound8K/audio/fold9/168906-9-0-47.wav\n",
            "UrbanSound8K/audio/fold9/189989-0-0-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-6.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-11-0.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-6-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-10.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-6.wav\n",
            "UrbanSound8K/audio/fold9/155044-9-0-3.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-1.wav\n",
            "UrbanSound8K/audio/fold9/196058-2-0-0.wav\n",
            "UrbanSound8K/audio/fold9/42953-9-0-50.wav\n",
            "UrbanSound8K/audio/fold9/192123-2-0-10.wav\n",
            "UrbanSound8K/audio/fold9/39532-4-1-0.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-10.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-1-3.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-17.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-122.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-3.wav\n",
            "UrbanSound8K/audio/fold9/59800-3-3-1.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-2.wav\n",
            "UrbanSound8K/audio/fold9/81117-4-0-2.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-6-0.wav\n",
            "UrbanSound8K/audio/fold9/94182-9-0-9.wav\n",
            "UrbanSound8K/audio/fold9/14385-9-0-11.wav\n",
            "UrbanSound8K/audio/fold9/119809-7-0-6.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-16.wav\n",
            "UrbanSound8K/audio/fold9/168906-9-0-28.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-106.wav\n",
            "UrbanSound8K/audio/fold9/57105-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-60.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-134.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-25.wav\n",
            "UrbanSound8K/audio/fold9/26186-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-3-0.wav\n",
            "UrbanSound8K/audio/fold9/152570-9-1-41.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-1-3.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-10.wav\n",
            "UrbanSound8K/audio/fold9/185374-9-0-60.wav\n",
            "UrbanSound8K/audio/fold9/155044-9-0-15.wav\n",
            "UrbanSound8K/audio/fold9/149255-9-0-3.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-14.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-8.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-9.wav\n",
            "UrbanSound8K/audio/fold9/174287-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-9.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-48.wav\n",
            "UrbanSound8K/audio/fold9/145390-9-0-26.wav\n",
            "UrbanSound8K/audio/fold9/13579-2-0-16.wav\n",
            "UrbanSound8K/audio/fold9/59037-2-2-0.wav\n",
            "UrbanSound8K/audio/fold9/174786-2-0-30.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-2.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-1.wav\n",
            "UrbanSound8K/audio/fold9/149929-9-0-5.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-1.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-8.wav\n",
            "UrbanSound8K/audio/fold9/174786-2-0-19.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-3-0.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-1-1.wav\n",
            "UrbanSound8K/audio/fold9/54823-3-2-1.wav\n",
            "UrbanSound8K/audio/fold9/187378-3-0-30.wav\n",
            "UrbanSound8K/audio/fold9/207211-2-0-11.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-6.wav\n",
            "UrbanSound8K/audio/fold9/161005-2-0-27.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-24.wav\n",
            "UrbanSound8K/audio/fold9/60935-2-0-4.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-7.wav\n",
            "UrbanSound8K/audio/fold9/192123-2-0-11.wav\n",
            "UrbanSound8K/audio/fold9/98859-7-1-0.wav\n",
            "UrbanSound8K/audio/fold9/155242-9-0-27.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-8.wav\n",
            "UrbanSound8K/audio/fold9/99500-2-0-1.wav\n",
            "UrbanSound8K/audio/fold9/59037-2-4-8.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-8.wav\n",
            "UrbanSound8K/audio/fold9/14385-9-0-17.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-10.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-16-0.wav\n",
            "UrbanSound8K/audio/fold9/152570-9-1-42.wav\n",
            "UrbanSound8K/audio/fold9/22885-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/171406-9-0-23.wav\n",
            "UrbanSound8K/audio/fold9/54187-1-0-1.wav\n",
            "UrbanSound8K/audio/fold9/116483-3-0-2.wav\n",
            "UrbanSound8K/audio/fold9/99500-2-0-39.wav\n",
            "UrbanSound8K/audio/fold9/50223-3-0-3.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-4.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-11.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-4.wav\n",
            "UrbanSound8K/audio/fold9/194310-9-0-7.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-14.wav\n",
            "UrbanSound8K/audio/fold9/59037-2-4-5.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-7.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-41.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-52.wav\n",
            "UrbanSound8K/audio/fold9/187378-3-0-12.wav\n",
            "UrbanSound8K/audio/fold9/57105-3-0-1.wav\n",
            "UrbanSound8K/audio/fold9/155044-9-0-11.wav\n",
            "UrbanSound8K/audio/fold9/165567-3-4-0.wav\n",
            "UrbanSound8K/audio/fold9/72265-3-5-0.wav\n",
            "UrbanSound8K/audio/fold9/54187-1-0-2.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-1-3.wav\n",
            "UrbanSound8K/audio/fold9/50414-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/52171-3-6-0.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-10.wav\n",
            "UrbanSound8K/audio/fold9/185374-9-0-16.wav\n",
            "UrbanSound8K/audio/fold9/145683-6-5-0.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-4.wav\n",
            "UrbanSound8K/audio/fold9/105088-3-0-19.wav\n",
            "UrbanSound8K/audio/fold9/177620-3-0-25.wav\n",
            "UrbanSound8K/audio/fold9/33641-3-9-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-16.wav\n",
            "UrbanSound8K/audio/fold9/174287-6-2-0.wav\n",
            "UrbanSound8K/audio/fold9/155130-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-33.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-8.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-2-9.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-15.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-13.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-1-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-4.wav\n",
            "UrbanSound8K/audio/fold9/174786-2-0-27.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-1.wav\n",
            "UrbanSound8K/audio/fold9/192123-2-0-17.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-9-0.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-7-0.wav\n",
            "UrbanSound8K/audio/fold9/66601-8-0-5.wav\n",
            "UrbanSound8K/audio/fold9/52171-3-6-1.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-16.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-2.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-25.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-17.wav\n",
            "UrbanSound8K/audio/fold9/155130-1-1-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-4-2.wav\n",
            "UrbanSound8K/audio/fold9/18592-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/87562-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-4.wav\n",
            "UrbanSound8K/audio/fold9/192123-2-0-22.wav\n",
            "UrbanSound8K/audio/fold9/184575-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-6.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-0-13.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-5.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-5.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-0-12.wav\n",
            "UrbanSound8K/audio/fold9/152570-9-1-81.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-0-4.wav\n",
            "UrbanSound8K/audio/fold9/71082-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/137803-3-0-2.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-8-0.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-3.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-2.wav\n",
            "UrbanSound8K/audio/fold9/79584-3-0-5.wav\n",
            "UrbanSound8K/audio/fold9/98859-7-2-5.wav\n",
            "UrbanSound8K/audio/fold9/73168-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-5.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-24.wav\n",
            "UrbanSound8K/audio/fold9/14111-4-0-4.wav\n",
            "UrbanSound8K/audio/fold9/60935-2-0-15.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-6.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-15.wav\n",
            "UrbanSound8K/audio/fold9/54823-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-5.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-13.wav\n",
            "UrbanSound8K/audio/fold9/171406-9-0-7.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-12-0.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-7.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-27.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/96921-9-0-17.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-4.wav\n",
            "UrbanSound8K/audio/fold9/178118-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/204067-2-0-29.wav\n",
            "UrbanSound8K/audio/fold9/60935-2-0-12.wav\n",
            "UrbanSound8K/audio/fold9/42953-9-0-49.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-7.wav\n",
            "UrbanSound8K/audio/fold9/14385-9-0-14.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/168906-9-0-128.wav\n",
            "UrbanSound8K/audio/fold9/61250-3-0-36.wav\n",
            "UrbanSound8K/audio/fold9/189988-0-0-5.wav\n",
            "UrbanSound8K/audio/fold9/106955-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-28.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-0-4.wav\n",
            "UrbanSound8K/audio/fold9/192123-2-0-0.wav\n",
            "UrbanSound8K/audio/fold9/165567-3-3-0.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-6.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-9.wav\n",
            "UrbanSound8K/audio/fold9/185374-9-0-30.wav\n",
            "UrbanSound8K/audio/fold9/69777-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-1-6.wav\n",
            "UrbanSound8K/audio/fold9/59800-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/204067-2-0-39.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-5.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-36.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-40.wav\n",
            "UrbanSound8K/audio/fold9/85664-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-6.wav\n",
            "UrbanSound8K/audio/fold9/14385-9-0-13.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-18.wav\n",
            "UrbanSound8K/audio/fold9/52411-9-0-6.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-28.wav\n",
            "UrbanSound8K/audio/fold9/69777-3-0-1.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-1-54.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-0-14.wav\n",
            "UrbanSound8K/audio/fold9/196066-2-0-0.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-2-0.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-5.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-26.wav\n",
            "UrbanSound8K/audio/fold9/161005-2-0-14.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-1.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-1-2.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-14.wav\n",
            "UrbanSound8K/audio/fold9/137803-3-0-1.wav\n",
            "UrbanSound8K/audio/fold9/174282-6-2-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-19.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-6-0.wav\n",
            "UrbanSound8K/audio/fold9/33641-3-7-0.wav\n",
            "UrbanSound8K/audio/fold9/145683-6-2-0.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-1-47.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-1-1.wav\n",
            "UrbanSound8K/audio/fold9/99500-2-0-2.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-3-1.wav\n",
            "UrbanSound8K/audio/fold9/42953-9-0-16.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-8.wav\n",
            "UrbanSound8K/audio/fold9/190894-2-0-2.wav\n",
            "UrbanSound8K/audio/fold9/164625-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/79584-3-1-2.wav\n",
            "UrbanSound8K/audio/fold9/184449-2-0-24.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-75.wav\n",
            "UrbanSound8K/audio/fold9/119449-5-0-1.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-1-27.wav\n",
            "UrbanSound8K/audio/fold9/194310-9-0-3.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-12.wav\n",
            "UrbanSound8K/audio/fold9/52740-3-0-1.wav\n",
            "UrbanSound8K/audio/fold9/99500-2-0-41.wav\n",
            "UrbanSound8K/audio/fold9/69777-3-0-2.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-0-3.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-3.wav\n",
            "UrbanSound8K/audio/fold9/190894-2-0-4.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-22.wav\n",
            "UrbanSound8K/audio/fold9/52171-3-2-0.wav\n",
            "UrbanSound8K/audio/fold9/159735-2-0-11.wav\n",
            "UrbanSound8K/audio/fold9/14111-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-6.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-3-12.wav\n",
            "UrbanSound8K/audio/fold9/14111-4-0-6.wav\n",
            "UrbanSound8K/audio/fold9/145390-9-0-3.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-10.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-3.wav\n",
            "UrbanSound8K/audio/fold9/194310-9-0-8.wav\n",
            "UrbanSound8K/audio/fold9/98859-7-0-0.wav\n",
            "UrbanSound8K/audio/fold9/14111-4-0-3.wav\n",
            "UrbanSound8K/audio/fold9/127538-4-1-0.wav\n",
            "UrbanSound8K/audio/fold9/194310-9-0-35.wav\n",
            "UrbanSound8K/audio/fold9/98859-7-2-1.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-12.wav\n",
            "UrbanSound8K/audio/fold9/119449-5-0-5.wav\n",
            "UrbanSound8K/audio/fold9/184575-3-0-1.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-12.wav\n",
            "UrbanSound8K/audio/fold9/119809-7-0-2.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-32.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-1.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-9.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-19.wav\n",
            "UrbanSound8K/audio/fold9/7975-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/79584-3-0-8.wav\n",
            "UrbanSound8K/audio/fold9/14111-4-0-7.wav\n",
            "UrbanSound8K/audio/fold9/13579-2-0-2.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-6.wav\n",
            "UrbanSound8K/audio/fold9/16772-8-0-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-0-5.wav\n",
            "UrbanSound8K/audio/fold9/13579-2-0-53.wav\n",
            "UrbanSound8K/audio/fold9/14527-9-0-3.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-70.wav\n",
            "UrbanSound8K/audio/fold9/149929-9-1-4.wav\n",
            "UrbanSound8K/audio/fold9/207211-2-0-88.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-19.wav\n",
            "UrbanSound8K/audio/fold9/175915-3-0-3.wav\n",
            "UrbanSound8K/audio/fold9/94182-9-0-16.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-2-1.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-1-1.wav\n",
            "UrbanSound8K/audio/fold9/42953-9-0-37.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-4.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-11.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-2.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-14.wav\n",
            "UrbanSound8K/audio/fold9/52411-9-0-79.wav\n",
            "UrbanSound8K/audio/fold9/25038-6-1-0.wav\n",
            "UrbanSound8K/audio/fold9/81117-4-0-5.wav\n",
            "UrbanSound8K/audio/fold9/189988-0-0-0.wav\n",
            "UrbanSound8K/audio/fold9/59800-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-0.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-16.wav\n",
            "UrbanSound8K/audio/fold9/60935-2-0-14.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-6.wav\n",
            "UrbanSound8K/audio/fold9/152570-9-1-63.wav\n",
            "UrbanSound8K/audio/fold9/81117-4-0-4.wav\n",
            "UrbanSound8K/audio/fold9/54187-1-0-3.wav\n",
            "UrbanSound8K/audio/fold9/94182-9-0-23.wav\n",
            "UrbanSound8K/audio/fold9/178118-3-2-0.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-2-2.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-5.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-1.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-3-7.wav\n",
            "UrbanSound8K/audio/fold9/149929-9-1-0.wav\n",
            "UrbanSound8K/audio/fold9/72265-3-4-0.wav\n",
            "UrbanSound8K/audio/fold9/96921-9-0-11.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-11.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-11.wav\n",
            "UrbanSound8K/audio/fold9/52740-3-0-2.wav\n",
            "UrbanSound8K/audio/fold9/175915-3-0-1.wav\n",
            "UrbanSound8K/audio/fold9/42371-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-14.wav\n",
            "UrbanSound8K/audio/fold9/145390-9-0-34.wav\n",
            "UrbanSound8K/audio/fold9/184449-2-0-19.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-1-0.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-1-5.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-1-0.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-12.wav\n",
            "UrbanSound8K/audio/fold9/190894-2-0-5.wav\n",
            "UrbanSound8K/audio/fold9/152588-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-12.wav\n",
            "UrbanSound8K/audio/fold9/171406-9-0-124.wav\n",
            "UrbanSound8K/audio/fold9/204067-2-0-32.wav\n",
            "UrbanSound8K/audio/fold9/189988-0-0-1.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-14-0.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-1-0.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-7.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-3-0.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-8.wav\n",
            "UrbanSound8K/audio/fold9/204067-2-0-35.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-8.wav\n",
            "UrbanSound8K/audio/fold9/155242-9-0-44.wav\n",
            "UrbanSound8K/audio/fold9/99500-2-0-29.wav\n",
            "UrbanSound8K/audio/fold9/52411-9-0-64.wav\n",
            "UrbanSound8K/audio/fold9/184575-3-0-3.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-25.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-19-0.wav\n",
            "UrbanSound8K/audio/fold9/196066-2-0-1.wav\n",
            "UrbanSound8K/audio/fold9/52411-9-0-66.wav\n",
            "UrbanSound8K/audio/fold9/204067-2-0-1.wav\n",
            "UrbanSound8K/audio/fold9/22882-5-0-1.wav\n",
            "UrbanSound8K/audio/fold9/159735-2-0-34.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-13.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-5-0.wav\n",
            "UrbanSound8K/audio/fold9/189989-0-0-2.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-2.wav\n",
            "UrbanSound8K/audio/fold9/14111-4-0-2.wav\n",
            "UrbanSound8K/audio/fold9/119420-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/70098-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/171406-9-0-90.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-7.wav\n",
            "UrbanSound8K/audio/fold9/159735-2-0-9.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-18.wav\n",
            "UrbanSound8K/audio/fold9/159755-8-0-3.wav\n",
            "UrbanSound8K/audio/fold9/207211-2-0-58.wav\n",
            "UrbanSound8K/audio/fold9/148166-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-1-1.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-18.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-12.wav\n",
            "UrbanSound8K/audio/fold9/138468-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-5.wav\n",
            "UrbanSound8K/audio/fold9/54187-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-2.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-0.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-17.wav\n",
            "UrbanSound8K/audio/fold9/26185-1-1-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-73.wav\n",
            "UrbanSound8K/audio/fold9/39532-4-2-0.wav\n",
            "UrbanSound8K/audio/fold9/175915-3-1-8.wav\n",
            "UrbanSound8K/audio/fold9/99500-2-0-23.wav\n",
            "UrbanSound8K/audio/fold9/70098-3-3-0.wav\n",
            "UrbanSound8K/audio/fold9/119809-7-0-3.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-92.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-28.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-2-0.wav\n",
            "UrbanSound8K/audio/fold9/127538-4-2-0.wav\n",
            "UrbanSound8K/audio/fold9/175843-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-4.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-4.wav\n",
            "UrbanSound8K/audio/fold9/184449-2-0-33.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-0-2.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-0-1.wav\n",
            "UrbanSound8K/audio/fold9/165567-3-2-0.wav\n",
            "UrbanSound8K/audio/fold9/98859-7-2-2.wav\n",
            "UrbanSound8K/audio/fold9/52171-3-3-0.wav\n",
            "UrbanSound8K/audio/fold9/184449-2-0-16.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-20-0.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-9.wav\n",
            "UrbanSound8K/audio/fold9/174282-6-1-0.wav\n",
            "UrbanSound8K/audio/fold9/60935-2-0-13.wav\n",
            "UrbanSound8K/audio/fold9/14527-9-0-5.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-21.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-8-0.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-6.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-9.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-3-0.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-14.wav\n",
            "UrbanSound8K/audio/fold9/54187-1-0-4.wav\n",
            "UrbanSound8K/audio/fold9/168906-9-0-73.wav\n",
            "UrbanSound8K/audio/fold9/190894-2-0-3.wav\n",
            "UrbanSound8K/audio/fold9/33641-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/159735-2-0-80.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-19.wav\n",
            "UrbanSound8K/audio/fold9/79584-3-0-4.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-12.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-10.wav\n",
            "UrbanSound8K/audio/fold9/81722-3-0-26.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-13.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-12.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-7.wav\n",
            "UrbanSound8K/audio/fold9/155242-9-0-4.wav\n",
            "UrbanSound8K/audio/fold9/185374-9-0-18.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-11.wav\n",
            "UrbanSound8K/audio/fold9/72265-3-15-0.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-19.wav\n",
            "UrbanSound8K/audio/fold9/174282-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-3-9.wav\n",
            "UrbanSound8K/audio/fold9/177620-3-0-21.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-17.wav\n",
            "UrbanSound8K/audio/fold9/149255-9-0-4.wav\n",
            "UrbanSound8K/audio/fold9/94182-9-0-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-43.wav\n",
            "UrbanSound8K/audio/fold9/73168-1-1-0.wav\n",
            "UrbanSound8K/audio/fold9/66601-8-0-4.wav\n",
            "UrbanSound8K/audio/fold9/177620-3-0-8.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-6.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-26.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-1-20.wav\n",
            "UrbanSound8K/audio/fold9/145390-9-0-22.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-19.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-1-2.wav\n",
            "UrbanSound8K/audio/fold9/12812-5-0-2.wav\n",
            "UrbanSound8K/audio/fold9/204067-2-0-30.wav\n",
            "UrbanSound8K/audio/fold9/137803-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/61250-3-0-47.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-15.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-22.wav\n",
            "UrbanSound8K/audio/fold9/185374-9-0-23.wav\n",
            "UrbanSound8K/audio/fold9/207211-2-0-100.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-8.wav\n",
            "UrbanSound8K/audio/fold9/137815-4-0-3.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-23.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-21.wav\n",
            "UrbanSound8K/audio/fold9/161005-2-0-19.wav\n",
            "UrbanSound8K/audio/fold9/66601-8-0-2.wav\n",
            "UrbanSound8K/audio/fold9/190894-2-0-6.wav\n",
            "UrbanSound8K/audio/fold9/184449-2-0-15.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-0-4.wav\n",
            "UrbanSound8K/audio/fold9/33641-3-8-0.wav\n",
            "UrbanSound8K/audio/fold9/145390-9-0-13.wav\n",
            "UrbanSound8K/audio/fold9/14527-9-0-2.wav\n",
            "UrbanSound8K/audio/fold9/184449-2-0-13.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-15-0.wav\n",
            "UrbanSound8K/audio/fold9/59037-2-3-0.wav\n",
            "UrbanSound8K/audio/fold9/105088-3-0-10.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-11-0.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-3.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-11.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-2-2.wav\n",
            "UrbanSound8K/audio/fold9/190894-2-0-8.wav\n",
            "UrbanSound8K/audio/fold9/50223-3-0-10.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-7.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-2.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-5.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-2-2.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-7.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-10.wav\n",
            "UrbanSound8K/audio/fold9/70098-3-2-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-0.wav\n",
            "UrbanSound8K/audio/fold9/50223-3-0-6.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-0.wav\n",
            "UrbanSound8K/audio/fold9/146249-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/149929-9-0-2.wav\n",
            "UrbanSound8K/audio/fold9/161005-2-0-0.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-0-0.wav\n",
            "UrbanSound8K/audio/fold9/27068-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-3.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-1.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-12.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-4.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-0-3.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-4-0.wav\n",
            "UrbanSound8K/audio/fold9/155312-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-17.wav\n",
            "UrbanSound8K/audio/fold9/71082-4-1-0.wav\n",
            "UrbanSound8K/audio/fold9/174287-6-3-0.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-9.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-5-0.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-11.wav\n",
            "UrbanSound8K/audio/fold9/39532-4-3-0.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-5-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-15.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-13.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-5.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-40.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-3-3.wav\n",
            "UrbanSound8K/audio/fold9/192123-2-0-18.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-8.wav\n",
            "UrbanSound8K/audio/fold9/192123-2-0-4.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-20.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-0-2.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-6.wav\n",
            "UrbanSound8K/audio/fold9/119420-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/189988-0-0-4.wav\n",
            "UrbanSound8K/audio/fold9/61250-3-0-31.wav\n",
            "UrbanSound8K/audio/fold9/22882-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-6.wav\n",
            "UrbanSound8K/audio/fold9/72723-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-123.wav\n",
            "UrbanSound8K/audio/fold9/13579-2-0-15.wav\n",
            "UrbanSound8K/audio/fold9/187378-3-0-7.wav\n",
            "UrbanSound8K/audio/fold9/70098-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/204067-2-0-20.wav\n",
            "UrbanSound8K/audio/fold9/159755-8-0-2.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-4.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-22.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-13.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-1-4.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-2.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-4-1.wav\n",
            "UrbanSound8K/audio/fold9/57105-3-4-2.wav\n",
            "UrbanSound8K/audio/fold9/59037-2-0-6.wav\n",
            "UrbanSound8K/audio/fold9/116483-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/96921-9-0-9.wav\n",
            "UrbanSound8K/audio/fold9/189988-0-0-2.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-10-0.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-4.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-8.wav\n",
            "UrbanSound8K/audio/fold9/103249-5-0-7.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-11.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-1-30.wav\n",
            "UrbanSound8K/audio/fold9/207211-2-0-141.wav\n",
            "UrbanSound8K/audio/fold9/81117-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/14111-4-0-5.wav\n",
            "UrbanSound8K/audio/fold9/116483-3-1-2.wav\n",
            "UrbanSound8K/audio/fold9/145683-6-4-0.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/59037-2-1-2.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-115.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-1-0.wav\n",
            "UrbanSound8K/audio/fold9/152570-9-0-0.wav\n",
            "UrbanSound8K/audio/fold9/175915-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/14527-9-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-0.wav\n",
            "UrbanSound8K/audio/fold9/98859-7-2-3.wav\n",
            "UrbanSound8K/audio/fold9/25038-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/161005-2-0-12.wav\n",
            "UrbanSound8K/audio/fold9/156200-2-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-7.wav\n",
            "UrbanSound8K/audio/fold9/159726-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/174786-2-0-39.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-7-0.wav\n",
            "UrbanSound8K/audio/fold9/159755-8-0-0.wav\n",
            "UrbanSound8K/audio/fold9/13579-2-0-38.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-9-0.wav\n",
            "UrbanSound8K/audio/fold9/190894-2-0-7.wav\n",
            "UrbanSound8K/audio/fold9/159745-8-1-7.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-0.wav\n",
            "UrbanSound8K/audio/fold9/60935-2-0-9.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-0-6.wav\n",
            "UrbanSound8K/audio/fold9/13579-2-0-62.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-2-10.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-29.wav\n",
            "UrbanSound8K/audio/fold9/184575-3-0-2.wav\n",
            "UrbanSound8K/audio/fold9/73168-1-2-0.wav\n",
            "UrbanSound8K/audio/fold9/187075-5-0-4.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-12.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-3.wav\n",
            "UrbanSound8K/audio/fold9/66601-8-0-0.wav\n",
            "UrbanSound8K/audio/fold9/54823-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/61250-3-0-62.wav\n",
            "UrbanSound8K/audio/fold9/159735-2-0-17.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-3-5.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-8.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-2-0.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-2.wav\n",
            "UrbanSound8K/audio/fold9/165454-0-0-1.wav\n",
            "UrbanSound8K/audio/fold9/119809-7-0-1.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-13.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-8.wav\n",
            "UrbanSound8K/audio/fold9/105088-3-0-8.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-3.wav\n",
            "UrbanSound8K/audio/fold9/178118-3-1-0.wav\n",
            "UrbanSound8K/audio/fold9/60935-2-0-11.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-21.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-2-1.wav\n",
            "UrbanSound8K/audio/fold9/59037-2-4-3.wav\n",
            "UrbanSound8K/audio/fold9/175853-1-0-0.wav\n",
            "UrbanSound8K/audio/fold9/192123-2-0-23.wav\n",
            "UrbanSound8K/audio/fold9/185374-9-0-33.wav\n",
            "UrbanSound8K/audio/fold9/54976-4-0-1.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-9-0.wav\n",
            "UrbanSound8K/audio/fold9/161005-2-0-28.wav\n",
            "UrbanSound8K/audio/fold9/72265-3-7-0.wav\n",
            "UrbanSound8K/audio/fold9/204067-2-0-3.wav\n",
            "UrbanSound8K/audio/fold9/12812-5-0-0.wav\n",
            "UrbanSound8K/audio/fold9/159744-8-0-11.wav\n",
            "UrbanSound8K/audio/fold9/66601-8-0-1.wav\n",
            "UrbanSound8K/audio/fold9/187378-3-0-19.wav\n",
            "UrbanSound8K/audio/fold9/207211-2-0-82.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-3-6.wav\n",
            "UrbanSound8K/audio/fold9/62567-5-0-1.wav\n",
            "UrbanSound8K/audio/fold9/152570-9-1-61.wav\n",
            "UrbanSound8K/audio/fold9/180156-1-4-0.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-18.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-39.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-0-7.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-38.wav\n",
            "UrbanSound8K/audio/fold9/157866-8-0-23.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-2-5.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-4-0.wav\n",
            "UrbanSound8K/audio/fold9/194310-9-0-73.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-4-3.wav\n",
            "UrbanSound8K/audio/fold9/145683-6-0-0.wav\n",
            "UrbanSound8K/audio/fold9/14385-9-0-21.wav\n",
            "UrbanSound8K/audio/fold9/161005-2-0-4.wav\n",
            "UrbanSound8K/audio/fold9/60935-2-0-0.wav\n",
            "UrbanSound8K/audio/fold9/165567-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/155044-9-0-37.wav\n",
            "UrbanSound8K/audio/fold9/58937-4-1-0.wav\n",
            "UrbanSound8K/audio/fold9/50414-4-0-1.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-4-0.wav\n",
            "UrbanSound8K/audio/fold9/52411-9-0-4.wav\n",
            "UrbanSound8K/audio/fold9/159735-2-0-99.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-0-11.wav\n",
            "UrbanSound8K/audio/fold9/39856-5-0-23.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-3.wav\n",
            "UrbanSound8K/audio/fold9/52740-3-0-3.wav\n",
            "UrbanSound8K/audio/fold9/180937-4-1-46.wav\n",
            "UrbanSound8K/audio/fold9/59037-2-1-3.wav\n",
            "UrbanSound8K/audio/fold9/119809-7-0-5.wav\n",
            "UrbanSound8K/audio/fold9/105029-7-1-8.wav\n",
            "UrbanSound8K/audio/fold9/101729-0-0-4.wav\n",
            "UrbanSound8K/audio/fold9/174786-2-0-18.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-12-0.wav\n",
            "UrbanSound8K/audio/fold9/149255-9-0-5.wav\n",
            "UrbanSound8K/audio/fold9/145683-6-3-0.wav\n",
            "UrbanSound8K/audio/fold9/155242-9-0-12.wav\n",
            "UrbanSound8K/audio/fold9/13579-2-0-17.wav\n",
            "UrbanSound8K/audio/fold9/152588-3-3-0.wav\n",
            "UrbanSound8K/audio/fold9/52740-3-0-0.wav\n",
            "UrbanSound8K/audio/fold9/14527-9-0-6.wav\n",
            "UrbanSound8K/audio/fold9/194310-9-0-15.wav\n",
            "UrbanSound8K/audio/fold9/155242-9-0-15.wav\n",
            "UrbanSound8K/audio/fold9/145390-9-0-15.wav\n",
            "UrbanSound8K/audio/fold9/119449-5-0-4.wav\n",
            "UrbanSound8K/audio/fold9/188823-7-2-3.wav\n",
            "UrbanSound8K/audio/fold9/168906-9-0-114.wav\n",
            "UrbanSound8K/audio/fold9/127538-4-0-0.wav\n",
            "UrbanSound8K/audio/fold9/145683-6-1-0.wav\n",
            "UrbanSound8K/audio/fold9/159748-8-0-0.wav\n",
            "UrbanSound8K/audio/fold9/96921-9-0-1.wav\n",
            "UrbanSound8K/audio/fold9/75743-0-0-13.wav\n",
            "UrbanSound8K/audio/fold9/79089-0-0-51.wav\n",
            "UrbanSound8K/audio/fold9/136399-6-7-0.wav\n",
            "UrbanSound8K/audio/fold9/105088-3-0-11.wav\n",
            "UrbanSound8K/audio/fold9/98859-7-2-0.wav\n",
            "UrbanSound8K/audio/fold9/98859-7-2-4.wav\n",
            "UrbanSound8K/audio/fold9/180029-4-4-0.wav\n",
            "UrbanSound8K/audio/fold9/42953-9-0-21.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/174873-3-5-13.wav\n",
            "UrbanSound8K/audio/fold8/144028-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/81787-2-0-39.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-5.wav\n",
            "UrbanSound8K/audio/fold8/42324-4-2-4.wav\n",
            "UrbanSound8K/audio/fold8/190996-3-0-1.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-6.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-3-6.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-3-3.wav\n",
            "UrbanSound8K/audio/fold8/36429-2-0-14.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-8.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/204526-2-0-160.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-16.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-0.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-3.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-4-0.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-30.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-64.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-0.wav\n",
            "UrbanSound8K/audio/fold8/196068-2-0-1.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-0.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-1-1.wav\n",
            "UrbanSound8K/audio/fold8/62048-3-0-4.wav\n",
            "UrbanSound8K/audio/fold8/107090-1-1-0.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-15.wav\n",
            "UrbanSound8K/audio/fold8/36429-2-0-13.wav\n",
            "UrbanSound8K/audio/fold8/155313-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/7065-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-2.wav\n",
            "UrbanSound8K/audio/fold8/76266-2-0-7.wav\n",
            "UrbanSound8K/audio/fold8/41364-9-0-18.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-10-0.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-3.wav\n",
            "UrbanSound8K/audio/fold8/66324-9-0-53.wav\n",
            "UrbanSound8K/audio/fold8/159706-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-35.wav\n",
            "UrbanSound8K/audio/fold8/145206-6-5-0.wav\n",
            "UrbanSound8K/audio/fold8/126153-9-0-5.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-5-0.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-2-1.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-5.wav\n",
            "UrbanSound8K/audio/fold8/171243-9-0-91.wav\n",
            "UrbanSound8K/audio/fold8/196561-3-0-44.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-37.wav\n",
            "UrbanSound8K/audio/fold8/189846-3-3-0.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-4.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-7.wav\n",
            "UrbanSound8K/audio/fold8/125520-1-4-0.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-58.wav\n",
            "UrbanSound8K/audio/fold8/145612-6-2-0.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-3.wav\n",
            "UrbanSound8K/audio/fold8/189825-9-0-7.wav\n",
            "UrbanSound8K/audio/fold8/189825-9-0-5.wav\n",
            "UrbanSound8K/audio/fold8/29936-3-3-0.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-0.wav\n",
            "UrbanSound8K/audio/fold8/138465-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-89.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-25.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-4.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-1.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-8.wav\n",
            "UrbanSound8K/audio/fold8/145612-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/7390-9-1-11.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-1-2.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-7-0.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-15.wav\n",
            "UrbanSound8K/audio/fold8/155217-9-0-85.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-3.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-5.wav\n",
            "UrbanSound8K/audio/fold8/7390-9-0-3.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-7.wav\n",
            "UrbanSound8K/audio/fold8/142003-2-0-20.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-12.wav\n",
            "UrbanSound8K/audio/fold8/170022-0-0-1.wav\n",
            "UrbanSound8K/audio/fold8/204526-2-0-166.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-9-0.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-26.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-5-2.wav\n",
            "UrbanSound8K/audio/fold8/164626-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/14386-9-0-2.wav\n",
            "UrbanSound8K/audio/fold8/142003-2-0-19.wav\n",
            "UrbanSound8K/audio/fold8/42324-4-2-1.wav\n",
            "UrbanSound8K/audio/fold8/17009-2-0-1.wav\n",
            "UrbanSound8K/audio/fold8/186935-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-7.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-9.wav\n",
            "UrbanSound8K/audio/fold8/125520-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/169043-2-0-24.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-1.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-4.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-10.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-6.wav\n",
            "UrbanSound8K/audio/fold8/55013-3-0-3.wav\n",
            "UrbanSound8K/audio/fold8/52633-3-0-1.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-17.wav\n",
            "UrbanSound8K/audio/fold8/179039-9-0-4.wav\n",
            "UrbanSound8K/audio/fold8/66599-9-1-21.wav\n",
            "UrbanSound8K/audio/fold8/72221-3-4-1.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-1.wav\n",
            "UrbanSound8K/audio/fold8/29936-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/156358-5-0-4.wav\n",
            "UrbanSound8K/audio/fold8/114280-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-0-1.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-9.wav\n",
            "UrbanSound8K/audio/fold8/24728-7-3-0.wav\n",
            "UrbanSound8K/audio/fold8/54914-2-0-23.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-12.wav\n",
            "UrbanSound8K/audio/fold8/180132-4-1-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-3-5.wav\n",
            "UrbanSound8K/audio/fold8/142003-2-0-8.wav\n",
            "UrbanSound8K/audio/fold8/66324-9-0-42.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-3-7.wav\n",
            "UrbanSound8K/audio/fold8/133090-2-0-20.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-18.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-0.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-2-0.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-61.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-1-3.wav\n",
            "UrbanSound8K/audio/fold8/7068-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/196561-3-0-9.wav\n",
            "UrbanSound8K/audio/fold8/99179-9-0-12.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-14.wav\n",
            "UrbanSound8K/audio/fold8/14386-9-0-20.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-9.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-97.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-11.wav\n",
            "UrbanSound8K/audio/fold8/66324-9-0-4.wav\n",
            "UrbanSound8K/audio/fold8/41364-9-0-27.wav\n",
            "UrbanSound8K/audio/fold8/193699-2-0-33.wav\n",
            "UrbanSound8K/audio/fold8/80589-0-0-2.wav\n",
            "UrbanSound8K/audio/fold8/180132-4-2-0.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-14.wav\n",
            "UrbanSound8K/audio/fold8/171243-9-0-81.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-2-0.wav\n",
            "UrbanSound8K/audio/fold8/179039-9-0-23.wav\n",
            "UrbanSound8K/audio/fold8/72015-2-0-0.wav\n",
            "UrbanSound8K/audio/fold8/174873-3-5-12.wav\n",
            "UrbanSound8K/audio/fold8/16860-9-0-45.wav\n",
            "UrbanSound8K/audio/fold8/95549-3-0-14.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-6.wav\n",
            "UrbanSound8K/audio/fold8/76266-2-0-76.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-8.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-31.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-75.wav\n",
            "UrbanSound8K/audio/fold8/205610-4-0-2.wav\n",
            "UrbanSound8K/audio/fold8/155294-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-21.wav\n",
            "UrbanSound8K/audio/fold8/160016-2-0-26.wav\n",
            "UrbanSound8K/audio/fold8/34866-9-0-11.wav\n",
            "UrbanSound8K/audio/fold8/133090-2-0-28.wav\n",
            "UrbanSound8K/audio/fold8/76266-2-0-46.wav\n",
            "UrbanSound8K/audio/fold8/41364-9-0-23.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-3-2.wav\n",
            "UrbanSound8K/audio/fold8/39967-9-0-0.wav\n",
            "UrbanSound8K/audio/fold8/4918-3-4-0.wav\n",
            "UrbanSound8K/audio/fold8/156358-5-0-3.wav\n",
            "UrbanSound8K/audio/fold8/189825-9-0-2.wav\n",
            "UrbanSound8K/audio/fold8/39967-9-0-100.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-6-0.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-2-0.wav\n",
            "UrbanSound8K/audio/fold8/194733-9-0-14.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-8-0.wav\n",
            "UrbanSound8K/audio/fold8/52284-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-2.wav\n",
            "UrbanSound8K/audio/fold8/110134-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-1.wav\n",
            "UrbanSound8K/audio/fold8/133090-2-0-76.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-20.wav\n",
            "UrbanSound8K/audio/fold8/7390-9-0-9.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-6-0.wav\n",
            "UrbanSound8K/audio/fold8/54914-2-0-26.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-20.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-1-5.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-2.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-93.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-56.wav\n",
            "UrbanSound8K/audio/fold8/175856-1-2-0.wav\n",
            "UrbanSound8K/audio/fold8/26176-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/52633-3-0-9.wav\n",
            "UrbanSound8K/audio/fold8/59595-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/83465-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/44110-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-17.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-2-0.wav\n",
            "UrbanSound8K/audio/fold8/31325-3-3-6.wav\n",
            "UrbanSound8K/audio/fold8/145206-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-7.wav\n",
            "UrbanSound8K/audio/fold8/207214-2-0-126.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-4.wav\n",
            "UrbanSound8K/audio/fold8/171464-3-2-0.wav\n",
            "UrbanSound8K/audio/fold8/7390-9-1-5.wav\n",
            "UrbanSound8K/audio/fold8/122199-3-1-2.wav\n",
            "UrbanSound8K/audio/fold8/133090-2-0-37.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-1-7.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-2.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-6.wav\n",
            "UrbanSound8K/audio/fold8/98536-8-0-0.wav\n",
            "UrbanSound8K/audio/fold8/110688-3-0-17.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-2-0.wav\n",
            "UrbanSound8K/audio/fold8/145206-6-1-0.wav\n",
            "UrbanSound8K/audio/fold8/95549-3-0-6.wav\n",
            "UrbanSound8K/audio/fold8/189825-9-0-0.wav\n",
            "UrbanSound8K/audio/fold8/156358-5-0-2.wav\n",
            "UrbanSound8K/audio/fold8/115240-9-0-1.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-0-2.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-11.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-7.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-2.wav\n",
            "UrbanSound8K/audio/fold8/49974-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-8.wav\n",
            "UrbanSound8K/audio/fold8/16860-9-0-30.wav\n",
            "UrbanSound8K/audio/fold8/205610-4-0-4.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-6.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-3.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-22.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-13.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-7-1.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-1-0.wav\n",
            "UrbanSound8K/audio/fold8/89207-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-1-4.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-2.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-21.wav\n",
            "UrbanSound8K/audio/fold8/54914-2-0-3.wav\n",
            "UrbanSound8K/audio/fold8/156358-5-0-1.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-3.wav\n",
            "UrbanSound8K/audio/fold8/99179-9-0-38.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-22.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/17009-2-0-6.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-27.wav\n",
            "UrbanSound8K/audio/fold8/126153-9-0-11.wav\n",
            "UrbanSound8K/audio/fold8/139000-4-0-1.wav\n",
            "UrbanSound8K/audio/fold8/169043-2-0-21.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-8-0.wav\n",
            "UrbanSound8K/audio/fold8/106905-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/133473-8-0-1.wav\n",
            "UrbanSound8K/audio/fold8/115240-9-0-36.wav\n",
            "UrbanSound8K/audio/fold8/157649-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/54914-2-0-35.wav\n",
            "UrbanSound8K/audio/fold8/155283-1-1-0.wav\n",
            "UrbanSound8K/audio/fold8/106905-5-0-2.wav\n",
            "UrbanSound8K/audio/fold8/72015-2-0-5.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-16.wav\n",
            "UrbanSound8K/audio/fold8/31325-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/31325-3-1-1.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-5-0.wav\n",
            "UrbanSound8K/audio/fold8/145612-6-3-0.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-2.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-14.wav\n",
            "UrbanSound8K/audio/fold8/160016-2-0-5.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-4-0.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-10.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-11.wav\n",
            "UrbanSound8K/audio/fold8/194733-9-0-10.wav\n",
            "UrbanSound8K/audio/fold8/25039-6-1-0.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-4.wav\n",
            "UrbanSound8K/audio/fold8/155217-9-1-24.wav\n",
            "UrbanSound8K/audio/fold8/142003-2-0-24.wav\n",
            "UrbanSound8K/audio/fold8/95549-3-0-20.wav\n",
            "UrbanSound8K/audio/fold8/41364-9-0-11.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-25.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-6.wav\n",
            "UrbanSound8K/audio/fold8/14386-9-0-6.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-6.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/155217-9-0-57.wav\n",
            "UrbanSound8K/audio/fold8/14386-9-0-16.wav\n",
            "UrbanSound8K/audio/fold8/54914-2-0-27.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-94.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-62.wav\n",
            "UrbanSound8K/audio/fold8/96657-8-0-1.wav\n",
            "UrbanSound8K/audio/fold8/70168-3-1-11.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-17.wav\n",
            "UrbanSound8K/audio/fold8/174873-3-5-10.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-23.wav\n",
            "UrbanSound8K/audio/fold8/189846-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/52633-3-0-2.wav\n",
            "UrbanSound8K/audio/fold8/72221-3-4-5.wav\n",
            "UrbanSound8K/audio/fold8/7390-9-0-0.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-3-0.wav\n",
            "UrbanSound8K/audio/fold8/194733-9-0-1.wav\n",
            "UrbanSound8K/audio/fold8/115240-9-0-16.wav\n",
            "UrbanSound8K/audio/fold8/193699-2-0-62.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-4.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-8.wav\n",
            "UrbanSound8K/audio/fold8/160016-2-0-40.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-0-1.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-6.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-8-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-8.wav\n",
            "UrbanSound8K/audio/fold8/157649-3-1-1.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-1.wav\n",
            "UrbanSound8K/audio/fold8/55013-3-0-7.wav\n",
            "UrbanSound8K/audio/fold8/54914-2-0-48.wav\n",
            "UrbanSound8K/audio/fold8/189846-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/17810-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/17810-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-5-0.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-7-0.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-1.wav\n",
            "UrbanSound8K/audio/fold8/175856-1-1-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-0.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-1-0.wav\n",
            "UrbanSound8K/audio/fold8/194733-9-0-11.wav\n",
            "UrbanSound8K/audio/fold8/170022-0-0-0.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-11.wav\n",
            "UrbanSound8K/audio/fold8/81787-2-0-14.wav\n",
            "UrbanSound8K/audio/fold8/122199-3-1-1.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-1-0.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-5.wav\n",
            "UrbanSound8K/audio/fold8/160016-2-0-37.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-116.wav\n",
            "UrbanSound8K/audio/fold8/174285-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/61077-3-3-0.wav\n",
            "UrbanSound8K/audio/fold8/113216-5-0-4.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-13.wav\n",
            "UrbanSound8K/audio/fold8/81787-2-0-4.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-14.wav\n",
            "UrbanSound8K/audio/fold8/146343-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-15-0.wav\n",
            "UrbanSound8K/audio/fold8/174285-6-1-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-5.wav\n",
            "UrbanSound8K/audio/fold8/207214-2-0-63.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-1-0.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-16-0.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-12.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-9.wav\n",
            "UrbanSound8K/audio/fold8/42324-4-2-2.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-1.wav\n",
            "UrbanSound8K/audio/fold8/103076-3-2-0.wav\n",
            "UrbanSound8K/audio/fold8/76266-2-0-80.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-0-2.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-5.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-4.wav\n",
            "UrbanSound8K/audio/fold8/42324-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/145206-6-2-0.wav\n",
            "UrbanSound8K/audio/fold8/61077-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/36429-2-0-18.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-1.wav\n",
            "UrbanSound8K/audio/fold8/157649-3-0-1.wav\n",
            "UrbanSound8K/audio/fold8/196074-2-0-0.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-11.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-2.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-13.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-4-0.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-10.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-37.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-6.wav\n",
            "UrbanSound8K/audio/fold8/14386-9-0-11.wav\n",
            "UrbanSound8K/audio/fold8/207369-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/16860-9-0-28.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-16.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-95.wav\n",
            "UrbanSound8K/audio/fold8/96657-8-0-2.wav\n",
            "UrbanSound8K/audio/fold8/180132-4-3-0.wav\n",
            "UrbanSound8K/audio/fold8/39967-9-0-44.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-1.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-3.wav\n",
            "UrbanSound8K/audio/fold8/196561-3-0-29.wav\n",
            "UrbanSound8K/audio/fold8/171243-9-0-123.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-7-0.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-2-0.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-1-3.wav\n",
            "UrbanSound8K/audio/fold8/95549-3-0-7.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-10.wav\n",
            "UrbanSound8K/audio/fold8/81787-2-0-23.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-134.wav\n",
            "UrbanSound8K/audio/fold8/16860-9-0-50.wav\n",
            "UrbanSound8K/audio/fold8/179039-9-0-30.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-6-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-9.wav\n",
            "UrbanSound8K/audio/fold8/24728-7-0-0.wav\n",
            "UrbanSound8K/audio/fold8/76266-2-0-91.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-7.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-19.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-9-0.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-9.wav\n",
            "UrbanSound8K/audio/fold8/52633-3-0-8.wav\n",
            "UrbanSound8K/audio/fold8/59595-4-0-1.wav\n",
            "UrbanSound8K/audio/fold8/196057-2-0-0.wav\n",
            "UrbanSound8K/audio/fold8/76266-2-0-50.wav\n",
            "UrbanSound8K/audio/fold8/50613-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-7.wav\n",
            "UrbanSound8K/audio/fold8/70168-3-1-20.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-3.wav\n",
            "UrbanSound8K/audio/fold8/81787-2-0-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-9.wav\n",
            "UrbanSound8K/audio/fold8/113216-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/66599-9-1-11.wav\n",
            "UrbanSound8K/audio/fold8/80589-0-0-3.wav\n",
            "UrbanSound8K/audio/fold8/142003-2-0-0.wav\n",
            "UrbanSound8K/audio/fold8/103076-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/62048-3-0-3.wav\n",
            "UrbanSound8K/audio/fold8/175852-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-5.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-13.wav\n",
            "UrbanSound8K/audio/fold8/194733-9-0-12.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-92.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-2.wav\n",
            "UrbanSound8K/audio/fold8/66324-9-0-54.wav\n",
            "UrbanSound8K/audio/fold8/171243-9-0-11.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-11.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-9-0.wav\n",
            "UrbanSound8K/audio/fold8/207214-2-0-26.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-10.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-6.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-6-0.wav\n",
            "UrbanSound8K/audio/fold8/145612-6-1-0.wav\n",
            "UrbanSound8K/audio/fold8/142003-2-0-30.wav\n",
            "UrbanSound8K/audio/fold8/186935-5-0-1.wav\n",
            "UrbanSound8K/audio/fold8/189825-9-0-3.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-7-0.wav\n",
            "UrbanSound8K/audio/fold8/169043-2-0-13.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-69.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-18.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-8.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-57.wav\n",
            "UrbanSound8K/audio/fold8/16860-9-0-8.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-17.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-34.wav\n",
            "UrbanSound8K/audio/fold8/122199-3-1-3.wav\n",
            "UrbanSound8K/audio/fold8/205610-4-0-3.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-3-0.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-13-0.wav\n",
            "UrbanSound8K/audio/fold8/30226-3-1-3.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-10.wav\n",
            "UrbanSound8K/audio/fold8/71700-3-4-0.wav\n",
            "UrbanSound8K/audio/fold8/115240-9-0-4.wav\n",
            "UrbanSound8K/audio/fold8/25039-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/42324-4-2-3.wav\n",
            "UrbanSound8K/audio/fold8/106905-5-0-1.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-1-8.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-36.wav\n",
            "UrbanSound8K/audio/fold8/160016-2-0-13.wav\n",
            "UrbanSound8K/audio/fold8/204526-2-0-153.wav\n",
            "UrbanSound8K/audio/fold8/171243-9-0-31.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-8.wav\n",
            "UrbanSound8K/audio/fold8/207214-2-0-54.wav\n",
            "UrbanSound8K/audio/fold8/66599-9-1-23.wav\n",
            "UrbanSound8K/audio/fold8/110688-3-0-11.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-4.wav\n",
            "UrbanSound8K/audio/fold8/196068-2-0-0.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-1-0.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-2.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-55.wav\n",
            "UrbanSound8K/audio/fold8/7390-9-1-12.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-5.wav\n",
            "UrbanSound8K/audio/fold8/155217-9-0-27.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-1.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-0.wav\n",
            "UrbanSound8K/audio/fold8/156358-5-0-5.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-9.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-23.wav\n",
            "UrbanSound8K/audio/fold8/126153-9-0-8.wav\n",
            "UrbanSound8K/audio/fold8/204526-2-0-193.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-6.wav\n",
            "UrbanSound8K/audio/fold8/66599-9-0-17.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-9.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-27.wav\n",
            "UrbanSound8K/audio/fold8/155217-9-1-58.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-25.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-3.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-1.wav\n",
            "UrbanSound8K/audio/fold8/110688-3-0-2.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-2.wav\n",
            "UrbanSound8K/audio/fold8/113216-5-0-3.wav\n",
            "UrbanSound8K/audio/fold8/42324-4-1-0.wav\n",
            "UrbanSound8K/audio/fold8/99179-9-0-17.wav\n",
            "UrbanSound8K/audio/fold8/107090-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/193699-2-0-69.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-36.wav\n",
            "UrbanSound8K/audio/fold8/175856-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/44110-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-1-2.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-3-1.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-24.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-5-0.wav\n",
            "UrbanSound8K/audio/fold8/169043-2-0-28.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-5.wav\n",
            "UrbanSound8K/audio/fold8/39967-9-0-99.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-6.wav\n",
            "UrbanSound8K/audio/fold8/193699-2-0-54.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-0.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-103.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-7.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-4.wav\n",
            "UrbanSound8K/audio/fold8/76266-2-0-40.wav\n",
            "UrbanSound8K/audio/fold8/71700-3-4-1.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-10.wav\n",
            "UrbanSound8K/audio/fold8/122199-3-1-6.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-4-0.wav\n",
            "UrbanSound8K/audio/fold8/34866-9-0-13.wav\n",
            "UrbanSound8K/audio/fold8/207214-2-0-3.wav\n",
            "UrbanSound8K/audio/fold8/179039-9-0-40.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-5.wav\n",
            "UrbanSound8K/audio/fold8/169043-2-0-10.wav\n",
            "UrbanSound8K/audio/fold8/34866-9-0-9.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-10.wav\n",
            "UrbanSound8K/audio/fold8/196561-3-0-16.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-10-0.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-21.wav\n",
            "UrbanSound8K/audio/fold8/55013-3-0-4.wav\n",
            "UrbanSound8K/audio/fold8/62048-3-0-5.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-11.wav\n",
            "UrbanSound8K/audio/fold8/205610-4-0-1.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-9.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-21.wav\n",
            "UrbanSound8K/audio/fold8/133473-8-0-5.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-7.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-5.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-15.wav\n",
            "UrbanSound8K/audio/fold8/125520-1-3-0.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-2.wav\n",
            "UrbanSound8K/audio/fold8/96657-8-0-3.wav\n",
            "UrbanSound8K/audio/fold8/70168-3-1-24.wav\n",
            "UrbanSound8K/audio/fold8/171464-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/193699-2-0-109.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-130.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-1-0.wav\n",
            "UrbanSound8K/audio/fold8/99179-9-0-58.wav\n",
            "UrbanSound8K/audio/fold8/125520-1-2-0.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-24.wav\n",
            "UrbanSound8K/audio/fold8/115240-9-0-28.wav\n",
            "UrbanSound8K/audio/fold8/133090-2-0-70.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-19.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-2.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-29.wav\n",
            "UrbanSound8K/audio/fold8/142003-2-0-21.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-3.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-6.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-81.wav\n",
            "UrbanSound8K/audio/fold8/107190-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/156358-5-0-6.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-6.wav\n",
            "UrbanSound8K/audio/fold8/99179-9-0-19.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-17.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-135.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-5.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-19.wav\n",
            "UrbanSound8K/audio/fold8/29936-3-2-0.wav\n",
            "UrbanSound8K/audio/fold8/39967-9-0-78.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-0.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-61.wav\n",
            "UrbanSound8K/audio/fold8/34866-9-0-3.wav\n",
            "UrbanSound8K/audio/fold8/44110-3-4-0.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-33.wav\n",
            "UrbanSound8K/audio/fold8/169043-2-0-3.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-5.wav\n",
            "UrbanSound8K/audio/fold8/6984-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/24728-7-1-0.wav\n",
            "UrbanSound8K/audio/fold8/17009-2-0-4.wav\n",
            "UrbanSound8K/audio/fold8/80589-0-0-4.wav\n",
            "UrbanSound8K/audio/fold8/133090-2-0-38.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-22.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-28.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-6.wav\n",
            "UrbanSound8K/audio/fold8/133473-8-0-4.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-3-0.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-17.wav\n",
            "UrbanSound8K/audio/fold8/133473-8-0-3.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-11-0.wav\n",
            "UrbanSound8K/audio/fold8/189846-3-4-0.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-19.wav\n",
            "UrbanSound8K/audio/fold8/36429-2-0-6.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-4.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-13.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-4.wav\n",
            "UrbanSound8K/audio/fold8/193699-2-0-32.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-27.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-5-1.wav\n",
            "UrbanSound8K/audio/fold8/131571-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-2.wav\n",
            "UrbanSound8K/audio/fold8/96159-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/133473-8-0-0.wav\n",
            "UrbanSound8K/audio/fold8/36429-2-0-23.wav\n",
            "UrbanSound8K/audio/fold8/17009-2-0-0.wav\n",
            "UrbanSound8K/audio/fold8/113216-5-0-2.wav\n",
            "UrbanSound8K/audio/fold8/24728-7-2-0.wav\n",
            "UrbanSound8K/audio/fold8/190996-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-0-0.wav\n",
            "UrbanSound8K/audio/fold8/72221-3-4-7.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-4.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-6.wav\n",
            "UrbanSound8K/audio/fold8/126153-9-0-4.wav\n",
            "UrbanSound8K/audio/fold8/186940-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-7.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-7-0.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-105.wav\n",
            "UrbanSound8K/audio/fold8/103076-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-26.wav\n",
            "UrbanSound8K/audio/fold8/62048-3-0-2.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-28.wav\n",
            "UrbanSound8K/audio/fold8/110688-3-0-32.wav\n",
            "UrbanSound8K/audio/fold8/194733-9-0-16.wav\n",
            "UrbanSound8K/audio/fold8/142003-2-0-1.wav\n",
            "UrbanSound8K/audio/fold8/41364-9-0-22.wav\n",
            "UrbanSound8K/audio/fold8/72015-2-0-3.wav\n",
            "UrbanSound8K/audio/fold8/96657-8-0-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-3-0.wav\n",
            "UrbanSound8K/audio/fold8/204526-2-0-71.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-1-0.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-16.wav\n",
            "UrbanSound8K/audio/fold8/125520-1-1-0.wav\n",
            "UrbanSound8K/audio/fold8/171243-9-0-49.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-15.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-5.wav\n",
            "UrbanSound8K/audio/fold8/117181-8-0-12.wav\n",
            "UrbanSound8K/audio/fold8/160016-2-0-8.wav\n",
            "UrbanSound8K/audio/fold8/4918-3-3-0.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-7.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-7.wav\n",
            "UrbanSound8K/audio/fold8/99179-9-0-53.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-13.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-3-1.wav\n",
            "UrbanSound8K/audio/fold8/145206-6-4-0.wav\n",
            "UrbanSound8K/audio/fold8/204526-2-0-121.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-1-4.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/55013-3-0-1.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-1.wav\n",
            "UrbanSound8K/audio/fold8/207214-2-0-62.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-47.wav\n",
            "UrbanSound8K/audio/fold8/139000-4-0-2.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-3-0.wav\n",
            "UrbanSound8K/audio/fold8/174873-3-5-1.wav\n",
            "UrbanSound8K/audio/fold8/72015-2-0-2.wav\n",
            "UrbanSound8K/audio/fold8/180132-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/54914-2-0-34.wav\n",
            "UrbanSound8K/audio/fold8/4918-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-2.wav\n",
            "UrbanSound8K/audio/fold8/72015-2-0-4.wav\n",
            "UrbanSound8K/audio/fold8/91209-5-1-0.wav\n",
            "UrbanSound8K/audio/fold8/133090-2-0-14.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-8.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-67.wav\n",
            "UrbanSound8K/audio/fold8/204526-2-0-134.wav\n",
            "UrbanSound8K/audio/fold8/30226-3-1-5.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-12.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-8-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-16.wav\n",
            "UrbanSound8K/audio/fold8/156358-5-0-0.wav\n",
            "UrbanSound8K/audio/fold8/17009-2-0-9.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-3.wav\n",
            "UrbanSound8K/audio/fold8/114280-3-0-1.wav\n",
            "UrbanSound8K/audio/fold8/39967-9-0-56.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-7.wav\n",
            "UrbanSound8K/audio/fold8/42324-4-2-0.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-3.wav\n",
            "UrbanSound8K/audio/fold8/34866-9-0-5.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-18.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-3-0.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-66.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-15.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-8-0.wav\n",
            "UrbanSound8K/audio/fold8/14386-9-0-17.wav\n",
            "UrbanSound8K/audio/fold8/113216-5-0-1.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-26.wav\n",
            "UrbanSound8K/audio/fold8/71700-3-3-2.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-0-1.wav\n",
            "UrbanSound8K/audio/fold8/30226-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-14.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-14-0.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-7.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-1-1.wav\n",
            "UrbanSound8K/audio/fold8/24728-7-4-0.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-3.wav\n",
            "UrbanSound8K/audio/fold8/171243-9-0-85.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-3-0.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-12.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-27.wav\n",
            "UrbanSound8K/audio/fold8/157649-3-2-0.wav\n",
            "UrbanSound8K/audio/fold8/24728-7-5-0.wav\n",
            "UrbanSound8K/audio/fold8/72015-2-0-1.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-23.wav\n",
            "UrbanSound8K/audio/fold8/7390-9-0-6.wav\n",
            "UrbanSound8K/audio/fold8/190996-3-0-8.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-8.wav\n",
            "UrbanSound8K/audio/fold8/61077-3-2-0.wav\n",
            "UrbanSound8K/audio/fold8/81787-2-0-49.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-35.wav\n",
            "UrbanSound8K/audio/fold8/133090-2-0-64.wav\n",
            "UrbanSound8K/audio/fold8/4918-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-5-0.wav\n",
            "UrbanSound8K/audio/fold8/151069-6-0-0.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-11.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-1-2.wav\n",
            "UrbanSound8K/audio/fold8/115240-9-0-34.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-28.wav\n",
            "UrbanSound8K/audio/fold8/168037-4-12-0.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-1.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-12.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-19.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-6-0.wav\n",
            "UrbanSound8K/audio/fold8/71700-3-4-3.wav\n",
            "UrbanSound8K/audio/fold8/139000-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-6.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-13.wav\n",
            "UrbanSound8K/audio/fold8/50668-5-1-0.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-7.wav\n",
            "UrbanSound8K/audio/fold8/179039-9-0-38.wav\n",
            "UrbanSound8K/audio/fold8/147019-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/169043-2-0-15.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-11-0.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-3.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-8.wav\n",
            "UrbanSound8K/audio/fold8/36429-2-0-7.wav\n",
            "UrbanSound8K/audio/fold8/145206-6-3-0.wav\n",
            "UrbanSound8K/audio/fold8/76266-2-0-55.wav\n",
            "UrbanSound8K/audio/fold8/29936-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-5-0.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-18.wav\n",
            "UrbanSound8K/audio/fold8/34866-9-0-10.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-1.wav\n",
            "UrbanSound8K/audio/fold8/144028-3-0-0.wav\n",
            "UrbanSound8K/audio/fold8/126153-9-0-0.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-7-0.wav\n",
            "UrbanSound8K/audio/fold8/66324-9-0-30.wav\n",
            "UrbanSound8K/audio/fold8/61077-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/31325-3-4-0.wav\n",
            "UrbanSound8K/audio/fold8/17009-2-0-3.wav\n",
            "UrbanSound8K/audio/fold8/66599-9-0-11.wav\n",
            "UrbanSound8K/audio/fold8/162433-6-4-0.wav\n",
            "UrbanSound8K/audio/fold8/155217-9-0-39.wav\n",
            "UrbanSound8K/audio/fold8/205610-4-0-0.wav\n",
            "UrbanSound8K/audio/fold8/81787-2-0-35.wav\n",
            "UrbanSound8K/audio/fold8/36429-2-0-15.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-12-0.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-15.wav\n",
            "UrbanSound8K/audio/fold8/179039-9-0-22.wav\n",
            "UrbanSound8K/audio/fold8/81787-2-0-48.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-0.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-2-0.wav\n",
            "UrbanSound8K/audio/fold8/126153-9-0-1.wav\n",
            "UrbanSound8K/audio/fold8/76085-4-0-38.wav\n",
            "UrbanSound8K/audio/fold8/148632-8-0-10.wav\n",
            "UrbanSound8K/audio/fold8/44110-3-3-0.wav\n",
            "UrbanSound8K/audio/fold8/41364-9-0-24.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-1-9.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-24.wav\n",
            "UrbanSound8K/audio/fold8/174285-6-2-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-8.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-66.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-2-19.wav\n",
            "UrbanSound8K/audio/fold8/71309-1-0-3.wav\n",
            "UrbanSound8K/audio/fold8/194733-9-0-7.wav\n",
            "UrbanSound8K/audio/fold8/80589-0-0-1.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-14.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-1-6.wav\n",
            "UrbanSound8K/audio/fold8/167702-4-6-0.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-0-3.wav\n",
            "UrbanSound8K/audio/fold8/155283-1-0-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-3-4.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-13-0.wav\n",
            "UrbanSound8K/audio/fold8/144028-3-1-1.wav\n",
            "UrbanSound8K/audio/fold8/180134-4-1-3.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-5.wav\n",
            "UrbanSound8K/audio/fold8/72221-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-38.wav\n",
            "UrbanSound8K/audio/fold8/71177-8-2-0.wav\n",
            "UrbanSound8K/audio/fold8/80589-0-0-0.wav\n",
            "UrbanSound8K/audio/fold8/193699-2-0-46.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-9.wav\n",
            "UrbanSound8K/audio/fold8/66599-9-1-4.wav\n",
            "UrbanSound8K/audio/fold8/54383-0-0-1.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-4-0.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-4.wav\n",
            "UrbanSound8K/audio/fold8/171464-3-1-0.wav\n",
            "UrbanSound8K/audio/fold8/30226-3-1-1.wav\n",
            "UrbanSound8K/audio/fold8/74677-0-0-14.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-8.wav\n",
            "UrbanSound8K/audio/fold8/96159-4-1-0.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-4.wav\n",
            "UrbanSound8K/audio/fold8/70168-3-1-13.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-3.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-5.wav\n",
            "UrbanSound8K/audio/fold8/66324-9-0-19.wav\n",
            "UrbanSound8K/audio/fold8/113203-5-1-1.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-13.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-0-0.wav\n",
            "UrbanSound8K/audio/fold8/207214-2-0-68.wav\n",
            "UrbanSound8K/audio/fold8/189825-9-0-1.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-11.wav\n",
            "UrbanSound8K/audio/fold8/113202-5-0-1.wav\n",
            "UrbanSound8K/audio/fold8/133473-8-0-2.wav\n",
            "UrbanSound8K/audio/fold8/177726-0-0-32.wav\n",
            "UrbanSound8K/audio/fold8/193699-2-0-3.wav\n",
            "UrbanSound8K/audio/fold8/33340-7-0-0.wav\n",
            "UrbanSound8K/audio/fold8/126153-9-0-6.wav\n",
            "UrbanSound8K/audio/fold8/160016-2-0-25.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-15.wav\n",
            "UrbanSound8K/audio/fold8/17009-2-0-10.wav\n",
            "UrbanSound8K/audio/fold8/161129-4-0-4.wav\n",
            "UrbanSound8K/audio/fold8/16860-9-0-26.wav\n",
            "UrbanSound8K/audio/fold8/207214-2-0-31.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-16.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-4-2.wav\n",
            "UrbanSound8K/audio/fold8/68080-7-0-8.wav\n",
            "UrbanSound8K/audio/fold8/125678-7-2-8.wav\n",
            "UrbanSound8K/audio/fold8/157868-8-0-20.wav\n",
            "UrbanSound8K/audio/fold8/205610-4-0-5.wav\n",
            "UrbanSound8K/audio/fold8/162103-0-0-0.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-2.wav\n",
            "UrbanSound8K/audio/fold2/58202-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-1.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-9.wav\n",
            "UrbanSound8K/audio/fold2/127872-0-0-0.wav\n",
            "UrbanSound8K/audio/fold2/102104-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-21.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-7-0.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-58.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-4-2.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-28.wav\n",
            "UrbanSound8K/audio/fold2/204773-3-8-0.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-0-1.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-6.wav\n",
            "UrbanSound8K/audio/fold2/160366-3-0-4.wav\n",
            "UrbanSound8K/audio/fold2/40717-8-0-3.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-5-0.wav\n",
            "UrbanSound8K/audio/fold2/59594-4-0-3.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-0.wav\n",
            "UrbanSound8K/audio/fold2/189991-0-0-7.wav\n",
            "UrbanSound8K/audio/fold2/172593-2-0-13.wav\n",
            "UrbanSound8K/audio/fold2/192269-2-0-1.wav\n",
            "UrbanSound8K/audio/fold2/132073-1-3-0.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-93.wav\n",
            "UrbanSound8K/audio/fold2/60591-2-0-12.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-9.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-54.wav\n",
            "UrbanSound8K/audio/fold2/71080-4-1-0.wav\n",
            "UrbanSound8K/audio/fold2/60605-9-0-95.wav\n",
            "UrbanSound8K/audio/fold2/59594-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/74458-9-1-13.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-9-2.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-27-0.wav\n",
            "UrbanSound8K/audio/fold2/179096-3-0-5.wav\n",
            "UrbanSound8K/audio/fold2/14387-9-0-12.wav\n",
            "UrbanSound8K/audio/fold2/196384-9-0-27.wav\n",
            "UrbanSound8K/audio/fold2/73623-7-6-0.wav\n",
            "UrbanSound8K/audio/fold2/91396-8-0-0.wav\n",
            "UrbanSound8K/audio/fold2/14387-9-0-11.wav\n",
            "UrbanSound8K/audio/fold2/49808-3-1-8.wav\n",
            "UrbanSound8K/audio/fold2/60605-9-0-52.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-1-0.wav\n",
            "UrbanSound8K/audio/fold2/84359-2-0-6.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-4-1.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-2.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-5.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-4.wav\n",
            "UrbanSound8K/audio/fold2/46668-4-0-2.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-2-1.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-11.wav\n",
            "UrbanSound8K/audio/fold2/76090-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/172593-2-0-18.wav\n",
            "UrbanSound8K/audio/fold2/60591-2-0-8.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-8-0.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-25.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-13.wav\n",
            "UrbanSound8K/audio/fold2/74226-9-0-7.wav\n",
            "UrbanSound8K/audio/fold2/96169-9-1-55.wav\n",
            "UrbanSound8K/audio/fold2/158597-2-0-3.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-13.wav\n",
            "UrbanSound8K/audio/fold2/76091-6-5-0.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-15-0.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-9.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-5-6.wav\n",
            "UrbanSound8K/audio/fold2/96475-9-0-5.wav\n",
            "UrbanSound8K/audio/fold2/18453-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-24.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-3.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-15.wav\n",
            "UrbanSound8K/audio/fold2/14780-9-0-0.wav\n",
            "UrbanSound8K/audio/fold2/132073-1-2-0.wav\n",
            "UrbanSound8K/audio/fold2/182739-2-0-24.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-10-0.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-25-0.wav\n",
            "UrbanSound8K/audio/fold2/96169-9-1-3.wav\n",
            "UrbanSound8K/audio/fold2/22347-3-1-1.wav\n",
            "UrbanSound8K/audio/fold2/96475-9-0-6.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-87.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-1-6.wav\n",
            "UrbanSound8K/audio/fold2/96169-9-1-49.wav\n",
            "UrbanSound8K/audio/fold2/69883-3-0-5.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-7-0.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-8.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-11.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-7.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-7-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-1-3.wav\n",
            "UrbanSound8K/audio/fold2/194841-9-0-48.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-2-0.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-2-5.wav\n",
            "UrbanSound8K/audio/fold2/22347-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/73623-7-1-1.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-0-2.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-4-3.wav\n",
            "UrbanSound8K/audio/fold2/39970-9-0-54.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-3-0.wav\n",
            "UrbanSound8K/audio/fold2/178521-2-0-2.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-3.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-15.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-5-0.wav\n",
            "UrbanSound8K/audio/fold2/196384-9-0-2.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-17.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-15.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-125.wav\n",
            "UrbanSound8K/audio/fold2/33849-3-2-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-1-7.wav\n",
            "UrbanSound8K/audio/fold2/178521-2-0-22.wav\n",
            "UrbanSound8K/audio/fold2/109703-2-0-32.wav\n",
            "UrbanSound8K/audio/fold2/22347-3-3-0.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-18.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-1-8.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-2-1.wav\n",
            "UrbanSound8K/audio/fold2/91396-8-0-1.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-3-4.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-6-0.wav\n",
            "UrbanSound8K/audio/fold2/97193-3-0-6.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-6.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-41.wav\n",
            "UrbanSound8K/audio/fold2/14780-9-0-2.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-14-0.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-24.wav\n",
            "UrbanSound8K/audio/fold2/63261-3-0-1.wav\n",
            "UrbanSound8K/audio/fold2/76090-6-1-0.wav\n",
            "UrbanSound8K/audio/fold2/178521-2-0-86.wav\n",
            "UrbanSound8K/audio/fold2/194841-9-0-222.wav\n",
            "UrbanSound8K/audio/fold2/76089-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-36.wav\n",
            "UrbanSound8K/audio/fold2/54545-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-29.wav\n",
            "UrbanSound8K/audio/fold2/176634-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-6.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-43.wav\n",
            "UrbanSound8K/audio/fold2/168713-9-0-38.wav\n",
            "UrbanSound8K/audio/fold2/160011-2-0-3.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-2-0.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-2-0.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/192269-2-0-24.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-18.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-21.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-5-0.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-13.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-22-0.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-3.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-17.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-13-0.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-17-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-2-5.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/100652-3-0-2.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-3.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-3-0.wav\n",
            "UrbanSound8K/audio/fold2/118962-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/4201-3-3-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-2-0.wav\n",
            "UrbanSound8K/audio/fold2/93193-9-1-11.wav\n",
            "UrbanSound8K/audio/fold2/46655-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-3-9.wav\n",
            "UrbanSound8K/audio/fold2/145577-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/178521-2-0-18.wav\n",
            "UrbanSound8K/audio/fold2/160011-2-0-12.wav\n",
            "UrbanSound8K/audio/fold2/14780-9-0-1.wav\n",
            "UrbanSound8K/audio/fold2/74458-9-2-18.wav\n",
            "UrbanSound8K/audio/fold2/179096-3-0-10.wav\n",
            "UrbanSound8K/audio/fold2/18581-3-1-1.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-4.wav\n",
            "UrbanSound8K/audio/fold2/59594-4-0-2.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-15.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-55.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-18.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-2.wav\n",
            "UrbanSound8K/audio/fold2/96169-9-1-61.wav\n",
            "UrbanSound8K/audio/fold2/79377-9-0-13.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-11.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-5.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-8.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-2-8.wav\n",
            "UrbanSound8K/audio/fold2/194841-9-0-130.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-5-0.wav\n",
            "UrbanSound8K/audio/fold2/112195-3-0-57.wav\n",
            "UrbanSound8K/audio/fold2/155129-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-5-4.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-14.wav\n",
            "UrbanSound8K/audio/fold2/160011-2-0-7.wav\n",
            "UrbanSound8K/audio/fold2/182739-2-0-78.wav\n",
            "UrbanSound8K/audio/fold2/100652-3-0-1.wav\n",
            "UrbanSound8K/audio/fold2/168713-9-0-33.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-0.wav\n",
            "UrbanSound8K/audio/fold2/69883-3-0-20.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-3-1.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-13.wav\n",
            "UrbanSound8K/audio/fold2/50416-4-0-2.wav\n",
            "UrbanSound8K/audio/fold2/143970-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/155219-2-0-51.wav\n",
            "UrbanSound8K/audio/fold2/189991-0-0-2.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-5-1.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-1-5.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-11-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-6-1.wav\n",
            "UrbanSound8K/audio/fold2/73623-7-3-0.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-1-0.wav\n",
            "UrbanSound8K/audio/fold2/192269-2-0-18.wav\n",
            "UrbanSound8K/audio/fold2/74458-9-0-5.wav\n",
            "UrbanSound8K/audio/fold2/94710-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/132073-1-4-0.wav\n",
            "UrbanSound8K/audio/fold2/149254-9-0-30.wav\n",
            "UrbanSound8K/audio/fold2/74226-9-0-13.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-14.wav\n",
            "UrbanSound8K/audio/fold2/66996-8-3-0.wav\n",
            "UrbanSound8K/audio/fold2/50416-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-5.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-17.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-16.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-12.wav\n",
            "UrbanSound8K/audio/fold2/113785-3-1-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-3-3.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-5-0.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-0.wav\n",
            "UrbanSound8K/audio/fold2/96475-9-0-4.wav\n",
            "UrbanSound8K/audio/fold2/76091-6-4-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-1-2.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-2.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-8.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-8-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-1.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-14.wav\n",
            "UrbanSound8K/audio/fold2/59594-4-0-4.wav\n",
            "UrbanSound8K/audio/fold2/189991-0-0-1.wav\n",
            "UrbanSound8K/audio/fold2/33849-3-3-0.wav\n",
            "UrbanSound8K/audio/fold2/166421-3-0-29.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-2-6.wav\n",
            "UrbanSound8K/audio/fold2/147672-3-2-0.wav\n",
            "UrbanSound8K/audio/fold2/182739-2-0-56.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-3-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-11.wav\n",
            "UrbanSound8K/audio/fold2/91396-8-0-3.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-165.wav\n",
            "UrbanSound8K/audio/fold2/63261-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/60591-2-0-15.wav\n",
            "UrbanSound8K/audio/fold2/59594-4-0-1.wav\n",
            "UrbanSound8K/audio/fold2/60591-2-0-16.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-151.wav\n",
            "UrbanSound8K/audio/fold2/72539-3-0-6.wav\n",
            "UrbanSound8K/audio/fold2/40717-8-0-5.wav\n",
            "UrbanSound8K/audio/fold2/163460-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-4.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-6-11.wav\n",
            "UrbanSound8K/audio/fold2/66996-8-1-0.wav\n",
            "UrbanSound8K/audio/fold2/178521-2-0-70.wav\n",
            "UrbanSound8K/audio/fold2/149254-9-0-51.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-5-5.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-3-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-5.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-4.wav\n",
            "UrbanSound8K/audio/fold2/18581-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/37236-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-9.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-8.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-2-5.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-36.wav\n",
            "UrbanSound8K/audio/fold2/174293-6-2-0.wav\n",
            "UrbanSound8K/audio/fold2/109703-2-0-134.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-12-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-7.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-9.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/189991-0-0-3.wav\n",
            "UrbanSound8K/audio/fold2/165775-7-1-0.wav\n",
            "UrbanSound8K/audio/fold2/79377-9-0-10.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-44.wav\n",
            "UrbanSound8K/audio/fold2/98202-9-1-27.wav\n",
            "UrbanSound8K/audio/fold2/76091-6-2-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-11.wav\n",
            "UrbanSound8K/audio/fold2/56385-0-0-1.wav\n",
            "UrbanSound8K/audio/fold2/185800-4-2-2.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-9-0.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-2-0.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-137.wav\n",
            "UrbanSound8K/audio/fold2/94710-5-0-2.wav\n",
            "UrbanSound8K/audio/fold2/39970-9-0-108.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-8.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-2-3.wav\n",
            "UrbanSound8K/audio/fold2/73623-7-5-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-4.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-8.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-2-2.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-23.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-1-0.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-7.wav\n",
            "UrbanSound8K/audio/fold2/84359-2-0-1.wav\n",
            "UrbanSound8K/audio/fold2/178520-2-0-11.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-6.wav\n",
            "UrbanSound8K/audio/fold2/149254-9-0-25.wav\n",
            "UrbanSound8K/audio/fold2/27349-3-2-1.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-5.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-53.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-0-0.wav\n",
            "UrbanSound8K/audio/fold2/196063-2-0-1.wav\n",
            "UrbanSound8K/audio/fold2/96475-9-0-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-3-2.wav\n",
            "UrbanSound8K/audio/fold2/74458-9-1-5.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-80.wav\n",
            "UrbanSound8K/audio/fold2/179866-1-1-0.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-4-0.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-28.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-10.wav\n",
            "UrbanSound8K/audio/fold2/50416-4-0-1.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-7.wav\n",
            "UrbanSound8K/audio/fold2/192269-2-0-37.wav\n",
            "UrbanSound8K/audio/fold2/174293-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-4-0.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-3.wav\n",
            "UrbanSound8K/audio/fold2/149370-9-0-32.wav\n",
            "UrbanSound8K/audio/fold2/182739-2-0-35.wav\n",
            "UrbanSound8K/audio/fold2/74458-9-1-12.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-25.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-2.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-2-2.wav\n",
            "UrbanSound8K/audio/fold2/18581-3-1-3.wav\n",
            "UrbanSound8K/audio/fold2/160366-3-0-8.wav\n",
            "UrbanSound8K/audio/fold2/149370-9-0-22.wav\n",
            "UrbanSound8K/audio/fold2/147672-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-20.wav\n",
            "UrbanSound8K/audio/fold2/84359-2-0-8.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-3-1.wav\n",
            "UrbanSound8K/audio/fold2/89211-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/173995-3-0-27.wav\n",
            "UrbanSound8K/audio/fold2/96920-9-0-3.wav\n",
            "UrbanSound8K/audio/fold2/113201-5-0-5.wav\n",
            "UrbanSound8K/audio/fold2/23131-3-4-0.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-0-1.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-17.wav\n",
            "UrbanSound8K/audio/fold2/196082-2-0-0.wav\n",
            "UrbanSound8K/audio/fold2/178521-2-0-69.wav\n",
            "UrbanSound8K/audio/fold2/27349-3-0-2.wav\n",
            "UrbanSound8K/audio/fold2/185800-4-0-1.wav\n",
            "UrbanSound8K/audio/fold2/132073-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/39970-9-0-41.wav\n",
            "UrbanSound8K/audio/fold2/160366-3-0-7.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-20.wav\n",
            "UrbanSound8K/audio/fold2/60591-2-0-7.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-16.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-11.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-4-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-4.wav\n",
            "UrbanSound8K/audio/fold2/56385-0-0-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-8.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-19.wav\n",
            "UrbanSound8K/audio/fold2/168713-9-0-62.wav\n",
            "UrbanSound8K/audio/fold2/73623-7-1-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-8.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-4.wav\n",
            "UrbanSound8K/audio/fold2/189991-0-0-5.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-9.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-56.wav\n",
            "UrbanSound8K/audio/fold2/204773-3-7-1.wav\n",
            "UrbanSound8K/audio/fold2/168713-9-0-82.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-1-0.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-9-0.wav\n",
            "UrbanSound8K/audio/fold2/79377-9-0-2.wav\n",
            "UrbanSound8K/audio/fold2/132073-1-6-0.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-3-0.wav\n",
            "UrbanSound8K/audio/fold2/96169-9-1-74.wav\n",
            "UrbanSound8K/audio/fold2/39970-9-0-142.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-112.wav\n",
            "UrbanSound8K/audio/fold2/18581-3-0-5.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-24.wav\n",
            "UrbanSound8K/audio/fold2/166421-3-0-5.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-5.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-4.wav\n",
            "UrbanSound8K/audio/fold2/98202-9-0-10.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-6.wav\n",
            "UrbanSound8K/audio/fold2/196078-2-0-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-9.wav\n",
            "UrbanSound8K/audio/fold2/113201-5-0-7.wav\n",
            "UrbanSound8K/audio/fold2/50898-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/14387-9-0-7.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-8-0.wav\n",
            "UrbanSound8K/audio/fold2/194841-9-0-178.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-2-3.wav\n",
            "UrbanSound8K/audio/fold2/174994-3-0-1.wav\n",
            "UrbanSound8K/audio/fold2/174906-2-0-18.wav\n",
            "UrbanSound8K/audio/fold2/40717-8-0-0.wav\n",
            "UrbanSound8K/audio/fold2/196384-9-0-11.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-47.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-140.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-12.wav\n",
            "UrbanSound8K/audio/fold2/158607-3-2-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-11.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-2.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-12.wav\n",
            "UrbanSound8K/audio/fold2/172593-2-0-27.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-12.wav\n",
            "UrbanSound8K/audio/fold2/160011-2-0-34.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-3-10.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-3-3.wav\n",
            "UrbanSound8K/audio/fold2/4911-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/60605-9-0-64.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-4-0.wav\n",
            "UrbanSound8K/audio/fold2/196063-2-0-2.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-2-2.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-10.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-38.wav\n",
            "UrbanSound8K/audio/fold2/196384-9-0-16.wav\n",
            "UrbanSound8K/audio/fold2/149370-9-0-21.wav\n",
            "UrbanSound8K/audio/fold2/96920-9-0-2.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-11.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-17.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-19.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-11.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-0.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-12.wav\n",
            "UrbanSound8K/audio/fold2/172593-2-0-10.wav\n",
            "UrbanSound8K/audio/fold2/74458-9-0-7.wav\n",
            "UrbanSound8K/audio/fold2/96920-9-0-13.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-50.wav\n",
            "UrbanSound8K/audio/fold2/72539-3-0-5.wav\n",
            "UrbanSound8K/audio/fold2/93193-9-1-6.wav\n",
            "UrbanSound8K/audio/fold2/96475-9-0-3.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-43.wav\n",
            "UrbanSound8K/audio/fold2/203128-3-1-0.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-10.wav\n",
            "UrbanSound8K/audio/fold2/155219-2-0-57.wav\n",
            "UrbanSound8K/audio/fold2/118723-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-17.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-11.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-2.wav\n",
            "UrbanSound8K/audio/fold2/173995-3-0-11.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-7.wav\n",
            "UrbanSound8K/audio/fold2/112195-3-0-48.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-16-0.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-6.wav\n",
            "UrbanSound8K/audio/fold2/49808-3-0-6.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-9-0.wav\n",
            "UrbanSound8K/audio/fold2/72539-3-0-1.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-50.wav\n",
            "UrbanSound8K/audio/fold2/165643-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/185800-4-1-0.wav\n",
            "UrbanSound8K/audio/fold2/44735-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-1-0.wav\n",
            "UrbanSound8K/audio/fold2/113201-5-0-4.wav\n",
            "UrbanSound8K/audio/fold2/179866-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/40717-8-0-1.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-0.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-13.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-4.wav\n",
            "UrbanSound8K/audio/fold2/27349-3-0-6.wav\n",
            "UrbanSound8K/audio/fold2/56385-0-0-2.wav\n",
            "UrbanSound8K/audio/fold2/74495-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-8.wav\n",
            "UrbanSound8K/audio/fold2/4201-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/196384-9-0-15.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-2-0.wav\n",
            "UrbanSound8K/audio/fold2/178521-2-0-7.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-4-6.wav\n",
            "UrbanSound8K/audio/fold2/155129-1-2-0.wav\n",
            "UrbanSound8K/audio/fold2/145608-6-3-0.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-10.wav\n",
            "UrbanSound8K/audio/fold2/189991-0-0-0.wav\n",
            "UrbanSound8K/audio/fold2/158597-2-0-16.wav\n",
            "UrbanSound8K/audio/fold2/102858-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/158597-2-0-85.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-2.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-9.wav\n",
            "UrbanSound8K/audio/fold2/23131-3-2-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-1-2.wav\n",
            "UrbanSound8K/audio/fold2/174906-2-0-14.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-5.wav\n",
            "UrbanSound8K/audio/fold2/40717-8-0-6.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-16.wav\n",
            "UrbanSound8K/audio/fold2/203128-3-3-0.wav\n",
            "UrbanSound8K/audio/fold2/173995-3-0-3.wav\n",
            "UrbanSound8K/audio/fold2/155219-2-0-24.wav\n",
            "UrbanSound8K/audio/fold2/149254-9-0-29.wav\n",
            "UrbanSound8K/audio/fold2/174994-3-0-2.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-10.wav\n",
            "UrbanSound8K/audio/fold2/96475-9-0-9.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-3.wav\n",
            "UrbanSound8K/audio/fold2/46668-4-0-1.wav\n",
            "UrbanSound8K/audio/fold2/149370-9-0-37.wav\n",
            "UrbanSound8K/audio/fold2/27349-3-1-2.wav\n",
            "UrbanSound8K/audio/fold2/40717-8-0-2.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-1-1.wav\n",
            "UrbanSound8K/audio/fold2/162541-1-2-0.wav\n",
            "UrbanSound8K/audio/fold2/159710-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/182739-2-0-85.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-37.wav\n",
            "UrbanSound8K/audio/fold2/113201-5-0-6.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-10.wav\n",
            "UrbanSound8K/audio/fold2/185800-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/97193-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/172593-2-0-22.wav\n",
            "UrbanSound8K/audio/fold2/113201-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-3.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-7.wav\n",
            "UrbanSound8K/audio/fold2/160011-2-0-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-10.wav\n",
            "UrbanSound8K/audio/fold2/14387-9-0-15.wav\n",
            "UrbanSound8K/audio/fold2/73623-7-2-0.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-4-1.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-5.wav\n",
            "UrbanSound8K/audio/fold2/174906-2-0-8.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-2-0.wav\n",
            "UrbanSound8K/audio/fold2/94710-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-10-1.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-3.wav\n",
            "UrbanSound8K/audio/fold2/158597-2-0-41.wav\n",
            "UrbanSound8K/audio/fold2/174906-2-0-20.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-9.wav\n",
            "UrbanSound8K/audio/fold2/143970-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/172593-2-0-29.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-9.wav\n",
            "UrbanSound8K/audio/fold2/84359-2-0-9.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-12.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-26-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-10.wav\n",
            "UrbanSound8K/audio/fold2/84359-2-0-5.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-14.wav\n",
            "UrbanSound8K/audio/fold2/174293-6-1-0.wav\n",
            "UrbanSound8K/audio/fold2/19218-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/196384-9-0-18.wav\n",
            "UrbanSound8K/audio/fold2/145608-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-4.wav\n",
            "UrbanSound8K/audio/fold2/194841-9-0-144.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-0.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/155234-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/155219-2-0-1.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-1-4.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-20.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-9-3.wav\n",
            "UrbanSound8K/audio/fold2/40717-8-0-4.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-8.wav\n",
            "UrbanSound8K/audio/fold2/158597-2-0-2.wav\n",
            "UrbanSound8K/audio/fold2/179096-3-0-9.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-34.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-64.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-5-10.wav\n",
            "UrbanSound8K/audio/fold2/155219-2-0-25.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-2.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-4-5.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-10.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-155.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-2.wav\n",
            "UrbanSound8K/audio/fold2/108187-3-3-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-4.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-154.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-20-0.wav\n",
            "UrbanSound8K/audio/fold2/115537-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/113201-5-0-2.wav\n",
            "UrbanSound8K/audio/fold2/178521-2-0-93.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-6.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-1-0.wav\n",
            "UrbanSound8K/audio/fold2/94401-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-6.wav\n",
            "UrbanSound8K/audio/fold2/143970-5-0-2.wav\n",
            "UrbanSound8K/audio/fold2/155129-1-1-0.wav\n",
            "UrbanSound8K/audio/fold2/113201-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-7.wav\n",
            "UrbanSound8K/audio/fold2/172593-2-0-14.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-7-4.wav\n",
            "UrbanSound8K/audio/fold2/155219-2-0-22.wav\n",
            "UrbanSound8K/audio/fold2/149370-9-0-15.wav\n",
            "UrbanSound8K/audio/fold2/109703-2-0-14.wav\n",
            "UrbanSound8K/audio/fold2/84359-2-0-2.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-1.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-13.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-8.wav\n",
            "UrbanSound8K/audio/fold2/22347-3-1-2.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-0-3.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-2-1.wav\n",
            "UrbanSound8K/audio/fold2/96920-9-0-0.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-10-0.wav\n",
            "UrbanSound8K/audio/fold2/160011-2-0-9.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-1.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-9.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-10-0.wav\n",
            "UrbanSound8K/audio/fold2/174994-3-0-4.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-5.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-4.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-21-0.wav\n",
            "UrbanSound8K/audio/fold2/160011-2-0-1.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-2.wav\n",
            "UrbanSound8K/audio/fold2/178520-2-0-42.wav\n",
            "UrbanSound8K/audio/fold2/174906-2-0-11.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-7.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-7.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-18.wav\n",
            "UrbanSound8K/audio/fold2/178520-2-0-38.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/73623-7-4-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-2-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-15.wav\n",
            "UrbanSound8K/audio/fold2/73623-7-0-0.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-1.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-9.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-8.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-5-1.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-52.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-4.wav\n",
            "UrbanSound8K/audio/fold2/4201-3-2-0.wav\n",
            "UrbanSound8K/audio/fold2/44735-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-1-1.wav\n",
            "UrbanSound8K/audio/fold2/46668-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-6.wav\n",
            "UrbanSound8K/audio/fold2/60605-9-0-90.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-4.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-2.wav\n",
            "UrbanSound8K/audio/fold2/93193-9-1-19.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-10.wav\n",
            "UrbanSound8K/audio/fold2/155219-2-0-0.wav\n",
            "UrbanSound8K/audio/fold2/74226-9-0-14.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-2-3.wav\n",
            "UrbanSound8K/audio/fold2/182739-2-0-17.wav\n",
            "UrbanSound8K/audio/fold2/162541-1-1-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-2-2.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-1-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-3-1.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-3.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-12.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-12.wav\n",
            "UrbanSound8K/audio/fold2/145608-6-1-0.wav\n",
            "UrbanSound8K/audio/fold2/174906-2-0-21.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-2-0.wav\n",
            "UrbanSound8K/audio/fold2/79377-9-0-4.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-117.wav\n",
            "UrbanSound8K/audio/fold2/98202-9-0-7.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-4-2.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-19.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-1.wav\n",
            "UrbanSound8K/audio/fold2/60605-9-0-73.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-14.wav\n",
            "UrbanSound8K/audio/fold2/162541-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/178520-2-0-39.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-17.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-6.wav\n",
            "UrbanSound8K/audio/fold2/113785-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/76091-6-3-0.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-5.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-3.wav\n",
            "UrbanSound8K/audio/fold2/168713-9-0-46.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-8-0.wav\n",
            "UrbanSound8K/audio/fold2/204773-3-9-1.wav\n",
            "UrbanSound8K/audio/fold2/97193-3-0-4.wav\n",
            "UrbanSound8K/audio/fold2/160366-3-0-13.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-1-0.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-1-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-2-3.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-14.wav\n",
            "UrbanSound8K/audio/fold2/76091-6-1-0.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-3.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-14.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-4-4.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-4.wav\n",
            "UrbanSound8K/audio/fold2/94710-5-1-0.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-6.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-6-10.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-4-0.wav\n",
            "UrbanSound8K/audio/fold2/60591-2-0-4.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-6-0.wav\n",
            "UrbanSound8K/audio/fold2/97193-3-0-1.wav\n",
            "UrbanSound8K/audio/fold2/192269-2-0-54.wav\n",
            "UrbanSound8K/audio/fold2/160092-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/93193-9-0-4.wav\n",
            "UrbanSound8K/audio/fold2/108187-3-6-0.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-5-2.wav\n",
            "UrbanSound8K/audio/fold2/39970-9-0-98.wav\n",
            "UrbanSound8K/audio/fold2/109703-2-0-50.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/174994-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-0.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-2-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-3-2.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-20.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-11.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-6-2.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-23.wav\n",
            "UrbanSound8K/audio/fold2/204773-3-9-0.wav\n",
            "UrbanSound8K/audio/fold2/112195-3-0-80.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-2.wav\n",
            "UrbanSound8K/audio/fold2/158607-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/158597-2-0-57.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-11-0.wav\n",
            "UrbanSound8K/audio/fold2/33849-3-4-0.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-22.wav\n",
            "UrbanSound8K/audio/fold2/168713-9-0-32.wav\n",
            "UrbanSound8K/audio/fold2/4201-3-1-0.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-2.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-15.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-5.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-6.wav\n",
            "UrbanSound8K/audio/fold2/54545-3-0-2.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-5-7.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-19.wav\n",
            "UrbanSound8K/audio/fold2/173995-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/84359-2-0-0.wav\n",
            "UrbanSound8K/audio/fold2/178520-2-0-23.wav\n",
            "UrbanSound8K/audio/fold2/76091-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/109703-2-0-153.wav\n",
            "UrbanSound8K/audio/fold2/14387-9-0-16.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-1-1.wav\n",
            "UrbanSound8K/audio/fold2/93193-9-1-22.wav\n",
            "UrbanSound8K/audio/fold2/172593-2-0-28.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-15.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-5-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-3-0.wav\n",
            "UrbanSound8K/audio/fold2/196063-2-0-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-12.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-2.wav\n",
            "UrbanSound8K/audio/fold2/158607-3-1-0.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-7-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-1.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-2-4.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-7.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-12.wav\n",
            "UrbanSound8K/audio/fold2/145608-6-2-0.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-39.wav\n",
            "UrbanSound8K/audio/fold2/203128-3-9-0.wav\n",
            "UrbanSound8K/audio/fold2/178520-2-0-29.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-12.wav\n",
            "UrbanSound8K/audio/fold2/158597-2-0-30.wav\n",
            "UrbanSound8K/audio/fold2/109703-2-0-48.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-27.wav\n",
            "UrbanSound8K/audio/fold2/149370-9-0-19.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-38.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-7.wav\n",
            "UrbanSound8K/audio/fold2/98202-9-0-4.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-7.wav\n",
            "UrbanSound8K/audio/fold2/174906-2-0-6.wav\n",
            "UrbanSound8K/audio/fold2/185800-4-2-1.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-10.wav\n",
            "UrbanSound8K/audio/fold2/203128-3-6-0.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-42.wav\n",
            "UrbanSound8K/audio/fold2/108187-3-2-0.wav\n",
            "UrbanSound8K/audio/fold2/175844-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/96169-9-1-10.wav\n",
            "UrbanSound8K/audio/fold2/91396-8-0-2.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-6-9.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-6-8.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-2-4.wav\n",
            "UrbanSound8K/audio/fold2/60591-2-0-11.wav\n",
            "UrbanSound8K/audio/fold2/14387-9-0-19.wav\n",
            "UrbanSound8K/audio/fold2/155219-2-0-26.wav\n",
            "UrbanSound8K/audio/fold2/23131-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/74226-9-0-21.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-1.wav\n",
            "UrbanSound8K/audio/fold2/54545-3-0-1.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-3-0.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-0.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-16.wav\n",
            "UrbanSound8K/audio/fold2/100652-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/178520-2-0-28.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-86.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-1.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-6-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-9-18.wav\n",
            "UrbanSound8K/audio/fold2/60605-9-0-34.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-35.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-12-0.wav\n",
            "UrbanSound8K/audio/fold2/166421-3-0-31.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-35.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-5-3.wav\n",
            "UrbanSound8K/audio/fold2/178520-2-0-27.wav\n",
            "UrbanSound8K/audio/fold2/185800-4-2-0.wav\n",
            "UrbanSound8K/audio/fold2/174906-2-0-10.wav\n",
            "UrbanSound8K/audio/fold2/132073-1-1-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-9.wav\n",
            "UrbanSound8K/audio/fold2/189991-0-0-6.wav\n",
            "UrbanSound8K/audio/fold2/79377-9-0-12.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-5-11.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-13.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-3-5.wav\n",
            "UrbanSound8K/audio/fold2/158597-2-0-33.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-3.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-1.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-5-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-8-0.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-0.wav\n",
            "UrbanSound8K/audio/fold2/96920-9-0-8.wav\n",
            "UrbanSound8K/audio/fold2/149177-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-2.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-27.wav\n",
            "UrbanSound8K/audio/fold2/23131-3-5-0.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-1.wav\n",
            "UrbanSound8K/audio/fold2/98202-9-1-5.wav\n",
            "UrbanSound8K/audio/fold2/194841-9-0-164.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-6.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-16.wav\n",
            "UrbanSound8K/audio/fold2/192269-2-0-56.wav\n",
            "UrbanSound8K/audio/fold2/100652-3-0-3.wav\n",
            "UrbanSound8K/audio/fold2/132073-1-5-0.wav\n",
            "UrbanSound8K/audio/fold2/159743-8-0-0.wav\n",
            "UrbanSound8K/audio/fold2/71080-4-0-0.wav\n",
            "UrbanSound8K/audio/fold2/177592-5-0-8.wav\n",
            "UrbanSound8K/audio/fold2/94710-5-0-3.wav\n",
            "UrbanSound8K/audio/fold2/109703-2-0-29.wav\n",
            "UrbanSound8K/audio/fold2/74226-9-0-10.wav\n",
            "UrbanSound8K/audio/fold2/102858-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/179096-3-0-1.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-18.wav\n",
            "UrbanSound8K/audio/fold2/196067-2-0-0.wav\n",
            "UrbanSound8K/audio/fold2/96920-9-0-11.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-17.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-10.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-27.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-8.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-24-0.wav\n",
            "UrbanSound8K/audio/fold2/112195-3-0-38.wav\n",
            "UrbanSound8K/audio/fold2/147926-0-0-20.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-100.wav\n",
            "UrbanSound8K/audio/fold2/74226-9-0-0.wav\n",
            "UrbanSound8K/audio/fold2/60591-2-0-2.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-2-9.wav\n",
            "UrbanSound8K/audio/fold2/72567-1-4-7.wav\n",
            "UrbanSound8K/audio/fold2/165775-7-0-0.wav\n",
            "UrbanSound8K/audio/fold2/102871-8-0-6.wav\n",
            "UrbanSound8K/audio/fold2/34621-4-18-0.wav\n",
            "UrbanSound8K/audio/fold2/159750-8-0-7.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-11.wav\n",
            "UrbanSound8K/audio/fold2/182739-2-0-13.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-1-1.wav\n",
            "UrbanSound8K/audio/fold2/69883-3-0-9.wav\n",
            "UrbanSound8K/audio/fold2/74226-9-0-6.wav\n",
            "UrbanSound8K/audio/fold2/159747-8-0-18.wav\n",
            "UrbanSound8K/audio/fold2/149254-9-0-56.wav\n",
            "UrbanSound8K/audio/fold2/180126-4-1-2.wav\n",
            "UrbanSound8K/audio/fold2/147672-3-1-0.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-32.wav\n",
            "UrbanSound8K/audio/fold2/74495-3-0-1.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-115.wav\n",
            "UrbanSound8K/audio/fold2/113201-5-0-3.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-12.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-9-1.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-1.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-2-4.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-2-11.wav\n",
            "UrbanSound8K/audio/fold2/108187-3-4-0.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-13.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-4-4.wav\n",
            "UrbanSound8K/audio/fold2/79377-9-0-8.wav\n",
            "UrbanSound8K/audio/fold2/160011-2-0-5.wav\n",
            "UrbanSound8K/audio/fold2/106015-5-0-3.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-2.wav\n",
            "UrbanSound8K/audio/fold2/49808-3-1-22.wav\n",
            "UrbanSound8K/audio/fold2/76086-4-0-3.wav\n",
            "UrbanSound8K/audio/fold2/143970-5-0-3.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-1-3.wav\n",
            "UrbanSound8K/audio/fold2/93193-9-1-18.wav\n",
            "UrbanSound8K/audio/fold2/156893-7-4-0.wav\n",
            "UrbanSound8K/audio/fold2/35800-6-0-0.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-5.wav\n",
            "UrbanSound8K/audio/fold2/149254-9-0-42.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-0-0.wav\n",
            "UrbanSound8K/audio/fold2/179864-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/182739-2-0-62.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-8.wav\n",
            "UrbanSound8K/audio/fold2/123688-8-0-5.wav\n",
            "UrbanSound8K/audio/fold2/152908-5-0-0.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-16.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-6-3.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-116.wav\n",
            "UrbanSound8K/audio/fold2/104817-4-0-9.wav\n",
            "UrbanSound8K/audio/fold2/169098-7-4-5.wav\n",
            "UrbanSound8K/audio/fold2/201652-5-4-6.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-10.wav\n",
            "UrbanSound8K/audio/fold2/72539-3-0-8.wav\n",
            "UrbanSound8K/audio/fold2/189023-0-0-7.wav\n",
            "UrbanSound8K/audio/fold2/17307-1-0-0.wav\n",
            "UrbanSound8K/audio/fold2/192269-2-0-11.wav\n",
            "UrbanSound8K/audio/fold2/189991-0-0-4.wav\n",
            "UrbanSound8K/audio/fold2/33849-3-0-0.wav\n",
            "UrbanSound8K/audio/fold2/39970-9-0-46.wav\n",
            "UrbanSound8K/audio/fold2/197320-6-11-0.wav\n",
            "UrbanSound8K/audio/fold2/192269-2-0-35.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-3.wav\n",
            "UrbanSound8K/audio/fold2/74507-0-0-22.wav\n",
            "UrbanSound8K/audio/fold2/98202-9-1-20.wav\n",
            "UrbanSound8K/audio/fold2/77751-4-1-0.wav\n",
            "UrbanSound8K/audio/fold2/203929-7-10-2.wav\n",
            "UrbanSound8K/audio/fold2/146690-0-0-8.wav\n",
            "Max Padding =  174\n",
            "Creating output folder:  features_mfcc\n",
            "Saving features in  features_mfcc\n",
            " 20% 3551/17464 [01:21<05:23, 43.00it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
            "  warnings.warn(\n",
            " 48% 8325/17464 [03:07<02:20, 64.90it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
            "  warnings.warn(\n",
            "100% 17464/17464 [05:40<00:00, 51.29it/s]\n",
            "Temps d'éxécution : 340.488945023 s\n",
            "\n",
            "Reshaping and saving complete.\n"
          ]
        }
      ],
      "source": [
        "!pip install audiomentations\n",
        "!rm -R features_mfcc\n",
        "!rm -R reshaped_features\n",
        "!rm extracted.csv\n",
        "!python data_augmentation.py\n",
        "!python extract.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS1mmVvzOieS"
      },
      "source": [
        "**MODEL DE BASE / DATA AUGMENTED**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "2Hx0RGdl8YK5",
        "outputId": "09664961-84ac-441f-cba8-95c99303c75a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17464/17464 [00:01<00:00, 10415.69it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Accuracy: 0.963\n",
            "82/82 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 0.958\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['results/history_base_aug.joblib']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 200\n",
        "PATIENCE = 200\n",
        "DROPOUT = 0.5\n",
        "DECAY = 0.97\n",
        "RS = 1\n",
        "\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = get_data(\"extracted.csv\", random_state = RS)\n",
        "model = base_model(input_shape=X_train.shape[1:], dropout_ratio=DROPOUT)\n",
        "_ = model(X_train[:1])\n",
        "trained_model, history = launch_training(model, X_train, y_train, X_val, y_val, lr = LEARNING_RATE, bs = BATCH_SIZE, epochs = EPOCHS, patience = PATIENCE, decay=DECAY, verbose=0)\n",
        "get_eval(trained_model, history, X_test, y_test, matrix=False)\n",
        "if not os.path.exists(\"results\"):\n",
        "  os.mkdir(\"results\")\n",
        "dump(history.history, os.path.join(\"results\",\"history_base_aug.joblib\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1rR-Wf9Ov8A"
      },
      "source": [
        "**MODELE AMÉLIORÉ / DATA AUGMENTED**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "Ixb4QB3n8i0J",
        "outputId": "7e5e47b2-776c-4371-92c5-2d498c57762e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17464/17464 [00:01<00:00, 9091.97it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Accuracy: 0.977\n",
            "82/82 [==============================] - 0s 5ms/step\n",
            "Test Accuracy: 0.975\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['results/history_improved_aug.joblib']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 200\n",
        "PATIENCE = 100\n",
        "DROPOUT = 0.5\n",
        "DECAY = 0.97\n",
        "RS = 1\n",
        "\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = get_data(\"extracted.csv\", random_state = RS)\n",
        "model = improved_model(input_shape=X_train.shape[1:], dropout_ratio=DROPOUT)\n",
        "_ = model(X_train[:1])\n",
        "trained_model, history = launch_training(model, X_train, y_train, X_val, y_val, lr = LEARNING_RATE, bs = BATCH_SIZE, epochs = EPOCHS, patience = PATIENCE, decay=DECAY, verbose=0)\n",
        "get_eval(trained_model, history, X_test, y_test, matrix=False)\n",
        "if not os.path.exists(\"results\"):\n",
        "  os.mkdir(\"results\")\n",
        "dump(history.history, os.path.join(\"results\",\"history_improved_aug.joblib\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZtwj_Z_O_Io"
      },
      "source": [
        "**MODELE AMÉLIORÉ V2 / DATA AUGMENTED**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "A-8lM0E08no_",
        "outputId": "db0d9ebe-798a-41c1-8fc5-b5f689640611"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17464/17464 [00:01<00:00, 9658.88it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Accuracy: 0.984\n",
            "82/82 [==============================] - 1s 9ms/step\n",
            "Test Accuracy: 0.979\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['results/history_improved2_aug.joblib']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 200\n",
        "PATIENCE = 100\n",
        "DROPOUT = 0.5\n",
        "DECAY = 0.97\n",
        "RS = 1\n",
        "\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = get_data(\"extracted.csv\", random_state = RS)\n",
        "model = reimproved_model(input_shape=X_train.shape[1:], dropout_ratio=DROPOUT)\n",
        "_ = model(X_train[:1])\n",
        "trained_model, history = launch_training(model, X_train, y_train, X_val, y_val, lr = LEARNING_RATE, bs = BATCH_SIZE, epochs = EPOCHS, patience = PATIENCE, decay=DECAY, verbose=0)\n",
        "get_eval(trained_model, history, X_test, y_test, matrix=False)\n",
        "if not os.path.exists(\"results\"):\n",
        "  os.mkdir(\"results\")\n",
        "dump(history.history, os.path.join(\"results\",\"history_improved2_aug.joblib\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSr-58xZ0xXz"
      },
      "outputs": [],
      "source": [
        "history_base = load('results/history_base.joblib')\n",
        "history_base_aug = load('results/history_base_aug.joblib')\n",
        "history_improved2 = load('results/history_improved2.joblib')\n",
        "history_improved2_aug = load('results/history_improved2_aug.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "jjCVH7Vt1olz",
        "outputId": "c76cac92-91aa-48ba-fb6e-f612d49652bd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVRklEQVR4nOzdd1wT5x8H8E8SCHuoIEsExYkDN26sorj3tuJe1brrrLsWtdWqdbVuq1bqts4q7omKuFAEREHZInsnz++P++VCJIxAIALf9+uVV5K75577XhK9L8+4EzDGGAghhBBCygihpgMghBBCCFEnSm4IIYQQUqZQckMIIYSQMoWSG0IIIYSUKZTcEEIIIaRMoeSGEEIIIWUKJTeEEEIIKVMouSGEEEJImULJDSGEEELKFEpuCCFftX379kEgEODdu3eaDoVowPLlyyEQCDQdBillKLkhpdK2bdsgEAjg7Oys6VDKrHfv3kEgEEAgEOD48eM51stOOjExMRqIrmAOHz6MjRs3ajqMMq+on3NKSgqWL1+O69evqy0mUr5RckNKpUOHDsHe3h7e3t4IDAzUdDhl3sqVK1Eab0NHyU3JUEdys2LFCqXJzY8//ojU1NTCB0fKJUpuSKkTHByMu3fvYsOGDTA3N8ehQ4c0HVKukpOTNR1CkTVq1AjPnj3DyZMnNR0KKYe0tLSgq6ur6TBIKUPJDSl1Dh06hAoVKqBHjx4YOHBgrslNXFwcZs2aBXt7e+jo6KBKlSpwd3dX6EZJS0vD8uXLUatWLejq6sLKygr9+/dHUFAQAOD69esQCAQ5/qKUddns27ePXzZ69GgYGhoiKCgI3bt3h5GREUaMGAEAuHXrFgYNGoSqVatCR0cHtra2mDVrltK/SF+/fo3BgwfD3Nwcenp6qF27NhYvXgwAuHbtGgQCgdJE4/DhwxAIBLh3755Kn2d+hg4dilq1ahW49ebo0aNo2rQp9PT0YGZmhm+//RYfP34s0L5evnyJjh07Qk9PD1WqVMFPP/0EqVSao9zp06fRo0cPWFtbQ0dHBw4ODli1ahUkEglfpkOHDjh37hzev3/Pd6/Z29sDADIyMrB06VI0bdoUJiYmMDAwQLt27XDt2rUCxVmQ/QOAvb09Ro8enWP7Dh06oEOHDgrL3r9/j969e8PAwACVK1fGrFmzcOnSpRy/vw4dOqB+/fp49uwZXFxcoK+vjxo1auDYsWMAgBs3bsDZ2Zn/7Vy5ciXH/j9+/IixY8fCwsICOjo6qFevHvbs2aNQRvbb/+eff7B69WpUqVIFurq66NSpk0JraVE/53fv3sHc3BwAsGLFCr6O5cuXA1A+5iYrKwurVq2Cg4MDdHR0YG9vj0WLFiE9PT3H59+zZ0/cvn0bLVq0gK6uLqpXr44DBw7k+ExI2aKl6QAIUdWhQ4fQv39/iMViDBs2DNu3b8fDhw/RvHlzvkxSUhLatWuHV69eYezYsWjSpAliYmJw5swZfPjwAWZmZpBIJOjZsye8vLwwdOhQzJgxA4mJibh8+TJevHgBBwcHlWPLysqCm5sb2rZti19//RX6+voAuBN+SkoKpkyZgkqVKsHb2xu///47Pnz4gKNHj/LbP3v2DO3atYO2tjYmTpwIe3t7BAUF4d9//8Xq1avRoUMH2Nra4tChQ+jXr1+Oz8XBwQGtWrUq5CernEgkwo8//gh3d3ecPHkS/fv3z7Xsvn37MGbMGDRv3hweHh6IjIzEpk2bcOfOHTx58gSmpqa5bhsREYFvvvkGWVlZWLBgAQwMDPDnn39CT09P6X4MDQ0xe/ZsGBoa4urVq1i6dCkSEhLwyy+/AAAWL16M+Ph4fPjwAb/99hsAwNDQEACQkJCAXbt2YdiwYZgwYQISExOxe/duuLm5wdvbG40aNcrzMynI/lWRnJyMjh07Ijw8HDNmzIClpSUOHz6ca7L1+fNn9OzZE0OHDsWgQYOwfft2DB06FIcOHcLMmTMxefJkDB8+HL/88gsGDhyI0NBQGBkZAQAiIyPRsmVLCAQCTJs2Debm5rhw4QLGjRuHhIQEzJw5U2Ffa9asgVAoxNy5cxEfH49169ZhxIgRePDggVo+Z3Nzc2zfvh1TpkxBv379+N9Xw4YNc/28xo8fj/3792PgwIGYM2cOHjx4AA8PD7x69SpH4h8YGIiBAwdi3LhxGDVqFPbs2YPRo0ejadOmqFevnsrfFSklGCGlyKNHjxgAdvnyZcYYY1KplFWpUoXNmDFDodzSpUsZAHbixIkcdUilUsYYY3v27GEA2IYNG3Itc+3aNQaAXbt2TWF9cHAwA8D27t3LLxs1ahQDwBYsWJCjvpSUlBzLPDw8mEAgYO/fv+eXtW/fnhkZGSksyx4PY4wtXLiQ6ejosLi4OH5ZVFQU09LSYsuWLcuxn8KSHeMvv/zCsrKyWM2aNZmTkxMfy7JlyxgAFh0dzRhjLCMjg1WuXJnVr1+fpaam8vWcPXuWAWBLly7Nc38zZ85kANiDBw8UjsvExIQBYMHBwfxyZZ/npEmTmL6+PktLS+OX9ejRg9nZ2eUom5WVxdLT0xWWff78mVlYWLCxY8fmGacq+7ezs2OjRo3KUdbFxYW5uLjw79evX88AsFOnTvHLUlNTWZ06dXL8/lxcXBgAdvjwYX7Z69evGQAmFArZ/fv3+eWXLl3K8TsdN24cs7KyYjExMQoxDR06lJmYmPDHJvvt161bV+Gz2rRpEwPAnj9/zi8r6uccHR3NACj9/cp+ZzK+vr4MABs/frxCublz5zIA7OrVq/wyOzs7BoDdvHmTXxYVFcV0dHTYnDlzcuyLlB3ULUVKlUOHDsHCwgLffPMNAEAgEGDIkCE4cuSIQpfA8ePH4eTklKN1Q7aNrIyZmRm+//77XMsUxpQpU3Isy976kJycjJiYGLRu3RqMMTx58gQAEB0djZs3b2Ls2LGoWrVqrvG4u7sjPT2d74YAAE9PT2RlZeHbb78tdNx5kbXePH36FKdOnVJa5tGjR4iKisJ3332nMEaiR48eqFOnDs6dO5fnPs6fP4+WLVuiRYsW/DJzc3O+ay+77J9nYmIiYmJi0K5dO6SkpOD169cFOh6xWAwAkEqliI2NRVZWFpo1awYfH598ty/q/r908eJF2NjYoHfv3vwyXV1dTJgwQWl5Q0NDDB06lH9fu3ZtmJqaom7dugozCGWv3759CwBgjOH48ePo1asXGGOIiYnhH25uboiPj89x/GPGjOE/KwBo166dQp15KernrMz58+cBALNnz1ZYPmfOHADI8TtzdHTkYwa431Tt2rULFD8pvSi5IaWGRCLBkSNH8M033yA4OBiBgYEIDAyEs7MzIiMj4eXlxZcNCgpC/fr186wvKCgItWvXhpaW+npntbS0UKVKlRzLQ0JCMHr0aFSsWBGGhoYwNzeHi4sLACA+Ph6A/GSRX9x16tRB8+bNFcYaHTp0CC1btkSNGjVy3U4ikSAiIkLhkZGRUeBjGzFiBGrUqJHr2Jv3798D4E60ymKWrc/N+/fvUbNmzRzLldX38uVL9OvXDyYmJjA2Noa5uTmf2Mk+z/zs378fDRs2hK6uLipVqgRzc3OcO3euQNurY//ZvX//Hg4ODjmS6ty+zypVquQoa2JiAltb2xzLAK4bC+AS6Li4OPz5558wNzdXeIwZMwYAEBUVpVDHl4l2hQoVFOrMT1E+Z2Xev38PoVCY47OxtLSEqalpjt/Zl/HLjqGg8ZPSicbckFLj6tWrCA8Px5EjR3DkyJEc6w8dOoQuXbqodZ+5teB8OXBURkdHB0KhMEfZzp07IzY2FvPnz0edOnVgYGCAjx8/YvTo0UoHzObH3d0dM2bMwIcPH5Ceno779+9jy5YteW4TGhqKatWqKSy7du1ajoGtuZG13owePRqnT59WOWZ1iYuLg4uLC4yNjbFy5Uo4ODhAV1cXPj4+mD9/foE+z4MHD2L06NHo27cvfvjhB1SuXBkikQgeHh78YHJ17D+v349IJFLtwLPJbdvclsuSUVls3377LUaNGqW07JdjXfKrMy9F+ZzzU9DW1aLET0ovSm5IqXHo0CFUrlwZW7duzbHuxIkTOHnyJHbs2AE9PT04ODjgxYsXedbn4OCABw8eIDMzE9ra2krLyP5KjYuLU1ieXytEds+fP8ebN2+wf/9+uLu788svX76sUK569eoAkG/cADeDafbs2fj777+RmpoKbW1tDBkyJM9tLC0tc+zTycmpoIcBgDsp/vTTT1ixYoVCFwoA2NnZAQD8/f3RsWNHhXX+/v78+tzY2dkhICAgx3J/f3+F99evX8enT59w4sQJtG/fnl8eHBycY9vcToDHjh1D9erVceLECYUyy5YtyzNGVfdfoUKFHL8dgPv9yL5vgDt2Pz8/MMYU4lH3NZzMzc1hZGQEiUQCV1dXtdVb1M9ZlW5gOzs7SKVSBAQEoG7duvzyyMhIxMXF5fs7I+UDdUuRUiE1NRUnTpxAz549MXDgwByPadOmITExEWfOnAEADBgwAE+fPlU6ZVr2F9uAAQMQExOjtMVDVsbOzg4ikQg3b95UWL9t27YCxy77yzH7X4qMMWzatEmhnLm5Odq3b489e/YgJCREaTwyZmZm6NatGw4ePIhDhw6ha9euMDMzyzMOXV1duLq6KjxkyZsqx/Ljjz/C19eX/6xlmjVrhsqVK2PHjh0KU3IvXLiAV69eoUePHnnW3b17d9y/fx/e3t78sujo6BxT/ZV9nhkZGUq/EwMDA6XdH8rqePDgQYGm0auyfwcHB9y/f1+h++/s2bMIDQ1VKOfm5oaPHz8qfKZpaWnYuXNnvvGoQiQSYcCAATh+/LjSJDo6OrpQ9Rb1c5bNKlSWCH6pe/fuAJDjooEbNmwAgHx/Z6R8oJYbUiqcOXMGiYmJOVoLZFq2bMlf0G/IkCH44YcfcOzYMQwaNAhjx45F06ZNERsbizNnzmDHjh1wcnKCu7s7Dhw4gNmzZ8Pb2xvt2rVDcnIyrly5gu+++w59+vSBiYkJBg0ahN9//x0CgQAODg44e/ZsjnEJealTpw4cHBwwd+5cfPz4EcbGxjh+/LjSPv/Nmzejbdu2aNKkCSZOnIhq1arh3bt3OHfuHHx9fRXKuru7Y+DAgQCAVatWFfzDLKIRI0Zg1apVOeLR1tbG2rVrMWbMGLi4uGDYsGH8VHB7e3vMmjUrz3rnzZuHv/76C127dsWMGTP4qeB2dnZ49uwZX65169aoUKECRo0ahenTp0MgEOCvv/5S2s3QtGlTeHp6Yvbs2WjevDkMDQ3Rq1cv9OzZEydOnEC/fv3Qo0cPBAcHY8eOHXB0dERSUlKecaqy//Hjx+PYsWPo2rUrBg8ejKCgIBw8eDDHZQYmTZqELVu2YNiwYZgxYwasrKxw6NAhfmC2Ou+ttGbNGly7dg3Ozs6YMGECHB0dERsbCx8fH1y5cgWxsbEq11nUz1lPTw+Ojo7w9PRErVq1ULFiRdSvX1/p+DMnJyeMGjUKf/75J99F6O3tjf3796Nv3778ZANSzpXw7CxCCqVXr15MV1eXJScn51pm9OjRTFtbm5/i+unTJzZt2jRmY2PDxGIxq1KlChs1apTCFNiUlBS2ePFiVq1aNaatrc0sLS3ZwIEDWVBQEF8mOjqaDRgwgOnr67MKFSqwSZMmsRcvXiidCm5gYKA0Nj8/P+bq6soMDQ2ZmZkZmzBhAnv69GmOOhhj7MWLF6xfv37M1NSU6erqstq1a7MlS5bkqDM9PZ1VqFCBmZiYKEy9VpfsU8G/tHfvXgZAYSq4jKenJ2vcuDHT0dFhFStWZCNGjGAfPnwo0D6fPXvGXFxcmK6uLrOxsWGrVq1iu3fvzjEV/M6dO6xly5ZMT0+PWVtbs3nz5vHTnrNPm05KSmLDhw9npqamDAA/XVkqlbKff/6Z2dnZMR0dHda4cWN29uxZNmrUKKVTmr9U0P0zxk3ztrGxYTo6OqxNmzbs0aNHOaaCM8bY27dvWY8ePZienh4zNzdnc+bMYcePH2cAFKZ3u7i4sHr16uWIyc7OjvXo0SPHcgBs6tSpCssiIyPZ1KlTma2tLf+779SpE/vzzz/5MrKp4EePHlXYVtllENTxOd+9e5c1bdqUicVihWnhX04FZ4yxzMxMtmLFCv7fra2tLVu4cKHCNPy8PhNlnz8pWwSM0agqQkqjrKwsWFtbo1evXti9e7emwyHFYOPGjZg1axY+fPgAGxsbTYdDSKlBY24IKaVOnTqF6OhohUHKpPT68lYcaWlp+OOPP1CzZk1KbAhREY25IaSUefDgAZ49e4ZVq1ahcePG/PVySOnWv39/VK1aFY0aNUJ8fDwOHjyI169ff9U3hiXka0XJDSGlzPbt23Hw4EE0atRI4cadpHRzc3PDrl27cOjQIUgkEjg6OuLIkSP5TvEnhOREY24IIYQQUqbQmBtCCCGElCmU3BBCCCGkTCl3Y26kUinCwsJgZGSk1gtjEUIIIaT4MMaQmJgIa2vrHPfw+1K5S27CwsJy3DmXEEIIIaVDaGgoqlSpkmeZcpfcGBkZAeA+HGNjYw1HQwghhJCCSEhIgK2tLX8ez0u5S25kXVHGxsaU3BBCCCGlTEGGlNCAYkIIIYSUKZTcEEIIIaRMoeSGEEIIIWUKJTeEEEIIKVMouSGEEEJImULJDSGEEELKFEpuCCGEEFKmUHJDCCGEkDKFkhtCCCGElCmU3BBCCCGkTKHkhhBCCCFlCiU3hBBCCClTKLkhhBBC1EjKpEjLStN0GHlKyUxBamaqpsMoNpTcEEJICYlIikBsaqymwyDFbOq5qaiwtgJ8wn00sv9N9zdh7e21YIwpLE/JTMGMCzPguNURRh5GsN9kj/dx7zUSY3Gj5IYQQkpA8Odg1Pq9Fhpsb4DIpEhNh1NuPAp7hI8JHwu1bWh8KAb8MwA/3/q5wC0xofGh2OmzE2lZafjt/m+F2m9R3A65jZmXZmKB1wKsurmKXy5lUow8ORKbvTfjVcwrSJkUUclRGH5iOLKkWSUeZ3Gj5IYQQlQUlhgGzxeekDJpgbeZf2U+EjMSEZYYBvdT7nluK2VSLPJahGZ/NsOt97cKFePd0LuYdXEWXPa5wHq9NSx/tUSVDVUw/cL0HK1HR14cQaMdjXDg6YEC1y+RSjD8+HDU21YPI06MwE83f8La22vxy51fcMb/DD4kfMjRclAc0rPScfLVSez22Y3HYY+RnpXOr7sQcAHNdzZHmz1tkJKZolK9WdIsDD0+FCdencDiq4vhuNUR5wPO8+tPvz6NFjtb4L+g/xS22/5oOyRMAgA45ncMn1M/57uvLz8nxhg+JHzA6densfPxTqWJVcCnABz3O57jd7Tk2hL+9bLry3Dw2UFkSjKxyGsRTrw6AbFIjIP9DsJ7vDeMdYxxN/Qull9fnm+M+XkZ9RK7fHYhKSOpyHWpg4CVxK/vK5KQkAATExPEx8fD2NhY0+EQUio8i3yGw88Po3al2qhWoRpOvz6NIy+PoIVNC5wacgoCgUDTIaosJTMF+tr6hdq2x+EeOB9wHlu7b8V3zb/Lt/yt97fQfl97CAVCiEVipGWlYXzj8QhJCMH9D/dxoO8B9KnTBwCX2Ew+Oxk7fXYCAEQCEX7t8itmOM/gP+e0rDQ8+PAATyKewCfcBz7hPgiOC0bv2r2x1nUt/nr6F5ZcWwIG5f+9V9KrhNUdV2N8k/G48f4G3A668X+9T2k2Bb+5/QYdLZ08j+n3B79j+sXpeZZxsXPB4QGHYW1kne9nlJu4tDgIIICJronCcr9oP+z22Y0Dzw4gJiWGX26iY4LDAw6jvV171NtWDyHxIQCAlR1WYonLEjDG8DzqOR6HPeY+uwgf+Eb4Qk9LD02smqBVlVYY6TQS+3z3YfWt1TDWMYaR2AgfEz9CAAF2996N2ma10XF/R6RL0mGqawrfSb6wM7VDWlYabH+zRUxKDPS19ZGSmYLfu/2OaS2m8fFlSDIgFAihJdQCAJx6fQrjzoxDx2od8UvnX/Ax4SNmXpqJR2GP+G3mtpqLX7r8wr9/Ff0KrXa3Qnx6PMY0GoOdvXZCJBThavBVdDrQCWKRGMMbDMc+3305Ps+D/Q5iRMMRAIB/Xv6DIceGAAAaWjREU6ummNBkAlrZtuJjzZJm5fnv5FLgJay4sQL3PtwDAPSq1Qunh54ulv8TVDl/U3JDSBkUnhgOLaEWzA3MFZbHp8VjybUlcK3uit61exeorref36LlrpaITolWuv700NMFrisvGZIMfEz4iGoVqhW5rrwkZSRh4r8T4fnSE3/0/APjm4xXeftK6yohQ5KBBpUb4Onkp3n+R56QnoCO+zvicfhjTGwyEc2sm2Hi2YkKZWyMbOA/zR/62voYf2Y89vjugVAgRHu79rj+7joAwKOTBxa0XYDUzFS03N0SzyKfKd2fUCDk/5ofXG8wutfojvqV60MsEiMkPgQLvBbgRdQLAEAjy0Z4F/cOcWlxcLJwwrPIZ2Bg6FenH44PPp7rcYXEh8BxqyOSM5PxQ+sfYKJjgqDPQWBgSM9Kx4uoF/CL9oOESWBhYIEl7ZfgXdw7RCZHoletXuhduzd8wn3w94u/YSg2xCinUahtVpuvPzY1FnP/m4tr767hXdw7AIBDBQfUMasDkVCE8MRwPAx7yJe3NrJGHbM68I3wRWxqLLSF2mhv1x5ewV4wFBsiKSMJ+tr6uDv2LuZenosrb6/k/SVn4znQE91rdsfMizOx+8luAICxjjES0hMgFomRIclAG9s2uD76Og4+O4gxp8fA1tgWs1vNxqxLs9DQoiF8J/lCIBAgU5KJNnvaICA2AHt670EV4ypw2eeC1CxuYK+sPoBLamtUrAH/T/7Q1dLF2+lvYWVkhejkaDjvckZwXDAf44gGIzC+yXgs9FqI+x/uY1rzadjUbRPGnRnHJzjaQm2s+mYV5redr3B8c/+bi/X31iss+7bhtzDVMcXB5weRlJGEXrV64duG36KiXkUIBUI0tmwMIx0jHH5+GO4n3SFhEj5Zy5JmYVPXTZjunHfiWxiU3OSBkhtS1r2KfgXnXc4wFBvCf5o/jHSMAACZkkz0/Lsn/gv6D8Y6xgieEYyKehXzrCsuLQ6td7fGq5hXqF2pNqyMrOAf4w/nKs7QEenA86UnnCyc4DPJB0IB18udJc3Crfe30MSqSY6/tnMTmRQJ179c8SLqBXb02IFJzSYV+HgffnwIYx1jhZNjbt58eoN+nv3gF+0HADDVNUXA9wEw0zfLUTZTkon/gv5DM+tmsDC04Jf/6/8veh+RJ3MPxj9AC5sWALhWl+XXl+PfN/8CABLTExH0OQgAYCQ2QuD0QJjrm+P7C9/j8tvLGOQ4CIefH0ZwXDCWuSyDlEmx6uYqiAQi/NXvLwytPxTr7qzDAq8F0NfWx5tpb7DPdx9+vPYjjHWM0bFaRzSxbIImVk1grGOMxVcX41bILeiIdLC1+1aMazIux3FlSbOw/eF2LL2+FHFpcQCAVlVa4eqoq7gafBV9j/RFpjQT/wz8B4PqDeK3S8lMwcXAi0jOSMa+p/twNfgq2ti2wc0xN/nvPrvA2ED09+yP51HPc6zTEekgXZKusMy1uisO9juIygaV0edIH/4zzI1IIELPWj0xvsl4dK3RFVpCLWRKMjHixAgc9TvKl7s44iLfsiBL/HREOmhl24r/7JpYNUFKZgoehz/GydcncSnwEhgYxjcej529uRY0xhhmXpyJzd6bAQBNrJpgf9/9aLOnDRLSE1CzYk3EpMTgc9pneHTywKSmk2C9wZprZfv/b2Tn450Kia2R2AiJGYnoVK0TJEyC6++uQwABxjUeh9WdVsNc3xyt97TG/Q/38X2L77Gk/RL0+rsXHnx8gOoVqmNe63mYen4q3w0GQCERkv0GJUwCsUicawtMaHwofMJ9cMr/FPb77s+1xU/GQNsAnR0644z/GUiZFN82/Ba/dP4Fx/yO4fsL30MsEuP+uPtobNU4z3pURclNHii5IV8DxhhuhdzC289vMaLBCGiLtNVSb1pWGpx3OfN/1a/vsh6zW80GYwxTzk3BH4//4MsubLsQP3f6Oc8Yux/ujouBF2FjZIMH4x/AxtiGXx+bGotqm6ohIT0BRwcdxUDHgbgWfA3TL07Hi6gX6F6zO84NP6dQZ2h8KC4FXcLgeoNhrMP9+wtPDEfHAx3xOuY1AO6kdW74ObjVcMv3eP9+/jeGnxgOoUCIyU0nY+U3K1FJv5LSsqHxoWixqwUikiJgZWgFYx1j+H/yx9TmU7Gl+5Yc5UefGo39T/dDS6iF3rV7Y5nLMjS0aIip56Zi26NtEECgcAKUSCUYd2Yc9j/dn6OuqiZV8Zvbb+hft3+Odcf8jmHQ0UHQFmojU5oJANjdezfGNh7Lfw/t9rbDndA76FmrJ64FX0NyZjIO9z+MYQ2GKdTFGMOVt1dgZ2qHWpVq5fnZRSdHY8WNFQhNCMWuXrv4Vr5l15Zh5c2VsDCwwKupr1BBr4LSREUsEsN3ki/qmtfNdR8pmSlY5LUITyKeoEHlBtDX1seh54cQlhgGPS09DHQciM9pn3E+4DykTIo6ZnUwsO5A/HTrJy55HuiJ9nbtIWVSPIl4wrfiiEVidK7emT+BZ5clzcLoU6Nx6PkhjG00Frv77Ib3R28473IGANSqVAsnBp9Avcr1co07JD4EPuE+6FGzh8K/TcYY1t1Zh3sf7mFbj22wNrKG5wtPDD0+lC9jrGOMoOlBMNM3w8iTI3Hw2UG0q9oO54afQ71t9RCaEApnG2c8+PgAANCgcgPcHnsbRmIjXA2+isoGldHAogFf35W3V9D5r84Qi8SwMLBAaEIoTHVNcW/cPdQxq4Ozb85i5Y2VSM5MhlAgxHfNvsOU5lPy+urz9PDjQ6y5swY6Ih2MaTQGloaW2Ou7F1feXoGESZCQnoAPCR/48hOaTMCOnjsgFAjBGEM/z3447X8aNSvWhO9k30J3/SpDyU0eKLkhmnb4+WGsuLECbz69AQDMbjkb6924ZuG0rDSIBKJCJzvTzk/D1odbIRKIIGES2BjZ4O2Mt9jivQVz/psDAQSY3Gwytj/aDgNtAwTPCMbj8Md4GvEUM1rOgK6WLl/Xcb/jGHh0IHS1dHFv3D00smyUY3/Lry/HihsrYK5vDj1tPX58g0zg94FwqOiAtKw0rL+7Hj/f/hkpmSnoXL0zLn57EZ9TP6PNnjbw/+SPKsZV0Ny6OU6+PgkjsRHujbvHn4CypFnIkmYpxHcn5A46HujIN+MDQBXjKng6+SnfIhWbGgt9bX1kSjLRdm9bPIt8hvqV6+PyyMt4Ff0KHQ90hEggwrMpz+Bo7sjXc/DZQYw8OVLhWMz1zRHwfQAa/9EYwXHBmNtqLn699ysMtA1wc8xNeNz2wDG/YxAJRNjgtgG1K9WGWCRG/cr1c3QPZscYg8s+F9wK4QYOL2izAB6uHgplHn58iBa7WvDvW1Zpibtj7xbLuIb0rHQ0+qMRXse8RhvbNnA0d8Q/L/9BfHo8zPXN0cSqCQQCAUY2HInhDYarXH+WNAvPI5+jeoXqfMuef4w/Ov/VGaEJoXy5L8eqqIIxhtcxr1HbrDbfqvTn4z8RFBuExe0X84m1ujwJf4Ko5CgAQB2zOrAztQMAvI55jRY7WyAxIxE1K9ZEQGwArI2sETQ9CBcCLuB8wHks67AMVYyr5Hks3+z/Bjfe3wDAJWfHBx9H/cr11XoMBcUYw53QO/jr6V+oalIVC9stVGi5+5TyCa12t8KcVnMwselEtf5GKbnJAyU3pKg+p35G0Ocg1DWrCwOxgUrbvoh6gYbbG4KBwUDbAMmZyQCAc8PPITwxHN9f+B6tbFvhysgrCv8pyAZB1jWrmyPxyZJm4dCzQ9j1ZBduh9wGAJwacgpTzk1BeFI4RjQYgcPPD4OBYX2X9ZjVchZa7GqBR2GPUMW4Cv9X2KK2i7C602oAXJLluNURwXHBWNJ+CVZ+s1Lp8cSnxaPapmr4nMbNCBEJRJjcbDJeRL3Ajfc3sLDtQvzU8Se4HnDFtXfXFLZd9c0qXH57GTff34StsS2uj74OGyMbdDnYBTff30Rjy8bwnuCN5IxktN3bFpFJkfBy90IDiwYI+BSA1ntaIyYlBn3r9MX3Lb6H+0l3fEz8iH199mFUo1G4E3IH7fe1hwACVNKvhKjkKFgYWODB+Af8yaefZz+cen0KDhUc8Hu339G1Rlf4hPugw/4OSMpIwnKX5RjgOAAD/hnAdWnV6YeTr09CLBIj5ocYNNvZjE9SAUBLqIUjA45ggOMAlX4XTyOewmWfC/rW6Ys9ffYo7eZxP+mOv579BQC4P+4+nKs4q7QPVdwJuYO2e9sqLGtVpRWODjqq0HqnTsGfg/HN/m/wPv49+tTug5NDTpbKgepfuhR4CT0O9+C7jgo6CD27R2GP0PNwT3Sw74A/ev5R4O5eTcmUZKqtNTo7Sm7yQMlN2fQy6iWEAmGeTeSFwRjDhcALaG3bGqa6psiUZKLxH43xMprbn5OFE/b33a/QjJyXgf8MxPFXx9GjZg8cGXgEi7wW4Xfv33OMQTg++DjfhfEk/Am+v/A97oTeQQf7Drj07SWIRWK+7PQL0/G79+8AuORiRYcVWNx+MdbdWYf5V+SDByc3nYxtPbZBIBDgQsAFdD/cnd9GwiTQEeng9bTXsDe157e1NrKG/zR/GIoNcz2mx2GPce/DPTS0aIhGlo1grGPMt/pYGlpiYduFmHFxBgy0DbCz104kZiRi0ln5mBpjHWPcGXuH/0s0MikSdbfWxee0z1jruhaPwx/jn5f/AOC6dw70PYBhx4chPCkcTa2a4sboGzAQG+DHqz9i9a3VGFp/KP4e8DfGnR6HPb57+P3oaenhxugbaG7TnF8W/DkYbfe2RVhiGAAoJJzt7drjqvtViIQinH1zFr3+7sVv16laJ1xxv4JN9zdh5qWZEAqE6FqjK+a3mY/2du0L9Fv4EmMsz5N5WGIY+h7pi07VOuVo2SkO596c4y9CZ2VkBXcnd4XfXXGITIrExcCLGOg4UOU/HL5m2x9ux3fnv4O9qT1eT32d70w0ZfL7fZQHlNzkgZKbsic+LR62v9lCyqR4O+MtKhtUVlvdmx9sxoyLM9DUqinujruL7Q+3Y+almfx4CwBoatUU3hO8FWapKPvL2zfCF43/aAwBBHg+5TnqVa6HtKw0tNrdCr4RvhAKhGhh0wL3P9xH/cr18XTyU6y+uRrLri9TGOA3ymkU9vbZC4FAgLef36L2ltrIkmZhafulmNRsEj/tNj4tHlU3VkVCegK6OHTB2WFn+b+mGGOYd3keIpIjsKT9Ekw5NwVXg69ikOMgDK43GGNPj0ViRiL2990Pdyd3lT+3DEkGbH+zRVRyFP+5bO66Gd87fw/GGIYeH4p/Xv4DkUCE8yPOo4tDF4Xt9/nuw5jTY/httYRasDGywft4+dVUG1RugCvuV/jvW9baUFGvIsJmh8Fmgw0+pX7C4f6HYSg2RPUK1ZWOs0hIT8CqG6uw8cFGZEmzoCPSQTu7dtjXZx/fSsEYg9tBN1x+exkA8GvnXzGn9RxImRT/Bf2Heub1YGtiq/LnRMqP2yG3UdWkKqqaVNV0KKWWSudvVs7Ex8czACw+Pl7ToRA1OffmHMNyMCwH++nGTznWJ6QlMIlUonK9SelJrPIvlfm6x50ex0zXmDIsB/vz0Z8s8FMgM/YwZlgOtu/JPhb4KZA5bHJgej/psZa7WrL5l+ezpPQkvr5eh3sxLAcbdmyYwn6CPwezSf9OYl5vvdjn1M/8Pjru78jve+ixoWzfk31MuELIsBxs6dWlTCqVstGnRjMsB+vyVxelx3Dy1Uk29dxUFpcal+exPo14ytcte7TZ3aZQn5vMvP/m8XW13NWSZUmy+HVxqXFs9sXZ7F//f5VuK5VKWaf9nfjt19xaw97EvGEV11ZkWA7WaEcjFp0crbBNpiST/+xW31zNsBys0tpKLFOSWaB4wxLC2NOIpywjK0Pp+ueRz/nPyC/Kr4CfAiFEXVQ5f1PLDSk14tLiEJkUmWPK7/zL87Hu7joA3PVCgmcE8y0UFwMvYsA/A9DGtg0ujLgAkVCU5z72+e7Dy6iXWNRuEf58/CcWeC1ARb2KCld0bWjRED4TfSASivDLnV8w78o8WBpaQiQQ4WOi4mXeZbMkdjzagXlX5kEoEMLvO788py3/dPMnhauMbnTbiBktZwAAtj3chqnnpwIAetfujbNvzkLKpArTkQtr0r+T8KfPn9AR6WB+m/mY33Z+kWY6BHwKQJ2tdSASiOAzyUflAZBBsUHosL8DnG2c8c+gfyAUCPEi6gX+9f8Xk5tNRgW9Cjm2GXx0MI76HYWelh5Ss1L52TLqcvr1acSnxxeqNYsQUjTULZUHSm5Kr3Z72+F2yG2+e0Om1e5WuP/hPv9edn2O55HP0WZPGyRmJALIf/ZFaHwoqm2qBgmToHqF6ohLi0NsaiwO9D2Ah2EP+XEtXu5e6FitIwBuZonjNke8/fwWAOBo7oi9ffbCL9oPMy7OQEJ6AirpVcKn1E8AgB9a/4B1ndfleZyJ6Ylw2OyA6JRopYMPN93fhDn/zeEHKPas1RP/Dsv7miAFkZaVhiMvjqCDfQfYm9oXuT4A8HrrBV0tXbSp2kYt9eVn75O9GHtmLP/+7LCz6FGrR4nsmxBSvCi5yQMlN6VTXFocKq6tyI89kV2/JTkjGaZrTZElzcLIhiPx17O/0LJKS8xqOQs/XP4BIfEhsDayRlhiGAzFhnj53ctc+7wXeS2Cx23FgZp1zOrgxZQXyJRm4rtz38HW2BYrvlmhUOZf/3/Rz7Mf6lWuhysjr/DTfh+FPULnvzojLi0O2kJtbOq6CZObTS7QoMC3n9/iU8onhcGv2d18fxODjw5GQnoC7o67q3SadnkUnhgO6w3cmCMjsRGifohSmD5OCCm9KLnJAyU3X4dPKZ9QQa+C0oG3yshm92S/0NmBvgdgZWSFzn91hq2xLe6Pvw+7jXYKd7itVakW7oy9g75H+uJO6B30qNkD/w77N0eCkf2eMLt67cLJ1ydx+e1lnBh8okB/+YfGh8LKyIq/BLnM88jn2PpwK8Y0GqP2qbspmSmIS4sr0n17yqLGfzSGb4QvP2uKEFI2qHL+pruCkxJ3MfAizH4xw5rbawq8zZ3QOwCA4Q2GY34bbnrzD5d/wLk33BVwXexdYG1kjRnO3JTjZtbNMKXZFFwZeQVm+mb4s9efEIvEOBdwjp9WnN2RF0cQkxKDqiZVMarRKJwdfhZx8+MK3KVha2KbI7EBgAYWDbCj545iuSaJvrY+JTZKzGo5CxYGFpjeQv33tiGElA6U3JASd8zvGADg7xcF/6tadnG6tlXbYuU3K1GjYg1EJkdi04NNAID2Vblri/za5VckLUrCwwkPsa3HNn56rqO5Ixa3WwwA+P7C9/iU8omvmzGGzQ+4+8V81+w7PknR09YrymESDXF3ckfE3Aj+zsaElCfJycC33wL9+wMvX2o6Gs2h5IaUOO+P3gC4q/VmTzJykyHJ4LdpY9sGYpEY67twtyuQjcFxsXfJt54FbRegnnk9RKdEY+7lufzyh2EP8STiCXS1dFW+QzQhhBSERAJIpcW7j8REoFs34NAh4ORJwMkJmDULiIsret1fxp6UBOzZA7RpAzRuDMTEFH0f6kTJDSlRSRlJeBkt/3NCdj8dZT4kfOBumBf+BKlZqaikVwl1zOoAAHrV6oVO1ToBACwMLFCzYs189y0WibGz104IIMA+3324+f4mAODA0wMAgP51++d600VCSMn68AHIzNR0FOoRFgZYWgI9egBZWfmXV4W/PzBuHNda06YNcOsWYGICdO/OJVQbNwK1agG7dnHvc/PsGTB7Nvf8pS1bAENDYOlSrg4vL6B6dW6/d+8Cvr7A4cNc2dhYoGVLYOvWvPdX3Ci5ISXqcdhj/iq+APgEI7u3n9+i75G+sP3NFj0P98T1d9cBAG2qtuEHAgsEAmzuthnVK1TH9y2+L/BlyVvZtsKEJhMAAKtvrUaGJIPvHhvlNKooh0ZIufHyJRAfX3z1Hz0KVK0K9OwpP0EeOACMGgWkpuYsv2oVMGYMd9ItTOuInx8QEVG0mFNSgEWLgGXLgC+n6fz9N9eycfEiF2tBSCTA69fA9eu5H1NSEtC7N9eCcugQ8Pw5UKECcOUKcO4ccOkSUKcOEB0NTJgAODsD9+4p1hEfD0ybxrW+/PYb1/KTvRUmIwNYuZL73FetApo3B7p04eqsXp1LogCupQgADh4EHjwAdu4EhJrMMIrvWoJfJ7pCsWatvb2WYTmYwWoDhuVgTf5oorB+x8MdTGeVjsKVcnV/0mVYDrb29lq1xPA29i0TrRAxLAdbdm0Zw3Iwq1+tFK6gSwjJKS2NsYkTGQMYa96cMalUPfX6+DB2/DhjWVmMvX3LmLExtw+AsdWrGTt6VP7+4EHFba9dk68DGKtZkzG//19AWipl7PRpru7g4JzxvnvH2MCB3HbW1owV9rQQGMhYw4byGM6cUVzfurV8nUDA2MmTjJ0/z9jmzYxt2sTYunWMjRrFmJMTY/b23MPAQL7N5MnKP+vRo7n1NjaMrV/P1RUcrFgmI4OxDRsUP9MVK+Trhw2TL5eV6dVLvj/ZZ29qypienrzsmDGMpaRwnyHAmFDIWFQUY/Xrc++3bCncZ5kXVc7flNyQEjXAcwDDcrAZF2YwLAcTrhDytwbYcHcDn9C4HnBlm+5vYoLlAn7ZnZA7aotj2LFhCgnU3Etz1VY3IWWNVMrYnTtcQpM9kTh/Xnn55GTuRHv6tPwk+egRdzJPS5OXi4jgTpKy+ho1YqxxY/kJG2BMJGJMV1deZsoUxbjatuWWN2woPzlXq8ZYZCRjc+fmTHwePuS23bVL8WQNMDZ/vuJx+Plxda1Zk/tnExjInfhlJ3jZcUj+f+eSsDB5/b17K+4vv4e+PpcMAVyCwhhjiYmM3b7N2OLF8n1ev57/dxgRwdjYsdw2YjFjsbGMxcVxr2UJma8vYzo63PuNG7ntunTh3i9axNjTp4z178/Ynj2KyVaTJlyZ8eO5Z11dxj5/zj8mVVFykwdKbkpeXGocfx+gKhuqMCwHux58nTlscmBYDnbuzTn2042f+ERj0ZVFTPr/fznr767nW3rSMtPy2o1KnoQ/UUhunkU8U1vdpHRKSOD+sy8O798zlp6ec3lgIGPTpnF/HStbzxjXmuHvr/wv97t3ue0vXuTKFYcLFxirW1d+wq1YkbGuXbnXLi6KZaVSxjw9GbO1lZfv2JFLYGQn6aVLubLR0YxZWMjLZW+pMDXlWgSytyrI6mzQQL6/S5e4ZTo6jH34wLUcVK/OLTM3l29bvz5j2tryE3u3bvJ17dsz9uuv8nVv38rrHzRInmTITtbnzzO2YAGXwDHG2PDhXJkmTbiTv5ER9/7YMW79tm3c+5YtGUtK4lpnBALG6tThEoUhQ7jjXLqUa9G5f597+Plx36ksNoGAsdq15Z+j7CH7PAuqQQNuux07GNu/n3vt6Cj/ff3+u3x/q1bJ9xcUlHudP/2kGNPIkarFVFCU3OSBkpuSk5aZxtbcWsMMVhsww58N2ZnXZ/jWmsT0RDbm1BiG5WDm68z5JGP5teV8YsMYdwPFQ88OsStBV9Qen9tfbgzLwZy2O6m9blJ4mZncCeToUe4E8fFj8e/z3j3uhFqpkrxLIzuplLGbNxkbN46xGTNUSyRkJ4vx43Ouk/1VDDBmZsbY3r3ydZGR3ImrShX59tkTnLQ0xSSialXGli/nEqmCSE7mTqKXLjEWHs6dePfu5bok/vqLK/P+PWOGhvIT/OjRXLdHaKg8Wbh3T16nh4c8HhsbeStA9kflylzsS5dy7x0cuCQtKorr8qpShbF//38/1fh4LoHq2pWxgAD5SffzZ+6zaNGCWzZzpjyGV6/kLSkAY3/8wS3//Fmx5UQg4Lq8JBKuLldXbvnAgVz5N28UE4kNG7jPSfZ5TJzI2IsX8jI+Ptx2S5Zw7+vV434nsnrX/r9XPTOT684pKKmUsUmTFD9Da2vGevbkWsdUTWp/+YWro00beZKXvZtKKuW6wbLvz9U17zr9/BTL37ypWkwFVaqSmy1btjA7Ozumo6PDWrRowR48eJBr2YyMDLZixQpWvXp1pqOjwxo2bMguXLig0v4ouSke7z6/Y3t89rA7IXfYu8/v2Lrb61i1jdUUWke0VmoxLAdrsI3702vfk338Ou2V2myr99YSjfl55HPWendrdv5NLm3rRCNWr1b8j9LWlrFPn9S7j/h4xnbvZuzyZa5lQvbXNrJ1aQQHcyeCoUO5MRDZY/py3Eduzp6Vd1WIxVxrhczr1/KTrJWV/PXp01yLTvbERfbw8JBvL0uaKlRQPJkLBFxrTm7jYYKCGOvQQR6X7KGlJX8tFHIJRvfu8hPhl61asu4k2fiMO3e4LiSAa9lISeFaQYYOZeybbxi7cUPe1bRjB9cCBDD2zz8F/95q1OC2OX9e3mqjr891uWR38yZj7drl/J4kEm58S8uW3PbZPXsm/0w2bJCPLZJ9ttWry8e4yB61a3PP/fvL6/n8Wb5Nixbyz+TNm4If55cyMxn7+2/uuMPDC18PY9wfC7LjlMX2+rViGamUse+/lx/nkSP511unDle2Th31jcX6UqlJbo4cOcLEYjHbs2cPe/nyJZswYQIzNTVlkZGRSsvPmzePWVtbs3PnzrGgoCC2bds2pqury3xkKXMBUHJTPDrt76SQyMgelr9asp2Pd7L62+rzy8af5v6EDUsIY/qr9Zn1emt2N+Suho+AfA3S0xmztJQ381euzL3u16/g/2G+f8/9lZyYmHsZ2diD7I8OHbhWBFnrwpfN/wYGjDk7c69r1uROOMpkZjL24AE3oFLW1SI7icjGTTDGJSAA15qQmSk/merry5OdmjW5k9pvv8nj2LOHSxxkZbZt494fOsQlEV+2WEil3LiP9+8ZO3FCMRGysFDs6nBwYKxTJ+519m4cZa1Z2f9ab9eOMTs77vXw4bl/V7LuC9k4jxo1VGt5GDWK227xYsZ69OBeT59e8O3zs2KF/Jhk39nFi4qfGcBYnz6KyeTz54r1eHrKW3gAxa60r0H2FkMnJ+VlpFLu39Hkydyg5PysX8/Vt2uXWkNVUGqSmxYtWrCpU6fy7yUSCbO2tmYe2f88ycbKyopt+WIIdv/+/dmIESMKvE9KbtTjQ/wHlpqZyhjjuo6MPYwZloNVWluJYTmY805ntvPxTpaYzp1h3n1+xyx+sWBYDrb3yV6+nqikKJaSoUIbLdGo6GjupPzoUfHUf+gQ9x+klRWX6Dx6JD/Jbi1gw57spDd5snxZeLi89ScqSt5dIjshd+vGddN82aXRqRPXWnLxIjcmJzGR6z6SJRlfSk3lWgWynwg7duQG0gLc2BWplGs5kp38Ll/mts3IYKxzZ/l29eoptkhMny5fJxtXYmeXc6yOrNtBV5f7i1s24Db7w9mZ6+aRSUriWhYkEi4OWYIDMLZyZe6f9e+/Kw7KdXDIe8ZRZKQ8scmegBXUzp3ypEiWkBWlReRLUiljy5bJ42vVils2Z4582bBh3Gck+56HDlVe18eP3NgTbW3F7savwcGDylsDi0Iq5cY9FadSkdykp6czkUjETp48qbDc3d2d9e7dW+k2FStWZLu+SAtHjBjB7Ozsct1PWloai4+P5x+hoaGU3BTRrfe3mNZKLTbiOJdUfoj/wLAcTLRCxNIy03JNVt7EvGGb729mGVkF+DOAqJW3N3cCX726aGNYZC0ejo7y2SBFIZVyYxVkLQOyE0b2MQAbNnDLdHS4sR55iYiQ/8Wtrc11Lb18ySUSlpZcC8bPP3Prmzbl9p+SotjS8PQp91do9oGl2cmSB3t7+aBSmalT5a08bm7cccTHcw99fW7d7dvyY5IlOzJxcVxi0akTl4Rll5XF2I8/KiYHyv5Klki4fWdPZgQC7vMzNOSSpOwzlpT5/Jmro3fv3Ac6y4SEcCf8mjUZe/w477KMyVtfLCy4ZFAVr14pHle3bqptX1Dr1nFdaDducO+Dgrjfk56efExTVBT3O4mNzbuu4uqiKYqkJK47U1s799/516hUJDcfP35kANjdu4rdET/88ANr0aKF0m2GDRvGHB0d2Zs3b5hEImH//fcf09PTY2KxONf9LFu2jAHI8aDkpvB6He7FsByswpoKTCqVsv8C/2NYDlb799qaDq1US07mmosXL1Z/vbK/9GXN7dm7RwrqzRt54gDkvJaHKjIzudYMR0fFE5UsKck+riD7dN/Zs/OuN3v3jayLRHbdDVlLjGwsy759hYs9OVnedWZqyiU0p09zLTmy/Vy8mHM72RgV2VgTVVqjsgsM5I7L3T337oLISHm31bBh+SeFJSkoiBskLJtNpAqplBv0Lfv8cpuKXhy8vbnEt6x4+ZLrPi1NymxyExUVxfr06cOEQiETiUSsVq1a7LvvvmO6urq57odabopu2rlpzH6jPXsV/YoFxQYpXHvmbexb9tu93xiWg/U70k/ToZZqZ87I/9N++bLg2wUHc9fnmDaNm1XRvj130m3RgvtL94cfuDqtreUXEzM0VP2v5hEj5C0oADfINDupNO9xLjIREdzJTXasurqK41uU9TKfPy+PW/aX8vv33IyqH39k7NQpbpnsGikjRyomOebm8pYT2XtVjz+7//6Td2l9+ZibyyWT7tyRlxEKuQSlKDHkJzKS+/7LGtmMp5o11dN6SEqPUpHcFKZbSiY1NZV9+PCBSaVSNm/ePObo6Fjg/dKYG9XEp8Uz7ZXaDMvBGm5vyKaem6owYPjYy2NswpkJDMvBfvT6UdPhakxgYNFPVLKpsQA3K6MgwsO5KcDKTrKyZEDW2vLvv9zJwNqae3/2bP7179nDtThkv97F2bPyrpHbt7lyT55wg0qFwrwHFD59Kt+/kRE3ZiMujhtb064d16rx5eBMxrjESXYF2OXLc16cDWBs1ix5y090tHymD8DNjNm1S/5eHa1jEgmX5Iwdy8UmEnGJZW7dOFIpN0to3bqSmd5eVp04wSXYBZnBQ8qWUpHcMMYNKJ42bRr/XiKRMBsbm1wHFH8pIyODOTg4sIULFxZ4n5Tc5E0qlbIb726whLQExhhj/7z4R+ksqOqbqvMX3Guzuw3DcrDDzw5rOHrNkE1d/vbbotWT/cJiWlrcWIYvvXjB7cfdnTthy67zUaMGd32NpUu5C3Pdu6fYOjJkiLwO2biQsWO599HRXLeKbECpTPbxK7JHv/83zsmuRGphwc22yD6tWEeHS2JiYrh9zJnDjRdJT5d3EdWtq7xVIa/xCdkHQcoeTZooDsIFuJksss+qRg351WWlUm68iZNTzqnD6pCR8XWOryiL6HMun0pNcnPkyBGmo6PD9u3bx/z8/NjEiROZqakpi/j//zwjR45kCxYs4Mvfv3+fHT9+nAUFBbGbN2+yjh07smrVqrHPKlznmZKbvF0IuMCwHMztLzfGGGMjT4xkWA7WalcrPrFx2OTAtnpv5cuZrjFlWA7mG+6r4ehLllSq2NpSpYp83caN3DiRgp5EpVL5FVVlYyVmzZKvT0/nLh73ZbIhG8OhbMZIZiYXX58+XBeFjJcXt12lSlxrU6NG8roqVJBfQE02fqV6da6Odu24FirGuCvmZh/YKkugZFNMa9VS7LaZM4dr/ZF1CWW/3ktBZWbK6zQ0lI/ZkEq5bjnZvo4fV71uQsjXr9QkN4wx9vvvv7OqVasysVjMWrRowe7fv8+vc3FxYaNGjeLfX79+ndWtW5fp6OiwSpUqsZEjR7KPKrbvUnKTt1U3VvFJzP3Q+/zU7uvB19nCKwsZloPteryLeX/wZlgOpveTHn/VYdnU8LIgIIDr/khKyr3MunU5Ew1Zni27WFle02izk918TkuLuwQ7wM24iYnh1me/vHm/ftw0Z2NjbvaGbEZHQWVmyge1yqZN6+rK799jbc3NIJKNX8lt0Ku/P3cBvAsX5F1JUVHy5AyQfw6APDE7XIQGvrt3uVajL1t9pFKui2v69NyvP0MIKd1KVXJT0sp7cvM6+jVLz8p9bufYU2P55KbW77X4WVGZEu6MEZnENQGkZqbyd9bGcrCam2uWSPwlITNTPotHdsl0qZQbp7FmDbc++9VYf/1Vfon8O3e4E7zshF6jRsGa0I8d48o3bsyVl7WmyK70KmvV2bZNvk1KSv7TUHOT/WaFANeVlZIin0kk63bS1pYnWAV1/TrXKjRwIDeeZuVK+X66d6cuBUJI4ahy/haClBv/vPwHdbbWwY9Xf8y1zLv4d/zrN5/eAAC61ewGLaEWAKCyQWUAgK6WLupVrseXdTR3LIaIi1dWFnD2LPDhg+LyP/8E/Py4115e3LO3N7B6NbBgAdC1KzB8OCCRcM+zZwP163PlXrwAfH3ldQUGAg8eKO5vyBBg5EjA319e7tEj7rl5c0AgAFas4N5v3gysXQtERwP29sCECfJt9PSAChUKd+z9+8tfd+7MxaOnB/z4/5/Grl3cc48eQKVKqtXt4gJERQFHjwImJlyd8+cDrVsD27dzx0cIIcWJkptyZM+TPQAAz5eeYIwpLRP8ORgAYGNkwy/rVauX0rJNrZryrzWV3Eilhd92+nSgVy/Azo47iZ88yZ2Uly6Vl7l1C8jIAC5ckC/z8gLevwccHOQn6+zJzZMnivs5cAB4+hSoWZPb3z//AAcPctv88AOQng48fMiVbdaMe+7Vi0t0UlLkic6cOYCWVuGPNztXV8DaGjA2BnbskCccY8YA1arJy40cWbj6hdn+ZxEIgDVrgDt3gKpVCx8zIYQUFCU35URcWhyuBl8FAITEhyAgNiBHmSxpFkLiQwAAv3b5FQCgLdRG1xpdldbZxKoJ/1oTyU1gIGBmBixcqPq2J05wiQnAJUjnz3OtGba2wKdPgKMjYG4OpKZyLS+y5OaHH4A6dbik4O+/uWcAqPf/RqyXL+UtN998wz0fPgx07Ai8e8fFO2sWl7xkZQG//sq1xmRvuQG4hGDlSnm8ZmbA2LGqH2dudHW5JOzVK6B6dflybW15clehApf0EUJIaUPJTTlx7s05ZEoz+feXgy7nKPMh4QMkTAKxSIzB9QZjf9/9OD74OEx1TZXWqemWGy8v4PNnLnlQxfv3wLhx3Ov584E3b7hnCwuulQYANmyQJyf//CNvWZk5k0tgPnyQJyKA8pabOXO41pH4eCA2FnB2BgICuLrPnOG6bUQi4K+/uDI6OvIkCQDc3IA2bbjX06cD+vqqHWd+Klfm4vuSuzvXHXbiBBcTIYSUNpTclBMnXp8AAJjpmwEALr/NmdzIuqTsTOwgFAjh7uSOXrWVd0kBgJOlEyrpVUIlvUqoY1anGKLOW8D/G59CQrjkoSCysoARI4C4OC7ZWLWK6y5aswYIDeWSjn//5RKLjh25bf74gxsO6+TEJQNCIWBkpFhv3bpca0tUFPD6NbesaVOumwfgkpT//gNMTeXbDBwIbN0qf9+oEddyIiMQAMeOAXv2cGN9SopQCHz/PdChQ8ntkxBC1ImSm3IgJTMFFwK4fpWfO/4MALj27hqypFkK5d7FvQMAVKtQDQWhr62Pe+Pu4d64e9DXVnOzQgEEBspfZx/Em5cVK7ixH7JupezJhLY2113Usyf3XtZyk/n/Bq+uynvnAAAGBordO5aW3GPJEq5L68oVeRdWdpMmcV1dudVvacklSNnjJIQQkjdKbsqBS4GXkJqVCntTe4xtPBYV9SoiIT0B3h+9FcoFx3EtN9VMC5bcAEDNSjVRs1JNtcZbUAHZhg0VJLm5do2b8QRwM6Kq5XOYNWsCNvJx1ejWLe/y2buUGjXinnV0uKRFVzf37dat42ZO/Zj7JDZCCCEqoOSmHDjtfxoA0L9Of4iEInSq1glAznE3suTG3tS+ROMrDKkUCAqSv/9yhtKXMjOBUaO47qVx47jp2PkRCORdU8bG3FTmvMjG3QBA48b5159drVrqmwlFCCHlHSU35YCshca1uisAoHP1zgCAf/z+wYcE+UVeZGNuVGm50ZSPH7kp1DL5tdz8+y83psbCAti0qeD76dOHe+7bN/+uoezJjazlhhBCSMmj5KaMS8tKg/8n7mpxTpZOAIAetXrAUGwIv2g/1N5SG+vvrgdjTOUxN8UlKyv/MrIuKdkA3VevuGnbudm5k3seM4YbH1NQ/fsDd+8qDvzNTVFabgghhKgPJTdl3Muol5AyKcz0zWBlaAUAsDayxq0xt9DGtg1SMlMw9/JcnPE/g7DEMADF33Lz+TMwd678KsAyjHHLDQ25gb95XaBPNpi4VSvuejQSCTdFW5mQEODSJe61bAp4QQkE3D4MDfMvW6cON+6mSRPuAn+EEEI0g5KbMu5p5FMAQEOLhhBku+59I8tGuDXmFiY1nQQAmP3fbDAw6Gvr89PFi8uGDcD69UDv3oqtLZs2ccvT04Hly7lZSytWcK0na9cq1iFrualZU94FlH3cjUQC3L8PJCRwU6kZ42Y/1ahRfMelrQ08f85dE0dI/7IIIURj6L/gMu5pBJfcOFk45VgnEAiwuN1iaAm18PbzWwBcq42gmG/+c/489xwUJL+1wMmT3D2aAGDoUG520YULXJJz8iR3nRfvbJO7ZC03uSU3mzdzLS7W1sBvv3HLst+XqbgIBJTYEEKIptF/w2WcrOVGWXIDALYmthjRYAT/vrjH20READ4+8ve//gr068e1zjAGTJzIXXH43j1g0CBuhpOLC1c2+z2fZMlNjRry8S3ZBxUfO8Y9JydzrTcVK3L7IYQQUvbR5NMyjDEmT24slSc3ADCvzTzsf7ofQPGPt5GNfWnalLvo3dGjwKlTXIvHxInA779zrxs14m57AHAtPLVrc9veucO1yGRvuZHdMuHpU27Kt+x+UADg6cl1T7m55X2tGUIIIWUHtdyUcmf8z8D9pDs+p37Ose5DwgfEpcVBS6iFumZ1c63D0dwRfev0BZB7C4+6yG5A2a0b13Xk5MRd5t/bm7s7tbLp1g4O8tsYLFkChIUBaWncdWHs7LhrxFhYcHfQvngRuH6dG3NTowYweDA3xsfNrVgPixBCyFeEWm5Kubn/zUVAbACsjayxxnWNwjpZq00dszrQ0cr7DogH+h7ApaBL6FO7T7HFKpFw91cCuKv2WloW/LYJP/4I7N/PXWV4+nRumb29/MJ3w4dzY2v++otLdACgc2d1Rk8IIaS0oJabUiw8MRwBsdy0oe2PtiM+LR4Ady8pKZPmOZj4S0Y6RhjoOBDaosLdxOj+fWDjxryvNePtzU0DNzXlblqpCjs77iaXADfAGOC6pGTc3bnn06e5m18ClNwQQkh5RS03pdjN9zf51wnpCdjxaAecLJ0w6OggWBlawVDMXZylOLuaGOMGBS9YwF2X5uxZLrnQz3Yfzbg44PJlYN8+7n2XLoW71cD8+Vzrz+LF3Pvs07qdnLiL6L14wV3XRiiU3/iSEEJI+ULJTSkmS27sTOzwPv491t5Zi+TMZGRIMvgWHSDvwcRFNW4csHcv91pLC/DyArp355IcQ0MgMZG7qF1wsHybXr0Kv79Fi7grDG/YAAwcKF8uEHCtN/Pmce9btJBfvZgQQkj5Qt1SpdjNEC65WeO6BlWMq+Bz2mdkSDLQv25//ND6B2gLtaGrpYumVk2LZf9hYVxiIxAA27cDN24ARkbcs7s716rj4cElNpUrA5MmceNmhg0r2n5nzADevwfat1dcPmKE/Boz1CVFCCHll4AxxjQdRElKSEiAiYkJ4uPjYWxsrOlwCu1TyieY/cJdSThqbhROvj6JSWcnYWj9oTjQ9wC0RdoIjQ9FalYqalWqVSwxXLrEDQyuU4e7txPAXZ/GxYWbkr1gATfINz2dGwvTu3exhKFg+HDg+HHg0SOgQYPi3x8hhJCSocr5m1puSqlbIbcAAHXN6sLcwBwTmkxA6KxQHO5/mB8UbGtiq5bEJiWFayn50vPn3HP2JKJVK2DN/ydtrVnDJTadOhWtK0oV+/YB4eGU2BBCSHlGyU0p8+DDAwTGBvLjbVzsuMv3CgQCVDGuovZbJ6SkAC1bcoN3/f0V18mSm4YNFZfPnMldxwbguok2bOC6rkqCWMxdjZgQQkj5RQOKS5E7IXfQdm9bAICOiLtuTXu79nltUmQzZ8qTmHPnuCsFyzx7xj1/2UoiFHJja8aM4S7Q92XyQwghhBQnSm5KkYuBF/nX6ZJ0CCAo1uTG0xPYuVP+/uZN+c0ts7Lk42yUdQGZm3MzpgghhJCSRslNKXI79DYAYEWHFdDT0oONsQ1sjG2KZV8fP3KzmwBuavf588CtW9y1bIRCICCAG09jYMBdKZgQQgj5WlByU0pkSjLx4AN3N8hBjoNQ1zz3e0UVFWPA1KlAfDx3vZhjx7iWmNhY4OVLrqVG1lVVv758+jUhhBDyNaDTUinxJOIJUrNSUVGvImqb1c5/gyI4cYKbuq2lBezeDejpAa1bc+tu3OCelc2UIoQQQr4GlNyUErdDuC6pNrZtIBQU39cWGwtMm8a9XriQa5kBuGvXANy4G0A+mJgGCxNCCPnaUHJTStwJvQOAS26KS2YmMHgwEBHBzYpatEi+TnY14Bs3uG4rarkhhBDytaLkphRgjPEtN22rti2mfQDffcfdG8rAADhyBNDVla9v3hzQ0QGiooDHj+X3iqLkhhBCyNeGkptSIDA2EFHJURCLxGhqXTz3idq2Ddi1ixsc7OkJNGqkuF5Xl7uYHwC0/X9+ZWUFVKpULOEQQgghhUbJTSkg65Jqbt0culq6+ZRWXVSUvAvq11+BHj2Ulxs8mHtOT+eeu3dXeyiEEEJIkdFU8FLg+rvrAIqvS2rpUiAhAWjalLvjdm6++w7o2xdITQVEIsDOrljCIYQQQoqEkpuvnJRJ+SsTd3Hoovb6nz+XX4X4t9/yv2aNtbXaQyCEEELUirqlvnK+Eb6ITI6EgbZBkWdKpaQAW7cCISHce6kUmD6dex44EGjXTg0BE0IIIRpGyc1X7kLABQBAp+qdoKOlU6S6Dh7krmHTvj0QGcmNr7l+nbtI39q1agiWEEII+QpQt9RX7kIgl9x0q9GtyHUFBXHP798Drq7A69fc+82bgerVi1w9IYQQ8lWg5OYr9jn1M+59uAcA6Fqja5HrCw+Xv37xgnsePBgYN67IVRNCCCFfDeqW+opdeXsFUiZFHbM6sDe1L3J9YWHc87hxXFdUrVrAn38CAkGRqyaEEEK+GpTcfMXU2SUFyFtuhg4FQkOBp08BExO1VE0IIYR8Nahb6it27d01AICbg5ta6pMlN9bWdGVhQgghZRe13HylopOj8S7uHQDAuYpzketLSwM+f+ZeW1kVuTpCCCHkq0XJzVfqcfhjAECtSrVgqmta5PoiIrhnHR3AtOjVEUIIIV8tSm6+Uo/CHgEAmlk3U0t9ssHEVlY0gJgQQkjZRsnNV+ph2EMA3M0y1UE23oa6pAghhJR1Gk9utm7dCnt7e+jq6sLZ2Rne3t55lt+4cSNq164NPT092NraYtasWUhLSyuhaEuOultusg8mJoQQQsoyjSY3np6emD17NpYtWwYfHx84OTnBzc0NUVFRSssfPnwYCxYswLJly/Dq1Svs3r0bnp6eWLRoUQlHXrzCEsMQlhgGoUCIxpaNC13PkCFA27ZAejq13BBCCCk/NJrcbNiwARMmTMCYMWPg6OiIHTt2QF9fH3v27FFa/u7du2jTpg2GDx8Oe3t7dOnSBcOGDcu3tae0kbXaOJo7wkBsUKg6QkOBf/4B7twBHj2i5IYQQkj5obHkJiMjA48fP4arq6s8GKEQrq6uuHfvntJtWrdujcePH/PJzNu3b3H+/Hl079491/2kp6cjISFB4fG1U0eX1M2b8tc+PooDigkhhJCyTGMX8YuJiYFEIoGFhYXCcgsLC7yW3dHxC8OHD0dMTAzatm0LxhiysrIwefLkPLulPDw8sGLFCrXGXtzUMZg4e3Lz+DGNuSGEEFJ+aHxAsSquX7+On3/+Gdu2bYOPjw9OnDiBc+fOYdWqVblus3DhQsTHx/OP0NDQEoxYdYwxtbTc3Lghf+3jQ91ShBBCyg+NtdyYmZlBJBIhMjJSYXlkZCQsLS2VbrNkyRKMHDkS48ePBwA0aNAAycnJmDhxIhYvXgyhMGeupqOjAx0dHfUfQDF5GvkUMSkxEIvEaGjRsFB1REYC/v7y935+gFTKvabkhhBCSFmnsZYbsViMpk2bwsvLi18mlUrh5eWFVq1aKd0mJSUlRwIjEokAcC0eZcHOxzsBAP3q9IOulm6h6pB1STVsCFSuDEgkAGOAlhbdU4oQQkjZp9EbZ86ePRujRo1Cs2bN0KJFC2zcuBHJyckYM2YMAMDd3R02Njbw8PAAAPTq1QsbNmxA48aN4ezsjMDAQCxZsgS9evXik5zSLCUzBYeeHwIAjG8yvtD1yJIbFxcgIAC4eJF7b2kJKGncIoQQQsoUjSY3Q4YMQXR0NJYuXYqIiAg0atQIFy9e5AcZh4SEKLTU/PjjjxAIBPjxxx/x8eNHmJubo1evXli9erWmDkGtjr48ivj0eFQzrYaO1ToWuh7ZeJv27QFjY3lyQ4OJCSGElAcCVlb6cwooISEBJiYmiI+Ph7GxsabDUdB2T1vcCb2D1R1XY1G7wl2Y8NUrwNGRex0RwV3nZsAA7n2fPsCpU+qJlRBCCClJqpy/qZPiK/Eq+hXuhN6BSCDC6EajVd4+MxNYuBBo1Ih737QpYGEBNGkiL0ODiQkhhJQHlNx8JS6/vQwAcK3uCmsj1fuPNm8G1qwBMjIANzfu6sQAYGcHVKzIvabkhhBCSHlAyc1X4mnEUwBAC5sWhdr+wgXuecUK7nX16tx7gQBo8f8q7eyKGiUhhBDy9dPogGIi9zSSS26cLJxU3jYjA7h7l3s9YACX0GS3fj13A82BA4saJSGEEPL1o+TmK5AlzcLL6JcAACdL1ZMbHx8gNRUwM5MPJs7O0VH5ckIIIaQsom6pr0DApwCkZaXBQNsA1StUV3l72dTvdu1yttoQQggh5Q0lN18BWZdUA4sGEApU/0pkF+1r316dURFCCCGlEyU3XwHZYOLCjLeRSIDbt7nXLi7qjIoQQggpnSi5+QoUZTDx06dAQgJ3JeKGhbvPJiGEEFKmUHLzFeCTm0IMJpZ1SbVtC5SB22sRQgghRUbJjYbFpMQgLDEMANCgcgOVt5fdVJ26pAghhBAOJTca9izyGQCgeoXqMNIxUmnboCDg/HnudY8e6o6MEEIIKZ0oudGwogwm/vVXQCoFuncH6tVTd2SEEEJI6UTJjYY9Cn8EQPXkJiIC2LuXez1/vrqjIoQQQkovSm40SMqkuBzE3TDTxV61QTObNwPp6UDLltzF+wghhBDCoeRGg3zCfRCdEg0jsRHa2LYp8HYPHgC//869nj+frkpMCCGEZEfJjQZdCOBu5e1a3RXaIu0CbXPnDtC5M5CUBHToAPTuXYwBEkIIIaUQ3ThTgy4EcslNtxrdClQ+JARwcwOSk4FvvgHOnAGElJ4SQgghCii50ZDY1Fg8+PgAANC1RtcCbXPpEpfYODkBZ88C+vrFGSEhhBBSOtHf/RpyOegypEyKeub1YGtiW6Btnj/nnl1dKbEhhBBCckPJjYao2iUFyJObBqpfyJgQQggpNyi50ZDr764DANxquBWoPGPAM+5ixpTcEEIIIXmg5EYDJFIJPiR8AADUNatboG3Cw4HYWG4AsaNjcUZHCCGElG6U3GhAVHIUJEwCoUAIC0OLAm0j65KqVQvQ1S3G4AghhJBSjpIbDfiY+BEAYGloCS1hwSas0XgbQgghpGAoudGAjwlccmNjZFPgbSi5IYQQQgqGkhsNkLXcWBtZF3gbGkxMCCGEFAwlNxoQlhgGoOAtN1lZwKtX3OuGDYsrKkIIIaRsoORGA2QtNzbGBUtuAgK4O4AbGAD29sUYGCGEEFIGUHKjAaqOuZGNt6lfn+4lRQghhOSHTpUaoOqYmydPuGcab0MIIYTkj5IbDeDH3BSgW4ox4OhR7nX79sUZFSGEEFI2UHJTwlIyUxCXFgegYN1S9+8DQUHceJt+/Yo5OEIIIaQMoOSmhMnG2+hr68NYxzjf8gcOcM8DBgCGhsUZGSGEEFI2UHJTwviZUkY2EAgEeZZNTwc8PbnXI0cWd2SEEEJI2UDJTQlTZbzNuXPA58+AjQ3wzTfFHRkhhBBSNlByU8JUmQZ+8CD3/O23gEhUnFERQgghZQclNyVMlWngDx9yz717F2dEhBBCSNlCyU0Jyz7mJi+ZmUAY14OF6tWLOypCCCGk7KDkpoTx3VL5jLn5+BGQSgEdHaBy5ZKIjBBCCCkbKLkpYQW9aWZICPdsa0u3XCCEEEJUQafNEiRlUj65yW/Mzfv33LOdXXFHRQghhJQtlNyUoJiUGGRKMwEAVkZWeZaVtdxUrVrcURFCCCFlCyU3Jeh9HNccY2loCbFInHdZarkhhBBCCoWSmxL05tMbAECtSrXyLUstN4QQQkjhUHJTgvw/+QMAalXMP7mRtdxQckMIIYSoRuXkxt7eHitXrkSIrGmBFJis5aa2We08yzEmb7mhbilCCCFENSonNzNnzsSJEydQvXp1dO7cGUeOHEF6enqRgti6dSvs7e2hq6sLZ2dneHt751q2Q4cOEAgEOR49evQoUgwlgW+5yadb6tMnICWFe12lSnFHRQghhJQthUpufH194e3tjbp16+L777+HlZUVpk2bBh8fH5UD8PT0xOzZs7Fs2TL4+PjAyckJbm5uiIqKUlr+xIkTCA8P5x8vXryASCTCoEGDVN53SWKMyVtuKuXdciNrtbG0BHR1izsyQgghpGwp9JibJk2aYPPmzQgLC8OyZcuwa9cuNG/eHI0aNcKePXvAGCtQPRs2bMCECRMwZswYODo6YseOHdDX18eePXuUlq9YsSIsLS35x+XLl6Gvr//VJzcfEz8iJTMFIoEI1SpUy7MsjbchhBBCCq/QyU1mZib++ecf9O7dG3PmzEGzZs2wa9cuDBgwAIsWLcKIESPyrSMjIwOPHz+Gq6urPCChEK6urrh3716B4ti9ezeGDh0KAwMDpevT09ORkJCg8NAEWatN9QrV850GTuNtCCGEkMLTUnUDHx8f7N27F3///TeEQiHc3d3x22+/oU6dOnyZfv36oXnz5vnWFRMTA4lEAgsLC4XlFhYWeP36db7be3t748WLF9i9e3euZTw8PLBixYp86ypu/jF5j7eRSIDDh4GOHanlhhBCCCkKlZOb5s2bo3Pnzti+fTv69u0LbW3tHGWqVauGoUOHqiXAvOzevRsNGjRAixYtci2zcOFCzJ49m3+fkJAAW1vbYo/tS/mNtzl3DnB3B2rW5B4AtdwQQgghhaFycvP27VvY5XPWNTAwwN69e/Oty8zMDCKRCJGRkQrLIyMjYWlpmee2ycnJOHLkCFauXJlnOR0dHejo6OQbS3GTzZTKbRp4cDD3HBDAPQBquSGEEEIKQ+UxN1FRUXjw4EGO5Q8ePMCjR49UqkssFqNp06bw8vLil0mlUnh5eaFVq1Z5bnv06FGkp6fj22+/VWmfmpLf1YljYnIuo5YbQgghRHUqJzdTp05FaGhojuUfP37E1KlTVQ5g9uzZ2LlzJ/bv349Xr15hypQpSE5OxpgxYwAA7u7uWLhwYY7tdu/ejb59+6JSpUoq77OkpWelIziOa5rJrVvq0yfuWStbWxq13BBCCCGqU7lbys/PD02aNMmxvHHjxvDz81M5gCFDhiA6OhpLly5FREQEGjVqhIsXL/KDjENCQiAUKuZg/v7+uH37Nv777z+V96cJbz+/hZRJYSg2hKWh8u42WXIzZw5w8CBgbg5UqFCCQRJCCCFlhMrJjY6ODiIjI1G9enWF5eHh4dDSUrk6AMC0adMwbdo0peuuX7+eY1nt2rULfB2drwE/3qZSbQgEAqVlZMlNgwbAmzeAWAzkUpQQQggheVC5W6pLly5YuHAh4uPj+WVxcXFYtGgROnfurNbgyoqAT9wI4ZqVauZaRjbmplIlQF9fsXuKEEIIIQWn8in0119/Rfv27WFnZ4fGjRsDAHx9fWFhYYG//vpL7QGWBYGxgQCAmhVzT25kLTelYAgRIYQQ8lVTObmxsbHBs2fPcOjQITx9+hR6enoYM2YMhg0bpvSaNwQI+hwEAHCo4JBrGVlyY2ZWEhERQgghZVehOj8MDAwwceJEdcdSZslabmpUrKF0fUoKkJrKvaaWG0IIIaRoCj2yw8/PDyEhIcjIyFBY3rt37yIHVZakZ6UjNIGbOu9QUXnLTfZp4EZGJRUZIYQQUjYV6grF/fr1w/PnzyEQCPhZS7JZQBKJRL0RlnLv4t5ByqQw0DaAhYGF0jLZx9vQDClCCCGkaFSeLTVjxgxUq1YNUVFR0NfXx8uXL3Hz5k00a9ZM6bTt8o4fb1PRId9p4DTehhBCCCk6lVtu7t27h6tXr8LMzAxCoRBCoRBt27aFh4cHpk+fjidPnhRHnKVWUGz+g4mzTwMnhBBCSNGo3HIjkUhg9P+BIWZmZggLCwMA2NnZwd/fX73RlQH5DSYGaBo4IYQQok4qt9zUr18fT58+RbVq1eDs7Ix169ZBLBbjzz//zHHVYqLaNHBKbgghhJCiUzm5+fHHH5GcnAwAWLlyJXr27Il27dqhUqVK8PT0VHuApZ0qLTc05oYQQggpOpWTGzc3N/51jRo18Pr1a8TGxqJChQq5DpgtryRSCX838NymgQM05oYQQghRJ5XG3GRmZkJLSwsvXrxQWF6xYkVKbJT4kPABGZIMaAu1YWtsm2s56pYihBBC1Eel5EZbWxtVq1ala9kUkGy8TbUK1SASinItR8kNIYQQoj4qz5ZavHgxFi1ahNjY2OKIp0yRTQPPa7wNQGNuCCGEEHVSeczNli1bEBgYCGtra9jZ2cHAwEBhvY+Pj9qCK+1kg4nzmikF0JgbQgghRJ1UTm769u1bDGGUTW/j3gLIO7nJzAQSErjXlNwQQgghRadycrNs2bLiiKNMiknhmmQsDJXfUwoAZL17AgFQoUJJREUIIYSUbSqPuSEFF5cWBwAw1TXNtYxsvE2FCoAo9zHHhBBCCCkglVtuhEJhntO+aSaV3OfUzwCACrq5N8nQeBtCCCFEvVRObk6ePKnwPjMzE0+ePMH+/fuxYsUKtQVWFnxO45KbgrTcUHJDCCGEqIfKyU2fPn1yLBs4cCDq1asHT09PjBs3Ti2BlXYSqQQJ6dxI4Qp6ubfc0DRwQgghRL3UNuamZcuW8PLyUld1pV58ejz/mlpuCCGEkJKjluQmNTUVmzdvho2NjTqqKxNkg4n1tfUhFolzLUdjbgghhBD1Urlb6ssbZDLGkJiYCH19fRw8eFCtwZVmBRlMDADh4dwzdUsRQggh6qFycvPbb78pJDdCoRDm5uZwdnZGBbpQC68g08AZA27c4F43bVr8MRFCCCHlgcrJzejRo4shjLJHNlMqr8HE/v7Ahw+Ajg7Qrl1JRUYIIYSUbSqPudm7dy+OHj2aY/nRo0exf/9+tQRVFhSkW+ryZe65bVtAT68koiKEEELKPpWTGw8PD5gpGSBSuXJl/Pzzz2oJqiwoSLeULLnp3Ln44yGEEELKC5WTm5CQEFSrVi3Hcjs7O4SEhKglqLKA75bKpeUmMxO4fp177epaQkERQggh5YDKyU3lypXx7NmzHMufPn2KSjSfmZdfy82DB0BiIjcFvHHjkouLEEIIKetUTm6GDRuG6dOn49q1a5BIJJBIJLh69SpmzJiBoUOHFkeMpVJ+A4plXVKdOgFCun0pIYQQojYqz5ZatWoV3r17h06dOkFLi9tcKpXC3d2dxtxkIxtQnFvLzZUr3DONtyGEEELUS+XkRiwWw9PTEz/99BN8fX2hp6eHBg0awM7OrjjiK7Vk3VK5jbnx8+OeW7YsoYAIIYSQckLl5EamZs2aqFmzpjpjKVPy6pbKyADi4rjXVlYlGBQhhBBSDqg82mPAgAFYu3ZtjuXr1q3DoEGD1BJUWZDXgOLoaO5ZJALoos6EEEKIeqmc3Ny8eRPdu3fPsbxbt264efOmWoIq7RhjeV7ELyqKezY3p8HEhBBCiLqpfGpNSkqCWJzzLtfa2tpISEhQS1ClXUpmCjKlmQCUt9xERnLPFhYlGBQhhBBSTqic3DRo0ACenp45lh85cgSOjo5qCaq0k3VJiQQiGIoNc6yXtdxUrlyCQRFCCCHlhMoDipcsWYL+/fsjKCgIHTt2BAB4eXnh8OHDOHbsmNoDLI1kg4lNdU0V7qAuQ8kNIYQQUnxUTm569eqFU6dO4eeff8axY8egp6cHJycnXL16FRUrViyOGEsdfhp4Lhfwo+SGEEIIKT6Fmgreo0cP9OjRAwCQkJCAv//+G3PnzsXjx48hkUjUGmBplN8dwSm5IYQQQopPoefq3Lx5E6NGjYK1tTXWr1+Pjh074v79++qMrdTK3i2lDA0oJoQQQoqPSi03ERER2LdvH3bv3o2EhAQMHjwY6enpOHXqFA0mzoa6pQghhBDNKXDLTa9evVC7dm08e/YMGzduRFhYGH7//ffijK3U4u8rpWOqdD0lN4QQQkjxKXDLzYULFzB9+nRMmTKFbruQj7xabhij5IYQQggpTgVuubl9+zYSExPRtGlTODs7Y8uWLYiJiSnO2Eot/r5SSgYUJyRw95YCKLkhhBBCikOBk5uWLVti586dCA8Px6RJk3DkyBFYW1tDKpXi8uXLSExMLFQAW7duhb29PXR1deHs7Axvb+88y8fFxWHq1KmwsrKCjo4OatWqhfPnzxdq38Ulr/tKyQYTGxkBenolFxMhhBBSXqg8W8rAwABjx47F7du38fz5c8yZMwdr1qxB5cqV0bt3b5Xq8vT0xOzZs7Fs2TL4+PjAyckJbm5uiJL123whIyMDnTt3xrt373Ds2DH4+/tj586dsLGxUfUwilVedwSnLilCCCGkeBXpto21a9fGunXr8OHDB/z9998qb79hwwZMmDABY8aMgaOjI3bs2AF9fX3s2bNHafk9e/YgNjYWp06dQps2bWBvbw8XFxc4OTkV5TDUjh9QrKTlhpIbQgghpHip5Z7UIpEIffv2xZkzZwq8TUZGBh4/fgxXV1d5MEIhXF1dce/ePaXbnDlzBq1atcLUqVNhYWGB+vXr4+eff87zwoHp6elISEhQeBQ3fkBxHncEp+SGEEIIKR5qSW4KIyYmBhKJBBZfXMnOwsICERERSrd5+/Ytjh07BolEgvPnz2PJkiVYv349fvrpp1z34+HhARMTE/5ha2ur1uNQJq8xN5TcEEIIIcVLY8lNYUilUlSuXBl//vknmjZtiiFDhmDx4sXYsWNHrtssXLgQ8fHx/CM0NLRYY2SMISkjCQCU3hGcrk5MCCGEFK9C3VtKHczMzCASiRApO9v/X2RkJCwtLZVuY2VlBW1tbYhEIn5Z3bp1ERERgYyMDIjF4hzb6OjoQEdHR73B5yFdkg4GBgDQ19bPsZ5abgghhJDipbGWG7FYjKZNm8LLy4tfJpVK4eXlhVatWindpk2bNggMDIRUKuWXvXnzBlZWVkoTG01IyUzhX1NyQwghhJQ8jXZLzZ49Gzt37sT+/fvx6tUrTJkyBcnJyRgzZgwAwN3dHQsXLuTLT5kyBbGxsZgxYwbevHmDc+fO4eeff8bUqVM1dQg5yJIbbaE2tEXaOdZTckMIIYQUL411SwHAkCFDEB0djaVLlyIiIgKNGjXCxYsX+UHGISEhEArl+ZetrS0uXbqEWbNmoWHDhrCxscGMGTMwf/58TR1CDrLkRlmrDUDJDSGEEFLcBIwxpukgSlJCQgJMTEwQHx8PY2NjtdfvG+GLxn80hpWhFcLmhCmsy8wEZL1n0dGAmZnad08IIYSUSaqcv0vVbKnSIK+Wm+ho7lkoBCpWLMmoCCGEkPKDkhs1S85IBqA8uXn0iHu2s+MSHEIIIYSoH51i1SyvlpsTJ7hnFW/BRQghhBAVUHKjZrLkxkBsoLA8MxOQ3Z2if/+SjooQQggpPyi5UbPcWm5u3AA+fwbMzYE2bTQRGSGEEFI+UHKjZrklN7Iuqb59gWwXWCaEEEKImlFyo2bKkhupFDh1invdr58GgiKEEELKEUpu1IxPbrTkyc2DB0B4OGBsDHTsqKnICCGEkPKBkhs1S87MORX89m3uuXNnoATv4UkIIYSUS5TcqJmy2VIhIdxzzZqaiIgQQggpXyi5UTNlY25CQ7nnqlU1EREhhBBSvlByo2bKkhtZyw0lN4QQQkjxo+RGzfJKbmxtNRERIYQQUr5QcqNmXyY3KSnAp0/cOmq5IYQQQoofJTdq9mVyIxtvY2QEmJhoKipCCCGk/KDkRs2+nAqefbyNQKCpqAghhJDyg5IbNeOngmtzU8FpvA0hhBBSsii5UbMvu6VophQhhBBSsii5UTNKbgghhBDNouRGzXIbUEzJDSGEEFIyKLlRo0xJJrKkWQCo5YYQQgjRFEpu1EjWagNwyQ1jNKCYEEIIKWmU3KiRbBq4UCCEWCRGdDSQns5NAbex0XBwhBBCSDlByY0aZZ8GLhAI+PE2lpaAjo4GAyOEEELKEUpu1IhmShFCCCGaR8mNGuWW3NB4G0IIIaTkUHKjRtRyQwghhGgeJTdqlNs1bqjlhhBCCCk5lNyo0ZfJzefP3HIzM01FRAghhJQ/lNyoUXKG4h3BExO55UZGmoqIEEIIKX8ouVEjfiq4mLsjeEICt9zYWFMREUIIIeUPJTdq9GW3FLXcEEIIISWPkhs14pMbLUpuCCGEEE2h5EaNsrfcMCZPbqhbihBCCCk5lNyoUfbkJiUFkEq55dRyQwghhJQcSm7UKHtyIxtMLBAABgYaDIoQQggpZyi5USPZXcENxAYK420EAg0GRQghhJQzlNyoUfaWGxpMTAghhGgGJTdqpKxbigYTE0IIISWLkhs1opYbQgghRPMouVEjSm4IIYQQzaPkRo2oW4oQQgjRPEpu1IhabgghhBDNo+RGjfip4NoG1HJDCCGEaAglN2pELTeEEEKI5lFyoyZZ0ixkSDIAUHJDCCGEaBIlN2qSmpnKv6YBxYQQQojmfBXJzdatW2Fvbw9dXV04OzvD29s717L79u2DQCBQeOjq6pZgtMrJuqQAQFdLl1puCCGEEA3ReHLj6emJ2bNnY9myZfDx8YGTkxPc3NwQFRWV6zbGxsYIDw/nH+/fvy/BiJXLPt5GIBDwyQ213BBCCCElS+PJzYYNGzBhwgSMGTMGjo6O2LFjB/T19bFnz55ctxEIBLC0tOQfFhYWJRixctmTGwB8txS13BBCCCElS6PJTUZGBh4/fgxXV1d+mVAohKurK+7du5frdklJSbCzs4OtrS369OmDly9f5lo2PT0dCQkJCo/ikH0aOADqliKEEEI0RKPJTUxMDCQSSY6WFwsLC0RERCjdpnbt2tizZw9Onz6NgwcPQiqVonXr1vjw4YPS8h4eHjAxMeEftra2aj8OANASaqGRZSM4mjsCAA0oJoQQQjRES9MBqKpVq1Zo1aoV/75169aoW7cu/vjjD6xatSpH+YULF2L27Nn8+4SEhGJJcJpYNcGTSU8AAIxRyw0hhBCiKRpNbszMzCASiRAZGamwPDIyEpaWlgWqQ1tbG40bN0ZgYKDS9To6OtDR0SlyrKpISwMkEu41JTeEEEJIydJot5RYLEbTpk3h5eXFL5NKpfDy8lJoncmLRCLB8+fPYWVlVVxhqiz7sB5DQ83FQQghhJRHGu+Wmj17NkaNGoVmzZqhRYsW2LhxI5KTkzFmzBgAgLu7O2xsbODh4QEAWLlyJVq2bIkaNWogLi4Ov/zyC96/f4/x48dr8jAUyLqkDA0BocbnoxFCCCHli8aTmyFDhiA6OhpLly5FREQEGjVqhIsXL/KDjENCQiDMliF8/vwZEyZMQEREBCpUqICmTZvi7t27cHR01NQh5ECDiQkhhBDNETDGmKaDKEkJCQkwMTFBfHw8jIsp+7hxA+jQAahdG3j9ulh2QQghhJQrqpy/qdOkGNBMKUIIIURzKLkpBtQtRQghhGgOJTfFgFpuCCGEEM2h5KYY0E0zCSGEEM2h5KYY0E0zCSGEEM2h5KYYULcUIYQQojmU3BQDGlBMCCGEaA4lN8WAWm4IIYQQzaHkphhQckMIIYRoDiU3xYC6pQghhBDNoeSmGFDLDSGEEKI5lNwUA7rODSGEEKI5lNwUA7rODSGEEKI5lNwUg6Qk7tnQULNxEEIIIeURJTdqlpUFZGRwrw0MNBsLIYQQUh5RcqNmKSny1/r6mouDEEIIKa8ouVEzWXIjEAC6upqNhRBCCCmPKLlRs+Rk7llfn0twCCGEEFKyKLlRM1nLDY23IYQQQjSDkhs1kyU3NN6GEEII0QxKbtQse7cUIYQQQkoeJTdqRt1ShBBCiGZRcqNm1HJDCCGEaBYlN2pGLTeEEEKIZlFyo2Y0oJgQQgjRLEpu1Iy6pQghhBDNouRGzahbihBCCNEsSm7UjFpuCCGEEM2i5EbNqOWGEEII0SxKbtSMBhQTQgghmkXJjZpRtxQhhBCiWZTcqBl1SxFCCCGapaXpAMoaarkhhGiaVCpFRkaGpsMgRGVisRhCYdHbXSi5UTNquSGEaFJGRgaCg4MhlUo1HQohKhMKhahWrRrEYnGR6qHkRs1oQDEhRFMYYwgPD4dIJIKtra1a/gImpKRIpVKEhYUhPDwcVatWhUAgKHRdlNyoGXVLEUI0JSsrCykpKbC2toY+/SdESiFzc3OEhYUhKysL2traha6H0no1o24pQoimSCQSAChykz4hmiL77cp+y4VFyY2aUcsNIUTTitKcT4gmqeu3S8mNGjFGLTeEEFKc7O3tsXHjxjzLCAQCnDp1qkTiUWW/169fh0AgQFxcXLHG0aFDB8ycObNY9/G1o+RGjTIyANkEBWq5IYSQggsNDcXYsWNhbW0NsVgMOzs7zJgxA58+fdJ0aGrTunVrhIeHw8TEBACwb98+mJqaaiQWTSWAJYWSGzWSdUkBlNwQQkhBvX37Fs2aNUNAQAD+/vtvBAYGYseOHfDy8kKrVq0QGxur6RCRmZlZ5DrEYjEsLS3LVLfh13o9JUpu1EjWJaWtzT0IIYTkb+rUqRCLxfjvv//g4uKCqlWrolu3brhy5Qo+fvyIxYsX57ptQEAA2rdvD11dXTg6OuLy5cv57u/ixYto27YtTE1NUalSJfTs2RNBQUH8+nfv3kEgEMDT0xMuLi7Q1dXFoUOHAAB79uxBvXr1oKOjAysrK0ybNk2h7piYGPTr1w/6+vqoWbMmzpw5w6/L3i11/fp1jBkzBvHx8RAIBBAIBFi+fDkAID09HXPnzoWNjQ0MDAzg7OyM69evK+znzp076NChA/T19VGhQgW4ubnh8+fP/HqpVIp58+ahYsWKsLS05OsGuK49AOjXrx8EAgH/fvTo0ejbt6/CfmbOnIkOHTrw7zt06IBp06Zh5syZMDMzg5ubGwDgxYsX6NatGwwNDWFhYYGRI0ciJiYm3++iuFByo0Y0mJgQ8jVhjPt/SRMPxgoWY2xsLC5duoTvvvsOenp6CussLS0xYsQIeHp6gimpUCqVon///hCLxXjw4AF27NiB+fPn57vP5ORkzJ49G48ePYKXlxeEQiH69euX48KHCxYswIwZM/Dq1Su4ublh+/btmDp1KiZOnIjnz5/jzJkzqFGjhsI2K1aswODBg/Hs2TN0794dI0aMUNry1Lp1a2zcuBHGxsYIDw9HeHg45s6dCwCYNm0a7t27hyNHjuDZs2cYNGgQunbtioCAAACAr68vOnXqBEdHR9y7dw+3b99Gr169FGYY7d+/HwYGBnjw4AHWrVuHlStX8onfw4cPAQB79+5FeHg4/76g9u/fD7FYjDt37mDHjh2Ii4tDx44d0bhxYzx69AgXL15EZGQkBg8erFK9asXKmfj4eAaAxcfHq71uHx/GAMasrdVeNSGE5Cs1NZX5+fmx1NRUxhhjSUnc/0maeCQlFSzm+/fvMwDs5MmTStdv2LCBAWCRkZGMMcbs7OzYb7/9xhhj7NKlS0xLS4t9/PiRL3/hwoU861MmOjqaAWDPnz9njDEWHBzMALCNGzcqlLO2tmaLFy/OtR4A7Mcff+TfJyUlMQDswoULjDHGrl27xgCwz58/M8YY27t3LzMxMVGo4/3790wkEikcE2OMderUiS1cuJAxxtiwYcNYmzZtco3DxcWFtW3bVmFZ8+bN2fz58xVi/fIzGjVqFOvTp4/CshkzZjAXFxeFuhs3bqxQZtWqVaxLly4Ky0JDQxkA5u/vn2ucynz5G85OlfM3XcRPjejqxIQQUjisoE092bx69Qq2trawtrbml7Vq1Srf7QICArB06VI8ePAAMTExfItNSEgI6tevz5dr1qwZ/zoqKgphYWHo1KlTnnU3bNiQf21gYABjY2NERUUV+JieP38OiUSCWrVqKSxPT09HpUqVAHAtN4MGDSpwHABgZWWlUhx5adq0qcL7p0+f4tq1azA0NMxRNigoKMexlARKbtSIuqUIIV8TfX0gKUlz+y6IGjVqQCAQ4NWrV+jXr1+O9a9evUKFChVgbm6utth69eoFOzs77Ny5E9bW1pBKpahfv36OwbEG2a7p8WWXWW6+vKquQCBQ6T5fSUlJEIlEePz4MUQikcI6WfJQkFgKE4dQKMyRZCobSG3wxbVOkpKS0KtXL6xduzZHWSsrq3xjLQ6U3KgRXeOGEPI1EQi+/v+PKlWqhM6dO2Pbtm2YNWuWwok7IiIChw4dgru7u9IZRnXr1kVoaCjCw8P5k+j9+/fz3N+nT5/g7++PnTt3ol27dgCA27dv5xunkZER7O3t4eXlhW+++UaVQ8yVWCzOcSXexo0bQyKRICoqio/vSw0bNoSXlxdWrFhR6H1ra2vn2Le5uTlevHihsMzX1zff2yA0adIEx48fh729PbS0vo604qsYULx161bY29tDV1cXzs7O8Pb2LtB2R44cgUAgyDG6W1Oo5YYQQlS3ZcsWpKenw83NDTdv3kRoaCguXryIzp07w8bGBqtXr1a6naurK2rVqoVRo0bh6dOnuHXrVp4zqwCgQoUKqFSpEv78808EBgbi6tWrmD17doHiXL58OdavX4/NmzcjICAAPj4++P3331U+Xhl7e3skJSXBy8sLMTExSElJQa1atTBixAi4u7vjxIkTCA4Ohre3Nzw8PHDu3DkAwMKFC/Hw4UN89913ePbsGV6/fo3t27erNDtJlqhFRETws6w6duyIR48e4cCBAwgICMCyZctyJDvKTJ06FbGxsRg2bBgePnyIoKAgXLp0CWPGjCnybRQKS+PJjaenJ2bPno1ly5bBx8cHTk5OcHNzy7dv8N27d5g7d26uma0mUMsNIYSormbNmnj06BGqV6+OwYMHw8HBARMnTsQ333yDe/fuoWLFikq3EwqFOHnyJFJTU9GiRQuMHz8+10Qo+zZHjhzB48ePUb9+fcyaNQu//PJLgeIcNWoUNm7ciG3btqFevXro2bMnP4OpMFq3bo3JkydjyJAhMDc3x7p16wBws5jc3d0xZ84c1K5dG3379sXDhw9RtWpVAECtWrXw33//4enTp2jRogVatWqF06dPq9Rqsn79ely+fBm2trZo3LgxAMDNzQ1LlizBvHnz0Lx5cyQmJsLd3T3fuqytrXHnzh1IJBJ06dIFDRo0wMyZM2FqaqqxO9MLWGFGcamRs7Mzmjdvji1btgDgpvbZ2tri+++/x4IFC5RuI5FI0L59e4wdOxa3bt1CXFxcga+0mJCQABMTE8THx8PY2FhdhwEA2LQJmDkTGDoU+PtvtVZNCCH5SktLQ3BwMKpVqwZdXV1Nh0OIyvL6Daty/tZoy01GRgYeP34MV1dXfplQKISrqyvu3buX63YrV65E5cqVMW7cuHz3kZ6ejoSEBIVHcaFuKUIIIUTzNJrcxMTEQCKRwMLCQmG5hYUFIiIilG5z+/Zt7N69Gzt37izQPjw8PGBiYsI/bG1tixx3bqhbihBCCNE8jY+5UUViYiJGjhyJnTt3wszMrEDbLFy4EPHx8fwjNDS02OKjlhtCCCFE8zQ6Z8vMzAwikQiRkZEKyyMjI2FpaZmjfFBQEN69e4devXrxy2Tz9rW0tODv7w8HBweFbXR0dKCjo1MM0edELTeEEEKI5mm05UYsFqNp06bw8vLil0mlUv5OsF+qU6cOnj9/Dl9fX/7Ru3dvfPPNN/D19S3WLqeCoCsUE0IIIZqn8avtzJ49G6NGjUKzZs3QokULbNy4EcnJyRgzZgwAwN3dHTY2NvDw8ICurq7CpbEBwNTUFAByLNcE6pYihBBCNE/jyc2QIUMQHR2NpUuXIiIiAo0aNcLFixf5QcYhISEamyevKuqWIoQQQjRP48kNwN3efdq0aUrXXb9+Pc9t9+3bp/6AColabgghhBDNKx1NIqUEtdwQQgghmkfJjRrRgGJCCCFf2rdvHz8+NDejR48u9vskvnv3DgKBAL6+vsW6n68BJTdqRN1ShBCiutGjR0MgEGDNmjUKy0+dOqX0buBl0aZNmxSGWXTo0AEzZ84s8TgKkoiVBpTcqBF1SxFCSOHo6upi7dq1/B2qS4uMjAy11GNiYlImkorsMjMzNbZvSm7UiFpuCCGkcFxdXWFpaQkPD488y92+fRvt2rWDnp4ebG1tMX36dCT//z/fLVu2KFwWRNbys2PHDoX9/Pjjj7nWP3/+fNSqVQv6+vqoXr06lixZonCSXr58ORo1aoRdu3Yp3NwxLi4OkyZNgoWFBX/ZkrNnzyrUfenSJdStWxeGhobo2rUrwsPD+XXZu6VGjx6NGzduYNOmTRAIBBAIBHj37h0A4MWLF+jWrRsMDQ1hYWGBkSNHIiYmhq9HKpVi3bp1qFGjBnR0dFC1atUcd0p/+/YtvvnmG+jr68PJyYm/l+P169cxZswYxMfH8/tdvnw5AEAgEOS4QbWpqSnf2iTr8vL09ISLiwt0dXVx6NAhAMCuXbtQt25d6Orqok6dOti2bVuun7+6UHKjJlIpkJbGvaaWG0LI14AxhuSMZI08GGMqxSoSifDzzz/j999/x4cPH5SWCQoKQteuXTFgwAA8e/YMnp6euH37Nj/b1sXFBX5+foiOjgYA3LhxA2ZmZvys28zMTNy7dw8dOnTINQ4jIyPs27cPfn5+2LRpE3bu3InffvtNoUxgYCCOHz+OEydOwNfXF1KpFN26dcOdO3dw8OBB+Pn5Yc2aNRCJRPw2KSkp+PXXX/HXX3/h5s2bCAkJwdy5c5XGsGnTJrRq1QoTJkxAeHg4wsPDYWtri7i4OHTs2BGNGzfGo0ePcPHiRURGRmLw4MH8tgsXLsSaNWuwZMkS+Pn54fDhwznu37h48WLMnTsXvr6+qFWrFoYNG4asrCy0bt0aGzduhLGxMb/f3GLMzYIFCzBjxgy8evUKbm5uOHToEJYuXYrVq1fj1atX+Pnnn7FkyRLs379fpXpV9VVMBS8LUlPlr6nlhhDyNUjJTIGhh6FG9p20MAkGYtX+0uvXrx8aNWqEZcuWYffu3TnWe3h4YMSIEfxYlJo1a2Lz5s1wcXHB9u3bUb9+fVSsWBE3btzAwIEDcf36dcyZMwebNm0CAHh7eyMzMxOtW7fONYbsrTr29vaYO3cujhw5gnnz5vHLMzIycODAAZibmwMA/vvvP3h7e+PVq1eoVasWAKB69eoK9WZmZmLHjh38LYKmTZuGlStXKo3BxMQEYrEY+vr6Crci2rJlCxo3boyff/6ZX7Znzx7Y2trizZs3sLKywqZNm7BlyxaMGjUKAODg4IC2bdsq1D937lz06NEDALBixQrUq1cPgYGBqFOnDkxMTCAQCJTeAqkgZs6cif79+/Pvly1bhvXr1/PLqlWrBj8/P/zxxx98jMWBkhs1kXVJAYCenubiIISQ0mzt2rXo2LGj0haDp0+f4tmzZ3x3B8C1TkmlUgQHB6Nu3bpo3749rl+/DldXV/j5+eG7777DunXr8Pr1a9y4cQPNmzeHfh5/gXp6emLz5s0ICgpCUlISsrKyYGxsrFDGzs6OT2wAwNfXF1WqVOETG2X09fUV7n1oZWWFqKioAn0m2Y//2rVrMDTMmbAGBQUhLi4O6enp6NSpU571NGzYUCEOAIiKikKdOnVUikeZZs2a8a+Tk5MRFBSEcePGYcKECfzyrKwsmJiYFHlfeaHkRk1kg4n19IBSckFlQkgZp6+tj6SFSRrbd2G0b98ebm5uWLhwIUaPHq2wLikpCZMmTcL06dNzbFe1alUA3CyjP//8E7du3ULjxo1hbGzMJzw3btyAi4tLrvu+d+8eRowYgRUrVsDNzQ0mJiY4cuQI1q9fr1DO4IuxB3oF+ItWW1tb4b1AIFC56y4pKQm9evXC2rVrc6yzsrLC27dvC1RP9lhks9FkN6HOjbJ4lQ0Yzv7ZJCVxv72dO3fC2dlZoVz2LrviQMmNmtBgYkLI10YgEKjcNfQ1WLNmDRo1aoTatWsrLG/SpAn8/PxQo0aNXLd1cXHBzJkzcfToUX5sTYcOHXDlyhXcuXMHc+bMyXXbu3fvws7ODosXL+aXvX//Pt94GzZsiA8fPuDNmzd5tt6oQiwWQyKRKCxr0qQJjh8/Dnt7e2hp5Tx916xZE3p6evDy8sL48ePVtl8AMDc3VxgAHRAQgBTZX/W5sLCwgLW1Nd6+fYsRI0YUKp7CojYGNaFp4IQQoh4NGjTAiBEjsHnzZoXl8+fPx927dzFt2jT4+voiICAAp0+fVrh9T8OGDVGhQgUcPnxYIbk5deoU0tPT0aZNm1z3W7NmTYSEhODIkSMICgrC5s2bcfLkyXzjdXFxQfv27TFgwABcvnwZwcHBuHDhAi5evFi4DwDceJ8HDx7g3bt3iImJgVQqxdSpUxEbG4thw4bh4cOHCAoKwqVLlzBmzBhIJBLo6upi/vz5mDdvHg4cOICgoCDcv39f6filvPablJQELy8vxMTE8AlMx44dsWXLFjx58gSPHj3C5MmTc7RGKbNixQp4eHhg8+bNePPmDZ4/f469e/diw4YNhf5sCoKSGzXJzAQMDbkHIYSQolm5cmWOrpKGDRvixo0bePPmDdq1a4fGjRtj6dKlsLa25ssIBAK0a9cOAoGAH0jbsGFDGBsbo1mzZjm6lLLr3bs3Zs2ahWnTpqFRo0a4e/culixZUqB4jx8/jubNm2PYsGFwdHTEvHnzlLaAFNTcuXMhEong6OgIc3NzhISEwNraGnfu3IFEIkGXLl3QoEEDzJw5E6ampvwNppcsWYI5c+Zg6dKlqFu3LoYMGaLS2J7WrVtj8uTJGDJkCMzNzbFu3ToAwPr162Fra4t27dph+PDhmDt3bp5jl2TGjx+PXbt2Ye/evWjQoAFcXFywb98+VKtWrXAfTAEJmKqdfqVcQkICTExMEB8fn2OQmDowBpSTC2oSQr4yaWlpCA4OVrj+CiGlSV6/YVXO39Ryo2aU2BBCCCGaRckNIYQQQsoUSm4IIYQQUqZQckMIIYSQMoWSG0IIIYSUKZTcEEJIGVPOJsGSMkRdv11KbgghpIyQXdI+IyNDw5EQUjiy325Rb89At18ghJAyQktLC/r6+oiOjoa2tjZ/YTdCSgOpVIro6Gjo6+srvb2EKii5IYSQMkIgEMDKygrBwcEFuicSIV8boVCIqlWr8jf0LCxKbgghpAwRi8WoWbMmdU2RUkksFqulxZGSG0IIKWOEQiHdfoGUa9QhSwghhJAyhZIbQgghhJQplNwQQgghpEwpd2NuZBcISkhI0HAkhBBCCCko2Xm7IBf6K3fJTWJiIgDA1tZWw5EQQgghRFWJiYkwMTHJs4yAlbPrdEulUoSFhcHIyKjI8+i/lJCQAFtbW4SGhsLY2FitdX8NyvrxAXSMZUFZPz6AjrEsKOvHB6j/GBljSExMhLW1db7Txctdy41QKESVKlWKdR/GxsZl9scKlP3jA+gYy4KyfnwAHWNZUNaPD1DvMebXYiNDA4oJIYQQUqZQckMIIYSQMoWSGzXS0dHBsmXLoKOjo+lQikVZPz6AjrEsKOvHB9AxlgVl/fgAzR5juRtQTAghhJCyjVpuCCGEEFKmUHJDCCGEkDKFkhtCCCGElCmU3BBCCCGkTKHkRk22bt0Ke3t76OrqwtnZGd7e3poOqdA8PDzQvHlzGBkZoXLlyujbty/8/f0VynTo0AECgUDhMXnyZA1FrJrly5fniL1OnTr8+rS0NEydOhWVKlWCoaEhBgwYgMjISA1GrDp7e/scxygQCDB16lQApfP7u3nzJnr16gVra2sIBAKcOnVKYT1jDEuXLoWVlRX09PTg6uqKgIAAhTKxsbEYMWIEjI2NYWpqinHjxiEpKakEjyJ3eR1fZmYm5s+fjwYNGsDAwADW1tZwd3dHWFiYQh3Kvvc1a9aU8JHkLr/vcPTo0Tni79q1q0KZr/k7BPI/RmX/LgUCAX755Re+zNf8PRbk/FCQ/0NDQkLQo0cP6Ovro3Llyvjhhx+QlZWltjgpuVEDT09PzJ49G8uWLYOPjw+cnJzg5uaGqKgoTYdWKDdu3MDUqVNx//59XL58GZmZmejSpQuSk5MVyk2YMAHh4eH8Y926dRqKWHX16tVTiP327dv8ulmzZuHff//F0aNHcePGDYSFhaF///4ajFZ1Dx8+VDi+y5cvAwAGDRrElylt319ycjKcnJywdetWpevXrVuHzZs3Y8eOHXjw4AEMDAzg5uaGtLQ0vsyIESPw8uVLXL58GWfPnsXNmzcxceLEkjqEPOV1fCkpKfDx8cGSJUvg4+ODEydOwN/fH717985RduXKlQrf6/fff18S4RdIft8hAHTt2lUh/r///lth/df8HQL5H2P2YwsPD8eePXsgEAgwYMAAhXJf6/dYkPNDfv+HSiQS9OjRAxkZGbh79y7279+Pffv2YenSpeoLlJEia9GiBZs6dSr/XiKRMGtra+bh4aHBqNQnKiqKAWA3btzgl7m4uLAZM2ZoLqgiWLZsGXNyclK6Li4ujmlra7OjR4/yy169esUAsHv37pVQhOo3Y8YM5uDgwKRSKWOsdH9/jDEGgJ08eZJ/L5VKmaWlJfvll1/4ZXFxcUxHR4f9/fffjDHG/Pz8GAD28OFDvsyFCxeYQCBgHz9+LLHYC+LL41PG29ubAWDv37/nl9nZ2bHffvuteINTE2XHOGrUKNanT59ctylN3yFjBfse+/Tpwzp27KiwrDR9j1+eHwryf+j58+eZUChkERERfJnt27czY2Njlp6erpa4qOWmiDIyMvD48WO4urryy4RCIVxdXXHv3j0NRqY+8fHxAICKFSsqLD906BDMzMxQv359LFy4ECkpKZoIr1ACAgJgbW2N6tWrY8SIEQgJCQEAPH78GJmZmQrfZ506dVC1atVS+31mZGTg4MGDGDt2rMLNYkvz9/el4OBgREREKHxvJiYmcHZ25r+3e/fuwdTUFM2aNePLuLq6QigU4sGDByUec1HFx8dDIBDA1NRUYfmaNWtQqVIlNG7cGL/88otam/pLwvXr11G5cmXUrl0bU6ZMwadPn/h1Ze07jIyMxLlz5zBu3Lgc60rL9/jl+aEg/4feu3cPDRo0gIWFBV/Gzc0NCQkJePnypVriKnc3zlS3mJgYSCQShS8JACwsLPD69WsNRaU+UqkUM2fORJs2bVC/fn1++fDhw2FnZwdra2s8e/YM8+fPh7+/P06cOKHBaAvG2dkZ+/btQ+3atREeHo4VK1agXbt2ePHiBSIiIiAWi3OcMCwsLBAREaGZgIvo1KlTiIuLw+jRo/llpfn7U0b23Sj7dyhbFxERgcqVKyus19LSQsWKFUvdd5uWlob58+dj2LBhCjcknD59Opo0aYKKFSvi7t27WLhwIcLDw7FhwwYNRltwXbt2Rf/+/VGtWjUEBQVh0aJF6NatG+7duweRSFSmvkMA2L9/P4yMjHJ0e5eW71HZ+aEg/4dGREQo/bcqW6cOlNyQPE2dOhUvXrxQGJMCQKGPu0GDBrCyskKnTp0QFBQEBweHkg5TJd26deNfN2zYEM7OzrCzs8M///wDPT09DUZWPHbv3o1u3brB2tqaX1aav7/yLjMzE4MHDwZjDNu3b1dYN3v2bP51w4YNIRaLMWnSJHh4eJSKy/wPHTqUf92gQQM0bNgQDg4OuH79Ojp16qTByIrHnj17MGLECOjq6iosLy3fY27nh68BdUsVkZmZGUQiUY6R4JGRkbC0tNRQVOoxbdo0nD17FteuXUOVKlXyLOvs7AwACAwMLInQ1MrU1BS1atVCYGAgLC0tkZGRgbi4OIUypfX7fP/+Pa5cuYLx48fnWa40f38A+O8mr3+HlpaWOQb5Z2VlITY2ttR8t7LE5v3797h8+bJCq40yzs7OyMrKwrt370omQDWrXr06zMzM+N9lWfgOZW7dugV/f/98/20CX+f3mNv5oSD/h1paWir9typbpw6U3BSRWCxG06ZN4eXlxS+TSqXw8vpfe/cX0tTfxwH8PUvXtlKn888q/KUookVSVjIKoQzTgkqMTKRWF4ma0oVGREkWFF3pRRejwOyiSDAwhUjB1IssLcWpkEmKIZFhGdrmn/75eS562vMc/KX9esyje94vOLCdP/Pz4Xt29nbnHPYQFotFxcp+n4ggNzcXlZWVqK+vR2ho6Kzb2O12AIDZbP7D1c09p9OJvr4+mM1mxMbGwtPTUzGePT09GBgYWJTjWVZWhsDAQOzZs2fG9Rbz+AFAaGgogoODFeP28eNHtLS0uMbNYrFgZGQEbW1trnXq6+sxNTXlCncL2Y9g8/LlS9TV1cHf33/Wbex2Ozw8PKadylksXr9+jeHhYdd+udjH8L+VlpYiNjYWMTExs667kMZxts+HXzmGWiwWdHV1KYLqj7AeHR09Z4XS/6i8vFy0Wq3cvHlTnj9/LpmZmeLr66u4Enwxyc7OFh8fH2lsbJTBwUHXND4+LiIivb29cvHiRWltbZX+/n6pqqqSsLAwiY+PV7nyX5Ofny+NjY3S398vTU1NsnPnTjGZTDI0NCQiIllZWRISEiL19fXS2toqFotFLBaLylX/c9++fZOQkBA5ffq0Yv5iHT+HwyHt7e3S3t4uAKS4uFja29tddwtduXJFfH19paqqSjo7O2Xfvn0SGhoqExMTrtdISkqSDRs2SEtLizx69EgiIiIkPT1drZYUZurv8+fPsnfvXlm9erXY7XbF+/LH3SWPHz+WkpISsdvt0tfXJ7du3ZKAgAA5cuSIyp39x0w9OhwOKSgokCdPnkh/f7/U1dXJxo0bJSIiQiYnJ12vsZDHUGT2/VREZHR0VPR6vdhstmnbL/RxnO3zQWT2Y+jXr19l3bp1kpiYKHa7XWpqaiQgIEDOnDkzZ3Uy3MyRq1evSkhIiHh5ecmWLVukublZ7ZJ+G4C/ncrKykREZGBgQOLj48XPz0+0Wq2Eh4fLqVOnZHR0VN3Cf1FaWpqYzWbx8vKSVatWSVpamvT29rqWT0xMSE5OjhiNRtHr9ZKSkiKDg4MqVvx7amtrBYD09PQo5i/W8WtoaPjb/dJqtYrI99vBCwsLJSgoSLRarSQkJEzrfXh4WNLT02X58uXi7e0tx44dE4fDoUI3083UX39//0/flw0NDSIi0tbWJnFxceLj4yPLli2TqKgouXz5siIYqG2mHsfHxyUxMVECAgLE09NT/vrrLzl+/Pi0fxIX8hiKzL6fiohcu3ZNdDqdjIyMTNt+oY/jbJ8PIr92DH316pUkJyeLTqcTk8kk+fn58uXLlzmrU/PvYomIiIjcAq+5ISIiIrfCcENERERuheGGiIiI3ArDDREREbkVhhsiIiJyKww3RERE5FYYboiIiMitMNwQ0f89jUaDe/fuqV0GEc0RhhsiUtXRo0eh0WimTUlJSWqXRkSL1FK1CyAiSkpKQllZmWKeVqtVqRoiWuz4zQ0RqU6r1SI4OFgxGY1GAN9PGdlsNiQnJ0On0yEsLAx3795VbN/V1YUdO3ZAp9PB398fmZmZcDqdinVu3LiBtWvXQqvVwmw2Izc3V7H8/fv3SElJgV6vR0REBKqrq/9s00T0xzDcENGCV1hYiNTUVHR0dCAjIwOHDh1Cd3c3AGBsbAy7du2C0WjEs2fPUFFRgbq6OkV4sdlsOHHiBDIzM9HV1YXq6mqEh4cr/saFCxdw8OBBdHZ2Yvfu3cjIyMCHDx/mtU8imiNz9hOcRES/wWq1ypIlS8RgMCimS5cuicj3XyHOyspSbBMXFyfZ2dkiInL9+nUxGo3idDpdy+/fvy8eHh6uX5ReuXKlnD179qc1AJBz5865njudTgEgDx48mLM+iWj+8JobIlLd9u3bYbPZFPP8/Pxcjy0Wi2KZxWKB3W4HAHR3dyMmJgYGg8G1fOvWrZiamkJPTw80Gg3evHmDhISEGWtYv36967HBYIC3tzeGhoZ+tyUiUhHDDRGpzmAwTDtNNFd0Ot0vrefp6al4rtFoMDU19SdKIqI/jNfcENGC19zcPO15VFQUACAqKgodHR0YGxtzLW9qaoKHhwciIyOxYsUKrFmzBg8fPpzXmolIPfzmhohU9+nTJ7x9+1Yxb+nSpTCZTACAiooKbNq0Cdu2bcPt27fx9OlTlJaWAgAyMjJw/vx5WK1WFBUV4d27d8jLy8Phw4cRFBQEACgqKkJWVhYCAwORnJwMh8OBpqYm5OXlzW+jRDQvGG6ISHU1NTUwm82KeZGRkXjx4gWA73cylZeXIycnB2azGXfu3EF0dDQAQK/Xo7a2FidPnsTmzZuh1+uRmpqK4uJi12tZrVZMTk6ipKQEBQUFMJlMOHDgwPw1SETzSiMionYRREQ/o9FoUFlZif3796tdChEtErzmhoiIiNwKww0RERG5FV5zQ0QLGs+cE9E/xW9uiIiIyK0w3BAREZFbYbghIiIit8JwQ0RERG6F4YaIiIjcCsMNERERuRWGGyIiInIrDDdERETkVhhuiIiIyK38C+2i0WiIkKcbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Old CNN Validation accuracy : 0.919\n",
            "Improved CNN Validation accuracy : 0.949\n"
          ]
        }
      ],
      "source": [
        "  # Plot training and validation loss\n",
        "plt.plot(history_base['val_accuracy'], label='Old architechture', color=\"blue\")\n",
        "#plt.plot(history_base['accuracy'], label='Old architecture', color='red', linestyle='-', marker='.', markersize=1)\n",
        "\n",
        "plt.plot(history_improved2['val_accuracy'], label='New architechture', color=\"green\")\n",
        "#plt.plot(history_improved2['accuracy'], label='New architechture', color=\"green\", linestyle='-', marker='.', markersize=1)\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy - No data augmentation')\n",
        "plt.show()\n",
        "# Print best validation accuracy\n",
        "best_val_accuracy_base = round(max(history_base['val_accuracy']), 3)\n",
        "best_val_accuracy_improved = round(max(history_improved2['val_accuracy']), 3)\n",
        "print(f\"Old CNN Validation accuracy : {best_val_accuracy_base}\")\n",
        "print(f\"Improved CNN Validation accuracy : {best_val_accuracy_improved}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "A-KgrcZgs-tQ",
        "outputId": "3598353d-1165-4e98-c535-3e93db1fa389"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Old CNN Validation accuracy : 0.963\n",
            "Improved CNN Validation accuracy : 0.984\n"
          ]
        }
      ],
      "source": [
        "  # Plot training and validation loss\n",
        "plt.plot(history_base_aug['val_accuracy'], label='Old architechture', color=\"blue\")\n",
        "# plt.plot(history_base_aug['accuracy'], color='red', linestyle='-', marker='.', markersize=1)\n",
        "\n",
        "plt.plot(history_improved2_aug['val_accuracy'], label='New architechture', color=\"green\")\n",
        "# plt.plot(history_improved2_aug['ccuracy'], color=\"green\", linestyle='-', marker='.', markersize=1)\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy - Data augmentation')\n",
        "plt.show()\n",
        "# Print best validation accuracy\n",
        "best_val_accuracy_base_aug = round(max(history_base_aug['val_accuracy']), 3)\n",
        "best_val_accuracy_improved_aug = round(max(history_improved2_aug['val_accuracy']), 3)\n",
        "print(f\"Old CNN Validation accuracy : {best_val_accuracy_base_aug}\")\n",
        "print(f\"Improved CNN Validation accuracy : {best_val_accuracy_improved_aug}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBTySkcN81di",
        "outputId": "f493d5a9-aaf0-4fbd-ad91-e2abec6fbd53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 19:57:13,819] A new study created in RDB with name: audio-recognize01\n",
            "100%|██████████| 17464/17464 [00:01<00:00, 10214.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_88 (Conv2D)          (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_89 (Conv2D)          (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_54 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_90 (Conv2D)          (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_91 (Conv2D)          (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 256)               0         \n",
            " 2 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.11450, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 15s - loss: 4.6160 - accuracy: 0.1117 - val_loss: 2.2620 - val_accuracy: 0.1145 - lr: 0.0197 - 15s/epoch - 76ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2612 - accuracy: 0.1116 - val_loss: 2.2619 - val_accuracy: 0.1145 - lr: 0.0197 - 13s/epoch - 68ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2603 - accuracy: 0.1131 - val_loss: 2.2599 - val_accuracy: 0.1145 - lr: 0.0197 - 13s/epoch - 68ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2609 - accuracy: 0.1131 - val_loss: 2.2592 - val_accuracy: 0.1145 - lr: 0.0197 - 13s/epoch - 66ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2608 - accuracy: 0.1067 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0197 - 13s/epoch - 65ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.11450\n",
            "191/191 - 12s - loss: 2.2600 - accuracy: 0.1116 - val_loss: 2.2613 - val_accuracy: 0.1145 - lr: 0.0197 - 12s/epoch - 65ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.11450\n",
            "191/191 - 12s - loss: 2.2611 - accuracy: 0.1073 - val_loss: 2.2590 - val_accuracy: 0.1145 - lr: 0.0197 - 12s/epoch - 65ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2606 - accuracy: 0.1136 - val_loss: 2.2600 - val_accuracy: 0.1145 - lr: 0.0197 - 13s/epoch - 66ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2606 - accuracy: 0.1138 - val_loss: 2.2598 - val_accuracy: 0.1145 - lr: 0.0197 - 13s/epoch - 66ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2605 - accuracy: 0.1191 - val_loss: 2.2607 - val_accuracy: 0.1145 - lr: 0.0197 - 13s/epoch - 66ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2608 - accuracy: 0.1116 - val_loss: 2.2596 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2606 - accuracy: 0.1104 - val_loss: 2.2588 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2602 - accuracy: 0.1082 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2605 - accuracy: 0.1072 - val_loss: 2.2589 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2600 - accuracy: 0.1135 - val_loss: 2.2602 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2604 - accuracy: 0.1127 - val_loss: 2.2601 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2603 - accuracy: 0.1140 - val_loss: 2.2596 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2605 - accuracy: 0.1156 - val_loss: 2.2601 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2605 - accuracy: 0.1105 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2610 - accuracy: 0.1108 - val_loss: 2.2605 - val_accuracy: 0.1145 - lr: 0.0187 - 13s/epoch - 66ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2610 - accuracy: 0.1129 - val_loss: 2.2599 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2604 - accuracy: 0.1153 - val_loss: 2.2593 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2603 - accuracy: 0.1121 - val_loss: 2.2596 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2600 - accuracy: 0.1152 - val_loss: 2.2598 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2603 - accuracy: 0.1162 - val_loss: 2.2596 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2604 - accuracy: 0.1105 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2607 - accuracy: 0.1097 - val_loss: 2.2590 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2607 - accuracy: 0.1131 - val_loss: 2.2600 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2608 - accuracy: 0.1132 - val_loss: 2.2589 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2607 - accuracy: 0.1131 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0178 - 13s/epoch - 66ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.11450\n",
            "191/191 - 13s - loss: 2.2602 - accuracy: 0.1153 - val_loss: 2.2609 - val_accuracy: 0.1145 - lr: 0.0169 - 13s/epoch - 66ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 20:03:49,262] Trial 0 finished with value: 0.115 and parameters: {'optimizer': 'Adam', 'learning_rate': 0.019705583991941666, 'batch_size': 64, 'dropout_ratio': 0.17919707104847893, 'decay': 0.9517616040198058}. Best is trial 0 with value: 0.115.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_92 (Conv2D)          (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_93 (Conv2D)          (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_55 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_94 (Conv2D)          (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 256)               0         \n",
            " 3 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.29695, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 39s - loss: 4730.4097 - accuracy: 0.1690 - val_loss: 2.0024 - val_accuracy: 0.2969 - lr: 0.0447 - 39s/epoch - 2s/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.29695 to 0.31679, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 2.0727 - accuracy: 0.2467 - val_loss: 1.9024 - val_accuracy: 0.3168 - lr: 0.0447 - 13s/epoch - 542ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.31679 to 0.36489, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.9946 - accuracy: 0.2642 - val_loss: 1.7597 - val_accuracy: 0.3649 - lr: 0.0447 - 13s/epoch - 541ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.5192 - accuracy: 0.2049 - val_loss: 2.4622 - val_accuracy: 0.1218 - lr: 0.0447 - 13s/epoch - 538ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.8187 - accuracy: 0.1789 - val_loss: 2.1551 - val_accuracy: 0.1622 - lr: 0.0447 - 13s/epoch - 535ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.1189 - accuracy: 0.1814 - val_loss: 2.1104 - val_accuracy: 0.1721 - lr: 0.0447 - 13s/epoch - 532ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.0950 - accuracy: 0.1864 - val_loss: 2.1669 - val_accuracy: 0.1321 - lr: 0.0447 - 13s/epoch - 532ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.0875 - accuracy: 0.1869 - val_loss: 1.9973 - val_accuracy: 0.2122 - lr: 0.0447 - 13s/epoch - 533ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.0567 - accuracy: 0.2048 - val_loss: 1.9207 - val_accuracy: 0.2351 - lr: 0.0447 - 13s/epoch - 533ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.0274 - accuracy: 0.2071 - val_loss: 1.9358 - val_accuracy: 0.2416 - lr: 0.0447 - 13s/epoch - 532ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.1167 - accuracy: 0.1972 - val_loss: 1.8990 - val_accuracy: 0.2286 - lr: 0.0424 - 13s/epoch - 535ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.9876 - accuracy: 0.2191 - val_loss: 1.8701 - val_accuracy: 0.2496 - lr: 0.0424 - 13s/epoch - 536ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.9634 - accuracy: 0.2233 - val_loss: 1.8510 - val_accuracy: 0.2691 - lr: 0.0424 - 13s/epoch - 532ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 2.0132 - accuracy: 0.2200 - val_loss: 1.8113 - val_accuracy: 0.2737 - lr: 0.0424 - 13s/epoch - 532ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.9526 - accuracy: 0.2327 - val_loss: 1.7854 - val_accuracy: 0.2840 - lr: 0.0424 - 13s/epoch - 532ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.9203 - accuracy: 0.2427 - val_loss: 1.8884 - val_accuracy: 0.2332 - lr: 0.0424 - 13s/epoch - 533ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.9004 - accuracy: 0.2472 - val_loss: 1.7608 - val_accuracy: 0.2989 - lr: 0.0424 - 13s/epoch - 533ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 11.4249 - accuracy: 0.2187 - val_loss: 233.0339 - val_accuracy: 0.1172 - lr: 0.0424 - 13s/epoch - 534ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 69.2722 - accuracy: 0.2191 - val_loss: 2.0459 - val_accuracy: 0.2363 - lr: 0.0424 - 13s/epoch - 536ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.9192 - accuracy: 0.2614 - val_loss: 1.7424 - val_accuracy: 0.3053 - lr: 0.0424 - 13s/epoch - 535ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.8477 - accuracy: 0.2772 - val_loss: 1.7439 - val_accuracy: 0.3267 - lr: 0.0403 - 13s/epoch - 535ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.8834 - accuracy: 0.2749 - val_loss: 1.7640 - val_accuracy: 0.3164 - lr: 0.0403 - 13s/epoch - 535ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.36489\n",
            "24/24 - 13s - loss: 1.8311 - accuracy: 0.2862 - val_loss: 1.7349 - val_accuracy: 0.3214 - lr: 0.0403 - 13s/epoch - 535ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.36489 to 0.38626, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.8125 - accuracy: 0.2968 - val_loss: 1.6447 - val_accuracy: 0.3863 - lr: 0.0403 - 13s/epoch - 536ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.38626\n",
            "24/24 - 13s - loss: 1.9300 - accuracy: 0.2830 - val_loss: 1.6898 - val_accuracy: 0.3374 - lr: 0.0403 - 13s/epoch - 535ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.38626\n",
            "24/24 - 13s - loss: 3.5624 - accuracy: 0.3001 - val_loss: 1.6688 - val_accuracy: 0.3630 - lr: 0.0403 - 13s/epoch - 533ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.38626\n",
            "24/24 - 13s - loss: 1.7755 - accuracy: 0.3140 - val_loss: 1.6241 - val_accuracy: 0.3760 - lr: 0.0403 - 13s/epoch - 534ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.38626\n",
            "24/24 - 13s - loss: 1.7371 - accuracy: 0.3305 - val_loss: 2.1420 - val_accuracy: 0.2691 - lr: 0.0403 - 13s/epoch - 534ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.38626\n",
            "24/24 - 13s - loss: 1.7712 - accuracy: 0.3281 - val_loss: 1.5924 - val_accuracy: 0.3840 - lr: 0.0403 - 13s/epoch - 534ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.38626\n",
            "24/24 - 13s - loss: 1.7331 - accuracy: 0.3318 - val_loss: 1.5718 - val_accuracy: 0.3832 - lr: 0.0403 - 13s/epoch - 534ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy improved from 0.38626 to 0.43702, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.6935 - accuracy: 0.3647 - val_loss: 1.5424 - val_accuracy: 0.4370 - lr: 0.0383 - 13s/epoch - 537ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.43702\n",
            "24/24 - 13s - loss: 1.6643 - accuracy: 0.3717 - val_loss: 1.7159 - val_accuracy: 0.3687 - lr: 0.0383 - 13s/epoch - 537ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.43702\n",
            "24/24 - 13s - loss: 1.6464 - accuracy: 0.3839 - val_loss: 1.5012 - val_accuracy: 0.4210 - lr: 0.0383 - 13s/epoch - 536ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.43702\n",
            "24/24 - 13s - loss: 1.6114 - accuracy: 0.3995 - val_loss: 1.6594 - val_accuracy: 0.3573 - lr: 0.0383 - 13s/epoch - 538ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.43702 to 0.47824, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.5921 - accuracy: 0.4056 - val_loss: 1.4234 - val_accuracy: 0.4782 - lr: 0.0383 - 13s/epoch - 538ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.47824\n",
            "24/24 - 13s - loss: 1.5822 - accuracy: 0.4094 - val_loss: 1.5150 - val_accuracy: 0.4195 - lr: 0.0383 - 13s/epoch - 536ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.47824\n",
            "24/24 - 13s - loss: 1.5612 - accuracy: 0.4206 - val_loss: 1.4351 - val_accuracy: 0.4504 - lr: 0.0383 - 13s/epoch - 538ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.47824\n",
            "24/24 - 13s - loss: 1.5703 - accuracy: 0.4230 - val_loss: 1.5580 - val_accuracy: 0.4031 - lr: 0.0383 - 13s/epoch - 537ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy improved from 0.47824 to 0.50458, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.5380 - accuracy: 0.4284 - val_loss: 1.3639 - val_accuracy: 0.5046 - lr: 0.0383 - 13s/epoch - 538ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.50458\n",
            "24/24 - 13s - loss: 1.5000 - accuracy: 0.4512 - val_loss: 1.4928 - val_accuracy: 0.4313 - lr: 0.0383 - 13s/epoch - 536ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.50458\n",
            "24/24 - 13s - loss: 1.4617 - accuracy: 0.4602 - val_loss: 1.4979 - val_accuracy: 0.4794 - lr: 0.0364 - 13s/epoch - 538ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.50458\n",
            "24/24 - 13s - loss: 1.4750 - accuracy: 0.4620 - val_loss: 1.6681 - val_accuracy: 0.4206 - lr: 0.0364 - 13s/epoch - 538ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.50458\n",
            "24/24 - 13s - loss: 1.4637 - accuracy: 0.4694 - val_loss: 1.5590 - val_accuracy: 0.4679 - lr: 0.0364 - 13s/epoch - 537ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.50458\n",
            "24/24 - 13s - loss: 1.6042 - accuracy: 0.4494 - val_loss: 1.4590 - val_accuracy: 0.4744 - lr: 0.0364 - 13s/epoch - 540ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.50458\n",
            "24/24 - 13s - loss: 1.4867 - accuracy: 0.4752 - val_loss: 1.9041 - val_accuracy: 0.3798 - lr: 0.0364 - 13s/epoch - 540ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.50458\n",
            "24/24 - 13s - loss: 1.4606 - accuracy: 0.4722 - val_loss: 1.3488 - val_accuracy: 0.5031 - lr: 0.0364 - 13s/epoch - 539ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy improved from 0.50458 to 0.53588, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.4156 - accuracy: 0.4861 - val_loss: 1.2726 - val_accuracy: 0.5359 - lr: 0.0364 - 13s/epoch - 540ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.53588\n",
            "24/24 - 13s - loss: 1.4110 - accuracy: 0.4922 - val_loss: 1.8156 - val_accuracy: 0.3710 - lr: 0.0364 - 13s/epoch - 538ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.53588\n",
            "24/24 - 13s - loss: 1.4036 - accuracy: 0.4961 - val_loss: 1.4461 - val_accuracy: 0.4695 - lr: 0.0364 - 13s/epoch - 539ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.53588\n",
            "24/24 - 13s - loss: 1.3919 - accuracy: 0.4997 - val_loss: 1.3465 - val_accuracy: 0.5321 - lr: 0.0364 - 13s/epoch - 539ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.53588\n",
            "24/24 - 13s - loss: 1.3584 - accuracy: 0.5035 - val_loss: 1.3330 - val_accuracy: 0.5179 - lr: 0.0346 - 13s/epoch - 539ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.53588\n",
            "24/24 - 13s - loss: 1.3717 - accuracy: 0.5074 - val_loss: 1.3900 - val_accuracy: 0.4786 - lr: 0.0346 - 13s/epoch - 540ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.53588\n",
            "24/24 - 13s - loss: 1.4299 - accuracy: 0.5033 - val_loss: 1.2853 - val_accuracy: 0.5302 - lr: 0.0346 - 13s/epoch - 541ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy improved from 0.53588 to 0.56985, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.3131 - accuracy: 0.5285 - val_loss: 1.1817 - val_accuracy: 0.5698 - lr: 0.0346 - 13s/epoch - 542ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.56985\n",
            "24/24 - 13s - loss: 1.2923 - accuracy: 0.5359 - val_loss: 1.4789 - val_accuracy: 0.4878 - lr: 0.0346 - 13s/epoch - 540ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.56985\n",
            "24/24 - 13s - loss: 1.2986 - accuracy: 0.5287 - val_loss: 1.2243 - val_accuracy: 0.5515 - lr: 0.0346 - 13s/epoch - 541ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.56985\n",
            "24/24 - 13s - loss: 1.3811 - accuracy: 0.5164 - val_loss: 1.2595 - val_accuracy: 0.5389 - lr: 0.0346 - 13s/epoch - 541ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.56985\n",
            "24/24 - 13s - loss: 1.2708 - accuracy: 0.5358 - val_loss: 1.3354 - val_accuracy: 0.5546 - lr: 0.0346 - 13s/epoch - 540ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.56985\n",
            "24/24 - 13s - loss: 1.3551 - accuracy: 0.5272 - val_loss: 1.2250 - val_accuracy: 0.5466 - lr: 0.0346 - 13s/epoch - 541ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy improved from 0.56985 to 0.57786, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.2348 - accuracy: 0.5564 - val_loss: 1.1884 - val_accuracy: 0.5779 - lr: 0.0346 - 13s/epoch - 543ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.57786\n",
            "24/24 - 13s - loss: 1.2029 - accuracy: 0.5686 - val_loss: 1.1972 - val_accuracy: 0.5737 - lr: 0.0328 - 13s/epoch - 541ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy improved from 0.57786 to 0.59275, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.2134 - accuracy: 0.5645 - val_loss: 1.1666 - val_accuracy: 0.5927 - lr: 0.0328 - 13s/epoch - 544ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy improved from 0.59275 to 0.60115, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.2062 - accuracy: 0.5659 - val_loss: 1.1236 - val_accuracy: 0.6011 - lr: 0.0328 - 13s/epoch - 543ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.1679 - accuracy: 0.5798 - val_loss: 1.1783 - val_accuracy: 0.5569 - lr: 0.0328 - 13s/epoch - 541ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.1862 - accuracy: 0.5709 - val_loss: 1.2205 - val_accuracy: 0.5859 - lr: 0.0328 - 13s/epoch - 541ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.1665 - accuracy: 0.5791 - val_loss: 1.2070 - val_accuracy: 0.5737 - lr: 0.0328 - 13s/epoch - 541ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.1858 - accuracy: 0.5786 - val_loss: 1.1434 - val_accuracy: 0.5931 - lr: 0.0328 - 13s/epoch - 541ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.1330 - accuracy: 0.5856 - val_loss: 1.1389 - val_accuracy: 0.5908 - lr: 0.0328 - 13s/epoch - 541ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.1547 - accuracy: 0.5841 - val_loss: 1.1491 - val_accuracy: 0.5832 - lr: 0.0328 - 13s/epoch - 541ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.1313 - accuracy: 0.5923 - val_loss: 1.2441 - val_accuracy: 0.5618 - lr: 0.0328 - 13s/epoch - 541ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.1215 - accuracy: 0.5935 - val_loss: 1.1485 - val_accuracy: 0.5939 - lr: 0.0312 - 13s/epoch - 542ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.60115\n",
            "24/24 - 13s - loss: 1.0976 - accuracy: 0.6053 - val_loss: 1.1315 - val_accuracy: 0.5939 - lr: 0.0312 - 13s/epoch - 542ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy improved from 0.60115 to 0.60496, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.1433 - accuracy: 0.5867 - val_loss: 1.1370 - val_accuracy: 0.6050 - lr: 0.0312 - 13s/epoch - 543ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.60496\n",
            "24/24 - 13s - loss: 1.0595 - accuracy: 0.6207 - val_loss: 1.1708 - val_accuracy: 0.5851 - lr: 0.0312 - 13s/epoch - 541ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.60496\n",
            "24/24 - 13s - loss: 1.0678 - accuracy: 0.6138 - val_loss: 1.8420 - val_accuracy: 0.4439 - lr: 0.0312 - 13s/epoch - 542ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy improved from 0.60496 to 0.62786, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.0860 - accuracy: 0.6174 - val_loss: 1.0270 - val_accuracy: 0.6279 - lr: 0.0312 - 13s/epoch - 544ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.62786\n",
            "24/24 - 13s - loss: 1.0658 - accuracy: 0.6176 - val_loss: 1.0930 - val_accuracy: 0.6118 - lr: 0.0312 - 13s/epoch - 541ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.62786\n",
            "24/24 - 13s - loss: 1.0578 - accuracy: 0.6170 - val_loss: 1.0605 - val_accuracy: 0.6237 - lr: 0.0312 - 13s/epoch - 542ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy improved from 0.62786 to 0.63015, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.0265 - accuracy: 0.6338 - val_loss: 1.0661 - val_accuracy: 0.6302 - lr: 0.0312 - 13s/epoch - 544ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.63015\n",
            "24/24 - 13s - loss: 1.0152 - accuracy: 0.6329 - val_loss: 1.0434 - val_accuracy: 0.6263 - lr: 0.0312 - 13s/epoch - 542ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.63015\n",
            "24/24 - 13s - loss: 0.9986 - accuracy: 0.6414 - val_loss: 1.0482 - val_accuracy: 0.6271 - lr: 0.0296 - 13s/epoch - 543ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.63015\n",
            "24/24 - 13s - loss: 0.9888 - accuracy: 0.6430 - val_loss: 1.0699 - val_accuracy: 0.6153 - lr: 0.0296 - 13s/epoch - 542ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.63015\n",
            "24/24 - 13s - loss: 1.0150 - accuracy: 0.6374 - val_loss: 1.1121 - val_accuracy: 0.6065 - lr: 0.0296 - 13s/epoch - 542ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.63015\n",
            "24/24 - 13s - loss: 0.9437 - accuracy: 0.6616 - val_loss: 1.1450 - val_accuracy: 0.5962 - lr: 0.0296 - 13s/epoch - 542ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.63015\n",
            "24/24 - 13s - loss: 0.9793 - accuracy: 0.6479 - val_loss: 1.0928 - val_accuracy: 0.6038 - lr: 0.0296 - 13s/epoch - 542ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.63015\n",
            "24/24 - 13s - loss: 0.9604 - accuracy: 0.6590 - val_loss: 1.0503 - val_accuracy: 0.6271 - lr: 0.0296 - 13s/epoch - 542ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy improved from 0.63015 to 0.65229, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 1.1753 - accuracy: 0.6370 - val_loss: 0.9970 - val_accuracy: 0.6523 - lr: 0.0296 - 13s/epoch - 545ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.65229\n",
            "24/24 - 13s - loss: 0.9347 - accuracy: 0.6722 - val_loss: 1.0357 - val_accuracy: 0.6344 - lr: 0.0296 - 13s/epoch - 543ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.65229\n",
            "24/24 - 13s - loss: 0.9270 - accuracy: 0.6659 - val_loss: 0.9853 - val_accuracy: 0.6378 - lr: 0.0296 - 13s/epoch - 543ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.65229\n",
            "24/24 - 13s - loss: 0.9375 - accuracy: 0.6652 - val_loss: 1.0128 - val_accuracy: 0.6443 - lr: 0.0296 - 13s/epoch - 542ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy improved from 0.65229 to 0.65344, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.8983 - accuracy: 0.6855 - val_loss: 1.0066 - val_accuracy: 0.6534 - lr: 0.0282 - 13s/epoch - 545ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy improved from 0.65344 to 0.67137, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.9049 - accuracy: 0.6799 - val_loss: 0.9422 - val_accuracy: 0.6714 - lr: 0.0282 - 13s/epoch - 544ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8486 - accuracy: 0.6943 - val_loss: 1.0907 - val_accuracy: 0.6153 - lr: 0.0282 - 13s/epoch - 542ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8841 - accuracy: 0.6845 - val_loss: 1.0404 - val_accuracy: 0.6443 - lr: 0.0282 - 13s/epoch - 544ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8553 - accuracy: 0.6958 - val_loss: 1.0018 - val_accuracy: 0.6504 - lr: 0.0282 - 13s/epoch - 543ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8474 - accuracy: 0.6998 - val_loss: 1.1921 - val_accuracy: 0.6015 - lr: 0.0282 - 13s/epoch - 543ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8750 - accuracy: 0.6967 - val_loss: 1.0409 - val_accuracy: 0.6454 - lr: 0.0282 - 13s/epoch - 543ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8543 - accuracy: 0.7049 - val_loss: 1.0125 - val_accuracy: 0.6489 - lr: 0.0282 - 13s/epoch - 543ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8110 - accuracy: 0.7099 - val_loss: 1.0386 - val_accuracy: 0.6435 - lr: 0.0282 - 13s/epoch - 543ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8495 - accuracy: 0.7024 - val_loss: 1.0617 - val_accuracy: 0.6290 - lr: 0.0282 - 13s/epoch - 542ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.8113 - accuracy: 0.7125 - val_loss: 0.9666 - val_accuracy: 0.6618 - lr: 0.0267 - 13s/epoch - 543ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.7738 - accuracy: 0.7231 - val_loss: 1.0189 - val_accuracy: 0.6546 - lr: 0.0267 - 13s/epoch - 543ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.7759 - accuracy: 0.7275 - val_loss: 1.0268 - val_accuracy: 0.6439 - lr: 0.0267 - 13s/epoch - 543ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.7581 - accuracy: 0.7327 - val_loss: 0.9744 - val_accuracy: 0.6626 - lr: 0.0267 - 13s/epoch - 543ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.7731 - accuracy: 0.7296 - val_loss: 1.0111 - val_accuracy: 0.6412 - lr: 0.0267 - 13s/epoch - 543ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.7972 - accuracy: 0.7255 - val_loss: 1.0218 - val_accuracy: 0.6531 - lr: 0.0267 - 13s/epoch - 543ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.7213 - accuracy: 0.7385 - val_loss: 1.0124 - val_accuracy: 0.6618 - lr: 0.0267 - 13s/epoch - 543ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.7361 - accuracy: 0.7366 - val_loss: 1.0733 - val_accuracy: 0.6504 - lr: 0.0267 - 13s/epoch - 544ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.67137\n",
            "24/24 - 13s - loss: 0.7217 - accuracy: 0.7402 - val_loss: 1.1621 - val_accuracy: 0.6248 - lr: 0.0267 - 13s/epoch - 543ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy improved from 0.67137 to 0.67481, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.7162 - accuracy: 0.7424 - val_loss: 0.9512 - val_accuracy: 0.6748 - lr: 0.0267 - 13s/epoch - 545ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy improved from 0.67481 to 0.68206, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.6646 - accuracy: 0.7651 - val_loss: 0.9220 - val_accuracy: 0.6821 - lr: 0.0254 - 13s/epoch - 545ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.68206\n",
            "24/24 - 13s - loss: 0.6692 - accuracy: 0.7610 - val_loss: 0.9822 - val_accuracy: 0.6603 - lr: 0.0254 - 13s/epoch - 543ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.68206\n",
            "24/24 - 13s - loss: 0.6584 - accuracy: 0.7694 - val_loss: 1.0097 - val_accuracy: 0.6641 - lr: 0.0254 - 13s/epoch - 543ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy improved from 0.68206 to 0.69466, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.6546 - accuracy: 0.7673 - val_loss: 0.9147 - val_accuracy: 0.6947 - lr: 0.0254 - 13s/epoch - 545ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.69466\n",
            "24/24 - 13s - loss: 0.6529 - accuracy: 0.7667 - val_loss: 0.9751 - val_accuracy: 0.6756 - lr: 0.0254 - 13s/epoch - 543ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.69466\n",
            "24/24 - 13s - loss: 0.6299 - accuracy: 0.7788 - val_loss: 0.9561 - val_accuracy: 0.6813 - lr: 0.0254 - 13s/epoch - 543ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.69466\n",
            "24/24 - 13s - loss: 0.6355 - accuracy: 0.7772 - val_loss: 1.0102 - val_accuracy: 0.6760 - lr: 0.0254 - 13s/epoch - 544ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.69466\n",
            "24/24 - 13s - loss: 0.6179 - accuracy: 0.7808 - val_loss: 0.9791 - val_accuracy: 0.6805 - lr: 0.0254 - 13s/epoch - 544ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.69466\n",
            "24/24 - 13s - loss: 0.6186 - accuracy: 0.7795 - val_loss: 0.9883 - val_accuracy: 0.6733 - lr: 0.0254 - 13s/epoch - 543ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.69466\n",
            "24/24 - 13s - loss: 0.5868 - accuracy: 0.7951 - val_loss: 0.9930 - val_accuracy: 0.6855 - lr: 0.0254 - 13s/epoch - 544ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.69466\n",
            "24/24 - 13s - loss: 0.5891 - accuracy: 0.7922 - val_loss: 1.7455 - val_accuracy: 0.6103 - lr: 0.0241 - 13s/epoch - 543ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy improved from 0.69466 to 0.71412, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.5832 - accuracy: 0.8048 - val_loss: 0.9259 - val_accuracy: 0.7141 - lr: 0.0241 - 13s/epoch - 545ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.71412\n",
            "24/24 - 13s - loss: 0.5745 - accuracy: 0.8046 - val_loss: 0.9230 - val_accuracy: 0.7053 - lr: 0.0241 - 13s/epoch - 543ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.71412\n",
            "24/24 - 13s - loss: 0.5448 - accuracy: 0.8058 - val_loss: 0.8997 - val_accuracy: 0.7095 - lr: 0.0241 - 13s/epoch - 543ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy improved from 0.71412 to 0.72481, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.5241 - accuracy: 0.8131 - val_loss: 0.8989 - val_accuracy: 0.7248 - lr: 0.0241 - 13s/epoch - 545ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.72481\n",
            "24/24 - 13s - loss: 0.5753 - accuracy: 0.8032 - val_loss: 0.9509 - val_accuracy: 0.7145 - lr: 0.0241 - 13s/epoch - 543ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy improved from 0.72481 to 0.72863, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.5084 - accuracy: 0.8222 - val_loss: 0.9293 - val_accuracy: 0.7286 - lr: 0.0241 - 13s/epoch - 546ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.5092 - accuracy: 0.8232 - val_loss: 0.8917 - val_accuracy: 0.7225 - lr: 0.0241 - 13s/epoch - 544ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.6921 - accuracy: 0.7971 - val_loss: 1.0523 - val_accuracy: 0.6851 - lr: 0.0241 - 13s/epoch - 543ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4942 - accuracy: 0.8240 - val_loss: 1.0877 - val_accuracy: 0.6576 - lr: 0.0241 - 13s/epoch - 544ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4788 - accuracy: 0.8343 - val_loss: 1.0021 - val_accuracy: 0.7004 - lr: 0.0229 - 13s/epoch - 543ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4726 - accuracy: 0.8347 - val_loss: 0.8591 - val_accuracy: 0.7233 - lr: 0.0229 - 13s/epoch - 544ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4460 - accuracy: 0.8435 - val_loss: 0.9597 - val_accuracy: 0.7057 - lr: 0.0229 - 13s/epoch - 544ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4508 - accuracy: 0.8455 - val_loss: 0.9547 - val_accuracy: 0.7145 - lr: 0.0229 - 13s/epoch - 543ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4284 - accuracy: 0.8495 - val_loss: 1.1129 - val_accuracy: 0.6744 - lr: 0.0229 - 13s/epoch - 544ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4295 - accuracy: 0.8467 - val_loss: 0.9596 - val_accuracy: 0.7145 - lr: 0.0229 - 13s/epoch - 543ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4220 - accuracy: 0.8518 - val_loss: 0.9334 - val_accuracy: 0.7046 - lr: 0.0229 - 13s/epoch - 543ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4120 - accuracy: 0.8548 - val_loss: 1.0438 - val_accuracy: 0.6939 - lr: 0.0229 - 13s/epoch - 543ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.72863\n",
            "24/24 - 13s - loss: 0.4148 - accuracy: 0.8581 - val_loss: 0.9858 - val_accuracy: 0.7023 - lr: 0.0229 - 13s/epoch - 543ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy improved from 0.72863 to 0.72939, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.3738 - accuracy: 0.8666 - val_loss: 0.9605 - val_accuracy: 0.7294 - lr: 0.0229 - 13s/epoch - 545ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy improved from 0.72939 to 0.73435, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.3691 - accuracy: 0.8699 - val_loss: 0.9358 - val_accuracy: 0.7344 - lr: 0.0218 - 13s/epoch - 544ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.73435\n",
            "24/24 - 13s - loss: 0.3731 - accuracy: 0.8701 - val_loss: 0.9384 - val_accuracy: 0.7340 - lr: 0.0218 - 13s/epoch - 543ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.73435\n",
            "24/24 - 13s - loss: 0.3532 - accuracy: 0.8768 - val_loss: 1.0484 - val_accuracy: 0.7172 - lr: 0.0218 - 13s/epoch - 543ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.73435\n",
            "24/24 - 13s - loss: 0.3585 - accuracy: 0.8742 - val_loss: 0.9735 - val_accuracy: 0.7225 - lr: 0.0218 - 13s/epoch - 543ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy improved from 0.73435 to 0.73702, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.3672 - accuracy: 0.8749 - val_loss: 1.0270 - val_accuracy: 0.7370 - lr: 0.0218 - 13s/epoch - 545ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy improved from 0.73702 to 0.74504, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.3408 - accuracy: 0.8802 - val_loss: 0.8855 - val_accuracy: 0.7450 - lr: 0.0218 - 13s/epoch - 545ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.74504\n",
            "24/24 - 13s - loss: 0.3642 - accuracy: 0.8739 - val_loss: 1.1072 - val_accuracy: 0.7195 - lr: 0.0218 - 13s/epoch - 543ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.74504\n",
            "24/24 - 13s - loss: 0.3169 - accuracy: 0.8907 - val_loss: 0.9105 - val_accuracy: 0.7397 - lr: 0.0218 - 13s/epoch - 544ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.74504\n",
            "24/24 - 13s - loss: 0.3523 - accuracy: 0.8831 - val_loss: 0.9422 - val_accuracy: 0.7420 - lr: 0.0218 - 13s/epoch - 543ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.74504\n",
            "24/24 - 13s - loss: 0.3146 - accuracy: 0.8910 - val_loss: 0.9696 - val_accuracy: 0.7393 - lr: 0.0218 - 13s/epoch - 543ms/step\n",
            "Epoch 151/250\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.74504\n",
            "24/24 - 13s - loss: 0.3024 - accuracy: 0.8944 - val_loss: 0.9796 - val_accuracy: 0.7443 - lr: 0.0207 - 13s/epoch - 543ms/step\n",
            "Epoch 152/250\n",
            "\n",
            "Epoch 152: val_accuracy improved from 0.74504 to 0.75573, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.3395 - accuracy: 0.8950 - val_loss: 0.9552 - val_accuracy: 0.7557 - lr: 0.0207 - 13s/epoch - 545ms/step\n",
            "Epoch 153/250\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.75573\n",
            "24/24 - 13s - loss: 0.2562 - accuracy: 0.9093 - val_loss: 1.2163 - val_accuracy: 0.7046 - lr: 0.0207 - 13s/epoch - 544ms/step\n",
            "Epoch 154/250\n",
            "\n",
            "Epoch 154: val_accuracy improved from 0.75573 to 0.75954, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.3070 - accuracy: 0.8969 - val_loss: 0.8989 - val_accuracy: 0.7595 - lr: 0.0207 - 13s/epoch - 546ms/step\n",
            "Epoch 155/250\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.75954\n",
            "24/24 - 13s - loss: 0.2909 - accuracy: 0.9031 - val_loss: 0.9755 - val_accuracy: 0.7538 - lr: 0.0207 - 13s/epoch - 544ms/step\n",
            "Epoch 156/250\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.75954\n",
            "24/24 - 13s - loss: 0.2843 - accuracy: 0.9040 - val_loss: 1.0312 - val_accuracy: 0.7374 - lr: 0.0207 - 13s/epoch - 545ms/step\n",
            "Epoch 157/250\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.75954\n",
            "24/24 - 13s - loss: 0.2708 - accuracy: 0.9058 - val_loss: 1.0338 - val_accuracy: 0.7355 - lr: 0.0207 - 13s/epoch - 545ms/step\n",
            "Epoch 158/250\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.75954\n",
            "24/24 - 13s - loss: 0.3860 - accuracy: 0.8950 - val_loss: 1.0165 - val_accuracy: 0.7416 - lr: 0.0207 - 13s/epoch - 544ms/step\n",
            "Epoch 159/250\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.75954\n",
            "24/24 - 13s - loss: 0.2563 - accuracy: 0.9130 - val_loss: 0.9457 - val_accuracy: 0.7431 - lr: 0.0207 - 13s/epoch - 544ms/step\n",
            "Epoch 160/250\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.75954\n",
            "24/24 - 13s - loss: 0.2886 - accuracy: 0.9014 - val_loss: 0.9588 - val_accuracy: 0.7466 - lr: 0.0207 - 13s/epoch - 544ms/step\n",
            "Epoch 161/250\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.75954\n",
            "24/24 - 13s - loss: 0.2302 - accuracy: 0.9247 - val_loss: 1.0810 - val_accuracy: 0.7324 - lr: 0.0197 - 13s/epoch - 544ms/step\n",
            "Epoch 162/250\n",
            "\n",
            "Epoch 162: val_accuracy improved from 0.75954 to 0.76374, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.2097 - accuracy: 0.9260 - val_loss: 0.9896 - val_accuracy: 0.7637 - lr: 0.0197 - 13s/epoch - 545ms/step\n",
            "Epoch 163/250\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.76374\n",
            "24/24 - 13s - loss: 0.2329 - accuracy: 0.9181 - val_loss: 0.9963 - val_accuracy: 0.7477 - lr: 0.0197 - 13s/epoch - 543ms/step\n",
            "Epoch 164/250\n",
            "\n",
            "Epoch 164: val_accuracy improved from 0.76374 to 0.76489, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.2312 - accuracy: 0.9230 - val_loss: 0.9805 - val_accuracy: 0.7649 - lr: 0.0197 - 13s/epoch - 545ms/step\n",
            "Epoch 165/250\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.76489\n",
            "24/24 - 13s - loss: 0.5040 - accuracy: 0.9001 - val_loss: 1.0894 - val_accuracy: 0.7447 - lr: 0.0197 - 13s/epoch - 542ms/step\n",
            "Epoch 166/250\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.76489\n",
            "24/24 - 13s - loss: 0.1904 - accuracy: 0.9361 - val_loss: 1.3830 - val_accuracy: 0.6809 - lr: 0.0197 - 13s/epoch - 543ms/step\n",
            "Epoch 167/250\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.76489\n",
            "24/24 - 13s - loss: 0.2274 - accuracy: 0.9227 - val_loss: 0.9444 - val_accuracy: 0.7561 - lr: 0.0197 - 13s/epoch - 543ms/step\n",
            "Epoch 168/250\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.76489\n",
            "24/24 - 13s - loss: 0.2105 - accuracy: 0.9291 - val_loss: 0.9738 - val_accuracy: 0.7641 - lr: 0.0197 - 13s/epoch - 542ms/step\n",
            "Epoch 169/250\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.76489\n",
            "24/24 - 13s - loss: 0.2001 - accuracy: 0.9293 - val_loss: 1.0996 - val_accuracy: 0.7431 - lr: 0.0197 - 13s/epoch - 542ms/step\n",
            "Epoch 170/250\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.76489\n",
            "24/24 - 13s - loss: 0.2214 - accuracy: 0.9257 - val_loss: 1.0911 - val_accuracy: 0.7336 - lr: 0.0197 - 13s/epoch - 543ms/step\n",
            "Epoch 171/250\n",
            "\n",
            "Epoch 171: val_accuracy improved from 0.76489 to 0.76679, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.1867 - accuracy: 0.9356 - val_loss: 1.0487 - val_accuracy: 0.7668 - lr: 0.0187 - 13s/epoch - 544ms/step\n",
            "Epoch 172/250\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.76679\n",
            "24/24 - 13s - loss: 0.2031 - accuracy: 0.9315 - val_loss: 0.9611 - val_accuracy: 0.7534 - lr: 0.0187 - 13s/epoch - 543ms/step\n",
            "Epoch 173/250\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.76679\n",
            "24/24 - 13s - loss: 0.2163 - accuracy: 0.9325 - val_loss: 1.1948 - val_accuracy: 0.7244 - lr: 0.0187 - 13s/epoch - 543ms/step\n",
            "Epoch 174/250\n",
            "\n",
            "Epoch 174: val_accuracy did not improve from 0.76679\n",
            "24/24 - 13s - loss: 0.1778 - accuracy: 0.9411 - val_loss: 1.1922 - val_accuracy: 0.7401 - lr: 0.0187 - 13s/epoch - 543ms/step\n",
            "Epoch 175/250\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.76679\n",
            "24/24 - 13s - loss: 0.1721 - accuracy: 0.9418 - val_loss: 1.3072 - val_accuracy: 0.7004 - lr: 0.0187 - 13s/epoch - 543ms/step\n",
            "Epoch 176/250\n",
            "\n",
            "Epoch 176: val_accuracy improved from 0.76679 to 0.76947, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.1850 - accuracy: 0.9395 - val_loss: 1.0513 - val_accuracy: 0.7695 - lr: 0.0187 - 13s/epoch - 545ms/step\n",
            "Epoch 177/250\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1621 - accuracy: 0.9444 - val_loss: 1.1076 - val_accuracy: 0.7347 - lr: 0.0187 - 13s/epoch - 543ms/step\n",
            "Epoch 178/250\n",
            "\n",
            "Epoch 178: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.2125 - accuracy: 0.9350 - val_loss: 1.0604 - val_accuracy: 0.7672 - lr: 0.0187 - 13s/epoch - 543ms/step\n",
            "Epoch 179/250\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1756 - accuracy: 0.9428 - val_loss: 1.0882 - val_accuracy: 0.7550 - lr: 0.0187 - 13s/epoch - 543ms/step\n",
            "Epoch 180/250\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.2823 - accuracy: 0.9257 - val_loss: 1.2170 - val_accuracy: 0.7469 - lr: 0.0187 - 13s/epoch - 543ms/step\n",
            "Epoch 181/250\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1539 - accuracy: 0.9490 - val_loss: 1.0029 - val_accuracy: 0.7672 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 182/250\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1838 - accuracy: 0.9413 - val_loss: 1.0038 - val_accuracy: 0.7618 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 183/250\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1272 - accuracy: 0.9582 - val_loss: 1.1201 - val_accuracy: 0.7599 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 184/250\n",
            "\n",
            "Epoch 184: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1476 - accuracy: 0.9494 - val_loss: 1.2559 - val_accuracy: 0.7542 - lr: 0.0177 - 13s/epoch - 544ms/step\n",
            "Epoch 185/250\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1707 - accuracy: 0.9475 - val_loss: 1.0427 - val_accuracy: 0.7561 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 186/250\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1418 - accuracy: 0.9536 - val_loss: 1.1208 - val_accuracy: 0.7569 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 187/250\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1551 - accuracy: 0.9490 - val_loss: 1.2043 - val_accuracy: 0.7599 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 188/250\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1664 - accuracy: 0.9476 - val_loss: 1.2279 - val_accuracy: 0.7634 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 189/250\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1490 - accuracy: 0.9503 - val_loss: 1.0655 - val_accuracy: 0.7561 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 190/250\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.76947\n",
            "24/24 - 13s - loss: 0.1293 - accuracy: 0.9584 - val_loss: 1.1442 - val_accuracy: 0.7679 - lr: 0.0177 - 13s/epoch - 543ms/step\n",
            "Epoch 191/250\n",
            "\n",
            "Epoch 191: val_accuracy improved from 0.76947 to 0.78244, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 13s - loss: 0.1340 - accuracy: 0.9565 - val_loss: 1.0527 - val_accuracy: 0.7824 - lr: 0.0169 - 13s/epoch - 545ms/step\n",
            "Epoch 192/250\n",
            "\n",
            "Epoch 192: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1302 - accuracy: 0.9562 - val_loss: 1.1663 - val_accuracy: 0.7664 - lr: 0.0169 - 13s/epoch - 543ms/step\n",
            "Epoch 193/250\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1276 - accuracy: 0.9583 - val_loss: 1.1428 - val_accuracy: 0.7542 - lr: 0.0169 - 13s/epoch - 543ms/step\n",
            "Epoch 194/250\n",
            "\n",
            "Epoch 194: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1293 - accuracy: 0.9558 - val_loss: 1.1585 - val_accuracy: 0.7679 - lr: 0.0169 - 13s/epoch - 544ms/step\n",
            "Epoch 195/250\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1389 - accuracy: 0.9548 - val_loss: 1.1058 - val_accuracy: 0.7695 - lr: 0.0169 - 13s/epoch - 544ms/step\n",
            "Epoch 196/250\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1187 - accuracy: 0.9627 - val_loss: 1.1530 - val_accuracy: 0.7714 - lr: 0.0169 - 13s/epoch - 544ms/step\n",
            "Epoch 197/250\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1103 - accuracy: 0.9646 - val_loss: 1.1835 - val_accuracy: 0.7691 - lr: 0.0169 - 13s/epoch - 544ms/step\n",
            "Epoch 198/250\n",
            "\n",
            "Epoch 198: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1132 - accuracy: 0.9631 - val_loss: 1.2170 - val_accuracy: 0.7504 - lr: 0.0169 - 13s/epoch - 544ms/step\n",
            "Epoch 199/250\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1501 - accuracy: 0.9516 - val_loss: 1.1158 - val_accuracy: 0.7798 - lr: 0.0169 - 13s/epoch - 544ms/step\n",
            "Epoch 200/250\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.2559 - accuracy: 0.9399 - val_loss: 1.0996 - val_accuracy: 0.7725 - lr: 0.0169 - 13s/epoch - 543ms/step\n",
            "Epoch 201/250\n",
            "\n",
            "Epoch 201: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0809 - accuracy: 0.9721 - val_loss: 1.0780 - val_accuracy: 0.7763 - lr: 0.0160 - 13s/epoch - 543ms/step\n",
            "Epoch 202/250\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1187 - accuracy: 0.9620 - val_loss: 1.1723 - val_accuracy: 0.7702 - lr: 0.0160 - 13s/epoch - 543ms/step\n",
            "Epoch 203/250\n",
            "\n",
            "Epoch 203: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1178 - accuracy: 0.9623 - val_loss: 1.1145 - val_accuracy: 0.7794 - lr: 0.0160 - 13s/epoch - 544ms/step\n",
            "Epoch 204/250\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1058 - accuracy: 0.9654 - val_loss: 1.2125 - val_accuracy: 0.7595 - lr: 0.0160 - 13s/epoch - 543ms/step\n",
            "Epoch 205/250\n",
            "\n",
            "Epoch 205: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1013 - accuracy: 0.9674 - val_loss: 1.2684 - val_accuracy: 0.7660 - lr: 0.0160 - 13s/epoch - 543ms/step\n",
            "Epoch 206/250\n",
            "\n",
            "Epoch 206: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1018 - accuracy: 0.9654 - val_loss: 1.2367 - val_accuracy: 0.7569 - lr: 0.0160 - 13s/epoch - 544ms/step\n",
            "Epoch 207/250\n",
            "\n",
            "Epoch 207: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1126 - accuracy: 0.9638 - val_loss: 1.2250 - val_accuracy: 0.7611 - lr: 0.0160 - 13s/epoch - 543ms/step\n",
            "Epoch 208/250\n",
            "\n",
            "Epoch 208: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1036 - accuracy: 0.9662 - val_loss: 1.2872 - val_accuracy: 0.7565 - lr: 0.0160 - 13s/epoch - 543ms/step\n",
            "Epoch 209/250\n",
            "\n",
            "Epoch 209: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1112 - accuracy: 0.9654 - val_loss: 1.2397 - val_accuracy: 0.7637 - lr: 0.0160 - 13s/epoch - 543ms/step\n",
            "Epoch 210/250\n",
            "\n",
            "Epoch 210: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.1113 - accuracy: 0.9652 - val_loss: 1.3221 - val_accuracy: 0.7435 - lr: 0.0160 - 13s/epoch - 544ms/step\n",
            "Epoch 211/250\n",
            "\n",
            "Epoch 211: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0926 - accuracy: 0.9703 - val_loss: 1.3315 - val_accuracy: 0.7676 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 212/250\n",
            "\n",
            "Epoch 212: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0931 - accuracy: 0.9683 - val_loss: 1.2101 - val_accuracy: 0.7698 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 213/250\n",
            "\n",
            "Epoch 213: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0965 - accuracy: 0.9674 - val_loss: 1.2045 - val_accuracy: 0.7630 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 214/250\n",
            "\n",
            "Epoch 214: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.2315 - accuracy: 0.9526 - val_loss: 1.1889 - val_accuracy: 0.7725 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 215/250\n",
            "\n",
            "Epoch 215: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0763 - accuracy: 0.9758 - val_loss: 1.2564 - val_accuracy: 0.7618 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 216/250\n",
            "\n",
            "Epoch 216: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0913 - accuracy: 0.9723 - val_loss: 1.7381 - val_accuracy: 0.7034 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 217/250\n",
            "\n",
            "Epoch 217: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0941 - accuracy: 0.9711 - val_loss: 1.2052 - val_accuracy: 0.7718 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 218/250\n",
            "\n",
            "Epoch 218: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0776 - accuracy: 0.9739 - val_loss: 1.3370 - val_accuracy: 0.7790 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 219/250\n",
            "\n",
            "Epoch 219: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0924 - accuracy: 0.9719 - val_loss: 1.3525 - val_accuracy: 0.7561 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 220/250\n",
            "\n",
            "Epoch 220: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0924 - accuracy: 0.9701 - val_loss: 1.2937 - val_accuracy: 0.7756 - lr: 0.0152 - 13s/epoch - 543ms/step\n",
            "Epoch 221/250\n",
            "\n",
            "Epoch 221: val_accuracy did not improve from 0.78244\n",
            "24/24 - 13s - loss: 0.0876 - accuracy: 0.9737 - val_loss: 1.2317 - val_accuracy: 0.7779 - lr: 0.0145 - 13s/epoch - 543ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 20:52:08,886] Trial 1 finished with value: 0.782 and parameters: {'optimizer': 'RMSprop', 'learning_rate': 0.04467617911488097, 'batch_size': 512, 'dropout_ratio': 0.27326120467848797, 'decay': 0.8957029925623916}. Best is trial 1 with value: 0.782.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_96 (Conv2D)          (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_56 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 256)               0         \n",
            " 4 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.26260, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 15s - loss: 2.1319 - accuracy: 0.2358 - val_loss: 2.0290 - val_accuracy: 0.2626 - lr: 0.0016 - 15s/epoch - 626ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.26260 to 0.40649, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.7608 - accuracy: 0.3831 - val_loss: 1.7083 - val_accuracy: 0.4065 - lr: 0.0016 - 14s/epoch - 579ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.40649 to 0.41183, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5515 - accuracy: 0.4603 - val_loss: 1.6805 - val_accuracy: 0.4118 - lr: 0.0016 - 14s/epoch - 580ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.41183 to 0.55954, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.3757 - accuracy: 0.5226 - val_loss: 1.2482 - val_accuracy: 0.5595 - lr: 0.0016 - 14s/epoch - 579ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.55954 to 0.56679, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.2161 - accuracy: 0.5785 - val_loss: 1.2286 - val_accuracy: 0.5668 - lr: 0.0016 - 14s/epoch - 578ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.56679 to 0.63931, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1231 - accuracy: 0.6073 - val_loss: 1.0143 - val_accuracy: 0.6393 - lr: 0.0016 - 14s/epoch - 577ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.63931\n",
            "24/24 - 14s - loss: 1.0516 - accuracy: 0.6357 - val_loss: 1.1043 - val_accuracy: 0.6286 - lr: 0.0016 - 14s/epoch - 575ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.63931 to 0.66450, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0012 - accuracy: 0.6578 - val_loss: 0.9479 - val_accuracy: 0.6645 - lr: 0.0016 - 14s/epoch - 575ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.66450 to 0.69084, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9181 - accuracy: 0.6864 - val_loss: 0.8487 - val_accuracy: 0.6908 - lr: 0.0016 - 14s/epoch - 575ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.69084 to 0.71718, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.8880 - accuracy: 0.6983 - val_loss: 0.8544 - val_accuracy: 0.7172 - lr: 0.0016 - 14s/epoch - 575ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.71718 to 0.75687, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.7955 - accuracy: 0.7333 - val_loss: 0.7460 - val_accuracy: 0.7569 - lr: 0.0015 - 14s/epoch - 576ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.75687\n",
            "24/24 - 14s - loss: 0.7481 - accuracy: 0.7492 - val_loss: 0.8520 - val_accuracy: 0.7187 - lr: 0.0015 - 14s/epoch - 575ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.75687 to 0.80076, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.7166 - accuracy: 0.7594 - val_loss: 0.6162 - val_accuracy: 0.8008 - lr: 0.0015 - 14s/epoch - 577ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.80076\n",
            "24/24 - 14s - loss: 0.6654 - accuracy: 0.7747 - val_loss: 0.8021 - val_accuracy: 0.7355 - lr: 0.0015 - 14s/epoch - 576ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.80076\n",
            "24/24 - 14s - loss: 0.6340 - accuracy: 0.7871 - val_loss: 0.7159 - val_accuracy: 0.7492 - lr: 0.0015 - 14s/epoch - 576ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.80076 to 0.82824, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.6015 - accuracy: 0.7954 - val_loss: 0.5076 - val_accuracy: 0.8282 - lr: 0.0015 - 14s/epoch - 578ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.82824\n",
            "24/24 - 14s - loss: 0.5627 - accuracy: 0.8098 - val_loss: 0.5753 - val_accuracy: 0.8034 - lr: 0.0015 - 14s/epoch - 575ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.82824 to 0.84695, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.5597 - accuracy: 0.8114 - val_loss: 0.4549 - val_accuracy: 0.8469 - lr: 0.0015 - 14s/epoch - 576ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.84695\n",
            "24/24 - 14s - loss: 0.5145 - accuracy: 0.8273 - val_loss: 0.5205 - val_accuracy: 0.8183 - lr: 0.0015 - 14s/epoch - 574ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.84695 to 0.86107, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.4823 - accuracy: 0.8389 - val_loss: 0.4201 - val_accuracy: 0.8611 - lr: 0.0015 - 14s/epoch - 576ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.86107\n",
            "24/24 - 14s - loss: 0.4490 - accuracy: 0.8469 - val_loss: 0.4482 - val_accuracy: 0.8473 - lr: 0.0014 - 14s/epoch - 574ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.86107 to 0.87863, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.4317 - accuracy: 0.8509 - val_loss: 0.3554 - val_accuracy: 0.8786 - lr: 0.0014 - 14s/epoch - 575ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.87863 to 0.88397, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.3947 - accuracy: 0.8684 - val_loss: 0.3355 - val_accuracy: 0.8840 - lr: 0.0014 - 14s/epoch - 576ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.88397\n",
            "24/24 - 14s - loss: 0.3779 - accuracy: 0.8735 - val_loss: 0.4952 - val_accuracy: 0.8298 - lr: 0.0014 - 14s/epoch - 574ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.88397\n",
            "24/24 - 14s - loss: 0.3954 - accuracy: 0.8662 - val_loss: 0.6062 - val_accuracy: 0.8042 - lr: 0.0014 - 14s/epoch - 574ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.88397 to 0.90420, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.3767 - accuracy: 0.8750 - val_loss: 0.3092 - val_accuracy: 0.9042 - lr: 0.0014 - 14s/epoch - 575ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.90420\n",
            "24/24 - 14s - loss: 0.3277 - accuracy: 0.8923 - val_loss: 0.4243 - val_accuracy: 0.8416 - lr: 0.0014 - 14s/epoch - 573ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.90420\n",
            "24/24 - 14s - loss: 0.3202 - accuracy: 0.8902 - val_loss: 0.3195 - val_accuracy: 0.8870 - lr: 0.0014 - 14s/epoch - 574ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy improved from 0.90420 to 0.90496, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.3432 - accuracy: 0.8835 - val_loss: 0.2834 - val_accuracy: 0.9050 - lr: 0.0014 - 14s/epoch - 576ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.90496\n",
            "24/24 - 14s - loss: 0.2633 - accuracy: 0.9104 - val_loss: 0.4599 - val_accuracy: 0.8527 - lr: 0.0014 - 14s/epoch - 574ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.90496\n",
            "24/24 - 14s - loss: 0.2753 - accuracy: 0.9055 - val_loss: 0.3589 - val_accuracy: 0.8729 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.90496\n",
            "24/24 - 14s - loss: 0.2772 - accuracy: 0.9067 - val_loss: 0.3423 - val_accuracy: 0.8763 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy improved from 0.90496 to 0.91107, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.2403 - accuracy: 0.9170 - val_loss: 0.2471 - val_accuracy: 0.9111 - lr: 0.0013 - 14s/epoch - 578ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.91107\n",
            "24/24 - 14s - loss: 0.2531 - accuracy: 0.9104 - val_loss: 0.2699 - val_accuracy: 0.9088 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.91107 to 0.91870, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.2434 - accuracy: 0.9174 - val_loss: 0.2284 - val_accuracy: 0.9187 - lr: 0.0013 - 14s/epoch - 578ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.91870\n",
            "24/24 - 14s - loss: 0.2145 - accuracy: 0.9269 - val_loss: 0.2720 - val_accuracy: 0.9141 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy improved from 0.91870 to 0.92366, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.2115 - accuracy: 0.9333 - val_loss: 0.2164 - val_accuracy: 0.9237 - lr: 0.0013 - 14s/epoch - 577ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy improved from 0.92366 to 0.94427, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.1865 - accuracy: 0.9352 - val_loss: 0.1812 - val_accuracy: 0.9443 - lr: 0.0013 - 14s/epoch - 577ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.94427\n",
            "24/24 - 14s - loss: 0.2013 - accuracy: 0.9315 - val_loss: 0.2626 - val_accuracy: 0.9000 - lr: 0.0013 - 14s/epoch - 575ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.94427\n",
            "24/24 - 14s - loss: 0.1901 - accuracy: 0.9354 - val_loss: 0.1854 - val_accuracy: 0.9370 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.94427\n",
            "24/24 - 14s - loss: 0.1764 - accuracy: 0.9413 - val_loss: 0.2712 - val_accuracy: 0.9034 - lr: 0.0013 - 14s/epoch - 577ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.94427\n",
            "24/24 - 14s - loss: 0.1592 - accuracy: 0.9478 - val_loss: 0.3393 - val_accuracy: 0.8851 - lr: 0.0013 - 14s/epoch - 577ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy improved from 0.94427 to 0.94924, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.1572 - accuracy: 0.9467 - val_loss: 0.1637 - val_accuracy: 0.9492 - lr: 0.0013 - 14s/epoch - 578ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.94924\n",
            "24/24 - 14s - loss: 0.1513 - accuracy: 0.9503 - val_loss: 0.3576 - val_accuracy: 0.8870 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.94924\n",
            "24/24 - 14s - loss: 0.1427 - accuracy: 0.9544 - val_loss: 0.2637 - val_accuracy: 0.9206 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.94924\n",
            "24/24 - 14s - loss: 0.1401 - accuracy: 0.9524 - val_loss: 0.3300 - val_accuracy: 0.8897 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.94924\n",
            "24/24 - 14s - loss: 0.1568 - accuracy: 0.9489 - val_loss: 0.2927 - val_accuracy: 0.8969 - lr: 0.0013 - 14s/epoch - 575ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy improved from 0.94924 to 0.95000, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.1503 - accuracy: 0.9502 - val_loss: 0.1582 - val_accuracy: 0.9500 - lr: 0.0013 - 14s/epoch - 577ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy improved from 0.95000 to 0.95725, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.1395 - accuracy: 0.9587 - val_loss: 0.1348 - val_accuracy: 0.9573 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy improved from 0.95725 to 0.95954, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.1152 - accuracy: 0.9618 - val_loss: 0.1415 - val_accuracy: 0.9595 - lr: 0.0013 - 14s/epoch - 576ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.95954\n",
            "24/24 - 14s - loss: 0.1189 - accuracy: 0.9619 - val_loss: 0.1373 - val_accuracy: 0.9576 - lr: 0.0012 - 14s/epoch - 574ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.95954\n",
            "24/24 - 14s - loss: 0.0943 - accuracy: 0.9694 - val_loss: 0.2462 - val_accuracy: 0.9191 - lr: 0.0012 - 14s/epoch - 575ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.95954\n",
            "24/24 - 14s - loss: 0.1190 - accuracy: 0.9629 - val_loss: 0.1366 - val_accuracy: 0.9553 - lr: 0.0012 - 14s/epoch - 575ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.95954\n",
            "24/24 - 14s - loss: 0.0946 - accuracy: 0.9689 - val_loss: 0.2261 - val_accuracy: 0.9366 - lr: 0.0012 - 14s/epoch - 574ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.95954\n",
            "24/24 - 14s - loss: 0.1000 - accuracy: 0.9665 - val_loss: 0.5421 - val_accuracy: 0.8492 - lr: 0.0012 - 14s/epoch - 575ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.95954\n",
            "24/24 - 14s - loss: 0.1070 - accuracy: 0.9664 - val_loss: 0.1334 - val_accuracy: 0.9553 - lr: 0.0012 - 14s/epoch - 574ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy improved from 0.95954 to 0.96947, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0934 - accuracy: 0.9717 - val_loss: 0.1101 - val_accuracy: 0.9695 - lr: 0.0012 - 14s/epoch - 577ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.96947\n",
            "24/24 - 14s - loss: 0.0810 - accuracy: 0.9742 - val_loss: 0.1160 - val_accuracy: 0.9664 - lr: 0.0012 - 14s/epoch - 574ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.96947\n",
            "24/24 - 14s - loss: 0.1130 - accuracy: 0.9672 - val_loss: 0.1248 - val_accuracy: 0.9637 - lr: 0.0012 - 14s/epoch - 575ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.96947\n",
            "24/24 - 14s - loss: 0.0809 - accuracy: 0.9748 - val_loss: 0.1433 - val_accuracy: 0.9584 - lr: 0.0012 - 14s/epoch - 575ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.96947\n",
            "24/24 - 14s - loss: 0.0770 - accuracy: 0.9760 - val_loss: 0.1109 - val_accuracy: 0.9691 - lr: 0.0011 - 14s/epoch - 575ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy improved from 0.96947 to 0.97061, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0818 - accuracy: 0.9793 - val_loss: 0.1136 - val_accuracy: 0.9706 - lr: 0.0011 - 14s/epoch - 577ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.97061\n",
            "24/24 - 14s - loss: 0.0750 - accuracy: 0.9762 - val_loss: 0.1018 - val_accuracy: 0.9687 - lr: 0.0011 - 14s/epoch - 575ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.97061\n",
            "24/24 - 14s - loss: 0.0648 - accuracy: 0.9809 - val_loss: 0.1045 - val_accuracy: 0.9702 - lr: 0.0011 - 14s/epoch - 576ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy improved from 0.97061 to 0.97176, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0712 - accuracy: 0.9777 - val_loss: 0.1076 - val_accuracy: 0.9718 - lr: 0.0011 - 14s/epoch - 578ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.97176\n",
            "24/24 - 14s - loss: 0.0846 - accuracy: 0.9749 - val_loss: 0.0993 - val_accuracy: 0.9714 - lr: 0.0011 - 14s/epoch - 576ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.97176\n",
            "24/24 - 14s - loss: 0.0546 - accuracy: 0.9829 - val_loss: 0.1103 - val_accuracy: 0.9679 - lr: 0.0011 - 14s/epoch - 576ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.97176\n",
            "24/24 - 14s - loss: 0.0701 - accuracy: 0.9776 - val_loss: 0.1044 - val_accuracy: 0.9710 - lr: 0.0011 - 14s/epoch - 576ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.97176\n",
            "24/24 - 14s - loss: 0.0782 - accuracy: 0.9784 - val_loss: 0.1306 - val_accuracy: 0.9603 - lr: 0.0011 - 14s/epoch - 576ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.97176\n",
            "24/24 - 14s - loss: 0.0742 - accuracy: 0.9819 - val_loss: 0.4040 - val_accuracy: 0.9031 - lr: 0.0011 - 14s/epoch - 575ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.97176\n",
            "24/24 - 14s - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.1845 - val_accuracy: 0.9424 - lr: 0.0011 - 14s/epoch - 575ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.97176\n",
            "24/24 - 14s - loss: 0.0490 - accuracy: 0.9856 - val_loss: 0.1566 - val_accuracy: 0.9607 - lr: 0.0011 - 14s/epoch - 574ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy improved from 0.97176 to 0.97328, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0619 - accuracy: 0.9812 - val_loss: 0.0942 - val_accuracy: 0.9733 - lr: 0.0011 - 14s/epoch - 577ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy improved from 0.97328 to 0.97405, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0484 - accuracy: 0.9845 - val_loss: 0.1025 - val_accuracy: 0.9740 - lr: 0.0011 - 14s/epoch - 576ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0617 - accuracy: 0.9822 - val_loss: 0.1139 - val_accuracy: 0.9687 - lr: 0.0011 - 14s/epoch - 573ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0272 - accuracy: 0.9933 - val_loss: 0.2256 - val_accuracy: 0.9397 - lr: 0.0011 - 14s/epoch - 574ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0572 - accuracy: 0.9829 - val_loss: 0.1198 - val_accuracy: 0.9718 - lr: 0.0011 - 14s/epoch - 574ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0432 - accuracy: 0.9870 - val_loss: 0.1102 - val_accuracy: 0.9718 - lr: 0.0011 - 14s/epoch - 574ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0511 - accuracy: 0.9861 - val_loss: 0.1078 - val_accuracy: 0.9718 - lr: 0.0011 - 14s/epoch - 575ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0578 - accuracy: 0.9836 - val_loss: 0.1073 - val_accuracy: 0.9733 - lr: 0.0011 - 14s/epoch - 575ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0522 - accuracy: 0.9840 - val_loss: 0.1503 - val_accuracy: 0.9565 - lr: 0.0010 - 14s/epoch - 575ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.1272 - val_accuracy: 0.9714 - lr: 0.0010 - 14s/epoch - 576ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0585 - accuracy: 0.9836 - val_loss: 0.1099 - val_accuracy: 0.9737 - lr: 0.0010 - 14s/epoch - 576ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.97405\n",
            "24/24 - 14s - loss: 0.0493 - accuracy: 0.9859 - val_loss: 0.1336 - val_accuracy: 0.9645 - lr: 0.0010 - 14s/epoch - 575ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy improved from 0.97405 to 0.97748, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.1005 - val_accuracy: 0.9775 - lr: 0.0010 - 14s/epoch - 577ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.0917 - val_accuracy: 0.9775 - lr: 0.0010 - 14s/epoch - 574ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0478 - accuracy: 0.9869 - val_loss: 0.1107 - val_accuracy: 0.9748 - lr: 0.0010 - 14s/epoch - 574ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0382 - accuracy: 0.9895 - val_loss: 0.1076 - val_accuracy: 0.9748 - lr: 0.0010 - 14s/epoch - 574ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.1012 - val_accuracy: 0.9752 - lr: 0.0010 - 14s/epoch - 574ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0546 - accuracy: 0.9840 - val_loss: 0.1038 - val_accuracy: 0.9744 - lr: 0.0010 - 14s/epoch - 573ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.1152 - val_accuracy: 0.9698 - lr: 9.7963e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0648 - accuracy: 0.9827 - val_loss: 0.1128 - val_accuracy: 0.9763 - lr: 9.7963e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.1118 - val_accuracy: 0.9763 - lr: 9.7963e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.1040 - val_accuracy: 0.9725 - lr: 9.7963e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.1076 - val_accuracy: 0.9737 - lr: 9.7963e-04 - 14s/epoch - 573ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0352 - accuracy: 0.9894 - val_loss: 0.1389 - val_accuracy: 0.9702 - lr: 9.7963e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.1641 - val_accuracy: 0.9565 - lr: 9.7963e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0408 - accuracy: 0.9885 - val_loss: 0.0995 - val_accuracy: 0.9771 - lr: 9.7963e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0328 - accuracy: 0.9919 - val_loss: 0.3258 - val_accuracy: 0.9427 - lr: 9.7963e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.1499 - val_accuracy: 0.9649 - lr: 9.7963e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.1645 - val_accuracy: 0.9580 - lr: 9.3065e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0378 - accuracy: 0.9904 - val_loss: 0.1043 - val_accuracy: 0.9775 - lr: 9.3065e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0263 - accuracy: 0.9935 - val_loss: 0.1035 - val_accuracy: 0.9760 - lr: 9.3065e-04 - 14s/epoch - 576ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.1069 - val_accuracy: 0.9763 - lr: 9.3065e-04 - 14s/epoch - 576ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.97748\n",
            "24/24 - 14s - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.1133 - val_accuracy: 0.9740 - lr: 9.3065e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy improved from 0.97748 to 0.97824, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0474 - accuracy: 0.9875 - val_loss: 0.1027 - val_accuracy: 0.9782 - lr: 9.3065e-04 - 14s/epoch - 577ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.1151 - val_accuracy: 0.9752 - lr: 9.3065e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.1075 - val_accuracy: 0.9775 - lr: 9.3065e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.1046 - val_accuracy: 0.9771 - lr: 9.3065e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0326 - accuracy: 0.9897 - val_loss: 0.1104 - val_accuracy: 0.9767 - lr: 9.3065e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.1115 - val_accuracy: 0.9763 - lr: 8.8412e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.1146 - val_accuracy: 0.9782 - lr: 8.8412e-04 - 14s/epoch - 573ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.1999 - val_accuracy: 0.9466 - lr: 8.8412e-04 - 14s/epoch - 573ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.1162 - val_accuracy: 0.9748 - lr: 8.8412e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.1498 - val_accuracy: 0.9668 - lr: 8.8412e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.1149 - val_accuracy: 0.9767 - lr: 8.8412e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.1243 - val_accuracy: 0.9763 - lr: 8.8412e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0338 - accuracy: 0.9921 - val_loss: 0.1053 - val_accuracy: 0.9744 - lr: 8.8412e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.1097 - val_accuracy: 0.9767 - lr: 8.8412e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.1346 - val_accuracy: 0.9706 - lr: 8.8412e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.1013 - val_accuracy: 0.9779 - lr: 8.3991e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.2657 - val_accuracy: 0.9447 - lr: 8.3991e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0170 - accuracy: 0.9955 - val_loss: 0.1158 - val_accuracy: 0.9767 - lr: 8.3991e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.1137 - val_accuracy: 0.9763 - lr: 8.3991e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0156 - accuracy: 0.9955 - val_loss: 0.1788 - val_accuracy: 0.9641 - lr: 8.3991e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.1147 - val_accuracy: 0.9767 - lr: 8.3991e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.1147 - val_accuracy: 0.9756 - lr: 8.3991e-04 - 14s/epoch - 573ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.1105 - val_accuracy: 0.9760 - lr: 8.3991e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0264 - accuracy: 0.9940 - val_loss: 0.1183 - val_accuracy: 0.9737 - lr: 8.3991e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1183 - val_accuracy: 0.9767 - lr: 8.3991e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.1154 - val_accuracy: 0.9752 - lr: 7.9791e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.97824\n",
            "24/24 - 14s - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.1258 - val_accuracy: 0.9763 - lr: 7.9791e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy improved from 0.97824 to 0.97901, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1107 - val_accuracy: 0.9790 - lr: 7.9791e-04 - 14s/epoch - 577ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.97901\n",
            "24/24 - 14s - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.1224 - val_accuracy: 0.9782 - lr: 7.9791e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.97901\n",
            "24/24 - 14s - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.1253 - val_accuracy: 0.9775 - lr: 7.9791e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.97901\n",
            "24/24 - 14s - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.1235 - val_accuracy: 0.9752 - lr: 7.9791e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.97901\n",
            "24/24 - 14s - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.1178 - val_accuracy: 0.9767 - lr: 7.9791e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.97901\n",
            "24/24 - 14s - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.1175 - val_accuracy: 0.9763 - lr: 7.9791e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.97901\n",
            "24/24 - 14s - loss: 0.0257 - accuracy: 0.9963 - val_loss: 0.1117 - val_accuracy: 0.9771 - lr: 7.9791e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy improved from 0.97901 to 0.97977, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.1199 - val_accuracy: 0.9798 - lr: 7.9791e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1166 - val_accuracy: 0.9786 - lr: 7.5802e-04 - 14s/epoch - 573ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1109 - val_accuracy: 0.9794 - lr: 7.5802e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.1166 - val_accuracy: 0.9775 - lr: 7.5802e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.1173 - val_accuracy: 0.9775 - lr: 7.5802e-04 - 14s/epoch - 573ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.1174 - val_accuracy: 0.9775 - lr: 7.5802e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.1265 - val_accuracy: 0.9752 - lr: 7.5802e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1218 - val_accuracy: 0.9752 - lr: 7.5802e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.1205 - val_accuracy: 0.9779 - lr: 7.5802e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.2841 - val_accuracy: 0.9408 - lr: 7.5802e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1163 - val_accuracy: 0.9771 - lr: 7.5802e-04 - 14s/epoch - 576ms/step\n",
            "Epoch 151/250\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1146 - val_accuracy: 0.9790 - lr: 7.2012e-04 - 14s/epoch - 576ms/step\n",
            "Epoch 152/250\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.1133 - val_accuracy: 0.9786 - lr: 7.2012e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 153/250\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.1404 - val_accuracy: 0.9721 - lr: 7.2012e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 154/250\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.1195 - val_accuracy: 0.9786 - lr: 7.2012e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 155/250\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.1216 - val_accuracy: 0.9733 - lr: 7.2012e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 156/250\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1179 - val_accuracy: 0.9779 - lr: 7.2012e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 157/250\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1299 - val_accuracy: 0.9779 - lr: 7.2012e-04 - 14s/epoch - 573ms/step\n",
            "Epoch 158/250\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1174 - val_accuracy: 0.9790 - lr: 7.2012e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 159/250\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1245 - val_accuracy: 0.9779 - lr: 7.2012e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 160/250\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.1323 - val_accuracy: 0.9767 - lr: 7.2012e-04 - 14s/epoch - 574ms/step\n",
            "Epoch 161/250\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.1497 - val_accuracy: 0.9740 - lr: 6.8411e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 162/250\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.1323 - val_accuracy: 0.9782 - lr: 6.8411e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 163/250\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1290 - val_accuracy: 0.9771 - lr: 6.8411e-04 - 14s/epoch - 576ms/step\n",
            "Epoch 164/250\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1321 - val_accuracy: 0.9756 - lr: 6.8411e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 165/250\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1235 - val_accuracy: 0.9779 - lr: 6.8411e-04 - 14s/epoch - 576ms/step\n",
            "Epoch 166/250\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1430 - val_accuracy: 0.9744 - lr: 6.8411e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 167/250\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.2136 - val_accuracy: 0.9637 - lr: 6.8411e-04 - 14s/epoch - 575ms/step\n",
            "Epoch 168/250\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1262 - val_accuracy: 0.9779 - lr: 6.8411e-04 - 14s/epoch - 576ms/step\n",
            "Epoch 169/250\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1317 - val_accuracy: 0.9798 - lr: 6.8411e-04 - 14s/epoch - 576ms/step\n",
            "Epoch 170/250\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.97977\n",
            "24/24 - 14s - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.1357 - val_accuracy: 0.9756 - lr: 6.8411e-04 - 14s/epoch - 576ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 21:31:18,425] Trial 2 finished with value: 0.98 and parameters: {'optimizer': 'RMSprop', 'learning_rate': 0.0015543518459854308, 'batch_size': 512, 'dropout_ratio': 0.04350847259380484, 'decay': 0.8117173566100405}. Best is trial 2 with value: 0.98.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_100 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_57 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 256)               0         \n",
            " 5 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.23740, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 15s - loss: 2.2006 - accuracy: 0.1764 - val_loss: 1.8777 - val_accuracy: 0.2374 - lr: 0.0068 - 15s/epoch - 40ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.23740 to 0.30840, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 1.8217 - accuracy: 0.2678 - val_loss: 1.6935 - val_accuracy: 0.3084 - lr: 0.0068 - 14s/epoch - 35ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.30840 to 0.34237, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.7014 - accuracy: 0.3234 - val_loss: 1.6333 - val_accuracy: 0.3424 - lr: 0.0068 - 13s/epoch - 35ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.34237 to 0.38588, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.6063 - accuracy: 0.3671 - val_loss: 1.5441 - val_accuracy: 0.3859 - lr: 0.0068 - 13s/epoch - 35ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.38588 to 0.46412, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.5060 - accuracy: 0.4260 - val_loss: 1.4342 - val_accuracy: 0.4641 - lr: 0.0068 - 13s/epoch - 35ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.46412\n",
            "382/382 - 13s - loss: 1.4455 - accuracy: 0.4550 - val_loss: 17.9516 - val_accuracy: 0.2156 - lr: 0.0068 - 13s/epoch - 35ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.46412 to 0.47366, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.5252 - accuracy: 0.4232 - val_loss: 1.3792 - val_accuracy: 0.4737 - lr: 0.0068 - 13s/epoch - 35ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.47366 to 0.51450, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.3931 - accuracy: 0.4793 - val_loss: 1.3147 - val_accuracy: 0.5145 - lr: 0.0068 - 13s/epoch - 35ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.51450 to 0.53664, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.3527 - accuracy: 0.4988 - val_loss: 1.2821 - val_accuracy: 0.5366 - lr: 0.0068 - 13s/epoch - 35ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.53664\n",
            "382/382 - 13s - loss: 1.3108 - accuracy: 0.5181 - val_loss: 1.2807 - val_accuracy: 0.5153 - lr: 0.0068 - 13s/epoch - 35ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.53664 to 0.56565, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.2775 - accuracy: 0.5289 - val_loss: 1.2273 - val_accuracy: 0.5656 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.56565 to 0.57214, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.2229 - accuracy: 0.5540 - val_loss: 1.2131 - val_accuracy: 0.5721 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.57214\n",
            "382/382 - 13s - loss: 1.1766 - accuracy: 0.5747 - val_loss: 1.1948 - val_accuracy: 0.5714 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.57214 to 0.60115, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.1363 - accuracy: 0.5933 - val_loss: 1.1023 - val_accuracy: 0.6011 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.60115 to 0.60458, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 1.1031 - accuracy: 0.6102 - val_loss: 1.0957 - val_accuracy: 0.6046 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.60458\n",
            "382/382 - 13s - loss: 1.0613 - accuracy: 0.6240 - val_loss: 1.0849 - val_accuracy: 0.6015 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.60458 to 0.65229, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 1.0229 - accuracy: 0.6378 - val_loss: 0.9804 - val_accuracy: 0.6523 - lr: 0.0065 - 14s/epoch - 35ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.65229 to 0.65382, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.9915 - accuracy: 0.6466 - val_loss: 0.9869 - val_accuracy: 0.6538 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.65382 to 0.66603, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.9475 - accuracy: 0.6656 - val_loss: 0.9640 - val_accuracy: 0.6660 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.66603 to 0.69275, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.9199 - accuracy: 0.6776 - val_loss: 0.8810 - val_accuracy: 0.6927 - lr: 0.0065 - 13s/epoch - 35ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.69275\n",
            "382/382 - 13s - loss: 0.8897 - accuracy: 0.6928 - val_loss: 0.8979 - val_accuracy: 0.6882 - lr: 0.0062 - 13s/epoch - 35ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.69275\n",
            "382/382 - 13s - loss: 0.8787 - accuracy: 0.6963 - val_loss: 0.8997 - val_accuracy: 0.6844 - lr: 0.0062 - 13s/epoch - 35ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.69275 to 0.70305, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.8451 - accuracy: 0.7053 - val_loss: 0.8467 - val_accuracy: 0.7031 - lr: 0.0062 - 13s/epoch - 35ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.70305 to 0.70458, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.8174 - accuracy: 0.7181 - val_loss: 0.8330 - val_accuracy: 0.7046 - lr: 0.0062 - 13s/epoch - 35ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.70458 to 0.71031, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.7886 - accuracy: 0.7267 - val_loss: 0.8367 - val_accuracy: 0.7103 - lr: 0.0062 - 13s/epoch - 35ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.71031\n",
            "382/382 - 13s - loss: 0.7556 - accuracy: 0.7374 - val_loss: 0.8264 - val_accuracy: 0.7099 - lr: 0.0062 - 13s/epoch - 35ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.71031 to 0.71489, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.7420 - accuracy: 0.7390 - val_loss: 0.8169 - val_accuracy: 0.7149 - lr: 0.0062 - 13s/epoch - 35ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.71489 to 0.72710, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.7144 - accuracy: 0.7502 - val_loss: 0.7975 - val_accuracy: 0.7271 - lr: 0.0062 - 14s/epoch - 35ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.72710\n",
            "382/382 - 13s - loss: 0.6914 - accuracy: 0.7582 - val_loss: 0.7580 - val_accuracy: 0.7263 - lr: 0.0062 - 13s/epoch - 35ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.72710 to 0.73053, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.6623 - accuracy: 0.7669 - val_loss: 0.7869 - val_accuracy: 0.7305 - lr: 0.0062 - 14s/epoch - 35ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy improved from 0.73053 to 0.74008, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.6325 - accuracy: 0.7768 - val_loss: 0.7611 - val_accuracy: 0.7401 - lr: 0.0059 - 14s/epoch - 35ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy improved from 0.74008 to 0.74389, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.5999 - accuracy: 0.7857 - val_loss: 0.7452 - val_accuracy: 0.7439 - lr: 0.0059 - 14s/epoch - 35ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.74389\n",
            "382/382 - 13s - loss: 0.5723 - accuracy: 0.8000 - val_loss: 0.7760 - val_accuracy: 0.7271 - lr: 0.0059 - 13s/epoch - 35ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy improved from 0.74389 to 0.75534, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.5702 - accuracy: 0.8008 - val_loss: 0.7227 - val_accuracy: 0.7553 - lr: 0.0059 - 14s/epoch - 35ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.75534 to 0.75649, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.5320 - accuracy: 0.8148 - val_loss: 0.7255 - val_accuracy: 0.7565 - lr: 0.0059 - 14s/epoch - 35ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.75649\n",
            "382/382 - 13s - loss: 0.5028 - accuracy: 0.8221 - val_loss: 0.7708 - val_accuracy: 0.7275 - lr: 0.0059 - 13s/epoch - 35ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy improved from 0.75649 to 0.76145, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.4623 - accuracy: 0.8372 - val_loss: 0.7325 - val_accuracy: 0.7615 - lr: 0.0059 - 13s/epoch - 35ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy improved from 0.76145 to 0.77252, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.4561 - accuracy: 0.8415 - val_loss: 0.6628 - val_accuracy: 0.7725 - lr: 0.0059 - 13s/epoch - 35ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.77252\n",
            "382/382 - 13s - loss: 0.4231 - accuracy: 0.8519 - val_loss: 0.7545 - val_accuracy: 0.7473 - lr: 0.0059 - 13s/epoch - 35ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy improved from 0.77252 to 0.78397, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.3930 - accuracy: 0.8620 - val_loss: 0.6493 - val_accuracy: 0.7840 - lr: 0.0059 - 14s/epoch - 35ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.78397\n",
            "382/382 - 13s - loss: 0.3674 - accuracy: 0.8715 - val_loss: 0.7063 - val_accuracy: 0.7664 - lr: 0.0056 - 13s/epoch - 35ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.78397\n",
            "382/382 - 13s - loss: 0.3573 - accuracy: 0.8767 - val_loss: 0.6868 - val_accuracy: 0.7821 - lr: 0.0056 - 13s/epoch - 35ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.78397\n",
            "382/382 - 13s - loss: 0.3199 - accuracy: 0.8882 - val_loss: 0.7011 - val_accuracy: 0.7618 - lr: 0.0056 - 13s/epoch - 35ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.78397\n",
            "382/382 - 14s - loss: 0.3050 - accuracy: 0.8931 - val_loss: 0.6936 - val_accuracy: 0.7821 - lr: 0.0056 - 14s/epoch - 35ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.78397\n",
            "382/382 - 13s - loss: 0.3101 - accuracy: 0.8923 - val_loss: 0.6819 - val_accuracy: 0.7737 - lr: 0.0056 - 13s/epoch - 35ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.78397\n",
            "382/382 - 13s - loss: 0.2758 - accuracy: 0.9049 - val_loss: 0.7020 - val_accuracy: 0.7805 - lr: 0.0056 - 13s/epoch - 35ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy improved from 0.78397 to 0.78550, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.2643 - accuracy: 0.9088 - val_loss: 0.7051 - val_accuracy: 0.7855 - lr: 0.0056 - 14s/epoch - 35ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.78550\n",
            "382/382 - 13s - loss: 0.2398 - accuracy: 0.9182 - val_loss: 0.7141 - val_accuracy: 0.7775 - lr: 0.0056 - 13s/epoch - 35ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.78550\n",
            "382/382 - 13s - loss: 0.2355 - accuracy: 0.9160 - val_loss: 0.7045 - val_accuracy: 0.7805 - lr: 0.0056 - 13s/epoch - 35ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.78550\n",
            "382/382 - 13s - loss: 0.2157 - accuracy: 0.9259 - val_loss: 0.7605 - val_accuracy: 0.7855 - lr: 0.0056 - 13s/epoch - 35ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy improved from 0.78550 to 0.80496, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.2219 - accuracy: 0.9252 - val_loss: 0.6450 - val_accuracy: 0.8050 - lr: 0.0053 - 13s/epoch - 35ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.80496\n",
            "382/382 - 13s - loss: 0.2049 - accuracy: 0.9300 - val_loss: 0.7159 - val_accuracy: 0.7889 - lr: 0.0053 - 13s/epoch - 35ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.80496\n",
            "382/382 - 13s - loss: 0.1926 - accuracy: 0.9332 - val_loss: 0.7378 - val_accuracy: 0.7855 - lr: 0.0053 - 13s/epoch - 35ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.80496\n",
            "382/382 - 13s - loss: 0.1942 - accuracy: 0.9351 - val_loss: 0.6816 - val_accuracy: 0.7966 - lr: 0.0053 - 13s/epoch - 35ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.80496\n",
            "382/382 - 14s - loss: 0.1822 - accuracy: 0.9376 - val_loss: 0.7137 - val_accuracy: 0.8011 - lr: 0.0053 - 14s/epoch - 35ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.80496\n",
            "382/382 - 14s - loss: 0.1603 - accuracy: 0.9473 - val_loss: 0.7664 - val_accuracy: 0.7802 - lr: 0.0053 - 14s/epoch - 35ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.80496\n",
            "382/382 - 13s - loss: 0.1627 - accuracy: 0.9446 - val_loss: 0.7511 - val_accuracy: 0.7954 - lr: 0.0053 - 13s/epoch - 35ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.80496\n",
            "382/382 - 13s - loss: 0.1781 - accuracy: 0.9405 - val_loss: 0.7500 - val_accuracy: 0.7771 - lr: 0.0053 - 13s/epoch - 35ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.80496\n",
            "382/382 - 13s - loss: 0.1604 - accuracy: 0.9462 - val_loss: 0.7103 - val_accuracy: 0.7989 - lr: 0.0053 - 13s/epoch - 35ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.80496\n",
            "382/382 - 13s - loss: 0.1811 - accuracy: 0.9382 - val_loss: 0.7724 - val_accuracy: 0.7931 - lr: 0.0053 - 13s/epoch - 35ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy improved from 0.80496 to 0.81298, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.1452 - accuracy: 0.9522 - val_loss: 0.6852 - val_accuracy: 0.8130 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy improved from 0.81298 to 0.81718, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.1186 - accuracy: 0.9612 - val_loss: 0.7332 - val_accuracy: 0.8172 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy improved from 0.81718 to 0.82137, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1207 - accuracy: 0.9596 - val_loss: 0.7304 - val_accuracy: 0.8214 - lr: 0.0050 - 14s/epoch - 35ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1219 - accuracy: 0.9597 - val_loss: 0.8601 - val_accuracy: 0.7866 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1294 - accuracy: 0.9577 - val_loss: 0.7586 - val_accuracy: 0.7989 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1185 - accuracy: 0.9629 - val_loss: 0.7288 - val_accuracy: 0.8111 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1095 - accuracy: 0.9654 - val_loss: 0.7838 - val_accuracy: 0.8027 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1377 - accuracy: 0.9527 - val_loss: 0.7632 - val_accuracy: 0.8019 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1488 - accuracy: 0.9550 - val_loss: 0.7276 - val_accuracy: 0.8084 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.0928 - accuracy: 0.9682 - val_loss: 0.8468 - val_accuracy: 0.8095 - lr: 0.0050 - 13s/epoch - 35ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1411 - accuracy: 0.9585 - val_loss: 0.7619 - val_accuracy: 0.8130 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1005 - accuracy: 0.9669 - val_loss: 0.8155 - val_accuracy: 0.7966 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.0879 - accuracy: 0.9719 - val_loss: 0.8392 - val_accuracy: 0.8004 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1127 - accuracy: 0.9634 - val_loss: 0.7880 - val_accuracy: 0.8099 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.1158 - accuracy: 0.9620 - val_loss: 0.8069 - val_accuracy: 0.8080 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.82137\n",
            "382/382 - 13s - loss: 0.0817 - accuracy: 0.9729 - val_loss: 0.8279 - val_accuracy: 0.8057 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy improved from 0.82137 to 0.82328, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 13s - loss: 0.0781 - accuracy: 0.9755 - val_loss: 0.7964 - val_accuracy: 0.8233 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.1012 - accuracy: 0.9685 - val_loss: 0.7699 - val_accuracy: 0.8031 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0904 - accuracy: 0.9710 - val_loss: 0.7987 - val_accuracy: 0.8149 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0990 - accuracy: 0.9674 - val_loss: 0.8100 - val_accuracy: 0.8156 - lr: 0.0048 - 13s/epoch - 35ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.1099 - accuracy: 0.9636 - val_loss: 0.8628 - val_accuracy: 0.8011 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0721 - accuracy: 0.9768 - val_loss: 0.8121 - val_accuracy: 0.8229 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0867 - accuracy: 0.9728 - val_loss: 0.8428 - val_accuracy: 0.8202 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0788 - accuracy: 0.9736 - val_loss: 0.8687 - val_accuracy: 0.8126 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0850 - accuracy: 0.9747 - val_loss: 0.8180 - val_accuracy: 0.8088 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0695 - accuracy: 0.9780 - val_loss: 0.8321 - val_accuracy: 0.8046 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.1157 - accuracy: 0.9651 - val_loss: 0.8629 - val_accuracy: 0.8034 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0756 - accuracy: 0.9746 - val_loss: 0.9040 - val_accuracy: 0.8118 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0971 - accuracy: 0.9691 - val_loss: 0.9129 - val_accuracy: 0.7992 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.9846 - val_accuracy: 0.8145 - lr: 0.0045 - 13s/epoch - 35ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0682 - accuracy: 0.9769 - val_loss: 0.9418 - val_accuracy: 0.8126 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0699 - accuracy: 0.9775 - val_loss: 1.0006 - val_accuracy: 0.8061 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0974 - accuracy: 0.9715 - val_loss: 0.8312 - val_accuracy: 0.8153 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0494 - accuracy: 0.9843 - val_loss: 1.1509 - val_accuracy: 0.7840 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0645 - accuracy: 0.9794 - val_loss: 0.8665 - val_accuracy: 0.8160 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0660 - accuracy: 0.9798 - val_loss: 0.9435 - val_accuracy: 0.8149 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0535 - accuracy: 0.9833 - val_loss: 0.8692 - val_accuracy: 0.8221 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0659 - accuracy: 0.9787 - val_loss: 0.8488 - val_accuracy: 0.8164 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0888 - accuracy: 0.9728 - val_loss: 0.9547 - val_accuracy: 0.8073 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0537 - accuracy: 0.9822 - val_loss: 0.9166 - val_accuracy: 0.8156 - lr: 0.0043 - 13s/epoch - 35ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0742 - accuracy: 0.9756 - val_loss: 0.9258 - val_accuracy: 0.8149 - lr: 0.0041 - 13s/epoch - 35ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0582 - accuracy: 0.9822 - val_loss: 0.8499 - val_accuracy: 0.8187 - lr: 0.0041 - 13s/epoch - 35ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0512 - accuracy: 0.9844 - val_loss: 0.9207 - val_accuracy: 0.8195 - lr: 0.0041 - 13s/epoch - 35ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0656 - accuracy: 0.9782 - val_loss: 1.0420 - val_accuracy: 0.8015 - lr: 0.0041 - 13s/epoch - 35ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0559 - accuracy: 0.9815 - val_loss: 0.8551 - val_accuracy: 0.8233 - lr: 0.0041 - 13s/epoch - 35ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0662 - accuracy: 0.9795 - val_loss: 0.9662 - val_accuracy: 0.8195 - lr: 0.0041 - 13s/epoch - 35ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.82328\n",
            "382/382 - 13s - loss: 0.0753 - accuracy: 0.9775 - val_loss: 0.9539 - val_accuracy: 0.8122 - lr: 0.0041 - 13s/epoch - 35ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 21:55:20,344] Trial 3 finished with value: 0.823 and parameters: {'optimizer': 'Adam', 'learning_rate': 0.006844416555582907, 'batch_size': 32, 'dropout_ratio': 0.18789721100566836, 'decay': 0.9214628186841481}. Best is trial 2 with value: 0.98.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_104 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_105 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_58 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_106 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_107 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 256)               0         \n",
            " 6 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.19046, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 352.9620 - accuracy: 0.1948 - val_loss: 2.0323 - val_accuracy: 0.1905 - lr: 0.0296 - 14s/epoch - 75ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.19046 to 0.23244, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 4.5776 - accuracy: 0.2012 - val_loss: 1.8601 - val_accuracy: 0.2324 - lr: 0.0296 - 13s/epoch - 68ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.23244 to 0.29160, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 1.9060 - accuracy: 0.2610 - val_loss: 1.7350 - val_accuracy: 0.2916 - lr: 0.0296 - 13s/epoch - 68ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.29160\n",
            "191/191 - 13s - loss: 1.8078 - accuracy: 0.2805 - val_loss: 1.7954 - val_accuracy: 0.2790 - lr: 0.0296 - 13s/epoch - 67ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.29160 to 0.35496, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 1.7553 - accuracy: 0.3198 - val_loss: 1.6712 - val_accuracy: 0.3550 - lr: 0.0296 - 13s/epoch - 67ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.35496 to 0.42939, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 2.4863 - accuracy: 0.3752 - val_loss: 1.4917 - val_accuracy: 0.4294 - lr: 0.0296 - 13s/epoch - 67ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.42939 to 0.48473, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 1.7325 - accuracy: 0.4287 - val_loss: 1.4003 - val_accuracy: 0.4847 - lr: 0.0296 - 13s/epoch - 68ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.48473\n",
            "191/191 - 13s - loss: 1.7576 - accuracy: 0.4651 - val_loss: 1.4271 - val_accuracy: 0.4561 - lr: 0.0296 - 13s/epoch - 68ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.48473\n",
            "191/191 - 13s - loss: 1.3774 - accuracy: 0.5034 - val_loss: 1.3805 - val_accuracy: 0.4767 - lr: 0.0296 - 13s/epoch - 68ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.48473 to 0.59237, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 1.3473 - accuracy: 0.5248 - val_loss: 1.2136 - val_accuracy: 0.5924 - lr: 0.0296 - 13s/epoch - 68ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.59237\n",
            "191/191 - 13s - loss: 1.2727 - accuracy: 0.5428 - val_loss: 1.1683 - val_accuracy: 0.5687 - lr: 0.0281 - 13s/epoch - 67ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.59237 to 0.61069, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 1.2350 - accuracy: 0.5611 - val_loss: 1.1023 - val_accuracy: 0.6107 - lr: 0.0281 - 13s/epoch - 68ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.61069\n",
            "191/191 - 13s - loss: 1.2035 - accuracy: 0.5769 - val_loss: 1.4026 - val_accuracy: 0.4927 - lr: 0.0281 - 13s/epoch - 67ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.61069\n",
            "191/191 - 13s - loss: 1.1831 - accuracy: 0.5849 - val_loss: 1.6244 - val_accuracy: 0.5382 - lr: 0.0281 - 13s/epoch - 68ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.61069\n",
            "191/191 - 13s - loss: 1.1560 - accuracy: 0.5949 - val_loss: 1.0857 - val_accuracy: 0.5966 - lr: 0.0281 - 13s/epoch - 68ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.61069 to 0.61374, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 1.1320 - accuracy: 0.6102 - val_loss: 1.1262 - val_accuracy: 0.6137 - lr: 0.0281 - 13s/epoch - 68ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.61374\n",
            "191/191 - 13s - loss: 13.7595 - accuracy: 0.5434 - val_loss: 1.6309 - val_accuracy: 0.4309 - lr: 0.0281 - 13s/epoch - 68ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.61374\n",
            "191/191 - 13s - loss: 1.3906 - accuracy: 0.5190 - val_loss: 1.2013 - val_accuracy: 0.5821 - lr: 0.0281 - 13s/epoch - 68ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.61374\n",
            "191/191 - 13s - loss: 1.3409 - accuracy: 0.5570 - val_loss: 1.1854 - val_accuracy: 0.5752 - lr: 0.0281 - 13s/epoch - 68ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.61374\n",
            "191/191 - 13s - loss: 1.1650 - accuracy: 0.6009 - val_loss: 1.1911 - val_accuracy: 0.5763 - lr: 0.0281 - 13s/epoch - 68ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.61374\n",
            "191/191 - 13s - loss: 1.0883 - accuracy: 0.6182 - val_loss: 1.8970 - val_accuracy: 0.4878 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.61374 to 0.62519, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 1.1175 - accuracy: 0.6324 - val_loss: 1.0637 - val_accuracy: 0.6252 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.62519 to 0.63740, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 13s - loss: 1.0814 - accuracy: 0.6358 - val_loss: 1.0560 - val_accuracy: 0.6374 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.0640 - accuracy: 0.6387 - val_loss: 1.1192 - val_accuracy: 0.6088 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.0604 - accuracy: 0.6374 - val_loss: 1.0483 - val_accuracy: 0.6313 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.0653 - accuracy: 0.6371 - val_loss: 1.4881 - val_accuracy: 0.5267 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.0898 - accuracy: 0.6323 - val_loss: 1.0818 - val_accuracy: 0.6206 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.1245 - accuracy: 0.6316 - val_loss: 1.3383 - val_accuracy: 0.5996 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.2032 - accuracy: 0.6255 - val_loss: 1.1437 - val_accuracy: 0.5931 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.3203 - accuracy: 0.5949 - val_loss: 1.1402 - val_accuracy: 0.6118 - lr: 0.0267 - 13s/epoch - 68ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.2594 - accuracy: 0.5965 - val_loss: 1.1386 - val_accuracy: 0.5973 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.3536 - accuracy: 0.5721 - val_loss: 1.3652 - val_accuracy: 0.5389 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 1.7823 - accuracy: 0.5441 - val_loss: 1.5838 - val_accuracy: 0.4504 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 3.5752 - accuracy: 0.4530 - val_loss: 1.5387 - val_accuracy: 0.4443 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 59.0640 - accuracy: 0.3828 - val_loss: 1.7882 - val_accuracy: 0.3573 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 149.2535 - accuracy: 0.2961 - val_loss: 1.8964 - val_accuracy: 0.3511 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.1713 - accuracy: 0.2777 - val_loss: 1.9508 - val_accuracy: 0.2351 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.5241 - accuracy: 0.1968 - val_loss: 2.0421 - val_accuracy: 0.1905 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 4.6641 - accuracy: 0.1883 - val_loss: 2.0380 - val_accuracy: 0.1947 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 186.3870 - accuracy: 0.1858 - val_loss: 2.1098 - val_accuracy: 0.1729 - lr: 0.0254 - 13s/epoch - 68ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 135.8933 - accuracy: 0.1734 - val_loss: 3.4139 - val_accuracy: 0.1878 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.1409 - accuracy: 0.1940 - val_loss: 2.1408 - val_accuracy: 0.1916 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.2936 - accuracy: 0.1841 - val_loss: 2.1999 - val_accuracy: 0.2031 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.2534 - accuracy: 0.1848 - val_loss: 2.1530 - val_accuracy: 0.1931 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 13.6314 - accuracy: 0.1776 - val_loss: 2.1036 - val_accuracy: 0.1771 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.5138 - accuracy: 0.1724 - val_loss: 2.0903 - val_accuracy: 0.1706 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.1372 - accuracy: 0.1747 - val_loss: 2.0522 - val_accuracy: 0.1981 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.1637 - accuracy: 0.1769 - val_loss: 2.1282 - val_accuracy: 0.1924 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 3.5901 - accuracy: 0.1891 - val_loss: 2.2701 - val_accuracy: 0.1618 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 12.0597 - accuracy: 0.1846 - val_loss: 2.1235 - val_accuracy: 0.1752 - lr: 0.0241 - 13s/epoch - 68ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 3.6697 - accuracy: 0.1823 - val_loss: 2.2998 - val_accuracy: 0.1840 - lr: 0.0229 - 13s/epoch - 68ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 2.0992 - accuracy: 0.1900 - val_loss: 2.1912 - val_accuracy: 0.1752 - lr: 0.0229 - 13s/epoch - 68ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.63740\n",
            "191/191 - 13s - loss: 5.2411 - accuracy: 0.1863 - val_loss: 2.1079 - val_accuracy: 0.1855 - lr: 0.0229 - 13s/epoch - 68ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 22:06:48,378] Trial 4 finished with value: 0.637 and parameters: {'optimizer': 'RMSprop', 'learning_rate': 0.029593917357955402, 'batch_size': 64, 'dropout_ratio': 0.03780699401469011, 'decay': 0.9185991909735228}. Best is trial 2 with value: 0.98.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_108 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_109 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_59 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_111 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 256)               0         \n",
            " 7 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47748, saving model to saved_models/best_fcn.keras\n",
            "764/764 - 16s - loss: 16.5589 - accuracy: 0.2786 - val_loss: 1.4682 - val_accuracy: 0.4775 - lr: 0.0161 - 16s/epoch - 21ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.47748 to 0.52710, saving model to saved_models/best_fcn.keras\n",
            "764/764 - 14s - loss: 1.5443 - accuracy: 0.4836 - val_loss: 1.3160 - val_accuracy: 0.5271 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.52710 to 0.53550, saving model to saved_models/best_fcn.keras\n",
            "764/764 - 14s - loss: 1.3553 - accuracy: 0.5525 - val_loss: 1.2410 - val_accuracy: 0.5355 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.53550 to 0.60153, saving model to saved_models/best_fcn.keras\n",
            "764/764 - 14s - loss: 1.2695 - accuracy: 0.5753 - val_loss: 1.1399 - val_accuracy: 0.6015 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 1.3478 - accuracy: 0.5727 - val_loss: 1.2000 - val_accuracy: 0.5828 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 1.3945 - accuracy: 0.5703 - val_loss: 2.1735 - val_accuracy: 0.5111 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 1.5368 - accuracy: 0.5396 - val_loss: 1.4367 - val_accuracy: 0.5298 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 1.7574 - accuracy: 0.4995 - val_loss: 1.6897 - val_accuracy: 0.4385 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.3378 - accuracy: 0.3477 - val_loss: 1.7514 - val_accuracy: 0.3439 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.2729 - accuracy: 0.3145 - val_loss: 2.2712 - val_accuracy: 0.2733 - lr: 0.0161 - 14s/epoch - 19ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 4.5195 - accuracy: 0.2954 - val_loss: 1.8120 - val_accuracy: 0.3267 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 3.8921 - accuracy: 0.3104 - val_loss: 1.9603 - val_accuracy: 0.3286 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 3.2699 - accuracy: 0.3244 - val_loss: 1.7816 - val_accuracy: 0.3202 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.2577 - accuracy: 0.3168 - val_loss: 1.9467 - val_accuracy: 0.3328 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 1.9744 - accuracy: 0.3232 - val_loss: 1.9954 - val_accuracy: 0.3027 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.0399 - accuracy: 0.3155 - val_loss: 1.8757 - val_accuracy: 0.2882 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 10.3338 - accuracy: 0.3015 - val_loss: 1.8035 - val_accuracy: 0.2927 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 3.8461 - accuracy: 0.3032 - val_loss: 1.7776 - val_accuracy: 0.3198 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.2734 - accuracy: 0.2970 - val_loss: 1.8830 - val_accuracy: 0.2798 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.2984 - accuracy: 0.2986 - val_loss: 1.8864 - val_accuracy: 0.3210 - lr: 0.0153 - 14s/epoch - 19ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.3264 - accuracy: 0.2986 - val_loss: 1.9035 - val_accuracy: 0.2863 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.0508 - accuracy: 0.2837 - val_loss: 1.8977 - val_accuracy: 0.2874 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.0268 - accuracy: 0.2911 - val_loss: 1.9323 - val_accuracy: 0.3084 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 4.3012 - accuracy: 0.3007 - val_loss: 1.8300 - val_accuracy: 0.2931 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 1.9565 - accuracy: 0.2925 - val_loss: 1.9209 - val_accuracy: 0.2691 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.0832 - accuracy: 0.2951 - val_loss: 1.8142 - val_accuracy: 0.3061 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.5655 - accuracy: 0.2910 - val_loss: 1.9478 - val_accuracy: 0.2496 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.1417 - accuracy: 0.2902 - val_loss: 1.8982 - val_accuracy: 0.2832 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.0234 - accuracy: 0.3021 - val_loss: 2.2402 - val_accuracy: 0.2943 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.0123 - accuracy: 0.2965 - val_loss: 1.9266 - val_accuracy: 0.3214 - lr: 0.0145 - 14s/epoch - 19ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 1.9817 - accuracy: 0.2965 - val_loss: 2.1745 - val_accuracy: 0.3019 - lr: 0.0138 - 14s/epoch - 19ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.0936 - accuracy: 0.3001 - val_loss: 1.9581 - val_accuracy: 0.2691 - lr: 0.0138 - 14s/epoch - 19ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 1.9470 - accuracy: 0.2965 - val_loss: 2.1630 - val_accuracy: 0.3233 - lr: 0.0138 - 14s/epoch - 19ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.60153\n",
            "764/764 - 14s - loss: 2.0113 - accuracy: 0.2835 - val_loss: 1.9777 - val_accuracy: 0.2779 - lr: 0.0138 - 14s/epoch - 19ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 22:14:54,810] Trial 5 finished with value: 0.602 and parameters: {'optimizer': 'RMSprop', 'learning_rate': 0.016088295022160064, 'batch_size': 16, 'dropout_ratio': 0.03181486876965291, 'decay': 0.8851216092017713}. Best is trial 2 with value: 0.98.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_112 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_113 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_60 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_114 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_115 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 256)               0         \n",
            " 8 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.27634, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 15s - loss: 2.2397 - accuracy: 0.1441 - val_loss: 2.1097 - val_accuracy: 0.2763 - lr: 0.0066 - 15s/epoch - 627ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.27634 to 0.31069, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 2.1219 - accuracy: 0.1993 - val_loss: 2.0461 - val_accuracy: 0.3107 - lr: 0.0066 - 14s/epoch - 588ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.31069 to 0.31527, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 2.0578 - accuracy: 0.2389 - val_loss: 1.9968 - val_accuracy: 0.3153 - lr: 0.0066 - 14s/epoch - 590ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.31527 to 0.33168, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 2.0127 - accuracy: 0.2664 - val_loss: 1.9555 - val_accuracy: 0.3317 - lr: 0.0066 - 14s/epoch - 588ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.33168 to 0.33664, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.9787 - accuracy: 0.2759 - val_loss: 1.9200 - val_accuracy: 0.3366 - lr: 0.0066 - 14s/epoch - 588ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.33664 to 0.34656, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.9470 - accuracy: 0.2957 - val_loss: 1.8910 - val_accuracy: 0.3466 - lr: 0.0066 - 14s/epoch - 587ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.34656 to 0.35000, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.9176 - accuracy: 0.3069 - val_loss: 1.8600 - val_accuracy: 0.3500 - lr: 0.0066 - 14s/epoch - 586ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.35000 to 0.35763, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.8936 - accuracy: 0.3192 - val_loss: 1.8357 - val_accuracy: 0.3576 - lr: 0.0066 - 14s/epoch - 587ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.35763 to 0.37634, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.8706 - accuracy: 0.3260 - val_loss: 1.8084 - val_accuracy: 0.3763 - lr: 0.0066 - 14s/epoch - 587ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.37634 to 0.37977, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.8513 - accuracy: 0.3393 - val_loss: 1.7880 - val_accuracy: 0.3798 - lr: 0.0066 - 14s/epoch - 587ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.37977 to 0.39122, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.8228 - accuracy: 0.3532 - val_loss: 1.7638 - val_accuracy: 0.3912 - lr: 0.0063 - 14s/epoch - 588ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.39122 to 0.40000, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.8050 - accuracy: 0.3523 - val_loss: 1.7413 - val_accuracy: 0.4000 - lr: 0.0063 - 14s/epoch - 588ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.40000 to 0.41183, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.7843 - accuracy: 0.3680 - val_loss: 1.7174 - val_accuracy: 0.4118 - lr: 0.0063 - 14s/epoch - 588ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.41183 to 0.41679, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.7665 - accuracy: 0.3735 - val_loss: 1.6961 - val_accuracy: 0.4168 - lr: 0.0063 - 14s/epoch - 589ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.41679 to 0.42290, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.7533 - accuracy: 0.3788 - val_loss: 1.6821 - val_accuracy: 0.4229 - lr: 0.0063 - 14s/epoch - 589ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.42290\n",
            "24/24 - 14s - loss: 1.7303 - accuracy: 0.3865 - val_loss: 1.6666 - val_accuracy: 0.4195 - lr: 0.0063 - 14s/epoch - 587ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.42290 to 0.43511, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.7143 - accuracy: 0.3933 - val_loss: 1.6384 - val_accuracy: 0.4351 - lr: 0.0063 - 14s/epoch - 589ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.43511 to 0.44542, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.6869 - accuracy: 0.4023 - val_loss: 1.6198 - val_accuracy: 0.4454 - lr: 0.0063 - 14s/epoch - 589ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.44542\n",
            "24/24 - 14s - loss: 1.6821 - accuracy: 0.4133 - val_loss: 1.6169 - val_accuracy: 0.4324 - lr: 0.0063 - 14s/epoch - 587ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.44542 to 0.45916, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.6670 - accuracy: 0.4059 - val_loss: 1.5893 - val_accuracy: 0.4592 - lr: 0.0063 - 14s/epoch - 589ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.45916\n",
            "24/24 - 14s - loss: 1.6537 - accuracy: 0.4211 - val_loss: 1.5722 - val_accuracy: 0.4569 - lr: 0.0059 - 14s/epoch - 586ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.45916\n",
            "24/24 - 14s - loss: 1.6403 - accuracy: 0.4226 - val_loss: 1.5608 - val_accuracy: 0.4573 - lr: 0.0059 - 14s/epoch - 587ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.45916 to 0.46603, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.6218 - accuracy: 0.4333 - val_loss: 1.5447 - val_accuracy: 0.4660 - lr: 0.0059 - 14s/epoch - 589ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.46603\n",
            "24/24 - 14s - loss: 1.6099 - accuracy: 0.4346 - val_loss: 1.5350 - val_accuracy: 0.4645 - lr: 0.0059 - 14s/epoch - 587ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.46603 to 0.46641, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5989 - accuracy: 0.4397 - val_loss: 1.5164 - val_accuracy: 0.4664 - lr: 0.0059 - 14s/epoch - 588ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.46641 to 0.47481, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5748 - accuracy: 0.4500 - val_loss: 1.5036 - val_accuracy: 0.4748 - lr: 0.0059 - 14s/epoch - 588ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.47481 to 0.47824, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5728 - accuracy: 0.4469 - val_loss: 1.4901 - val_accuracy: 0.4782 - lr: 0.0059 - 14s/epoch - 588ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.47824 to 0.48550, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5658 - accuracy: 0.4507 - val_loss: 1.4910 - val_accuracy: 0.4855 - lr: 0.0059 - 14s/epoch - 588ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy improved from 0.48550 to 0.49466, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5520 - accuracy: 0.4580 - val_loss: 1.4694 - val_accuracy: 0.4947 - lr: 0.0059 - 14s/epoch - 588ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.49466 to 0.50229, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5497 - accuracy: 0.4604 - val_loss: 1.4620 - val_accuracy: 0.5023 - lr: 0.0059 - 14s/epoch - 589ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.50229\n",
            "24/24 - 14s - loss: 1.5289 - accuracy: 0.4656 - val_loss: 1.4533 - val_accuracy: 0.4878 - lr: 0.0057 - 14s/epoch - 586ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.50229\n",
            "24/24 - 14s - loss: 1.5236 - accuracy: 0.4623 - val_loss: 1.4438 - val_accuracy: 0.4996 - lr: 0.0057 - 14s/epoch - 587ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.50229\n",
            "24/24 - 14s - loss: 1.5088 - accuracy: 0.4729 - val_loss: 1.4285 - val_accuracy: 0.5004 - lr: 0.0057 - 14s/epoch - 587ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy improved from 0.50229 to 0.51031, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5152 - accuracy: 0.4706 - val_loss: 1.4190 - val_accuracy: 0.5103 - lr: 0.0057 - 14s/epoch - 589ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.51031 to 0.51298, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.5003 - accuracy: 0.4804 - val_loss: 1.4104 - val_accuracy: 0.5130 - lr: 0.0057 - 14s/epoch - 588ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy improved from 0.51298 to 0.51374, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.4757 - accuracy: 0.4880 - val_loss: 1.4006 - val_accuracy: 0.5137 - lr: 0.0057 - 14s/epoch - 588ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy improved from 0.51374 to 0.51718, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.4835 - accuracy: 0.4837 - val_loss: 1.3922 - val_accuracy: 0.5172 - lr: 0.0057 - 14s/epoch - 588ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy improved from 0.51718 to 0.51832, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.4668 - accuracy: 0.4914 - val_loss: 1.3841 - val_accuracy: 0.5183 - lr: 0.0057 - 14s/epoch - 589ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.51832\n",
            "24/24 - 14s - loss: 1.4662 - accuracy: 0.4917 - val_loss: 1.3951 - val_accuracy: 0.5179 - lr: 0.0057 - 14s/epoch - 586ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy improved from 0.51832 to 0.52634, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.4521 - accuracy: 0.5013 - val_loss: 1.3916 - val_accuracy: 0.5263 - lr: 0.0057 - 14s/epoch - 588ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.52634 to 0.53931, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.4472 - accuracy: 0.4941 - val_loss: 1.3642 - val_accuracy: 0.5393 - lr: 0.0054 - 14s/epoch - 588ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.53931\n",
            "24/24 - 14s - loss: 1.4266 - accuracy: 0.5067 - val_loss: 1.3580 - val_accuracy: 0.5309 - lr: 0.0054 - 14s/epoch - 586ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.53931\n",
            "24/24 - 14s - loss: 1.4337 - accuracy: 0.5051 - val_loss: 1.3460 - val_accuracy: 0.5324 - lr: 0.0054 - 14s/epoch - 586ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.53931\n",
            "24/24 - 14s - loss: 1.4288 - accuracy: 0.5016 - val_loss: 1.3712 - val_accuracy: 0.5233 - lr: 0.0054 - 14s/epoch - 587ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.53931\n",
            "24/24 - 14s - loss: 1.4159 - accuracy: 0.5067 - val_loss: 1.3619 - val_accuracy: 0.5218 - lr: 0.0054 - 14s/epoch - 587ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy improved from 0.53931 to 0.54618, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.4019 - accuracy: 0.5154 - val_loss: 1.3186 - val_accuracy: 0.5462 - lr: 0.0054 - 14s/epoch - 588ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.54618\n",
            "24/24 - 14s - loss: 1.4053 - accuracy: 0.5167 - val_loss: 1.3393 - val_accuracy: 0.5279 - lr: 0.0054 - 14s/epoch - 586ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy improved from 0.54618 to 0.55038, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.3912 - accuracy: 0.5159 - val_loss: 1.3051 - val_accuracy: 0.5504 - lr: 0.0054 - 14s/epoch - 588ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy improved from 0.55038 to 0.55611, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.3862 - accuracy: 0.5242 - val_loss: 1.3035 - val_accuracy: 0.5561 - lr: 0.0054 - 14s/epoch - 588ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.55611\n",
            "24/24 - 14s - loss: 1.3908 - accuracy: 0.5204 - val_loss: 1.3043 - val_accuracy: 0.5508 - lr: 0.0054 - 14s/epoch - 586ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy improved from 0.55611 to 0.55878, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.3676 - accuracy: 0.5318 - val_loss: 1.2916 - val_accuracy: 0.5588 - lr: 0.0051 - 14s/epoch - 588ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy improved from 0.55878 to 0.56718, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.3626 - accuracy: 0.5318 - val_loss: 1.2805 - val_accuracy: 0.5672 - lr: 0.0051 - 14s/epoch - 588ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.56718\n",
            "24/24 - 14s - loss: 1.3575 - accuracy: 0.5362 - val_loss: 1.2673 - val_accuracy: 0.5634 - lr: 0.0051 - 14s/epoch - 586ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.56718\n",
            "24/24 - 14s - loss: 1.3573 - accuracy: 0.5306 - val_loss: 1.2758 - val_accuracy: 0.5656 - lr: 0.0051 - 14s/epoch - 587ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.56718\n",
            "24/24 - 14s - loss: 1.3487 - accuracy: 0.5354 - val_loss: 1.2621 - val_accuracy: 0.5607 - lr: 0.0051 - 14s/epoch - 587ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.56718\n",
            "24/24 - 14s - loss: 1.3404 - accuracy: 0.5371 - val_loss: 1.2532 - val_accuracy: 0.5637 - lr: 0.0051 - 14s/epoch - 587ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.56718\n",
            "24/24 - 14s - loss: 1.3384 - accuracy: 0.5376 - val_loss: 1.2804 - val_accuracy: 0.5580 - lr: 0.0051 - 14s/epoch - 586ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.56718\n",
            "24/24 - 14s - loss: 1.3309 - accuracy: 0.5438 - val_loss: 1.2906 - val_accuracy: 0.5630 - lr: 0.0051 - 14s/epoch - 586ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy improved from 0.56718 to 0.57481, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.3270 - accuracy: 0.5410 - val_loss: 1.2749 - val_accuracy: 0.5748 - lr: 0.0051 - 14s/epoch - 588ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.57481\n",
            "24/24 - 14s - loss: 1.3166 - accuracy: 0.5464 - val_loss: 1.2310 - val_accuracy: 0.5729 - lr: 0.0051 - 14s/epoch - 586ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy improved from 0.57481 to 0.57748, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.3101 - accuracy: 0.5515 - val_loss: 1.2534 - val_accuracy: 0.5775 - lr: 0.0048 - 14s/epoch - 588ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy improved from 0.57748 to 0.59389, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.3052 - accuracy: 0.5525 - val_loss: 1.2326 - val_accuracy: 0.5939 - lr: 0.0048 - 14s/epoch - 588ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.59389\n",
            "24/24 - 14s - loss: 1.2994 - accuracy: 0.5525 - val_loss: 1.2261 - val_accuracy: 0.5813 - lr: 0.0048 - 14s/epoch - 586ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.59389\n",
            "24/24 - 14s - loss: 1.2895 - accuracy: 0.5535 - val_loss: 1.2330 - val_accuracy: 0.5798 - lr: 0.0048 - 14s/epoch - 586ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.59389\n",
            "24/24 - 14s - loss: 1.2996 - accuracy: 0.5499 - val_loss: 1.1995 - val_accuracy: 0.5889 - lr: 0.0048 - 14s/epoch - 586ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.59389\n",
            "24/24 - 14s - loss: 1.2809 - accuracy: 0.5628 - val_loss: 1.2050 - val_accuracy: 0.5824 - lr: 0.0048 - 14s/epoch - 587ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.59389\n",
            "24/24 - 14s - loss: 1.2740 - accuracy: 0.5608 - val_loss: 1.2297 - val_accuracy: 0.5782 - lr: 0.0048 - 14s/epoch - 586ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.59389\n",
            "24/24 - 14s - loss: 1.2743 - accuracy: 0.5638 - val_loss: 1.1830 - val_accuracy: 0.5893 - lr: 0.0048 - 14s/epoch - 586ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy improved from 0.59389 to 0.60038, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.2677 - accuracy: 0.5659 - val_loss: 1.1864 - val_accuracy: 0.6004 - lr: 0.0048 - 14s/epoch - 588ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.60038\n",
            "24/24 - 14s - loss: 1.2692 - accuracy: 0.5615 - val_loss: 1.2020 - val_accuracy: 0.5855 - lr: 0.0048 - 14s/epoch - 586ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.60038\n",
            "24/24 - 14s - loss: 1.2593 - accuracy: 0.5635 - val_loss: 1.1833 - val_accuracy: 0.5992 - lr: 0.0046 - 14s/epoch - 586ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy improved from 0.60038 to 0.60191, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.2395 - accuracy: 0.5742 - val_loss: 1.1741 - val_accuracy: 0.6019 - lr: 0.0046 - 14s/epoch - 588ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.60191\n",
            "24/24 - 14s - loss: 1.2524 - accuracy: 0.5668 - val_loss: 1.1898 - val_accuracy: 0.5809 - lr: 0.0046 - 14s/epoch - 586ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.60191\n",
            "24/24 - 14s - loss: 1.2344 - accuracy: 0.5764 - val_loss: 1.2016 - val_accuracy: 0.5740 - lr: 0.0046 - 14s/epoch - 586ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy improved from 0.60191 to 0.61221, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.2414 - accuracy: 0.5712 - val_loss: 1.1618 - val_accuracy: 0.6122 - lr: 0.0046 - 14s/epoch - 588ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.61221\n",
            "24/24 - 14s - loss: 1.2365 - accuracy: 0.5743 - val_loss: 1.1522 - val_accuracy: 0.6038 - lr: 0.0046 - 14s/epoch - 587ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.61221\n",
            "24/24 - 14s - loss: 1.2364 - accuracy: 0.5684 - val_loss: 1.1480 - val_accuracy: 0.6065 - lr: 0.0046 - 14s/epoch - 587ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.61221\n",
            "24/24 - 14s - loss: 1.2231 - accuracy: 0.5790 - val_loss: 1.1486 - val_accuracy: 0.6046 - lr: 0.0046 - 14s/epoch - 587ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.61221\n",
            "24/24 - 14s - loss: 1.2216 - accuracy: 0.5746 - val_loss: 1.1493 - val_accuracy: 0.5989 - lr: 0.0046 - 14s/epoch - 587ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.61221\n",
            "24/24 - 14s - loss: 1.2225 - accuracy: 0.5839 - val_loss: 1.1470 - val_accuracy: 0.6008 - lr: 0.0046 - 14s/epoch - 585ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy improved from 0.61221 to 0.61947, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.2096 - accuracy: 0.5868 - val_loss: 1.1313 - val_accuracy: 0.6195 - lr: 0.0044 - 14s/epoch - 587ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.61947\n",
            "24/24 - 14s - loss: 1.2022 - accuracy: 0.5832 - val_loss: 1.1236 - val_accuracy: 0.6172 - lr: 0.0044 - 14s/epoch - 586ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.61947\n",
            "24/24 - 14s - loss: 1.2014 - accuracy: 0.5839 - val_loss: 1.1441 - val_accuracy: 0.5863 - lr: 0.0044 - 14s/epoch - 587ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.61947\n",
            "24/24 - 14s - loss: 1.2009 - accuracy: 0.5822 - val_loss: 1.1296 - val_accuracy: 0.6038 - lr: 0.0044 - 14s/epoch - 589ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.61947\n",
            "24/24 - 14s - loss: 1.1978 - accuracy: 0.5893 - val_loss: 1.1046 - val_accuracy: 0.6179 - lr: 0.0044 - 14s/epoch - 588ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy improved from 0.61947 to 0.62252, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1926 - accuracy: 0.5873 - val_loss: 1.1053 - val_accuracy: 0.6225 - lr: 0.0044 - 14s/epoch - 590ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.62252\n",
            "24/24 - 14s - loss: 1.1860 - accuracy: 0.5883 - val_loss: 1.1065 - val_accuracy: 0.6214 - lr: 0.0044 - 14s/epoch - 588ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.62252\n",
            "24/24 - 14s - loss: 1.1882 - accuracy: 0.5906 - val_loss: 1.1040 - val_accuracy: 0.6214 - lr: 0.0044 - 14s/epoch - 588ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.62252\n",
            "24/24 - 14s - loss: 1.1931 - accuracy: 0.5876 - val_loss: 1.0986 - val_accuracy: 0.6225 - lr: 0.0044 - 14s/epoch - 588ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy improved from 0.62252 to 0.63206, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1710 - accuracy: 0.5949 - val_loss: 1.0873 - val_accuracy: 0.6321 - lr: 0.0044 - 14s/epoch - 590ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.63206\n",
            "24/24 - 14s - loss: 1.1768 - accuracy: 0.5945 - val_loss: 1.0941 - val_accuracy: 0.6313 - lr: 0.0042 - 14s/epoch - 587ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.63206\n",
            "24/24 - 14s - loss: 1.1699 - accuracy: 0.5947 - val_loss: 1.1134 - val_accuracy: 0.6191 - lr: 0.0042 - 14s/epoch - 588ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.63206\n",
            "24/24 - 14s - loss: 1.1739 - accuracy: 0.5888 - val_loss: 1.0953 - val_accuracy: 0.6244 - lr: 0.0042 - 14s/epoch - 587ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.63206\n",
            "24/24 - 14s - loss: 1.1664 - accuracy: 0.5986 - val_loss: 1.0857 - val_accuracy: 0.6183 - lr: 0.0042 - 14s/epoch - 587ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.63206\n",
            "24/24 - 14s - loss: 1.1600 - accuracy: 0.5996 - val_loss: 1.1012 - val_accuracy: 0.6275 - lr: 0.0042 - 14s/epoch - 586ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy improved from 0.63206 to 0.63588, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1587 - accuracy: 0.5977 - val_loss: 1.0788 - val_accuracy: 0.6359 - lr: 0.0042 - 14s/epoch - 588ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.63588\n",
            "24/24 - 14s - loss: 1.1543 - accuracy: 0.6011 - val_loss: 1.0761 - val_accuracy: 0.6321 - lr: 0.0042 - 14s/epoch - 586ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.63588\n",
            "24/24 - 14s - loss: 1.1550 - accuracy: 0.6018 - val_loss: 1.0723 - val_accuracy: 0.6324 - lr: 0.0042 - 14s/epoch - 586ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.63588\n",
            "24/24 - 14s - loss: 1.1444 - accuracy: 0.6036 - val_loss: 1.0974 - val_accuracy: 0.6183 - lr: 0.0042 - 14s/epoch - 587ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.63588\n",
            "24/24 - 14s - loss: 1.1461 - accuracy: 0.6042 - val_loss: 1.0982 - val_accuracy: 0.6103 - lr: 0.0042 - 14s/epoch - 586ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.63588\n",
            "24/24 - 14s - loss: 1.1429 - accuracy: 0.6009 - val_loss: 1.0516 - val_accuracy: 0.6351 - lr: 0.0039 - 14s/epoch - 586ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy improved from 0.63588 to 0.64008, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1270 - accuracy: 0.6103 - val_loss: 1.0532 - val_accuracy: 0.6401 - lr: 0.0039 - 14s/epoch - 589ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.64008\n",
            "24/24 - 14s - loss: 1.1342 - accuracy: 0.6104 - val_loss: 1.0532 - val_accuracy: 0.6374 - lr: 0.0039 - 14s/epoch - 588ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy improved from 0.64008 to 0.64542, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1218 - accuracy: 0.6131 - val_loss: 1.0473 - val_accuracy: 0.6454 - lr: 0.0039 - 14s/epoch - 590ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.64542\n",
            "24/24 - 14s - loss: 1.1213 - accuracy: 0.6123 - val_loss: 1.0346 - val_accuracy: 0.6431 - lr: 0.0039 - 14s/epoch - 587ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.64542\n",
            "24/24 - 14s - loss: 1.1193 - accuracy: 0.6140 - val_loss: 1.0578 - val_accuracy: 0.6271 - lr: 0.0039 - 14s/epoch - 586ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy improved from 0.64542 to 0.64695, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1176 - accuracy: 0.6127 - val_loss: 1.0280 - val_accuracy: 0.6469 - lr: 0.0039 - 14s/epoch - 587ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.64695\n",
            "24/24 - 14s - loss: 1.1157 - accuracy: 0.6137 - val_loss: 1.0376 - val_accuracy: 0.6443 - lr: 0.0039 - 14s/epoch - 585ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy improved from 0.64695 to 0.64809, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1151 - accuracy: 0.6145 - val_loss: 1.0259 - val_accuracy: 0.6481 - lr: 0.0039 - 14s/epoch - 587ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.64809\n",
            "24/24 - 14s - loss: 1.1062 - accuracy: 0.6166 - val_loss: 1.0553 - val_accuracy: 0.6355 - lr: 0.0039 - 14s/epoch - 586ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.64809\n",
            "24/24 - 14s - loss: 1.1085 - accuracy: 0.6138 - val_loss: 1.0334 - val_accuracy: 0.6393 - lr: 0.0037 - 14s/epoch - 587ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy improved from 0.64809 to 0.64924, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.1082 - accuracy: 0.6179 - val_loss: 1.0281 - val_accuracy: 0.6492 - lr: 0.0037 - 14s/epoch - 589ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.64924\n",
            "24/24 - 14s - loss: 1.1008 - accuracy: 0.6203 - val_loss: 1.0241 - val_accuracy: 0.6489 - lr: 0.0037 - 14s/epoch - 587ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy improved from 0.64924 to 0.65115, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0966 - accuracy: 0.6231 - val_loss: 1.0368 - val_accuracy: 0.6511 - lr: 0.0037 - 14s/epoch - 589ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy improved from 0.65115 to 0.65458, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0966 - accuracy: 0.6222 - val_loss: 1.0014 - val_accuracy: 0.6546 - lr: 0.0037 - 14s/epoch - 589ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.65458\n",
            "24/24 - 14s - loss: 1.0887 - accuracy: 0.6217 - val_loss: 1.0328 - val_accuracy: 0.6458 - lr: 0.0037 - 14s/epoch - 587ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.65458\n",
            "24/24 - 14s - loss: 1.0874 - accuracy: 0.6271 - val_loss: 1.0104 - val_accuracy: 0.6527 - lr: 0.0037 - 14s/epoch - 587ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.65458\n",
            "24/24 - 14s - loss: 1.0907 - accuracy: 0.6230 - val_loss: 1.0257 - val_accuracy: 0.6420 - lr: 0.0037 - 14s/epoch - 587ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy improved from 0.65458 to 0.65763, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0882 - accuracy: 0.6252 - val_loss: 0.9934 - val_accuracy: 0.6576 - lr: 0.0037 - 14s/epoch - 589ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.65763\n",
            "24/24 - 14s - loss: 1.0767 - accuracy: 0.6275 - val_loss: 1.0154 - val_accuracy: 0.6511 - lr: 0.0037 - 14s/epoch - 586ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.65763\n",
            "24/24 - 14s - loss: 1.0835 - accuracy: 0.6263 - val_loss: 1.0154 - val_accuracy: 0.6401 - lr: 0.0036 - 14s/epoch - 585ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy improved from 0.65763 to 0.66183, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0765 - accuracy: 0.6301 - val_loss: 0.9901 - val_accuracy: 0.6618 - lr: 0.0036 - 14s/epoch - 586ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.66183\n",
            "24/24 - 14s - loss: 1.0637 - accuracy: 0.6351 - val_loss: 0.9957 - val_accuracy: 0.6534 - lr: 0.0036 - 14s/epoch - 584ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.66183\n",
            "24/24 - 14s - loss: 1.0734 - accuracy: 0.6276 - val_loss: 0.9900 - val_accuracy: 0.6576 - lr: 0.0036 - 14s/epoch - 585ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.66183\n",
            "24/24 - 14s - loss: 1.0683 - accuracy: 0.6281 - val_loss: 1.0040 - val_accuracy: 0.6531 - lr: 0.0036 - 14s/epoch - 586ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy improved from 0.66183 to 0.66641, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0665 - accuracy: 0.6295 - val_loss: 0.9759 - val_accuracy: 0.6664 - lr: 0.0036 - 14s/epoch - 588ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy improved from 0.66641 to 0.66679, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0630 - accuracy: 0.6347 - val_loss: 0.9795 - val_accuracy: 0.6668 - lr: 0.0036 - 14s/epoch - 587ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy improved from 0.66679 to 0.66947, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0611 - accuracy: 0.6351 - val_loss: 0.9699 - val_accuracy: 0.6695 - lr: 0.0036 - 14s/epoch - 587ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.66947\n",
            "24/24 - 14s - loss: 1.0574 - accuracy: 0.6382 - val_loss: 0.9742 - val_accuracy: 0.6618 - lr: 0.0036 - 14s/epoch - 586ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.66947\n",
            "24/24 - 14s - loss: 1.0537 - accuracy: 0.6325 - val_loss: 0.9740 - val_accuracy: 0.6603 - lr: 0.0036 - 14s/epoch - 587ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.66947\n",
            "24/24 - 14s - loss: 1.0518 - accuracy: 0.6379 - val_loss: 0.9654 - val_accuracy: 0.6676 - lr: 0.0034 - 14s/epoch - 588ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.66947\n",
            "24/24 - 14s - loss: 1.0448 - accuracy: 0.6420 - val_loss: 0.9766 - val_accuracy: 0.6618 - lr: 0.0034 - 14s/epoch - 588ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.66947\n",
            "24/24 - 14s - loss: 1.0403 - accuracy: 0.6391 - val_loss: 0.9697 - val_accuracy: 0.6622 - lr: 0.0034 - 14s/epoch - 587ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.66947\n",
            "24/24 - 14s - loss: 1.0439 - accuracy: 0.6401 - val_loss: 0.9636 - val_accuracy: 0.6634 - lr: 0.0034 - 14s/epoch - 588ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy improved from 0.66947 to 0.67443, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0378 - accuracy: 0.6447 - val_loss: 0.9539 - val_accuracy: 0.6744 - lr: 0.0034 - 14s/epoch - 590ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.67443\n",
            "24/24 - 14s - loss: 1.0369 - accuracy: 0.6451 - val_loss: 0.9649 - val_accuracy: 0.6622 - lr: 0.0034 - 14s/epoch - 587ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.67443\n",
            "24/24 - 14s - loss: 1.0359 - accuracy: 0.6428 - val_loss: 0.9657 - val_accuracy: 0.6637 - lr: 0.0034 - 14s/epoch - 587ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.67443\n",
            "24/24 - 14s - loss: 1.0331 - accuracy: 0.6439 - val_loss: 0.9547 - val_accuracy: 0.6740 - lr: 0.0034 - 14s/epoch - 587ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy improved from 0.67443 to 0.67481, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0386 - accuracy: 0.6429 - val_loss: 0.9518 - val_accuracy: 0.6748 - lr: 0.0034 - 14s/epoch - 588ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.67481\n",
            "24/24 - 14s - loss: 1.0250 - accuracy: 0.6486 - val_loss: 0.9522 - val_accuracy: 0.6702 - lr: 0.0034 - 14s/epoch - 586ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy improved from 0.67481 to 0.67710, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0322 - accuracy: 0.6474 - val_loss: 0.9468 - val_accuracy: 0.6771 - lr: 0.0032 - 14s/epoch - 587ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.67710\n",
            "24/24 - 14s - loss: 1.0200 - accuracy: 0.6510 - val_loss: 0.9478 - val_accuracy: 0.6752 - lr: 0.0032 - 14s/epoch - 585ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.67710\n",
            "24/24 - 14s - loss: 1.0227 - accuracy: 0.6477 - val_loss: 0.9404 - val_accuracy: 0.6760 - lr: 0.0032 - 14s/epoch - 585ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy improved from 0.67710 to 0.67939, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0190 - accuracy: 0.6483 - val_loss: 0.9316 - val_accuracy: 0.6794 - lr: 0.0032 - 14s/epoch - 587ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy improved from 0.67939 to 0.68015, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0232 - accuracy: 0.6503 - val_loss: 0.9354 - val_accuracy: 0.6802 - lr: 0.0032 - 14s/epoch - 587ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.68015\n",
            "24/24 - 14s - loss: 1.0222 - accuracy: 0.6518 - val_loss: 0.9321 - val_accuracy: 0.6786 - lr: 0.0032 - 14s/epoch - 587ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy improved from 0.68015 to 0.68282, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0171 - accuracy: 0.6499 - val_loss: 0.9293 - val_accuracy: 0.6828 - lr: 0.0032 - 14s/epoch - 590ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.68282\n",
            "24/24 - 14s - loss: 1.0143 - accuracy: 0.6521 - val_loss: 0.9335 - val_accuracy: 0.6821 - lr: 0.0032 - 14s/epoch - 587ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.68282\n",
            "24/24 - 14s - loss: 1.0080 - accuracy: 0.6554 - val_loss: 0.9546 - val_accuracy: 0.6519 - lr: 0.0032 - 14s/epoch - 587ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy improved from 0.68282 to 0.68626, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 1.0179 - accuracy: 0.6484 - val_loss: 0.9211 - val_accuracy: 0.6863 - lr: 0.0032 - 14s/epoch - 587ms/step\n",
            "Epoch 151/250\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.68626\n",
            "24/24 - 14s - loss: 1.0135 - accuracy: 0.6481 - val_loss: 0.9375 - val_accuracy: 0.6824 - lr: 0.0031 - 14s/epoch - 585ms/step\n",
            "Epoch 152/250\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.68626\n",
            "24/24 - 14s - loss: 1.0007 - accuracy: 0.6570 - val_loss: 0.9246 - val_accuracy: 0.6760 - lr: 0.0031 - 14s/epoch - 584ms/step\n",
            "Epoch 153/250\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.68626\n",
            "24/24 - 14s - loss: 1.0030 - accuracy: 0.6558 - val_loss: 0.9205 - val_accuracy: 0.6836 - lr: 0.0031 - 14s/epoch - 584ms/step\n",
            "Epoch 154/250\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.68626\n",
            "24/24 - 14s - loss: 1.0057 - accuracy: 0.6597 - val_loss: 0.9188 - val_accuracy: 0.6790 - lr: 0.0031 - 14s/epoch - 585ms/step\n",
            "Epoch 155/250\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.68626\n",
            "24/24 - 14s - loss: 0.9973 - accuracy: 0.6604 - val_loss: 0.9165 - val_accuracy: 0.6836 - lr: 0.0031 - 14s/epoch - 586ms/step\n",
            "Epoch 156/250\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.68626\n",
            "24/24 - 14s - loss: 1.0023 - accuracy: 0.6523 - val_loss: 0.9214 - val_accuracy: 0.6859 - lr: 0.0031 - 14s/epoch - 586ms/step\n",
            "Epoch 157/250\n",
            "\n",
            "Epoch 157: val_accuracy improved from 0.68626 to 0.69084, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9966 - accuracy: 0.6623 - val_loss: 0.9098 - val_accuracy: 0.6908 - lr: 0.0031 - 14s/epoch - 589ms/step\n",
            "Epoch 158/250\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.69084\n",
            "24/24 - 14s - loss: 0.9973 - accuracy: 0.6620 - val_loss: 0.9141 - val_accuracy: 0.6847 - lr: 0.0031 - 14s/epoch - 587ms/step\n",
            "Epoch 159/250\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.69084\n",
            "24/24 - 14s - loss: 0.9942 - accuracy: 0.6584 - val_loss: 0.9095 - val_accuracy: 0.6897 - lr: 0.0031 - 14s/epoch - 587ms/step\n",
            "Epoch 160/250\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.69084\n",
            "24/24 - 14s - loss: 0.9854 - accuracy: 0.6631 - val_loss: 0.9127 - val_accuracy: 0.6859 - lr: 0.0031 - 14s/epoch - 587ms/step\n",
            "Epoch 161/250\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.69084\n",
            "24/24 - 14s - loss: 0.9843 - accuracy: 0.6605 - val_loss: 0.9183 - val_accuracy: 0.6882 - lr: 0.0029 - 14s/epoch - 587ms/step\n",
            "Epoch 162/250\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.69084\n",
            "24/24 - 14s - loss: 0.9861 - accuracy: 0.6625 - val_loss: 0.9059 - val_accuracy: 0.6889 - lr: 0.0029 - 14s/epoch - 587ms/step\n",
            "Epoch 163/250\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.69084\n",
            "24/24 - 14s - loss: 0.9788 - accuracy: 0.6618 - val_loss: 0.8934 - val_accuracy: 0.6908 - lr: 0.0029 - 14s/epoch - 586ms/step\n",
            "Epoch 164/250\n",
            "\n",
            "Epoch 164: val_accuracy improved from 0.69084 to 0.69466, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9790 - accuracy: 0.6670 - val_loss: 0.8939 - val_accuracy: 0.6947 - lr: 0.0029 - 14s/epoch - 588ms/step\n",
            "Epoch 165/250\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.69466\n",
            "24/24 - 14s - loss: 0.9776 - accuracy: 0.6657 - val_loss: 0.9106 - val_accuracy: 0.6824 - lr: 0.0029 - 14s/epoch - 586ms/step\n",
            "Epoch 166/250\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.69466\n",
            "24/24 - 14s - loss: 0.9751 - accuracy: 0.6684 - val_loss: 0.9004 - val_accuracy: 0.6847 - lr: 0.0029 - 14s/epoch - 586ms/step\n",
            "Epoch 167/250\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.69466\n",
            "24/24 - 14s - loss: 0.9714 - accuracy: 0.6672 - val_loss: 0.8893 - val_accuracy: 0.6935 - lr: 0.0029 - 14s/epoch - 586ms/step\n",
            "Epoch 168/250\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.69466\n",
            "24/24 - 14s - loss: 0.9689 - accuracy: 0.6722 - val_loss: 0.9029 - val_accuracy: 0.6931 - lr: 0.0029 - 14s/epoch - 586ms/step\n",
            "Epoch 169/250\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.69466\n",
            "24/24 - 14s - loss: 0.9710 - accuracy: 0.6654 - val_loss: 0.8885 - val_accuracy: 0.6931 - lr: 0.0029 - 14s/epoch - 586ms/step\n",
            "Epoch 170/250\n",
            "\n",
            "Epoch 170: val_accuracy improved from 0.69466 to 0.69580, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9703 - accuracy: 0.6647 - val_loss: 0.8884 - val_accuracy: 0.6958 - lr: 0.0029 - 14s/epoch - 588ms/step\n",
            "Epoch 171/250\n",
            "\n",
            "Epoch 171: val_accuracy improved from 0.69580 to 0.69847, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9715 - accuracy: 0.6700 - val_loss: 0.8821 - val_accuracy: 0.6985 - lr: 0.0028 - 14s/epoch - 587ms/step\n",
            "Epoch 172/250\n",
            "\n",
            "Epoch 172: val_accuracy improved from 0.69847 to 0.70496, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9652 - accuracy: 0.6675 - val_loss: 0.8771 - val_accuracy: 0.7050 - lr: 0.0028 - 14s/epoch - 587ms/step\n",
            "Epoch 173/250\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.70496\n",
            "24/24 - 14s - loss: 0.9614 - accuracy: 0.6712 - val_loss: 0.8734 - val_accuracy: 0.7015 - lr: 0.0028 - 14s/epoch - 586ms/step\n",
            "Epoch 174/250\n",
            "\n",
            "Epoch 174: val_accuracy improved from 0.70496 to 0.70534, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9528 - accuracy: 0.6720 - val_loss: 0.8721 - val_accuracy: 0.7053 - lr: 0.0028 - 14s/epoch - 588ms/step\n",
            "Epoch 175/250\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.70534\n",
            "24/24 - 14s - loss: 0.9582 - accuracy: 0.6667 - val_loss: 0.8774 - val_accuracy: 0.7000 - lr: 0.0028 - 14s/epoch - 586ms/step\n",
            "Epoch 176/250\n",
            "\n",
            "Epoch 176: val_accuracy improved from 0.70534 to 0.70573, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9651 - accuracy: 0.6689 - val_loss: 0.8720 - val_accuracy: 0.7057 - lr: 0.0028 - 14s/epoch - 588ms/step\n",
            "Epoch 177/250\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.70573\n",
            "24/24 - 14s - loss: 0.9593 - accuracy: 0.6733 - val_loss: 0.8708 - val_accuracy: 0.7046 - lr: 0.0028 - 14s/epoch - 586ms/step\n",
            "Epoch 178/250\n",
            "\n",
            "Epoch 178: val_accuracy improved from 0.70573 to 0.70840, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9568 - accuracy: 0.6742 - val_loss: 0.8671 - val_accuracy: 0.7084 - lr: 0.0028 - 14s/epoch - 588ms/step\n",
            "Epoch 179/250\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.70840\n",
            "24/24 - 14s - loss: 0.9497 - accuracy: 0.6744 - val_loss: 0.8707 - val_accuracy: 0.7084 - lr: 0.0028 - 14s/epoch - 585ms/step\n",
            "Epoch 180/250\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.70840\n",
            "24/24 - 14s - loss: 0.9458 - accuracy: 0.6767 - val_loss: 0.8654 - val_accuracy: 0.7080 - lr: 0.0028 - 14s/epoch - 586ms/step\n",
            "Epoch 181/250\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.70840\n",
            "24/24 - 14s - loss: 0.9540 - accuracy: 0.6722 - val_loss: 0.8649 - val_accuracy: 0.7076 - lr: 0.0026 - 14s/epoch - 586ms/step\n",
            "Epoch 182/250\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.70840\n",
            "24/24 - 14s - loss: 0.9536 - accuracy: 0.6695 - val_loss: 0.8927 - val_accuracy: 0.6954 - lr: 0.0026 - 14s/epoch - 586ms/step\n",
            "Epoch 183/250\n",
            "\n",
            "Epoch 183: val_accuracy improved from 0.70840 to 0.71145, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9440 - accuracy: 0.6783 - val_loss: 0.8647 - val_accuracy: 0.7115 - lr: 0.0026 - 14s/epoch - 588ms/step\n",
            "Epoch 184/250\n",
            "\n",
            "Epoch 184: val_accuracy improved from 0.71145 to 0.71183, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9524 - accuracy: 0.6775 - val_loss: 0.8578 - val_accuracy: 0.7118 - lr: 0.0026 - 14s/epoch - 587ms/step\n",
            "Epoch 185/250\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.71183\n",
            "24/24 - 14s - loss: 0.9515 - accuracy: 0.6759 - val_loss: 0.8605 - val_accuracy: 0.7073 - lr: 0.0026 - 14s/epoch - 586ms/step\n",
            "Epoch 186/250\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.71183\n",
            "24/24 - 14s - loss: 0.9452 - accuracy: 0.6748 - val_loss: 0.8533 - val_accuracy: 0.7115 - lr: 0.0026 - 14s/epoch - 587ms/step\n",
            "Epoch 187/250\n",
            "\n",
            "Epoch 187: val_accuracy improved from 0.71183 to 0.71336, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9463 - accuracy: 0.6772 - val_loss: 0.8630 - val_accuracy: 0.7134 - lr: 0.0026 - 14s/epoch - 588ms/step\n",
            "Epoch 188/250\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.71336\n",
            "24/24 - 14s - loss: 0.9382 - accuracy: 0.6797 - val_loss: 0.8540 - val_accuracy: 0.7126 - lr: 0.0026 - 14s/epoch - 586ms/step\n",
            "Epoch 189/250\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.71336\n",
            "24/24 - 14s - loss: 0.9341 - accuracy: 0.6813 - val_loss: 0.8810 - val_accuracy: 0.7023 - lr: 0.0026 - 14s/epoch - 587ms/step\n",
            "Epoch 190/250\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.71336\n",
            "24/24 - 14s - loss: 0.9433 - accuracy: 0.6753 - val_loss: 0.8579 - val_accuracy: 0.7115 - lr: 0.0026 - 14s/epoch - 586ms/step\n",
            "Epoch 191/250\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.71336\n",
            "24/24 - 14s - loss: 0.9329 - accuracy: 0.6803 - val_loss: 0.8494 - val_accuracy: 0.7107 - lr: 0.0025 - 14s/epoch - 587ms/step\n",
            "Epoch 192/250\n",
            "\n",
            "Epoch 192: val_accuracy improved from 0.71336 to 0.71985, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9386 - accuracy: 0.6764 - val_loss: 0.8464 - val_accuracy: 0.7198 - lr: 0.0025 - 14s/epoch - 588ms/step\n",
            "Epoch 193/250\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.71985\n",
            "24/24 - 14s - loss: 0.9274 - accuracy: 0.6759 - val_loss: 0.8431 - val_accuracy: 0.7195 - lr: 0.0025 - 14s/epoch - 586ms/step\n",
            "Epoch 194/250\n",
            "\n",
            "Epoch 194: val_accuracy did not improve from 0.71985\n",
            "24/24 - 14s - loss: 0.9230 - accuracy: 0.6834 - val_loss: 0.8444 - val_accuracy: 0.7137 - lr: 0.0025 - 14s/epoch - 586ms/step\n",
            "Epoch 195/250\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.71985\n",
            "24/24 - 14s - loss: 0.9316 - accuracy: 0.6786 - val_loss: 0.8514 - val_accuracy: 0.7130 - lr: 0.0025 - 14s/epoch - 587ms/step\n",
            "Epoch 196/250\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.71985\n",
            "24/24 - 14s - loss: 0.9260 - accuracy: 0.6863 - val_loss: 0.8390 - val_accuracy: 0.7179 - lr: 0.0025 - 14s/epoch - 587ms/step\n",
            "Epoch 197/250\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.71985\n",
            "24/24 - 14s - loss: 0.9304 - accuracy: 0.6894 - val_loss: 0.8463 - val_accuracy: 0.7141 - lr: 0.0025 - 14s/epoch - 586ms/step\n",
            "Epoch 198/250\n",
            "\n",
            "Epoch 198: val_accuracy improved from 0.71985 to 0.72214, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9164 - accuracy: 0.6906 - val_loss: 0.8334 - val_accuracy: 0.7221 - lr: 0.0025 - 14s/epoch - 588ms/step\n",
            "Epoch 199/250\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.72214\n",
            "24/24 - 14s - loss: 0.9178 - accuracy: 0.6903 - val_loss: 0.8311 - val_accuracy: 0.7218 - lr: 0.0025 - 14s/epoch - 587ms/step\n",
            "Epoch 200/250\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.72214\n",
            "24/24 - 14s - loss: 0.9290 - accuracy: 0.6870 - val_loss: 0.8377 - val_accuracy: 0.7122 - lr: 0.0025 - 14s/epoch - 586ms/step\n",
            "Epoch 201/250\n",
            "\n",
            "Epoch 201: val_accuracy did not improve from 0.72214\n",
            "24/24 - 14s - loss: 0.9141 - accuracy: 0.6845 - val_loss: 0.8371 - val_accuracy: 0.7183 - lr: 0.0024 - 14s/epoch - 586ms/step\n",
            "Epoch 202/250\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.72214\n",
            "24/24 - 14s - loss: 0.9165 - accuracy: 0.6900 - val_loss: 0.8313 - val_accuracy: 0.7198 - lr: 0.0024 - 14s/epoch - 586ms/step\n",
            "Epoch 203/250\n",
            "\n",
            "Epoch 203: val_accuracy improved from 0.72214 to 0.73015, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9257 - accuracy: 0.6846 - val_loss: 0.8276 - val_accuracy: 0.7302 - lr: 0.0024 - 14s/epoch - 588ms/step\n",
            "Epoch 204/250\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9134 - accuracy: 0.6864 - val_loss: 0.8372 - val_accuracy: 0.7225 - lr: 0.0024 - 14s/epoch - 586ms/step\n",
            "Epoch 205/250\n",
            "\n",
            "Epoch 205: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9214 - accuracy: 0.6868 - val_loss: 0.8237 - val_accuracy: 0.7244 - lr: 0.0024 - 14s/epoch - 586ms/step\n",
            "Epoch 206/250\n",
            "\n",
            "Epoch 206: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9074 - accuracy: 0.6907 - val_loss: 0.8257 - val_accuracy: 0.7248 - lr: 0.0024 - 14s/epoch - 585ms/step\n",
            "Epoch 207/250\n",
            "\n",
            "Epoch 207: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9099 - accuracy: 0.6901 - val_loss: 0.8274 - val_accuracy: 0.7214 - lr: 0.0024 - 14s/epoch - 585ms/step\n",
            "Epoch 208/250\n",
            "\n",
            "Epoch 208: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9187 - accuracy: 0.6865 - val_loss: 0.8337 - val_accuracy: 0.7244 - lr: 0.0024 - 14s/epoch - 585ms/step\n",
            "Epoch 209/250\n",
            "\n",
            "Epoch 209: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9164 - accuracy: 0.6868 - val_loss: 0.8292 - val_accuracy: 0.7229 - lr: 0.0024 - 14s/epoch - 585ms/step\n",
            "Epoch 210/250\n",
            "\n",
            "Epoch 210: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9076 - accuracy: 0.6895 - val_loss: 0.8339 - val_accuracy: 0.7172 - lr: 0.0024 - 14s/epoch - 586ms/step\n",
            "Epoch 211/250\n",
            "\n",
            "Epoch 211: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9100 - accuracy: 0.6927 - val_loss: 0.8314 - val_accuracy: 0.7195 - lr: 0.0022 - 14s/epoch - 586ms/step\n",
            "Epoch 212/250\n",
            "\n",
            "Epoch 212: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9093 - accuracy: 0.6906 - val_loss: 0.8245 - val_accuracy: 0.7244 - lr: 0.0022 - 14s/epoch - 586ms/step\n",
            "Epoch 213/250\n",
            "\n",
            "Epoch 213: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9130 - accuracy: 0.6875 - val_loss: 0.8209 - val_accuracy: 0.7256 - lr: 0.0022 - 14s/epoch - 586ms/step\n",
            "Epoch 214/250\n",
            "\n",
            "Epoch 214: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.8980 - accuracy: 0.6947 - val_loss: 0.8154 - val_accuracy: 0.7302 - lr: 0.0022 - 14s/epoch - 586ms/step\n",
            "Epoch 215/250\n",
            "\n",
            "Epoch 215: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9025 - accuracy: 0.6941 - val_loss: 0.8155 - val_accuracy: 0.7233 - lr: 0.0022 - 14s/epoch - 586ms/step\n",
            "Epoch 216/250\n",
            "\n",
            "Epoch 216: val_accuracy did not improve from 0.73015\n",
            "24/24 - 14s - loss: 0.9019 - accuracy: 0.6934 - val_loss: 0.8155 - val_accuracy: 0.7263 - lr: 0.0022 - 14s/epoch - 586ms/step\n",
            "Epoch 217/250\n",
            "\n",
            "Epoch 217: val_accuracy improved from 0.73015 to 0.73206, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.9028 - accuracy: 0.6958 - val_loss: 0.8142 - val_accuracy: 0.7321 - lr: 0.0022 - 14s/epoch - 588ms/step\n",
            "Epoch 218/250\n",
            "\n",
            "Epoch 218: val_accuracy did not improve from 0.73206\n",
            "24/24 - 14s - loss: 0.8969 - accuracy: 0.6990 - val_loss: 0.8158 - val_accuracy: 0.7229 - lr: 0.0022 - 14s/epoch - 585ms/step\n",
            "Epoch 219/250\n",
            "\n",
            "Epoch 219: val_accuracy improved from 0.73206 to 0.73244, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.8915 - accuracy: 0.6965 - val_loss: 0.8083 - val_accuracy: 0.7324 - lr: 0.0022 - 14s/epoch - 586ms/step\n",
            "Epoch 220/250\n",
            "\n",
            "Epoch 220: val_accuracy did not improve from 0.73244\n",
            "24/24 - 14s - loss: 0.9038 - accuracy: 0.6883 - val_loss: 0.8080 - val_accuracy: 0.7317 - lr: 0.0022 - 14s/epoch - 585ms/step\n",
            "Epoch 221/250\n",
            "\n",
            "Epoch 221: val_accuracy did not improve from 0.73244\n",
            "24/24 - 14s - loss: 0.8984 - accuracy: 0.6981 - val_loss: 0.8124 - val_accuracy: 0.7324 - lr: 0.0021 - 14s/epoch - 585ms/step\n",
            "Epoch 222/250\n",
            "\n",
            "Epoch 222: val_accuracy did not improve from 0.73244\n",
            "24/24 - 14s - loss: 0.8970 - accuracy: 0.6942 - val_loss: 0.8110 - val_accuracy: 0.7275 - lr: 0.0021 - 14s/epoch - 585ms/step\n",
            "Epoch 223/250\n",
            "\n",
            "Epoch 223: val_accuracy did not improve from 0.73244\n",
            "24/24 - 14s - loss: 0.8980 - accuracy: 0.6939 - val_loss: 0.8100 - val_accuracy: 0.7317 - lr: 0.0021 - 14s/epoch - 585ms/step\n",
            "Epoch 224/250\n",
            "\n",
            "Epoch 224: val_accuracy did not improve from 0.73244\n",
            "24/24 - 14s - loss: 0.8888 - accuracy: 0.7027 - val_loss: 0.8093 - val_accuracy: 0.7302 - lr: 0.0021 - 14s/epoch - 585ms/step\n",
            "Epoch 225/250\n",
            "\n",
            "Epoch 225: val_accuracy did not improve from 0.73244\n",
            "24/24 - 14s - loss: 0.8901 - accuracy: 0.6963 - val_loss: 0.8191 - val_accuracy: 0.7302 - lr: 0.0021 - 14s/epoch - 585ms/step\n",
            "Epoch 226/250\n",
            "\n",
            "Epoch 226: val_accuracy improved from 0.73244 to 0.73931, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.8892 - accuracy: 0.6975 - val_loss: 0.8038 - val_accuracy: 0.7393 - lr: 0.0021 - 14s/epoch - 587ms/step\n",
            "Epoch 227/250\n",
            "\n",
            "Epoch 227: val_accuracy did not improve from 0.73931\n",
            "24/24 - 14s - loss: 0.8839 - accuracy: 0.7039 - val_loss: 0.8046 - val_accuracy: 0.7275 - lr: 0.0021 - 14s/epoch - 585ms/step\n",
            "Epoch 228/250\n",
            "\n",
            "Epoch 228: val_accuracy did not improve from 0.73931\n",
            "24/24 - 14s - loss: 0.8887 - accuracy: 0.6958 - val_loss: 0.8003 - val_accuracy: 0.7389 - lr: 0.0021 - 14s/epoch - 585ms/step\n",
            "Epoch 229/250\n",
            "\n",
            "Epoch 229: val_accuracy improved from 0.73931 to 0.74046, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.8927 - accuracy: 0.6967 - val_loss: 0.7990 - val_accuracy: 0.7405 - lr: 0.0021 - 14s/epoch - 587ms/step\n",
            "Epoch 230/250\n",
            "\n",
            "Epoch 230: val_accuracy improved from 0.74046 to 0.74389, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.8843 - accuracy: 0.6972 - val_loss: 0.7998 - val_accuracy: 0.7439 - lr: 0.0021 - 14s/epoch - 587ms/step\n",
            "Epoch 231/250\n",
            "\n",
            "Epoch 231: val_accuracy did not improve from 0.74389\n",
            "24/24 - 14s - loss: 0.8776 - accuracy: 0.6995 - val_loss: 0.8118 - val_accuracy: 0.7321 - lr: 0.0020 - 14s/epoch - 585ms/step\n",
            "Epoch 232/250\n",
            "\n",
            "Epoch 232: val_accuracy did not improve from 0.74389\n",
            "24/24 - 14s - loss: 0.8800 - accuracy: 0.7049 - val_loss: 0.7946 - val_accuracy: 0.7374 - lr: 0.0020 - 14s/epoch - 585ms/step\n",
            "Epoch 233/250\n",
            "\n",
            "Epoch 233: val_accuracy did not improve from 0.74389\n",
            "24/24 - 14s - loss: 0.8791 - accuracy: 0.7012 - val_loss: 0.7940 - val_accuracy: 0.7431 - lr: 0.0020 - 14s/epoch - 585ms/step\n",
            "Epoch 234/250\n",
            "\n",
            "Epoch 234: val_accuracy did not improve from 0.74389\n",
            "24/24 - 14s - loss: 0.8838 - accuracy: 0.6987 - val_loss: 0.8075 - val_accuracy: 0.7271 - lr: 0.0020 - 14s/epoch - 584ms/step\n",
            "Epoch 235/250\n",
            "\n",
            "Epoch 235: val_accuracy did not improve from 0.74389\n",
            "24/24 - 14s - loss: 0.8769 - accuracy: 0.7040 - val_loss: 0.7920 - val_accuracy: 0.7347 - lr: 0.0020 - 14s/epoch - 583ms/step\n",
            "Epoch 236/250\n",
            "\n",
            "Epoch 236: val_accuracy did not improve from 0.74389\n",
            "24/24 - 14s - loss: 0.8839 - accuracy: 0.7023 - val_loss: 0.8017 - val_accuracy: 0.7382 - lr: 0.0020 - 14s/epoch - 585ms/step\n",
            "Epoch 237/250\n",
            "\n",
            "Epoch 237: val_accuracy did not improve from 0.74389\n",
            "24/24 - 14s - loss: 0.8681 - accuracy: 0.7067 - val_loss: 0.7910 - val_accuracy: 0.7385 - lr: 0.0020 - 14s/epoch - 587ms/step\n",
            "Epoch 238/250\n",
            "\n",
            "Epoch 238: val_accuracy did not improve from 0.74389\n",
            "24/24 - 14s - loss: 0.8789 - accuracy: 0.7035 - val_loss: 0.7945 - val_accuracy: 0.7313 - lr: 0.0020 - 14s/epoch - 587ms/step\n",
            "Epoch 239/250\n",
            "\n",
            "Epoch 239: val_accuracy improved from 0.74389 to 0.74618, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.8773 - accuracy: 0.7044 - val_loss: 0.7901 - val_accuracy: 0.7462 - lr: 0.0020 - 14s/epoch - 587ms/step\n",
            "Epoch 240/250\n",
            "\n",
            "Epoch 240: val_accuracy did not improve from 0.74618\n",
            "24/24 - 14s - loss: 0.8752 - accuracy: 0.6987 - val_loss: 0.8007 - val_accuracy: 0.7336 - lr: 0.0020 - 14s/epoch - 584ms/step\n",
            "Epoch 241/250\n",
            "\n",
            "Epoch 241: val_accuracy did not improve from 0.74618\n",
            "24/24 - 14s - loss: 0.8669 - accuracy: 0.7068 - val_loss: 0.7871 - val_accuracy: 0.7450 - lr: 0.0019 - 14s/epoch - 584ms/step\n",
            "Epoch 242/250\n",
            "\n",
            "Epoch 242: val_accuracy did not improve from 0.74618\n",
            "24/24 - 14s - loss: 0.8720 - accuracy: 0.7053 - val_loss: 0.7906 - val_accuracy: 0.7412 - lr: 0.0019 - 14s/epoch - 585ms/step\n",
            "Epoch 243/250\n",
            "\n",
            "Epoch 243: val_accuracy improved from 0.74618 to 0.74885, saving model to saved_models/best_fcn.keras\n",
            "24/24 - 14s - loss: 0.8692 - accuracy: 0.7030 - val_loss: 0.7858 - val_accuracy: 0.7489 - lr: 0.0019 - 14s/epoch - 588ms/step\n",
            "Epoch 244/250\n",
            "\n",
            "Epoch 244: val_accuracy did not improve from 0.74885\n",
            "24/24 - 14s - loss: 0.8750 - accuracy: 0.7049 - val_loss: 0.7899 - val_accuracy: 0.7447 - lr: 0.0019 - 14s/epoch - 587ms/step\n",
            "Epoch 245/250\n",
            "\n",
            "Epoch 245: val_accuracy did not improve from 0.74885\n",
            "24/24 - 14s - loss: 0.8708 - accuracy: 0.7042 - val_loss: 0.7907 - val_accuracy: 0.7385 - lr: 0.0019 - 14s/epoch - 587ms/step\n",
            "Epoch 246/250\n",
            "\n",
            "Epoch 246: val_accuracy did not improve from 0.74885\n",
            "24/24 - 14s - loss: 0.8701 - accuracy: 0.7055 - val_loss: 0.7822 - val_accuracy: 0.7420 - lr: 0.0019 - 14s/epoch - 585ms/step\n",
            "Epoch 247/250\n",
            "\n",
            "Epoch 247: val_accuracy did not improve from 0.74885\n",
            "24/24 - 14s - loss: 0.8713 - accuracy: 0.7058 - val_loss: 0.7812 - val_accuracy: 0.7458 - lr: 0.0019 - 14s/epoch - 584ms/step\n",
            "Epoch 248/250\n",
            "\n",
            "Epoch 248: val_accuracy did not improve from 0.74885\n",
            "24/24 - 14s - loss: 0.8713 - accuracy: 0.7012 - val_loss: 0.7818 - val_accuracy: 0.7431 - lr: 0.0019 - 14s/epoch - 584ms/step\n",
            "Epoch 249/250\n",
            "\n",
            "Epoch 249: val_accuracy did not improve from 0.74885\n",
            "24/24 - 14s - loss: 0.8653 - accuracy: 0.7056 - val_loss: 0.7776 - val_accuracy: 0.7473 - lr: 0.0019 - 14s/epoch - 585ms/step\n",
            "Epoch 250/250\n",
            "\n",
            "Epoch 250: val_accuracy did not improve from 0.74885\n",
            "24/24 - 14s - loss: 0.8631 - accuracy: 0.7071 - val_loss: 0.7767 - val_accuracy: 0.7489 - lr: 0.0019 - 14s/epoch - 584ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 23:13:38,466] Trial 6 finished with value: 0.749 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.006591564401846902, 'batch_size': 512, 'dropout_ratio': 0.4011115383146969, 'decay': 0.9724913505951103}. Best is trial 2 with value: 0.98.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_116 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_117 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_61 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_118 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_119 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 256)               0         \n",
            " 9 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.11450, saving model to saved_models/best_fcn.keras\n",
            "764/764 - 16s - loss: 2.3811 - accuracy: 0.1058 - val_loss: 2.2602 - val_accuracy: 0.1145 - lr: 0.0108 - 16s/epoch - 21ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2620 - accuracy: 0.1086 - val_loss: 2.2598 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2610 - accuracy: 0.1109 - val_loss: 2.2604 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2606 - accuracy: 0.1168 - val_loss: 2.2603 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2605 - accuracy: 0.1158 - val_loss: 2.2596 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2611 - accuracy: 0.1108 - val_loss: 2.2600 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2608 - accuracy: 0.1126 - val_loss: 2.2597 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2607 - accuracy: 0.1111 - val_loss: 2.2605 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2609 - accuracy: 0.1106 - val_loss: 2.2601 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2610 - accuracy: 0.1124 - val_loss: 2.2604 - val_accuracy: 0.1145 - lr: 0.0108 - 14s/epoch - 18ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2604 - accuracy: 0.1138 - val_loss: 2.2605 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2610 - accuracy: 0.1100 - val_loss: 2.2613 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2605 - accuracy: 0.1153 - val_loss: 2.2596 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2609 - accuracy: 0.1111 - val_loss: 2.2603 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2605 - accuracy: 0.1155 - val_loss: 2.2597 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2608 - accuracy: 0.1148 - val_loss: 2.2603 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2610 - accuracy: 0.1140 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2604 - accuracy: 0.1081 - val_loss: 2.2608 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2605 - accuracy: 0.1108 - val_loss: 2.2601 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2605 - accuracy: 0.1156 - val_loss: 2.2599 - val_accuracy: 0.1145 - lr: 0.0103 - 14s/epoch - 18ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2609 - accuracy: 0.1072 - val_loss: 2.2592 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2604 - accuracy: 0.1140 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2600 - accuracy: 0.1161 - val_loss: 2.2605 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2603 - accuracy: 0.1119 - val_loss: 2.2639 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2604 - accuracy: 0.1157 - val_loss: 2.2611 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2606 - accuracy: 0.1180 - val_loss: 2.2590 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2606 - accuracy: 0.1152 - val_loss: 2.2615 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2611 - accuracy: 0.1135 - val_loss: 2.2593 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2607 - accuracy: 0.1154 - val_loss: 2.2591 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2608 - accuracy: 0.1149 - val_loss: 2.2599 - val_accuracy: 0.1145 - lr: 0.0098 - 14s/epoch - 18ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.11450\n",
            "764/764 - 14s - loss: 2.2603 - accuracy: 0.1141 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0093 - 14s/epoch - 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 23:20:49,387] Trial 7 finished with value: 0.115 and parameters: {'optimizer': 'Adam', 'learning_rate': 0.01081699582972256, 'batch_size': 16, 'dropout_ratio': 0.08718568566549778, 'decay': 0.9465899232038297}. Best is trial 2 with value: 0.98.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_120 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_121 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_62 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_122 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_123 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 0 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.11450, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 20s - loss: 3.5844 - accuracy: 0.1113 - val_loss: 2.2599 - val_accuracy: 0.1145 - lr: 0.0143 - 20s/epoch - 209ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2606 - accuracy: 0.1145 - val_loss: 2.2599 - val_accuracy: 0.1145 - lr: 0.0143 - 13s/epoch - 133ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2608 - accuracy: 0.1101 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0143 - 13s/epoch - 133ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2606 - accuracy: 0.1108 - val_loss: 2.2592 - val_accuracy: 0.1145 - lr: 0.0143 - 13s/epoch - 133ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2607 - accuracy: 0.1075 - val_loss: 2.2597 - val_accuracy: 0.1145 - lr: 0.0143 - 13s/epoch - 132ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2597 - accuracy: 0.1143 - val_loss: 2.2598 - val_accuracy: 0.1145 - lr: 0.0143 - 13s/epoch - 132ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2598 - accuracy: 0.1104 - val_loss: 2.2592 - val_accuracy: 0.1145 - lr: 0.0143 - 13s/epoch - 132ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2597 - accuracy: 0.1167 - val_loss: 2.2593 - val_accuracy: 0.1145 - lr: 0.0143 - 13s/epoch - 132ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2600 - accuracy: 0.1131 - val_loss: 2.2590 - val_accuracy: 0.1145 - lr: 0.0143 - 13s/epoch - 132ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2594 - accuracy: 0.1137 - val_loss: 2.2589 - val_accuracy: 0.1145 - lr: 0.0143 - 12s/epoch - 130ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2595 - accuracy: 0.1137 - val_loss: 2.2591 - val_accuracy: 0.1145 - lr: 0.0136 - 13s/epoch - 130ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2597 - accuracy: 0.1120 - val_loss: 2.2589 - val_accuracy: 0.1145 - lr: 0.0136 - 13s/epoch - 130ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.11450\n",
            "96/96 - 13s - loss: 2.2594 - accuracy: 0.1144 - val_loss: 2.2592 - val_accuracy: 0.1145 - lr: 0.0136 - 13s/epoch - 130ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2595 - accuracy: 0.1129 - val_loss: 2.2590 - val_accuracy: 0.1145 - lr: 0.0136 - 12s/epoch - 130ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2594 - accuracy: 0.1175 - val_loss: 2.2591 - val_accuracy: 0.1145 - lr: 0.0136 - 12s/epoch - 130ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2597 - accuracy: 0.1108 - val_loss: 2.2590 - val_accuracy: 0.1145 - lr: 0.0136 - 12s/epoch - 130ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2594 - accuracy: 0.1138 - val_loss: 2.2591 - val_accuracy: 0.1145 - lr: 0.0136 - 12s/epoch - 130ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2598 - accuracy: 0.1140 - val_loss: 2.2592 - val_accuracy: 0.1145 - lr: 0.0136 - 12s/epoch - 130ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2598 - accuracy: 0.1133 - val_loss: 2.2587 - val_accuracy: 0.1145 - lr: 0.0136 - 12s/epoch - 130ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2599 - accuracy: 0.1135 - val_loss: 2.2593 - val_accuracy: 0.1145 - lr: 0.0136 - 12s/epoch - 130ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2598 - accuracy: 0.1109 - val_loss: 2.2601 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2598 - accuracy: 0.1140 - val_loss: 2.2587 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2596 - accuracy: 0.1093 - val_loss: 2.2595 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2597 - accuracy: 0.1107 - val_loss: 2.2594 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2595 - accuracy: 0.1131 - val_loss: 2.2591 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2599 - accuracy: 0.1112 - val_loss: 2.2592 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2596 - accuracy: 0.1104 - val_loss: 2.2590 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2599 - accuracy: 0.1094 - val_loss: 2.2588 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2595 - accuracy: 0.1110 - val_loss: 2.2588 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2597 - accuracy: 0.1108 - val_loss: 2.2587 - val_accuracy: 0.1145 - lr: 0.0129 - 12s/epoch - 130ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.11450\n",
            "96/96 - 12s - loss: 2.2594 - accuracy: 0.1149 - val_loss: 2.2591 - val_accuracy: 0.1145 - lr: 0.0122 - 12s/epoch - 130ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 23:27:26,696] Trial 8 finished with value: 0.115 and parameters: {'optimizer': 'Adam', 'learning_rate': 0.014267294675319201, 'batch_size': 128, 'dropout_ratio': 0.21061588289585223, 'decay': 0.9941114440831943}. Best is trial 2 with value: 0.98.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_124 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_125 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_63 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_126 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_127 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 1 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.32710, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 15s - loss: 1.8741 - accuracy: 0.3217 - val_loss: 1.7838 - val_accuracy: 0.3271 - lr: 0.0364 - 15s/epoch - 80ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.32710 to 0.51832, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.5084 - accuracy: 0.4737 - val_loss: 1.4338 - val_accuracy: 0.5183 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.51832 to 0.61450, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.2969 - accuracy: 0.5529 - val_loss: 1.1110 - val_accuracy: 0.6145 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.61450 to 0.62710, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.1467 - accuracy: 0.6036 - val_loss: 1.0655 - val_accuracy: 0.6271 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.62710 to 0.67176, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.0138 - accuracy: 0.6522 - val_loss: 0.9395 - val_accuracy: 0.6718 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.67176 to 0.71718, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.9011 - accuracy: 0.6909 - val_loss: 0.8182 - val_accuracy: 0.7172 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.71718\n",
            "191/191 - 14s - loss: 0.8057 - accuracy: 0.7317 - val_loss: 0.8328 - val_accuracy: 0.7080 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.71718 to 0.78015, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.7268 - accuracy: 0.7577 - val_loss: 0.6849 - val_accuracy: 0.7802 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.78015 to 0.81718, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.6511 - accuracy: 0.7813 - val_loss: 0.5549 - val_accuracy: 0.8172 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.81718 to 0.82824, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.6151 - accuracy: 0.7930 - val_loss: 0.5076 - val_accuracy: 0.8282 - lr: 0.0364 - 14s/epoch - 74ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.82824 to 0.84237, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5589 - accuracy: 0.8168 - val_loss: 0.4868 - val_accuracy: 0.8424 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.84237 to 0.85038, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5182 - accuracy: 0.8230 - val_loss: 0.4599 - val_accuracy: 0.8504 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.85038\n",
            "191/191 - 14s - loss: 0.4692 - accuracy: 0.8406 - val_loss: 0.5611 - val_accuracy: 0.8027 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.85038 to 0.86412, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4426 - accuracy: 0.8470 - val_loss: 0.4126 - val_accuracy: 0.8641 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.86412\n",
            "191/191 - 14s - loss: 0.4150 - accuracy: 0.8586 - val_loss: 0.3899 - val_accuracy: 0.8630 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.86412 to 0.89160, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3898 - accuracy: 0.8657 - val_loss: 0.3575 - val_accuracy: 0.8916 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.89160\n",
            "191/191 - 14s - loss: 0.3664 - accuracy: 0.8734 - val_loss: 0.3358 - val_accuracy: 0.8889 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.89160\n",
            "191/191 - 14s - loss: 0.3393 - accuracy: 0.8861 - val_loss: 0.4825 - val_accuracy: 0.8344 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.89160 to 0.91374, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3272 - accuracy: 0.8899 - val_loss: 0.2840 - val_accuracy: 0.9137 - lr: 0.0345 - 14s/epoch - 73ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.91374\n",
            "191/191 - 14s - loss: 0.3031 - accuracy: 0.8946 - val_loss: 0.2960 - val_accuracy: 0.9042 - lr: 0.0345 - 14s/epoch - 72ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.91374\n",
            "191/191 - 14s - loss: 0.2722 - accuracy: 0.9072 - val_loss: 0.2905 - val_accuracy: 0.8966 - lr: 0.0328 - 14s/epoch - 72ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.91374 to 0.91718, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2695 - accuracy: 0.9091 - val_loss: 0.2569 - val_accuracy: 0.9172 - lr: 0.0328 - 14s/epoch - 73ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.91718\n",
            "191/191 - 14s - loss: 0.2446 - accuracy: 0.9157 - val_loss: 0.2861 - val_accuracy: 0.9065 - lr: 0.0328 - 14s/epoch - 72ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.91718 to 0.92137, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2366 - accuracy: 0.9177 - val_loss: 0.2365 - val_accuracy: 0.9214 - lr: 0.0328 - 14s/epoch - 73ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.92137 to 0.93473, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2268 - accuracy: 0.9231 - val_loss: 0.2129 - val_accuracy: 0.9347 - lr: 0.0328 - 14s/epoch - 73ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.93473\n",
            "191/191 - 14s - loss: 0.2100 - accuracy: 0.9293 - val_loss: 0.2189 - val_accuracy: 0.9282 - lr: 0.0328 - 14s/epoch - 72ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.93473\n",
            "191/191 - 14s - loss: 0.2243 - accuracy: 0.9258 - val_loss: 0.2183 - val_accuracy: 0.9183 - lr: 0.0328 - 14s/epoch - 72ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.93473\n",
            "191/191 - 14s - loss: 0.1910 - accuracy: 0.9355 - val_loss: 0.2463 - val_accuracy: 0.9198 - lr: 0.0328 - 14s/epoch - 72ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy improved from 0.93473 to 0.93702, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1966 - accuracy: 0.9351 - val_loss: 0.1925 - val_accuracy: 0.9370 - lr: 0.0328 - 14s/epoch - 73ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.93702\n",
            "191/191 - 14s - loss: 0.1813 - accuracy: 0.9363 - val_loss: 0.2042 - val_accuracy: 0.9317 - lr: 0.0328 - 14s/epoch - 72ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy improved from 0.93702 to 0.94008, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1601 - accuracy: 0.9472 - val_loss: 0.1808 - val_accuracy: 0.9401 - lr: 0.0312 - 14s/epoch - 73ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy improved from 0.94008 to 0.94046, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1399 - accuracy: 0.9522 - val_loss: 0.1803 - val_accuracy: 0.9405 - lr: 0.0312 - 14s/epoch - 73ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy improved from 0.94046 to 0.94198, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1454 - accuracy: 0.9517 - val_loss: 0.1833 - val_accuracy: 0.9420 - lr: 0.0312 - 14s/epoch - 72ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy improved from 0.94198 to 0.95382, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1380 - accuracy: 0.9531 - val_loss: 0.1583 - val_accuracy: 0.9538 - lr: 0.0312 - 14s/epoch - 73ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.95382\n",
            "191/191 - 14s - loss: 0.1451 - accuracy: 0.9493 - val_loss: 0.1610 - val_accuracy: 0.9439 - lr: 0.0312 - 14s/epoch - 72ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.95382\n",
            "191/191 - 14s - loss: 0.1296 - accuracy: 0.9573 - val_loss: 0.1567 - val_accuracy: 0.9519 - lr: 0.0312 - 14s/epoch - 72ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.95382\n",
            "191/191 - 14s - loss: 0.1266 - accuracy: 0.9582 - val_loss: 0.1658 - val_accuracy: 0.9439 - lr: 0.0312 - 14s/epoch - 72ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.95382\n",
            "191/191 - 14s - loss: 0.1316 - accuracy: 0.9562 - val_loss: 0.1539 - val_accuracy: 0.9473 - lr: 0.0312 - 14s/epoch - 72ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.95382\n",
            "191/191 - 14s - loss: 0.1140 - accuracy: 0.9632 - val_loss: 0.1689 - val_accuracy: 0.9458 - lr: 0.0312 - 14s/epoch - 72ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy improved from 0.95382 to 0.95573, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1172 - accuracy: 0.9621 - val_loss: 0.1420 - val_accuracy: 0.9557 - lr: 0.0312 - 14s/epoch - 72ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.95573 to 0.95611, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1072 - accuracy: 0.9648 - val_loss: 0.1463 - val_accuracy: 0.9561 - lr: 0.0296 - 14s/epoch - 72ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.95611\n",
            "191/191 - 14s - loss: 0.1041 - accuracy: 0.9661 - val_loss: 0.1471 - val_accuracy: 0.9527 - lr: 0.0296 - 14s/epoch - 72ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.95611\n",
            "191/191 - 14s - loss: 0.1140 - accuracy: 0.9636 - val_loss: 0.1502 - val_accuracy: 0.9546 - lr: 0.0296 - 14s/epoch - 73ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy improved from 0.95611 to 0.96183, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0947 - accuracy: 0.9683 - val_loss: 0.1268 - val_accuracy: 0.9618 - lr: 0.0296 - 14s/epoch - 74ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.96183\n",
            "191/191 - 14s - loss: 0.0917 - accuracy: 0.9710 - val_loss: 0.1449 - val_accuracy: 0.9580 - lr: 0.0296 - 14s/epoch - 73ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.96183\n",
            "191/191 - 14s - loss: 0.0930 - accuracy: 0.9711 - val_loss: 0.1388 - val_accuracy: 0.9573 - lr: 0.0296 - 14s/epoch - 72ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy improved from 0.96183 to 0.96374, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0939 - accuracy: 0.9694 - val_loss: 0.1329 - val_accuracy: 0.9637 - lr: 0.0296 - 14s/epoch - 72ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.96374\n",
            "191/191 - 14s - loss: 0.0893 - accuracy: 0.9705 - val_loss: 0.2231 - val_accuracy: 0.9290 - lr: 0.0296 - 14s/epoch - 72ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.96374\n",
            "191/191 - 14s - loss: 0.0926 - accuracy: 0.9692 - val_loss: 0.1200 - val_accuracy: 0.9637 - lr: 0.0296 - 14s/epoch - 72ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.96374\n",
            "191/191 - 14s - loss: 0.0801 - accuracy: 0.9750 - val_loss: 0.1311 - val_accuracy: 0.9615 - lr: 0.0296 - 14s/epoch - 72ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy improved from 0.96374 to 0.96565, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0765 - accuracy: 0.9753 - val_loss: 0.1185 - val_accuracy: 0.9656 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy improved from 0.96565 to 0.96641, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0667 - accuracy: 0.9778 - val_loss: 0.1180 - val_accuracy: 0.9664 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy improved from 0.96641 to 0.96832, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0645 - accuracy: 0.9789 - val_loss: 0.1176 - val_accuracy: 0.9683 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.96832\n",
            "191/191 - 14s - loss: 0.0778 - accuracy: 0.9767 - val_loss: 0.1225 - val_accuracy: 0.9641 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.96832\n",
            "191/191 - 14s - loss: 0.0627 - accuracy: 0.9806 - val_loss: 0.1181 - val_accuracy: 0.9637 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy improved from 0.96832 to 0.96870, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0663 - accuracy: 0.9780 - val_loss: 0.1144 - val_accuracy: 0.9687 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.96870\n",
            "191/191 - 14s - loss: 0.0748 - accuracy: 0.9752 - val_loss: 0.1446 - val_accuracy: 0.9561 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.96870\n",
            "191/191 - 14s - loss: 0.0663 - accuracy: 0.9781 - val_loss: 0.1363 - val_accuracy: 0.9630 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.96870\n",
            "191/191 - 14s - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.1254 - val_accuracy: 0.9664 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.96870\n",
            "191/191 - 14s - loss: 0.0607 - accuracy: 0.9791 - val_loss: 0.1425 - val_accuracy: 0.9615 - lr: 0.0281 - 14s/epoch - 72ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy improved from 0.96870 to 0.97405, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.0973 - val_accuracy: 0.9740 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0519 - accuracy: 0.9827 - val_loss: 0.1000 - val_accuracy: 0.9702 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0631 - accuracy: 0.9801 - val_loss: 0.1159 - val_accuracy: 0.9683 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0570 - accuracy: 0.9826 - val_loss: 0.0994 - val_accuracy: 0.9725 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0494 - accuracy: 0.9830 - val_loss: 0.1321 - val_accuracy: 0.9592 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0661 - accuracy: 0.9796 - val_loss: 0.1046 - val_accuracy: 0.9695 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0515 - accuracy: 0.9833 - val_loss: 0.1163 - val_accuracy: 0.9676 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0556 - accuracy: 0.9854 - val_loss: 0.1289 - val_accuracy: 0.9641 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.1151 - val_accuracy: 0.9691 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0445 - accuracy: 0.9852 - val_loss: 0.1211 - val_accuracy: 0.9733 - lr: 0.0267 - 14s/epoch - 72ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0433 - accuracy: 0.9863 - val_loss: 0.1176 - val_accuracy: 0.9710 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy improved from 0.97405 to 0.97595, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0451 - accuracy: 0.9849 - val_loss: 0.0949 - val_accuracy: 0.9760 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0479 - accuracy: 0.9842 - val_loss: 0.1092 - val_accuracy: 0.9702 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy improved from 0.97595 to 0.97634, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.0969 - val_accuracy: 0.9763 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.1037 - val_accuracy: 0.9744 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0365 - accuracy: 0.9881 - val_loss: 0.1163 - val_accuracy: 0.9725 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0362 - accuracy: 0.9892 - val_loss: 0.0953 - val_accuracy: 0.9748 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0427 - accuracy: 0.9865 - val_loss: 0.1034 - val_accuracy: 0.9721 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0365 - accuracy: 0.9885 - val_loss: 0.1101 - val_accuracy: 0.9737 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.1101 - val_accuracy: 0.9714 - lr: 0.0254 - 14s/epoch - 72ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0343 - accuracy: 0.9899 - val_loss: 0.1126 - val_accuracy: 0.9744 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.1170 - val_accuracy: 0.9695 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.97634\n",
            "191/191 - 14s - loss: 0.0400 - accuracy: 0.9880 - val_loss: 0.1165 - val_accuracy: 0.9729 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy improved from 0.97634 to 0.97786, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.0902 - val_accuracy: 0.9779 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.1549 - val_accuracy: 0.9599 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0524 - accuracy: 0.9848 - val_loss: 0.1054 - val_accuracy: 0.9752 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0410 - accuracy: 0.9873 - val_loss: 0.1128 - val_accuracy: 0.9683 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0393 - accuracy: 0.9886 - val_loss: 0.1267 - val_accuracy: 0.9687 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0354 - accuracy: 0.9905 - val_loss: 0.0985 - val_accuracy: 0.9767 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy improved from 0.97786 to 0.97824, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.1009 - val_accuracy: 0.9782 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0246 - accuracy: 0.9929 - val_loss: 0.1011 - val_accuracy: 0.9760 - lr: 0.0229 - 14s/epoch - 74ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.1167 - val_accuracy: 0.9721 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.1035 - val_accuracy: 0.9771 - lr: 0.0229 - 14s/epoch - 72ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.1110 - val_accuracy: 0.9740 - lr: 0.0229 - 14s/epoch - 72ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0409 - accuracy: 0.9875 - val_loss: 0.0975 - val_accuracy: 0.9748 - lr: 0.0229 - 14s/epoch - 72ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.0908 - val_accuracy: 0.9775 - lr: 0.0229 - 14s/epoch - 72ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0244 - accuracy: 0.9929 - val_loss: 0.1113 - val_accuracy: 0.9763 - lr: 0.0229 - 14s/epoch - 72ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.0998 - val_accuracy: 0.9740 - lr: 0.0229 - 14s/epoch - 72ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.1031 - val_accuracy: 0.9733 - lr: 0.0229 - 14s/epoch - 72ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy improved from 0.97824 to 0.98092, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0254 - accuracy: 0.9928 - val_loss: 0.0932 - val_accuracy: 0.9809 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.1053 - val_accuracy: 0.9760 - lr: 0.0218 - 14s/epoch - 73ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.1039 - val_accuracy: 0.9771 - lr: 0.0218 - 14s/epoch - 73ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.1350 - val_accuracy: 0.9645 - lr: 0.0218 - 14s/epoch - 72ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0899 - val_accuracy: 0.9794 - lr: 0.0218 - 14s/epoch - 72ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0977 - val_accuracy: 0.9767 - lr: 0.0218 - 14s/epoch - 72ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.1022 - val_accuracy: 0.9733 - lr: 0.0218 - 14s/epoch - 72ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.1165 - val_accuracy: 0.9748 - lr: 0.0218 - 14s/epoch - 72ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.1001 - val_accuracy: 0.9767 - lr: 0.0218 - 14s/epoch - 72ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.1037 - val_accuracy: 0.9779 - lr: 0.0218 - 14s/epoch - 72ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.1058 - val_accuracy: 0.9763 - lr: 0.0218 - 14s/epoch - 72ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.1005 - val_accuracy: 0.9779 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.0931 - val_accuracy: 0.9779 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.1029 - val_accuracy: 0.9786 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0988 - val_accuracy: 0.9794 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.0929 - val_accuracy: 0.9794 - lr: 0.0207 - 14s/epoch - 72ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0181 - accuracy: 0.9955 - val_loss: 0.1011 - val_accuracy: 0.9798 - lr: 0.0207 - 14s/epoch - 72ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0211 - accuracy: 0.9941 - val_loss: 0.0972 - val_accuracy: 0.9756 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0971 - val_accuracy: 0.9775 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.0972 - val_accuracy: 0.9767 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.0898 - val_accuracy: 0.9790 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.1062 - val_accuracy: 0.9729 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.1101 - val_accuracy: 0.9771 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0945 - val_accuracy: 0.9767 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0974 - val_accuracy: 0.9782 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0952 - val_accuracy: 0.9760 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0936 - val_accuracy: 0.9782 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.0939 - val_accuracy: 0.9790 - lr: 0.0196 - 14s/epoch - 72ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0946 - val_accuracy: 0.9786 - lr: 0.0196 - 14s/epoch - 72ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.1260 - val_accuracy: 0.9706 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.98092\n",
            "191/191 - 14s - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.0934 - val_accuracy: 0.9782 - lr: 0.0196 - 14s/epoch - 72ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-20 23:57:28,220] Trial 9 finished with value: 0.981 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.036364176649056945, 'batch_size': 64, 'dropout_ratio': 0.11153936235747122, 'decay': 0.8373294137700815}. Best is trial 9 with value: 0.981.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_128 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_129 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_64 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_130 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_131 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 2 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.26031, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 30s - loss: 2.0856 - accuracy: 0.2181 - val_loss: 1.9765 - val_accuracy: 0.2603 - lr: 0.0360 - 30s/epoch - 633ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.26031 to 0.34733, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.8853 - accuracy: 0.3263 - val_loss: 1.7550 - val_accuracy: 0.3473 - lr: 0.0360 - 14s/epoch - 293ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.34733 to 0.41107, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.7740 - accuracy: 0.3737 - val_loss: 1.6855 - val_accuracy: 0.4111 - lr: 0.0360 - 14s/epoch - 292ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.41107 to 0.45115, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.6627 - accuracy: 0.4125 - val_loss: 1.5502 - val_accuracy: 0.4511 - lr: 0.0360 - 14s/epoch - 291ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.45115 to 0.49962, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.5882 - accuracy: 0.4481 - val_loss: 1.4462 - val_accuracy: 0.4996 - lr: 0.0360 - 14s/epoch - 290ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.49962\n",
            "48/48 - 14s - loss: 1.5248 - accuracy: 0.4755 - val_loss: 1.4467 - val_accuracy: 0.4882 - lr: 0.0360 - 14s/epoch - 289ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.49962 to 0.54427, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.4669 - accuracy: 0.4995 - val_loss: 1.3177 - val_accuracy: 0.5443 - lr: 0.0360 - 14s/epoch - 289ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.54427 to 0.54618, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.4059 - accuracy: 0.5159 - val_loss: 1.2867 - val_accuracy: 0.5462 - lr: 0.0360 - 14s/epoch - 290ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.54618 to 0.58817, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.3433 - accuracy: 0.5418 - val_loss: 1.2090 - val_accuracy: 0.5882 - lr: 0.0360 - 14s/epoch - 290ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.58817 to 0.60496, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.3045 - accuracy: 0.5585 - val_loss: 1.1652 - val_accuracy: 0.6050 - lr: 0.0360 - 14s/epoch - 290ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.60496 to 0.63282, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.2500 - accuracy: 0.5739 - val_loss: 1.1054 - val_accuracy: 0.6328 - lr: 0.0342 - 14s/epoch - 290ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.63282 to 0.64695, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.2190 - accuracy: 0.5885 - val_loss: 1.0536 - val_accuracy: 0.6469 - lr: 0.0342 - 14s/epoch - 290ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.64695\n",
            "48/48 - 14s - loss: 1.1807 - accuracy: 0.5999 - val_loss: 1.1570 - val_accuracy: 0.5985 - lr: 0.0342 - 14s/epoch - 289ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.64695\n",
            "48/48 - 14s - loss: 1.1419 - accuracy: 0.6113 - val_loss: 1.0600 - val_accuracy: 0.6309 - lr: 0.0342 - 14s/epoch - 289ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.64695\n",
            "48/48 - 14s - loss: 1.1053 - accuracy: 0.6251 - val_loss: 1.0234 - val_accuracy: 0.6443 - lr: 0.0342 - 14s/epoch - 289ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.64695 to 0.66221, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.0830 - accuracy: 0.6298 - val_loss: 1.0184 - val_accuracy: 0.6622 - lr: 0.0342 - 14s/epoch - 290ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.66221 to 0.66870, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 1.0506 - accuracy: 0.6456 - val_loss: 0.9443 - val_accuracy: 0.6687 - lr: 0.0342 - 14s/epoch - 290ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.66870\n",
            "48/48 - 14s - loss: 1.0138 - accuracy: 0.6548 - val_loss: 1.1498 - val_accuracy: 0.5973 - lr: 0.0342 - 14s/epoch - 289ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.66870 to 0.71870, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.9908 - accuracy: 0.6603 - val_loss: 0.8550 - val_accuracy: 0.7187 - lr: 0.0342 - 14s/epoch - 290ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.71870 to 0.71985, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.9761 - accuracy: 0.6671 - val_loss: 0.8324 - val_accuracy: 0.7198 - lr: 0.0342 - 14s/epoch - 290ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.71985 to 0.74580, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.9356 - accuracy: 0.6844 - val_loss: 0.7842 - val_accuracy: 0.7458 - lr: 0.0325 - 14s/epoch - 290ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.74580\n",
            "48/48 - 14s - loss: 0.8996 - accuracy: 0.6994 - val_loss: 0.8133 - val_accuracy: 0.7313 - lr: 0.0325 - 14s/epoch - 289ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.74580\n",
            "48/48 - 14s - loss: 0.8750 - accuracy: 0.7057 - val_loss: 0.7859 - val_accuracy: 0.7401 - lr: 0.0325 - 14s/epoch - 288ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.74580\n",
            "48/48 - 14s - loss: 0.8794 - accuracy: 0.7030 - val_loss: 0.7937 - val_accuracy: 0.7347 - lr: 0.0325 - 14s/epoch - 288ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.74580 to 0.76260, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.8385 - accuracy: 0.7188 - val_loss: 0.7145 - val_accuracy: 0.7626 - lr: 0.0325 - 14s/epoch - 289ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.76260\n",
            "48/48 - 14s - loss: 0.8400 - accuracy: 0.7117 - val_loss: 0.8139 - val_accuracy: 0.7405 - lr: 0.0325 - 14s/epoch - 288ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.76260\n",
            "48/48 - 14s - loss: 0.8111 - accuracy: 0.7251 - val_loss: 0.7530 - val_accuracy: 0.7538 - lr: 0.0325 - 14s/epoch - 287ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.76260 to 0.77061, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.8024 - accuracy: 0.7259 - val_loss: 0.7199 - val_accuracy: 0.7706 - lr: 0.0325 - 14s/epoch - 288ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.77061\n",
            "48/48 - 14s - loss: 0.7700 - accuracy: 0.7439 - val_loss: 0.6771 - val_accuracy: 0.7695 - lr: 0.0325 - 14s/epoch - 287ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.77061 to 0.78855, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.7605 - accuracy: 0.7394 - val_loss: 0.6324 - val_accuracy: 0.7885 - lr: 0.0325 - 14s/epoch - 288ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy improved from 0.78855 to 0.81260, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.7316 - accuracy: 0.7552 - val_loss: 0.6099 - val_accuracy: 0.8126 - lr: 0.0309 - 14s/epoch - 288ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.81260\n",
            "48/48 - 14s - loss: 0.7226 - accuracy: 0.7577 - val_loss: 0.6480 - val_accuracy: 0.7885 - lr: 0.0309 - 14s/epoch - 287ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.81260\n",
            "48/48 - 14s - loss: 0.7110 - accuracy: 0.7589 - val_loss: 0.5967 - val_accuracy: 0.8118 - lr: 0.0309 - 14s/epoch - 287ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.81260\n",
            "48/48 - 14s - loss: 0.7049 - accuracy: 0.7632 - val_loss: 0.6071 - val_accuracy: 0.7985 - lr: 0.0309 - 14s/epoch - 287ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.81260 to 0.81832, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.6773 - accuracy: 0.7736 - val_loss: 0.5724 - val_accuracy: 0.8183 - lr: 0.0309 - 14s/epoch - 288ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.81832\n",
            "48/48 - 14s - loss: 0.6729 - accuracy: 0.7750 - val_loss: 0.5913 - val_accuracy: 0.8069 - lr: 0.0309 - 14s/epoch - 287ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.81832\n",
            "48/48 - 14s - loss: 0.6657 - accuracy: 0.7721 - val_loss: 0.5752 - val_accuracy: 0.8141 - lr: 0.0309 - 14s/epoch - 287ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.81832\n",
            "48/48 - 14s - loss: 0.6580 - accuracy: 0.7770 - val_loss: 0.6117 - val_accuracy: 0.7977 - lr: 0.0309 - 14s/epoch - 287ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy improved from 0.81832 to 0.82634, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.6536 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.8263 - lr: 0.0309 - 14s/epoch - 288ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.82634\n",
            "48/48 - 14s - loss: 0.6257 - accuracy: 0.7889 - val_loss: 0.5512 - val_accuracy: 0.8176 - lr: 0.0309 - 14s/epoch - 287ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.82634 to 0.83702, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.6118 - accuracy: 0.7956 - val_loss: 0.4959 - val_accuracy: 0.8370 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.83702 to 0.84351, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.5935 - accuracy: 0.7976 - val_loss: 0.5026 - val_accuracy: 0.8435 - lr: 0.0293 - 14s/epoch - 289ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.84351\n",
            "48/48 - 14s - loss: 0.5955 - accuracy: 0.7952 - val_loss: 0.4917 - val_accuracy: 0.8359 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.84351\n",
            "48/48 - 14s - loss: 0.5842 - accuracy: 0.8055 - val_loss: 0.5395 - val_accuracy: 0.8202 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.84351\n",
            "48/48 - 14s - loss: 0.5784 - accuracy: 0.8067 - val_loss: 0.4884 - val_accuracy: 0.8427 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy improved from 0.84351 to 0.86527, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.5672 - accuracy: 0.8060 - val_loss: 0.4483 - val_accuracy: 0.8653 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.86527\n",
            "48/48 - 14s - loss: 0.5601 - accuracy: 0.8123 - val_loss: 0.4647 - val_accuracy: 0.8561 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.86527\n",
            "48/48 - 14s - loss: 0.5548 - accuracy: 0.8137 - val_loss: 0.4502 - val_accuracy: 0.8595 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.86527\n",
            "48/48 - 14s - loss: 0.5508 - accuracy: 0.8154 - val_loss: 0.4865 - val_accuracy: 0.8313 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.86527\n",
            "48/48 - 14s - loss: 0.5455 - accuracy: 0.8183 - val_loss: 0.4330 - val_accuracy: 0.8561 - lr: 0.0293 - 14s/epoch - 288ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.86527\n",
            "48/48 - 14s - loss: 0.5214 - accuracy: 0.8230 - val_loss: 0.4405 - val_accuracy: 0.8603 - lr: 0.0278 - 14s/epoch - 288ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.86527\n",
            "48/48 - 14s - loss: 0.5179 - accuracy: 0.8219 - val_loss: 0.4475 - val_accuracy: 0.8534 - lr: 0.0278 - 14s/epoch - 288ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy improved from 0.86527 to 0.86603, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.5218 - accuracy: 0.8226 - val_loss: 0.4073 - val_accuracy: 0.8660 - lr: 0.0278 - 14s/epoch - 289ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy improved from 0.86603 to 0.86985, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.5009 - accuracy: 0.8273 - val_loss: 0.4206 - val_accuracy: 0.8698 - lr: 0.0278 - 14s/epoch - 288ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.86985\n",
            "48/48 - 14s - loss: 0.4884 - accuracy: 0.8349 - val_loss: 0.4187 - val_accuracy: 0.8618 - lr: 0.0278 - 14s/epoch - 287ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy improved from 0.86985 to 0.87901, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.4875 - accuracy: 0.8387 - val_loss: 0.3840 - val_accuracy: 0.8790 - lr: 0.0278 - 14s/epoch - 288ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.87901\n",
            "48/48 - 14s - loss: 0.4875 - accuracy: 0.8357 - val_loss: 0.4043 - val_accuracy: 0.8733 - lr: 0.0278 - 14s/epoch - 287ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy improved from 0.87901 to 0.88130, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.4671 - accuracy: 0.8433 - val_loss: 0.3916 - val_accuracy: 0.8813 - lr: 0.0278 - 14s/epoch - 287ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.88130\n",
            "48/48 - 14s - loss: 0.4778 - accuracy: 0.8398 - val_loss: 0.3758 - val_accuracy: 0.8798 - lr: 0.0278 - 14s/epoch - 286ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.88130\n",
            "48/48 - 14s - loss: 0.4641 - accuracy: 0.8424 - val_loss: 0.3630 - val_accuracy: 0.8794 - lr: 0.0278 - 14s/epoch - 286ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.88130\n",
            "48/48 - 14s - loss: 0.4509 - accuracy: 0.8467 - val_loss: 0.3755 - val_accuracy: 0.8763 - lr: 0.0265 - 14s/epoch - 287ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.88130\n",
            "48/48 - 14s - loss: 0.4418 - accuracy: 0.8525 - val_loss: 0.3726 - val_accuracy: 0.8771 - lr: 0.0265 - 14s/epoch - 286ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy improved from 0.88130 to 0.88664, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.4425 - accuracy: 0.8500 - val_loss: 0.3478 - val_accuracy: 0.8866 - lr: 0.0265 - 14s/epoch - 287ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy improved from 0.88664 to 0.89198, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.4456 - accuracy: 0.8471 - val_loss: 0.3261 - val_accuracy: 0.8920 - lr: 0.0265 - 14s/epoch - 287ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy improved from 0.89198 to 0.89389, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.4298 - accuracy: 0.8546 - val_loss: 0.3303 - val_accuracy: 0.8939 - lr: 0.0265 - 14s/epoch - 287ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.89389\n",
            "48/48 - 14s - loss: 0.4290 - accuracy: 0.8565 - val_loss: 0.3686 - val_accuracy: 0.8821 - lr: 0.0265 - 14s/epoch - 287ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.89389\n",
            "48/48 - 14s - loss: 0.4175 - accuracy: 0.8581 - val_loss: 0.3474 - val_accuracy: 0.8832 - lr: 0.0265 - 14s/epoch - 287ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.89389\n",
            "48/48 - 14s - loss: 0.4202 - accuracy: 0.8572 - val_loss: 0.3426 - val_accuracy: 0.8836 - lr: 0.0265 - 14s/epoch - 287ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.89389\n",
            "48/48 - 14s - loss: 0.4142 - accuracy: 0.8619 - val_loss: 0.3425 - val_accuracy: 0.8885 - lr: 0.0265 - 14s/epoch - 287ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy improved from 0.89389 to 0.89542, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.4103 - accuracy: 0.8607 - val_loss: 0.3279 - val_accuracy: 0.8954 - lr: 0.0265 - 14s/epoch - 288ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.89542\n",
            "48/48 - 14s - loss: 0.3933 - accuracy: 0.8672 - val_loss: 0.3243 - val_accuracy: 0.8954 - lr: 0.0251 - 14s/epoch - 287ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy improved from 0.89542 to 0.90115, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.3835 - accuracy: 0.8706 - val_loss: 0.3193 - val_accuracy: 0.9011 - lr: 0.0251 - 14s/epoch - 288ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.90115\n",
            "48/48 - 14s - loss: 0.3918 - accuracy: 0.8653 - val_loss: 0.3093 - val_accuracy: 0.8989 - lr: 0.0251 - 14s/epoch - 287ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy improved from 0.90115 to 0.91031, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.3909 - accuracy: 0.8671 - val_loss: 0.2933 - val_accuracy: 0.9103 - lr: 0.0251 - 14s/epoch - 288ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.91031\n",
            "48/48 - 14s - loss: 0.3768 - accuracy: 0.8714 - val_loss: 0.3103 - val_accuracy: 0.8996 - lr: 0.0251 - 14s/epoch - 287ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.91031\n",
            "48/48 - 14s - loss: 0.3779 - accuracy: 0.8710 - val_loss: 0.3388 - val_accuracy: 0.8859 - lr: 0.0251 - 14s/epoch - 287ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.91031\n",
            "48/48 - 14s - loss: 0.3760 - accuracy: 0.8718 - val_loss: 0.2935 - val_accuracy: 0.9103 - lr: 0.0251 - 14s/epoch - 287ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.91031\n",
            "48/48 - 14s - loss: 0.3650 - accuracy: 0.8748 - val_loss: 0.3073 - val_accuracy: 0.8992 - lr: 0.0251 - 14s/epoch - 287ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy improved from 0.91031 to 0.91069, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.3642 - accuracy: 0.8788 - val_loss: 0.2867 - val_accuracy: 0.9107 - lr: 0.0251 - 14s/epoch - 288ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.91069\n",
            "48/48 - 14s - loss: 0.3601 - accuracy: 0.8781 - val_loss: 0.2825 - val_accuracy: 0.9092 - lr: 0.0251 - 14s/epoch - 287ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy improved from 0.91069 to 0.91794, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.3557 - accuracy: 0.8814 - val_loss: 0.2700 - val_accuracy: 0.9179 - lr: 0.0239 - 14s/epoch - 288ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.91794\n",
            "48/48 - 14s - loss: 0.3605 - accuracy: 0.8800 - val_loss: 0.2874 - val_accuracy: 0.9053 - lr: 0.0239 - 14s/epoch - 286ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.91794\n",
            "48/48 - 14s - loss: 0.3442 - accuracy: 0.8839 - val_loss: 0.2862 - val_accuracy: 0.9115 - lr: 0.0239 - 14s/epoch - 287ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.91794\n",
            "48/48 - 14s - loss: 0.3532 - accuracy: 0.8836 - val_loss: 0.2723 - val_accuracy: 0.9145 - lr: 0.0239 - 14s/epoch - 287ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy improved from 0.91794 to 0.92023, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.3483 - accuracy: 0.8839 - val_loss: 0.2599 - val_accuracy: 0.9202 - lr: 0.0239 - 14s/epoch - 288ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy improved from 0.92023 to 0.92061, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.3352 - accuracy: 0.8848 - val_loss: 0.2609 - val_accuracy: 0.9206 - lr: 0.0239 - 14s/epoch - 288ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.92061\n",
            "48/48 - 14s - loss: 0.3416 - accuracy: 0.8833 - val_loss: 0.2600 - val_accuracy: 0.9153 - lr: 0.0239 - 14s/epoch - 286ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.92061\n",
            "48/48 - 14s - loss: 0.3402 - accuracy: 0.8860 - val_loss: 0.2601 - val_accuracy: 0.9183 - lr: 0.0239 - 14s/epoch - 287ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.92061\n",
            "48/48 - 14s - loss: 0.3285 - accuracy: 0.8887 - val_loss: 0.2513 - val_accuracy: 0.9195 - lr: 0.0239 - 14s/epoch - 287ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.92061\n",
            "48/48 - 14s - loss: 0.3333 - accuracy: 0.8886 - val_loss: 0.2613 - val_accuracy: 0.9160 - lr: 0.0239 - 14s/epoch - 287ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.92061\n",
            "48/48 - 14s - loss: 0.3217 - accuracy: 0.8930 - val_loss: 0.2749 - val_accuracy: 0.9122 - lr: 0.0227 - 14s/epoch - 287ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.92061\n",
            "48/48 - 14s - loss: 0.3188 - accuracy: 0.8900 - val_loss: 0.2567 - val_accuracy: 0.9176 - lr: 0.0227 - 14s/epoch - 286ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy improved from 0.92061 to 0.92290, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.3173 - accuracy: 0.8959 - val_loss: 0.2504 - val_accuracy: 0.9229 - lr: 0.0227 - 14s/epoch - 287ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.92290\n",
            "48/48 - 14s - loss: 0.3129 - accuracy: 0.8928 - val_loss: 0.2462 - val_accuracy: 0.9225 - lr: 0.0227 - 14s/epoch - 286ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.92290\n",
            "48/48 - 14s - loss: 0.3129 - accuracy: 0.8942 - val_loss: 0.2527 - val_accuracy: 0.9168 - lr: 0.0227 - 14s/epoch - 287ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.92290\n",
            "48/48 - 14s - loss: 0.3086 - accuracy: 0.8930 - val_loss: 0.2529 - val_accuracy: 0.9202 - lr: 0.0227 - 14s/epoch - 286ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.92290\n",
            "48/48 - 14s - loss: 0.3049 - accuracy: 0.8977 - val_loss: 0.2519 - val_accuracy: 0.9218 - lr: 0.0227 - 14s/epoch - 286ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.92290\n",
            "48/48 - 14s - loss: 0.3068 - accuracy: 0.8966 - val_loss: 0.2504 - val_accuracy: 0.9195 - lr: 0.0227 - 14s/epoch - 286ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.92290\n",
            "48/48 - 14s - loss: 0.2988 - accuracy: 0.8968 - val_loss: 0.2427 - val_accuracy: 0.9195 - lr: 0.0227 - 14s/epoch - 286ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy improved from 0.92290 to 0.92443, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2975 - accuracy: 0.9012 - val_loss: 0.2315 - val_accuracy: 0.9244 - lr: 0.0227 - 14s/epoch - 288ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy improved from 0.92443 to 0.92481, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2902 - accuracy: 0.9004 - val_loss: 0.2335 - val_accuracy: 0.9248 - lr: 0.0215 - 14s/epoch - 287ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy improved from 0.92481 to 0.93206, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2897 - accuracy: 0.9020 - val_loss: 0.2213 - val_accuracy: 0.9321 - lr: 0.0215 - 14s/epoch - 288ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2893 - accuracy: 0.9041 - val_loss: 0.2233 - val_accuracy: 0.9252 - lr: 0.0215 - 14s/epoch - 287ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2933 - accuracy: 0.8991 - val_loss: 0.2287 - val_accuracy: 0.9267 - lr: 0.0215 - 14s/epoch - 286ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2913 - accuracy: 0.9021 - val_loss: 0.2298 - val_accuracy: 0.9248 - lr: 0.0215 - 14s/epoch - 287ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2788 - accuracy: 0.9064 - val_loss: 0.2308 - val_accuracy: 0.9240 - lr: 0.0215 - 14s/epoch - 287ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2814 - accuracy: 0.9085 - val_loss: 0.2238 - val_accuracy: 0.9279 - lr: 0.0215 - 14s/epoch - 286ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2849 - accuracy: 0.9011 - val_loss: 0.2204 - val_accuracy: 0.9298 - lr: 0.0215 - 14s/epoch - 287ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2804 - accuracy: 0.9048 - val_loss: 0.2285 - val_accuracy: 0.9252 - lr: 0.0215 - 14s/epoch - 287ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2707 - accuracy: 0.9103 - val_loss: 0.2098 - val_accuracy: 0.9321 - lr: 0.0215 - 14s/epoch - 287ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.93206\n",
            "48/48 - 14s - loss: 0.2687 - accuracy: 0.9089 - val_loss: 0.2212 - val_accuracy: 0.9263 - lr: 0.0205 - 14s/epoch - 287ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy improved from 0.93206 to 0.93588, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2832 - accuracy: 0.9036 - val_loss: 0.2033 - val_accuracy: 0.9359 - lr: 0.0205 - 14s/epoch - 287ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.93588\n",
            "48/48 - 14s - loss: 0.2687 - accuracy: 0.9081 - val_loss: 0.2167 - val_accuracy: 0.9324 - lr: 0.0205 - 14s/epoch - 286ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.93588\n",
            "48/48 - 14s - loss: 0.2661 - accuracy: 0.9111 - val_loss: 0.2139 - val_accuracy: 0.9347 - lr: 0.0205 - 14s/epoch - 287ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy improved from 0.93588 to 0.93626, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2747 - accuracy: 0.9094 - val_loss: 0.2061 - val_accuracy: 0.9363 - lr: 0.0205 - 14s/epoch - 287ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.93626\n",
            "48/48 - 14s - loss: 0.2736 - accuracy: 0.9058 - val_loss: 0.2197 - val_accuracy: 0.9286 - lr: 0.0205 - 14s/epoch - 286ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.93626\n",
            "48/48 - 14s - loss: 0.2730 - accuracy: 0.9085 - val_loss: 0.2157 - val_accuracy: 0.9328 - lr: 0.0205 - 14s/epoch - 287ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.93626\n",
            "48/48 - 14s - loss: 0.2617 - accuracy: 0.9145 - val_loss: 0.2131 - val_accuracy: 0.9313 - lr: 0.0205 - 14s/epoch - 287ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.93626\n",
            "48/48 - 14s - loss: 0.2657 - accuracy: 0.9105 - val_loss: 0.2086 - val_accuracy: 0.9336 - lr: 0.0205 - 14s/epoch - 287ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.93626\n",
            "48/48 - 14s - loss: 0.2596 - accuracy: 0.9137 - val_loss: 0.2023 - val_accuracy: 0.9332 - lr: 0.0205 - 14s/epoch - 287ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.93626\n",
            "48/48 - 14s - loss: 0.2501 - accuracy: 0.9167 - val_loss: 0.1989 - val_accuracy: 0.9363 - lr: 0.0194 - 14s/epoch - 286ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy improved from 0.93626 to 0.94160, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2441 - accuracy: 0.9192 - val_loss: 0.1952 - val_accuracy: 0.9416 - lr: 0.0194 - 14s/epoch - 288ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.94160\n",
            "48/48 - 14s - loss: 0.2467 - accuracy: 0.9153 - val_loss: 0.1936 - val_accuracy: 0.9385 - lr: 0.0194 - 14s/epoch - 287ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.94160\n",
            "48/48 - 14s - loss: 0.2512 - accuracy: 0.9167 - val_loss: 0.1915 - val_accuracy: 0.9344 - lr: 0.0194 - 14s/epoch - 287ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.94160\n",
            "48/48 - 14s - loss: 0.2528 - accuracy: 0.9126 - val_loss: 0.1992 - val_accuracy: 0.9366 - lr: 0.0194 - 14s/epoch - 287ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy improved from 0.94160 to 0.94275, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2451 - accuracy: 0.9175 - val_loss: 0.1881 - val_accuracy: 0.9427 - lr: 0.0194 - 14s/epoch - 288ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.94275\n",
            "48/48 - 14s - loss: 0.2399 - accuracy: 0.9171 - val_loss: 0.1916 - val_accuracy: 0.9347 - lr: 0.0194 - 14s/epoch - 287ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.94275\n",
            "48/48 - 14s - loss: 0.2427 - accuracy: 0.9195 - val_loss: 0.2001 - val_accuracy: 0.9363 - lr: 0.0194 - 14s/epoch - 287ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.94275\n",
            "48/48 - 14s - loss: 0.2479 - accuracy: 0.9165 - val_loss: 0.2059 - val_accuracy: 0.9359 - lr: 0.0194 - 14s/epoch - 287ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.94275\n",
            "48/48 - 14s - loss: 0.2447 - accuracy: 0.9165 - val_loss: 0.1916 - val_accuracy: 0.9389 - lr: 0.0194 - 14s/epoch - 287ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.94275\n",
            "48/48 - 14s - loss: 0.2414 - accuracy: 0.9188 - val_loss: 0.1927 - val_accuracy: 0.9370 - lr: 0.0185 - 14s/epoch - 286ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.94275\n",
            "48/48 - 14s - loss: 0.2295 - accuracy: 0.9242 - val_loss: 0.1949 - val_accuracy: 0.9385 - lr: 0.0185 - 14s/epoch - 286ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.94275\n",
            "48/48 - 14s - loss: 0.2259 - accuracy: 0.9238 - val_loss: 0.1943 - val_accuracy: 0.9389 - lr: 0.0185 - 14s/epoch - 286ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy improved from 0.94275 to 0.94351, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2311 - accuracy: 0.9207 - val_loss: 0.1850 - val_accuracy: 0.9435 - lr: 0.0185 - 14s/epoch - 288ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.94351\n",
            "48/48 - 14s - loss: 0.2233 - accuracy: 0.9247 - val_loss: 0.1810 - val_accuracy: 0.9424 - lr: 0.0185 - 14s/epoch - 287ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.94351\n",
            "48/48 - 14s - loss: 0.2246 - accuracy: 0.9245 - val_loss: 0.1884 - val_accuracy: 0.9412 - lr: 0.0185 - 14s/epoch - 286ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.94351\n",
            "48/48 - 14s - loss: 0.2261 - accuracy: 0.9211 - val_loss: 0.1777 - val_accuracy: 0.9431 - lr: 0.0185 - 14s/epoch - 286ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.94351\n",
            "48/48 - 14s - loss: 0.2252 - accuracy: 0.9238 - val_loss: 0.1905 - val_accuracy: 0.9351 - lr: 0.0185 - 14s/epoch - 286ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.94351\n",
            "48/48 - 14s - loss: 0.2153 - accuracy: 0.9273 - val_loss: 0.1711 - val_accuracy: 0.9431 - lr: 0.0185 - 14s/epoch - 287ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.94351\n",
            "48/48 - 14s - loss: 0.2175 - accuracy: 0.9283 - val_loss: 0.1852 - val_accuracy: 0.9389 - lr: 0.0185 - 14s/epoch - 287ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.94351\n",
            "48/48 - 14s - loss: 0.2233 - accuracy: 0.9247 - val_loss: 0.1797 - val_accuracy: 0.9431 - lr: 0.0176 - 14s/epoch - 286ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.94351\n",
            "48/48 - 14s - loss: 0.2177 - accuracy: 0.9268 - val_loss: 0.1830 - val_accuracy: 0.9405 - lr: 0.0176 - 14s/epoch - 286ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy improved from 0.94351 to 0.94427, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2220 - accuracy: 0.9248 - val_loss: 0.1773 - val_accuracy: 0.9443 - lr: 0.0176 - 14s/epoch - 287ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.94427\n",
            "48/48 - 14s - loss: 0.2228 - accuracy: 0.9245 - val_loss: 0.1774 - val_accuracy: 0.9439 - lr: 0.0176 - 14s/epoch - 287ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy improved from 0.94427 to 0.94618, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2161 - accuracy: 0.9269 - val_loss: 0.1758 - val_accuracy: 0.9462 - lr: 0.0176 - 14s/epoch - 287ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.94618\n",
            "48/48 - 14s - loss: 0.2153 - accuracy: 0.9269 - val_loss: 0.1800 - val_accuracy: 0.9431 - lr: 0.0176 - 14s/epoch - 287ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.94618\n",
            "48/48 - 14s - loss: 0.2116 - accuracy: 0.9302 - val_loss: 0.1807 - val_accuracy: 0.9416 - lr: 0.0176 - 14s/epoch - 287ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.94618\n",
            "48/48 - 14s - loss: 0.2132 - accuracy: 0.9278 - val_loss: 0.1837 - val_accuracy: 0.9389 - lr: 0.0176 - 14s/epoch - 287ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy improved from 0.94618 to 0.94809, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2129 - accuracy: 0.9283 - val_loss: 0.1677 - val_accuracy: 0.9481 - lr: 0.0176 - 14s/epoch - 288ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.94809\n",
            "48/48 - 14s - loss: 0.2030 - accuracy: 0.9305 - val_loss: 0.1714 - val_accuracy: 0.9450 - lr: 0.0176 - 14s/epoch - 287ms/step\n",
            "Epoch 151/250\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.94809\n",
            "48/48 - 14s - loss: 0.1990 - accuracy: 0.9335 - val_loss: 0.1680 - val_accuracy: 0.9450 - lr: 0.0167 - 14s/epoch - 287ms/step\n",
            "Epoch 152/250\n",
            "\n",
            "Epoch 152: val_accuracy improved from 0.94809 to 0.94885, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2017 - accuracy: 0.9319 - val_loss: 0.1612 - val_accuracy: 0.9489 - lr: 0.0167 - 14s/epoch - 288ms/step\n",
            "Epoch 153/250\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.94885\n",
            "48/48 - 14s - loss: 0.2037 - accuracy: 0.9323 - val_loss: 0.1656 - val_accuracy: 0.9473 - lr: 0.0167 - 14s/epoch - 286ms/step\n",
            "Epoch 154/250\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.94885\n",
            "48/48 - 14s - loss: 0.1994 - accuracy: 0.9320 - val_loss: 0.1680 - val_accuracy: 0.9481 - lr: 0.0167 - 14s/epoch - 286ms/step\n",
            "Epoch 155/250\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.94885\n",
            "48/48 - 14s - loss: 0.1972 - accuracy: 0.9330 - val_loss: 0.1687 - val_accuracy: 0.9462 - lr: 0.0167 - 14s/epoch - 285ms/step\n",
            "Epoch 156/250\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.94885\n",
            "48/48 - 14s - loss: 0.2043 - accuracy: 0.9323 - val_loss: 0.1641 - val_accuracy: 0.9462 - lr: 0.0167 - 14s/epoch - 284ms/step\n",
            "Epoch 157/250\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.94885\n",
            "48/48 - 14s - loss: 0.1954 - accuracy: 0.9344 - val_loss: 0.1589 - val_accuracy: 0.9485 - lr: 0.0167 - 14s/epoch - 283ms/step\n",
            "Epoch 158/250\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.94885\n",
            "48/48 - 14s - loss: 0.1997 - accuracy: 0.9323 - val_loss: 0.1635 - val_accuracy: 0.9458 - lr: 0.0167 - 14s/epoch - 282ms/step\n",
            "Epoch 159/250\n",
            "\n",
            "Epoch 159: val_accuracy improved from 0.94885 to 0.95000, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.2032 - accuracy: 0.9316 - val_loss: 0.1611 - val_accuracy: 0.9500 - lr: 0.0167 - 14s/epoch - 282ms/step\n",
            "Epoch 160/250\n",
            "\n",
            "Epoch 160: val_accuracy improved from 0.95000 to 0.95153, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.1971 - accuracy: 0.9344 - val_loss: 0.1558 - val_accuracy: 0.9515 - lr: 0.0167 - 14s/epoch - 282ms/step\n",
            "Epoch 161/250\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.95153\n",
            "48/48 - 13s - loss: 0.1925 - accuracy: 0.9358 - val_loss: 0.1576 - val_accuracy: 0.9508 - lr: 0.0158 - 13s/epoch - 281ms/step\n",
            "Epoch 162/250\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.95153\n",
            "48/48 - 13s - loss: 0.2014 - accuracy: 0.9305 - val_loss: 0.1557 - val_accuracy: 0.9485 - lr: 0.0158 - 13s/epoch - 281ms/step\n",
            "Epoch 163/250\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.95153\n",
            "48/48 - 14s - loss: 0.1982 - accuracy: 0.9333 - val_loss: 0.1558 - val_accuracy: 0.9496 - lr: 0.0158 - 14s/epoch - 284ms/step\n",
            "Epoch 164/250\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.95153\n",
            "48/48 - 14s - loss: 0.1969 - accuracy: 0.9344 - val_loss: 0.1569 - val_accuracy: 0.9500 - lr: 0.0158 - 14s/epoch - 290ms/step\n",
            "Epoch 165/250\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.95153\n",
            "48/48 - 14s - loss: 0.1851 - accuracy: 0.9377 - val_loss: 0.1555 - val_accuracy: 0.9481 - lr: 0.0158 - 14s/epoch - 291ms/step\n",
            "Epoch 166/250\n",
            "\n",
            "Epoch 166: val_accuracy improved from 0.95153 to 0.95229, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.1831 - accuracy: 0.9382 - val_loss: 0.1506 - val_accuracy: 0.9523 - lr: 0.0158 - 14s/epoch - 288ms/step\n",
            "Epoch 167/250\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.95229\n",
            "48/48 - 14s - loss: 0.1864 - accuracy: 0.9375 - val_loss: 0.1520 - val_accuracy: 0.9519 - lr: 0.0158 - 14s/epoch - 286ms/step\n",
            "Epoch 168/250\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.95229\n",
            "48/48 - 14s - loss: 0.1944 - accuracy: 0.9321 - val_loss: 0.1554 - val_accuracy: 0.9508 - lr: 0.0158 - 14s/epoch - 286ms/step\n",
            "Epoch 169/250\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.95229\n",
            "48/48 - 14s - loss: 0.1924 - accuracy: 0.9361 - val_loss: 0.1570 - val_accuracy: 0.9473 - lr: 0.0158 - 14s/epoch - 286ms/step\n",
            "Epoch 170/250\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.95229\n",
            "48/48 - 14s - loss: 0.1899 - accuracy: 0.9368 - val_loss: 0.1544 - val_accuracy: 0.9519 - lr: 0.0158 - 14s/epoch - 287ms/step\n",
            "Epoch 171/250\n",
            "\n",
            "Epoch 171: val_accuracy improved from 0.95229 to 0.95267, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.1889 - accuracy: 0.9355 - val_loss: 0.1482 - val_accuracy: 0.9527 - lr: 0.0150 - 14s/epoch - 288ms/step\n",
            "Epoch 172/250\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.95267\n",
            "48/48 - 14s - loss: 0.1829 - accuracy: 0.9399 - val_loss: 0.1562 - val_accuracy: 0.9485 - lr: 0.0150 - 14s/epoch - 287ms/step\n",
            "Epoch 173/250\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.95267\n",
            "48/48 - 14s - loss: 0.1814 - accuracy: 0.9376 - val_loss: 0.1570 - val_accuracy: 0.9485 - lr: 0.0150 - 14s/epoch - 287ms/step\n",
            "Epoch 174/250\n",
            "\n",
            "Epoch 174: val_accuracy did not improve from 0.95267\n",
            "48/48 - 14s - loss: 0.1827 - accuracy: 0.9386 - val_loss: 0.1524 - val_accuracy: 0.9515 - lr: 0.0150 - 14s/epoch - 287ms/step\n",
            "Epoch 175/250\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.95267\n",
            "48/48 - 14s - loss: 0.1804 - accuracy: 0.9398 - val_loss: 0.1460 - val_accuracy: 0.9523 - lr: 0.0150 - 14s/epoch - 286ms/step\n",
            "Epoch 176/250\n",
            "\n",
            "Epoch 176: val_accuracy improved from 0.95267 to 0.95305, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.1859 - accuracy: 0.9400 - val_loss: 0.1511 - val_accuracy: 0.9531 - lr: 0.0150 - 14s/epoch - 287ms/step\n",
            "Epoch 177/250\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.95305\n",
            "48/48 - 14s - loss: 0.1861 - accuracy: 0.9349 - val_loss: 0.1518 - val_accuracy: 0.9523 - lr: 0.0150 - 14s/epoch - 286ms/step\n",
            "Epoch 178/250\n",
            "\n",
            "Epoch 178: val_accuracy improved from 0.95305 to 0.95420, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.1808 - accuracy: 0.9387 - val_loss: 0.1475 - val_accuracy: 0.9542 - lr: 0.0150 - 14s/epoch - 287ms/step\n",
            "Epoch 179/250\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.95420\n",
            "48/48 - 14s - loss: 0.1897 - accuracy: 0.9342 - val_loss: 0.1494 - val_accuracy: 0.9538 - lr: 0.0150 - 14s/epoch - 286ms/step\n",
            "Epoch 180/250\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.95420\n",
            "48/48 - 14s - loss: 0.1805 - accuracy: 0.9380 - val_loss: 0.1486 - val_accuracy: 0.9531 - lr: 0.0150 - 14s/epoch - 287ms/step\n",
            "Epoch 181/250\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.95420\n",
            "48/48 - 14s - loss: 0.1832 - accuracy: 0.9383 - val_loss: 0.1484 - val_accuracy: 0.9515 - lr: 0.0143 - 14s/epoch - 287ms/step\n",
            "Epoch 182/250\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.95420\n",
            "48/48 - 14s - loss: 0.1780 - accuracy: 0.9409 - val_loss: 0.1500 - val_accuracy: 0.9508 - lr: 0.0143 - 14s/epoch - 287ms/step\n",
            "Epoch 183/250\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.95420\n",
            "48/48 - 14s - loss: 0.1726 - accuracy: 0.9417 - val_loss: 0.1509 - val_accuracy: 0.9538 - lr: 0.0143 - 14s/epoch - 287ms/step\n",
            "Epoch 184/250\n",
            "\n",
            "Epoch 184: val_accuracy improved from 0.95420 to 0.95534, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.1711 - accuracy: 0.9418 - val_loss: 0.1477 - val_accuracy: 0.9553 - lr: 0.0143 - 14s/epoch - 288ms/step\n",
            "Epoch 185/250\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1732 - accuracy: 0.9413 - val_loss: 0.1437 - val_accuracy: 0.9550 - lr: 0.0143 - 14s/epoch - 286ms/step\n",
            "Epoch 186/250\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1767 - accuracy: 0.9400 - val_loss: 0.1516 - val_accuracy: 0.9515 - lr: 0.0143 - 14s/epoch - 286ms/step\n",
            "Epoch 187/250\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1746 - accuracy: 0.9422 - val_loss: 0.1459 - val_accuracy: 0.9553 - lr: 0.0143 - 14s/epoch - 286ms/step\n",
            "Epoch 188/250\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1755 - accuracy: 0.9409 - val_loss: 0.1462 - val_accuracy: 0.9553 - lr: 0.0143 - 14s/epoch - 287ms/step\n",
            "Epoch 189/250\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1747 - accuracy: 0.9399 - val_loss: 0.1459 - val_accuracy: 0.9538 - lr: 0.0143 - 14s/epoch - 286ms/step\n",
            "Epoch 190/250\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1678 - accuracy: 0.9446 - val_loss: 0.1546 - val_accuracy: 0.9473 - lr: 0.0143 - 14s/epoch - 286ms/step\n",
            "Epoch 191/250\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1656 - accuracy: 0.9451 - val_loss: 0.1406 - val_accuracy: 0.9550 - lr: 0.0136 - 14s/epoch - 285ms/step\n",
            "Epoch 192/250\n",
            "\n",
            "Epoch 192: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1683 - accuracy: 0.9436 - val_loss: 0.1442 - val_accuracy: 0.9553 - lr: 0.0136 - 14s/epoch - 284ms/step\n",
            "Epoch 193/250\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.95534\n",
            "48/48 - 14s - loss: 0.1755 - accuracy: 0.9404 - val_loss: 0.1510 - val_accuracy: 0.9542 - lr: 0.0136 - 14s/epoch - 283ms/step\n",
            "Epoch 194/250\n",
            "\n",
            "Epoch 194: val_accuracy improved from 0.95534 to 0.95763, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.1679 - accuracy: 0.9435 - val_loss: 0.1392 - val_accuracy: 0.9576 - lr: 0.0136 - 14s/epoch - 283ms/step\n",
            "Epoch 195/250\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.95763\n",
            "48/48 - 14s - loss: 0.1655 - accuracy: 0.9433 - val_loss: 0.1443 - val_accuracy: 0.9557 - lr: 0.0136 - 14s/epoch - 282ms/step\n",
            "Epoch 196/250\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.95763\n",
            "48/48 - 14s - loss: 0.1594 - accuracy: 0.9481 - val_loss: 0.1418 - val_accuracy: 0.9557 - lr: 0.0136 - 14s/epoch - 282ms/step\n",
            "Epoch 197/250\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.95763\n",
            "48/48 - 14s - loss: 0.1644 - accuracy: 0.9467 - val_loss: 0.1398 - val_accuracy: 0.9553 - lr: 0.0136 - 14s/epoch - 282ms/step\n",
            "Epoch 198/250\n",
            "\n",
            "Epoch 198: val_accuracy did not improve from 0.95763\n",
            "48/48 - 14s - loss: 0.1618 - accuracy: 0.9449 - val_loss: 0.1351 - val_accuracy: 0.9557 - lr: 0.0136 - 14s/epoch - 282ms/step\n",
            "Epoch 199/250\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.95763\n",
            "48/48 - 14s - loss: 0.1645 - accuracy: 0.9454 - val_loss: 0.1515 - val_accuracy: 0.9508 - lr: 0.0136 - 14s/epoch - 282ms/step\n",
            "Epoch 200/250\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.95763\n",
            "48/48 - 14s - loss: 0.1604 - accuracy: 0.9470 - val_loss: 0.1386 - val_accuracy: 0.9553 - lr: 0.0136 - 14s/epoch - 281ms/step\n",
            "Epoch 201/250\n",
            "\n",
            "Epoch 201: val_accuracy improved from 0.95763 to 0.95840, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 14s - loss: 0.1606 - accuracy: 0.9448 - val_loss: 0.1355 - val_accuracy: 0.9584 - lr: 0.0129 - 14s/epoch - 282ms/step\n",
            "Epoch 202/250\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.95840\n",
            "48/48 - 13s - loss: 0.1571 - accuracy: 0.9464 - val_loss: 0.1398 - val_accuracy: 0.9576 - lr: 0.0129 - 13s/epoch - 281ms/step\n",
            "Epoch 203/250\n",
            "\n",
            "Epoch 203: val_accuracy did not improve from 0.95840\n",
            "48/48 - 13s - loss: 0.1630 - accuracy: 0.9467 - val_loss: 0.1330 - val_accuracy: 0.9580 - lr: 0.0129 - 13s/epoch - 280ms/step\n",
            "Epoch 204/250\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.95840\n",
            "48/48 - 13s - loss: 0.1609 - accuracy: 0.9469 - val_loss: 0.1339 - val_accuracy: 0.9580 - lr: 0.0129 - 13s/epoch - 280ms/step\n",
            "Epoch 205/250\n",
            "\n",
            "Epoch 205: val_accuracy did not improve from 0.95840\n",
            "48/48 - 13s - loss: 0.1540 - accuracy: 0.9469 - val_loss: 0.1382 - val_accuracy: 0.9550 - lr: 0.0129 - 13s/epoch - 280ms/step\n",
            "Epoch 206/250\n",
            "\n",
            "Epoch 206: val_accuracy improved from 0.95840 to 0.95916, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 13s - loss: 0.1508 - accuracy: 0.9484 - val_loss: 0.1333 - val_accuracy: 0.9592 - lr: 0.0129 - 13s/epoch - 281ms/step\n",
            "Epoch 207/250\n",
            "\n",
            "Epoch 207: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1567 - accuracy: 0.9463 - val_loss: 0.1373 - val_accuracy: 0.9550 - lr: 0.0129 - 13s/epoch - 280ms/step\n",
            "Epoch 208/250\n",
            "\n",
            "Epoch 208: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1568 - accuracy: 0.9463 - val_loss: 0.1335 - val_accuracy: 0.9576 - lr: 0.0129 - 13s/epoch - 280ms/step\n",
            "Epoch 209/250\n",
            "\n",
            "Epoch 209: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1582 - accuracy: 0.9466 - val_loss: 0.1378 - val_accuracy: 0.9565 - lr: 0.0129 - 13s/epoch - 279ms/step\n",
            "Epoch 210/250\n",
            "\n",
            "Epoch 210: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1617 - accuracy: 0.9464 - val_loss: 0.1354 - val_accuracy: 0.9561 - lr: 0.0129 - 13s/epoch - 280ms/step\n",
            "Epoch 211/250\n",
            "\n",
            "Epoch 211: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1540 - accuracy: 0.9488 - val_loss: 0.1308 - val_accuracy: 0.9588 - lr: 0.0123 - 13s/epoch - 280ms/step\n",
            "Epoch 212/250\n",
            "\n",
            "Epoch 212: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1515 - accuracy: 0.9490 - val_loss: 0.1352 - val_accuracy: 0.9569 - lr: 0.0123 - 13s/epoch - 279ms/step\n",
            "Epoch 213/250\n",
            "\n",
            "Epoch 213: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1586 - accuracy: 0.9464 - val_loss: 0.1373 - val_accuracy: 0.9569 - lr: 0.0123 - 13s/epoch - 279ms/step\n",
            "Epoch 214/250\n",
            "\n",
            "Epoch 214: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1537 - accuracy: 0.9495 - val_loss: 0.1336 - val_accuracy: 0.9542 - lr: 0.0123 - 13s/epoch - 279ms/step\n",
            "Epoch 215/250\n",
            "\n",
            "Epoch 215: val_accuracy did not improve from 0.95916\n",
            "48/48 - 13s - loss: 0.1540 - accuracy: 0.9472 - val_loss: 0.1262 - val_accuracy: 0.9573 - lr: 0.0123 - 13s/epoch - 279ms/step\n",
            "Epoch 216/250\n",
            "\n",
            "Epoch 216: val_accuracy improved from 0.95916 to 0.96107, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 13s - loss: 0.1480 - accuracy: 0.9493 - val_loss: 0.1253 - val_accuracy: 0.9611 - lr: 0.0123 - 13s/epoch - 280ms/step\n",
            "Epoch 217/250\n",
            "\n",
            "Epoch 217: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1514 - accuracy: 0.9503 - val_loss: 0.1256 - val_accuracy: 0.9584 - lr: 0.0123 - 13s/epoch - 279ms/step\n",
            "Epoch 218/250\n",
            "\n",
            "Epoch 218: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1514 - accuracy: 0.9488 - val_loss: 0.1319 - val_accuracy: 0.9569 - lr: 0.0123 - 13s/epoch - 279ms/step\n",
            "Epoch 219/250\n",
            "\n",
            "Epoch 219: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1459 - accuracy: 0.9494 - val_loss: 0.1286 - val_accuracy: 0.9546 - lr: 0.0123 - 13s/epoch - 279ms/step\n",
            "Epoch 220/250\n",
            "\n",
            "Epoch 220: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1458 - accuracy: 0.9523 - val_loss: 0.1295 - val_accuracy: 0.9580 - lr: 0.0123 - 13s/epoch - 279ms/step\n",
            "Epoch 221/250\n",
            "\n",
            "Epoch 221: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1423 - accuracy: 0.9530 - val_loss: 0.1263 - val_accuracy: 0.9595 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 222/250\n",
            "\n",
            "Epoch 222: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1445 - accuracy: 0.9526 - val_loss: 0.1342 - val_accuracy: 0.9546 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 223/250\n",
            "\n",
            "Epoch 223: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1478 - accuracy: 0.9520 - val_loss: 0.1242 - val_accuracy: 0.9611 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 224/250\n",
            "\n",
            "Epoch 224: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1480 - accuracy: 0.9505 - val_loss: 0.1336 - val_accuracy: 0.9588 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 225/250\n",
            "\n",
            "Epoch 225: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1535 - accuracy: 0.9488 - val_loss: 0.1232 - val_accuracy: 0.9595 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 226/250\n",
            "\n",
            "Epoch 226: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1426 - accuracy: 0.9514 - val_loss: 0.1284 - val_accuracy: 0.9576 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 227/250\n",
            "\n",
            "Epoch 227: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1477 - accuracy: 0.9499 - val_loss: 0.1347 - val_accuracy: 0.9599 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 228/250\n",
            "\n",
            "Epoch 228: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1454 - accuracy: 0.9510 - val_loss: 0.1266 - val_accuracy: 0.9607 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 229/250\n",
            "\n",
            "Epoch 229: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1449 - accuracy: 0.9522 - val_loss: 0.1233 - val_accuracy: 0.9607 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 230/250\n",
            "\n",
            "Epoch 230: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1473 - accuracy: 0.9499 - val_loss: 0.1294 - val_accuracy: 0.9592 - lr: 0.0116 - 13s/epoch - 279ms/step\n",
            "Epoch 231/250\n",
            "\n",
            "Epoch 231: val_accuracy did not improve from 0.96107\n",
            "48/48 - 13s - loss: 0.1438 - accuracy: 0.9513 - val_loss: 0.1246 - val_accuracy: 0.9603 - lr: 0.0111 - 13s/epoch - 279ms/step\n",
            "Epoch 232/250\n",
            "\n",
            "Epoch 232: val_accuracy improved from 0.96107 to 0.96221, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 13s - loss: 0.1407 - accuracy: 0.9517 - val_loss: 0.1340 - val_accuracy: 0.9622 - lr: 0.0111 - 13s/epoch - 280ms/step\n",
            "Epoch 233/250\n",
            "\n",
            "Epoch 233: val_accuracy did not improve from 0.96221\n",
            "48/48 - 13s - loss: 0.1397 - accuracy: 0.9530 - val_loss: 0.1258 - val_accuracy: 0.9603 - lr: 0.0111 - 13s/epoch - 279ms/step\n",
            "Epoch 234/250\n",
            "\n",
            "Epoch 234: val_accuracy improved from 0.96221 to 0.96298, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 13s - loss: 0.1417 - accuracy: 0.9530 - val_loss: 0.1253 - val_accuracy: 0.9630 - lr: 0.0111 - 13s/epoch - 280ms/step\n",
            "Epoch 235/250\n",
            "\n",
            "Epoch 235: val_accuracy did not improve from 0.96298\n",
            "48/48 - 13s - loss: 0.1385 - accuracy: 0.9548 - val_loss: 0.1253 - val_accuracy: 0.9595 - lr: 0.0111 - 13s/epoch - 279ms/step\n",
            "Epoch 236/250\n",
            "\n",
            "Epoch 236: val_accuracy did not improve from 0.96298\n",
            "48/48 - 13s - loss: 0.1390 - accuracy: 0.9551 - val_loss: 0.1273 - val_accuracy: 0.9584 - lr: 0.0111 - 13s/epoch - 279ms/step\n",
            "Epoch 237/250\n",
            "\n",
            "Epoch 237: val_accuracy did not improve from 0.96298\n",
            "48/48 - 13s - loss: 0.1412 - accuracy: 0.9537 - val_loss: 0.1253 - val_accuracy: 0.9580 - lr: 0.0111 - 13s/epoch - 279ms/step\n",
            "Epoch 238/250\n",
            "\n",
            "Epoch 238: val_accuracy did not improve from 0.96298\n",
            "48/48 - 13s - loss: 0.1433 - accuracy: 0.9509 - val_loss: 0.1211 - val_accuracy: 0.9607 - lr: 0.0111 - 13s/epoch - 279ms/step\n",
            "Epoch 239/250\n",
            "\n",
            "Epoch 239: val_accuracy improved from 0.96298 to 0.96412, saving model to saved_models/best_fcn.keras\n",
            "48/48 - 13s - loss: 0.1379 - accuracy: 0.9540 - val_loss: 0.1185 - val_accuracy: 0.9641 - lr: 0.0111 - 13s/epoch - 280ms/step\n",
            "Epoch 240/250\n",
            "\n",
            "Epoch 240: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1419 - accuracy: 0.9521 - val_loss: 0.1210 - val_accuracy: 0.9618 - lr: 0.0111 - 13s/epoch - 279ms/step\n",
            "Epoch 241/250\n",
            "\n",
            "Epoch 241: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1361 - accuracy: 0.9536 - val_loss: 0.1214 - val_accuracy: 0.9615 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 242/250\n",
            "\n",
            "Epoch 242: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1393 - accuracy: 0.9535 - val_loss: 0.1193 - val_accuracy: 0.9607 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 243/250\n",
            "\n",
            "Epoch 243: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1353 - accuracy: 0.9549 - val_loss: 0.1236 - val_accuracy: 0.9603 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 244/250\n",
            "\n",
            "Epoch 244: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1374 - accuracy: 0.9530 - val_loss: 0.1259 - val_accuracy: 0.9599 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 245/250\n",
            "\n",
            "Epoch 245: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1344 - accuracy: 0.9539 - val_loss: 0.1228 - val_accuracy: 0.9607 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 246/250\n",
            "\n",
            "Epoch 246: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1375 - accuracy: 0.9540 - val_loss: 0.1180 - val_accuracy: 0.9637 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 247/250\n",
            "\n",
            "Epoch 247: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1291 - accuracy: 0.9589 - val_loss: 0.1192 - val_accuracy: 0.9611 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 248/250\n",
            "\n",
            "Epoch 248: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1369 - accuracy: 0.9530 - val_loss: 0.1225 - val_accuracy: 0.9607 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 249/250\n",
            "\n",
            "Epoch 249: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1333 - accuracy: 0.9554 - val_loss: 0.1210 - val_accuracy: 0.9622 - lr: 0.0105 - 13s/epoch - 279ms/step\n",
            "Epoch 250/250\n",
            "\n",
            "Epoch 250: val_accuracy did not improve from 0.96412\n",
            "48/48 - 13s - loss: 0.1386 - accuracy: 0.9528 - val_loss: 0.1181 - val_accuracy: 0.9630 - lr: 0.0105 - 13s/epoch - 279ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 00:54:52,522] Trial 10 finished with value: 0.964 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.035987932603557635, 'batch_size': 256, 'dropout_ratio': 0.47224877240316343, 'decay': 0.8254526842699865}. Best is trial 9 with value: 0.981.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_132 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_133 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_65 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_134 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_135 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 3 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.39313, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 16s - loss: 1.8519 - accuracy: 0.3352 - val_loss: 1.6718 - val_accuracy: 0.3931 - lr: 0.0493 - 16s/epoch - 83ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.39313 to 0.53092, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.4692 - accuracy: 0.4845 - val_loss: 1.3438 - val_accuracy: 0.5309 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.53092 to 0.63053, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.2578 - accuracy: 0.5731 - val_loss: 1.1045 - val_accuracy: 0.6305 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.63053\n",
            "191/191 - 14s - loss: 1.0567 - accuracy: 0.6407 - val_loss: 1.0362 - val_accuracy: 0.6256 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.63053 to 0.73015, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.9270 - accuracy: 0.6869 - val_loss: 0.8314 - val_accuracy: 0.7302 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.73015 to 0.74733, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.8329 - accuracy: 0.7218 - val_loss: 0.7424 - val_accuracy: 0.7473 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.74733 to 0.75802, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.7424 - accuracy: 0.7503 - val_loss: 0.6992 - val_accuracy: 0.7580 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.75802 to 0.77595, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.6570 - accuracy: 0.7762 - val_loss: 0.6702 - val_accuracy: 0.7760 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.77595 to 0.83511, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.6078 - accuracy: 0.7947 - val_loss: 0.5125 - val_accuracy: 0.8351 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.83511\n",
            "191/191 - 14s - loss: 0.5491 - accuracy: 0.8134 - val_loss: 0.5056 - val_accuracy: 0.8252 - lr: 0.0493 - 14s/epoch - 72ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.83511 to 0.86489, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4898 - accuracy: 0.8361 - val_loss: 0.4143 - val_accuracy: 0.8649 - lr: 0.0469 - 14s/epoch - 72ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.86489 to 0.86947, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4645 - accuracy: 0.8441 - val_loss: 0.4011 - val_accuracy: 0.8695 - lr: 0.0469 - 14s/epoch - 72ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.86947\n",
            "191/191 - 14s - loss: 0.4232 - accuracy: 0.8559 - val_loss: 0.3958 - val_accuracy: 0.8641 - lr: 0.0469 - 14s/epoch - 72ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.86947 to 0.88244, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3783 - accuracy: 0.8712 - val_loss: 0.3469 - val_accuracy: 0.8824 - lr: 0.0469 - 14s/epoch - 74ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.88244 to 0.88855, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3623 - accuracy: 0.8756 - val_loss: 0.3291 - val_accuracy: 0.8885 - lr: 0.0469 - 14s/epoch - 75ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.88855 to 0.89008, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3476 - accuracy: 0.8788 - val_loss: 0.3330 - val_accuracy: 0.8901 - lr: 0.0469 - 14s/epoch - 74ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.89008 to 0.90725, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3094 - accuracy: 0.8945 - val_loss: 0.2925 - val_accuracy: 0.9073 - lr: 0.0469 - 14s/epoch - 73ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.90725 to 0.91489, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3222 - accuracy: 0.8909 - val_loss: 0.2613 - val_accuracy: 0.9149 - lr: 0.0469 - 14s/epoch - 73ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.91489\n",
            "191/191 - 14s - loss: 0.2760 - accuracy: 0.9063 - val_loss: 0.2936 - val_accuracy: 0.9061 - lr: 0.0469 - 14s/epoch - 73ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.91489 to 0.91641, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2468 - accuracy: 0.9139 - val_loss: 0.2543 - val_accuracy: 0.9164 - lr: 0.0469 - 14s/epoch - 74ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.91641 to 0.92443, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2315 - accuracy: 0.9196 - val_loss: 0.2339 - val_accuracy: 0.9244 - lr: 0.0445 - 14s/epoch - 74ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.92443 to 0.93931, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2218 - accuracy: 0.9238 - val_loss: 0.1978 - val_accuracy: 0.9393 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.93931\n",
            "191/191 - 14s - loss: 0.2248 - accuracy: 0.9261 - val_loss: 0.1979 - val_accuracy: 0.9363 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.93931\n",
            "191/191 - 14s - loss: 0.2072 - accuracy: 0.9298 - val_loss: 0.3121 - val_accuracy: 0.9031 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.93931\n",
            "191/191 - 14s - loss: 0.1997 - accuracy: 0.9339 - val_loss: 0.2005 - val_accuracy: 0.9340 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.93931\n",
            "191/191 - 14s - loss: 0.1808 - accuracy: 0.9410 - val_loss: 0.1824 - val_accuracy: 0.9385 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.93931\n",
            "191/191 - 14s - loss: 0.1801 - accuracy: 0.9382 - val_loss: 0.2207 - val_accuracy: 0.9267 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.93931 to 0.94542, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1715 - accuracy: 0.9407 - val_loss: 0.1784 - val_accuracy: 0.9454 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.94542\n",
            "191/191 - 14s - loss: 0.1562 - accuracy: 0.9472 - val_loss: 0.1785 - val_accuracy: 0.9443 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.94542 to 0.94695, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1514 - accuracy: 0.9482 - val_loss: 0.1794 - val_accuracy: 0.9469 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.94695\n",
            "191/191 - 14s - loss: 0.1394 - accuracy: 0.9534 - val_loss: 0.1904 - val_accuracy: 0.9363 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy improved from 0.94695 to 0.95229, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1275 - accuracy: 0.9569 - val_loss: 0.1631 - val_accuracy: 0.9523 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.95229\n",
            "191/191 - 14s - loss: 0.1353 - accuracy: 0.9521 - val_loss: 0.1800 - val_accuracy: 0.9473 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.95229\n",
            "191/191 - 14s - loss: 0.1192 - accuracy: 0.9588 - val_loss: 0.1495 - val_accuracy: 0.9511 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.95229\n",
            "191/191 - 14s - loss: 0.1200 - accuracy: 0.9614 - val_loss: 0.1738 - val_accuracy: 0.9454 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy improved from 0.95229 to 0.95878, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1219 - accuracy: 0.9595 - val_loss: 0.1403 - val_accuracy: 0.9588 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.95878\n",
            "191/191 - 14s - loss: 0.1546 - accuracy: 0.9563 - val_loss: 0.2137 - val_accuracy: 0.9393 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy improved from 0.95878 to 0.96069, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1328 - accuracy: 0.9555 - val_loss: 0.1320 - val_accuracy: 0.9607 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.96069\n",
            "191/191 - 14s - loss: 0.0995 - accuracy: 0.9666 - val_loss: 0.1896 - val_accuracy: 0.9443 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.96069\n",
            "191/191 - 14s - loss: 0.0923 - accuracy: 0.9692 - val_loss: 0.1653 - val_accuracy: 0.9531 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.96069 to 0.96336, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0874 - accuracy: 0.9720 - val_loss: 0.1389 - val_accuracy: 0.9634 - lr: 0.0402 - 14s/epoch - 72ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.96336 to 0.96412, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0932 - accuracy: 0.9701 - val_loss: 0.1379 - val_accuracy: 0.9641 - lr: 0.0402 - 14s/epoch - 72ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.96412\n",
            "191/191 - 14s - loss: 0.0723 - accuracy: 0.9761 - val_loss: 0.1566 - val_accuracy: 0.9550 - lr: 0.0402 - 14s/epoch - 71ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.96412\n",
            "191/191 - 14s - loss: 0.0853 - accuracy: 0.9715 - val_loss: 0.1644 - val_accuracy: 0.9450 - lr: 0.0402 - 14s/epoch - 71ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.96412\n",
            "191/191 - 14s - loss: 0.0850 - accuracy: 0.9740 - val_loss: 0.1695 - val_accuracy: 0.9504 - lr: 0.0402 - 14s/epoch - 71ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy improved from 0.96412 to 0.96641, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0774 - accuracy: 0.9752 - val_loss: 0.1274 - val_accuracy: 0.9664 - lr: 0.0402 - 14s/epoch - 71ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.96641\n",
            "191/191 - 14s - loss: 0.0822 - accuracy: 0.9732 - val_loss: 0.1391 - val_accuracy: 0.9576 - lr: 0.0402 - 14s/epoch - 71ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.96641\n",
            "191/191 - 14s - loss: 0.0984 - accuracy: 0.9700 - val_loss: 0.1287 - val_accuracy: 0.9630 - lr: 0.0402 - 14s/epoch - 71ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.96641\n",
            "191/191 - 14s - loss: 0.0731 - accuracy: 0.9759 - val_loss: 0.2274 - val_accuracy: 0.9309 - lr: 0.0402 - 14s/epoch - 71ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.96641\n",
            "191/191 - 14s - loss: 0.0678 - accuracy: 0.9792 - val_loss: 0.1302 - val_accuracy: 0.9615 - lr: 0.0402 - 14s/epoch - 71ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.96641\n",
            "191/191 - 14s - loss: 0.0716 - accuracy: 0.9775 - val_loss: 0.1247 - val_accuracy: 0.9664 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy improved from 0.96641 to 0.97061, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0659 - accuracy: 0.9795 - val_loss: 0.1155 - val_accuracy: 0.9706 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0644 - accuracy: 0.9777 - val_loss: 0.1092 - val_accuracy: 0.9698 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0618 - accuracy: 0.9813 - val_loss: 0.1030 - val_accuracy: 0.9706 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0522 - accuracy: 0.9837 - val_loss: 0.1249 - val_accuracy: 0.9634 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0512 - accuracy: 0.9839 - val_loss: 0.1244 - val_accuracy: 0.9618 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0453 - accuracy: 0.9854 - val_loss: 0.1169 - val_accuracy: 0.9698 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0494 - accuracy: 0.9846 - val_loss: 0.1365 - val_accuracy: 0.9611 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0532 - accuracy: 0.9834 - val_loss: 0.1223 - val_accuracy: 0.9679 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.1258 - val_accuracy: 0.9706 - lr: 0.0382 - 14s/epoch - 71ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0710 - accuracy: 0.9783 - val_loss: 0.1106 - val_accuracy: 0.9683 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0571 - accuracy: 0.9826 - val_loss: 0.1346 - val_accuracy: 0.9683 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy improved from 0.97061 to 0.97366, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0411 - accuracy: 0.9867 - val_loss: 0.1031 - val_accuracy: 0.9737 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0484 - accuracy: 0.9862 - val_loss: 0.1311 - val_accuracy: 0.9668 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0760 - accuracy: 0.9763 - val_loss: 0.1588 - val_accuracy: 0.9603 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.0990 - val_accuracy: 0.9729 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0461 - accuracy: 0.9845 - val_loss: 0.1463 - val_accuracy: 0.9584 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.1254 - val_accuracy: 0.9698 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.1431 - val_accuracy: 0.9603 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0640 - accuracy: 0.9813 - val_loss: 0.1077 - val_accuracy: 0.9710 - lr: 0.0363 - 14s/epoch - 71ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0407 - accuracy: 0.9881 - val_loss: 0.1141 - val_accuracy: 0.9729 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0396 - accuracy: 0.9871 - val_loss: 0.1029 - val_accuracy: 0.9729 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.1053 - val_accuracy: 0.9733 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.97366\n",
            "191/191 - 14s - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.1008 - val_accuracy: 0.9737 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy improved from 0.97366 to 0.97519, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.0960 - val_accuracy: 0.9752 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy improved from 0.97519 to 0.97557, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.1005 - val_accuracy: 0.9756 - lr: 0.0345 - 14s/epoch - 72ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.97557\n",
            "191/191 - 14s - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.1183 - val_accuracy: 0.9702 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.97557\n",
            "191/191 - 14s - loss: 0.0319 - accuracy: 0.9908 - val_loss: 0.1094 - val_accuracy: 0.9737 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.97557\n",
            "191/191 - 14s - loss: 0.0759 - accuracy: 0.9813 - val_loss: 0.1120 - val_accuracy: 0.9679 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.97557\n",
            "191/191 - 14s - loss: 0.0612 - accuracy: 0.9816 - val_loss: 0.0980 - val_accuracy: 0.9729 - lr: 0.0345 - 14s/epoch - 71ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.97557\n",
            "191/191 - 14s - loss: 0.0379 - accuracy: 0.9876 - val_loss: 0.1044 - val_accuracy: 0.9733 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.97557\n",
            "191/191 - 14s - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.1018 - val_accuracy: 0.9737 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy improved from 0.97557 to 0.97710, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.0982 - val_accuracy: 0.9771 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.97710\n",
            "191/191 - 14s - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.1069 - val_accuracy: 0.9752 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.97710\n",
            "191/191 - 14s - loss: 0.0261 - accuracy: 0.9925 - val_loss: 0.1178 - val_accuracy: 0.9698 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.97710\n",
            "191/191 - 14s - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.1052 - val_accuracy: 0.9767 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy improved from 0.97710 to 0.97748, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0949 - val_accuracy: 0.9775 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy improved from 0.97748 to 0.97824, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.0921 - val_accuracy: 0.9782 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.1100 - val_accuracy: 0.9733 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.1181 - val_accuracy: 0.9729 - lr: 0.0327 - 14s/epoch - 71ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.1062 - val_accuracy: 0.9729 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.1040 - val_accuracy: 0.9737 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.1074 - val_accuracy: 0.9782 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.0978 - val_accuracy: 0.9771 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.1061 - val_accuracy: 0.9767 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.1182 - val_accuracy: 0.9748 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.1201 - val_accuracy: 0.9733 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.1051 - val_accuracy: 0.9767 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.1140 - val_accuracy: 0.9767 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0311 - accuracy: 0.9908 - val_loss: 0.1103 - val_accuracy: 0.9767 - lr: 0.0311 - 14s/epoch - 71ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.1030 - val_accuracy: 0.9775 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.1062 - val_accuracy: 0.9740 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.1130 - val_accuracy: 0.9760 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.1052 - val_accuracy: 0.9748 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.1012 - val_accuracy: 0.9740 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0987 - val_accuracy: 0.9779 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy improved from 0.97824 to 0.97939, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.1072 - val_accuracy: 0.9794 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.1054 - val_accuracy: 0.9760 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.1035 - val_accuracy: 0.9786 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.1039 - val_accuracy: 0.9752 - lr: 0.0295 - 14s/epoch - 71ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.1150 - val_accuracy: 0.9718 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.0975 - val_accuracy: 0.9763 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.1019 - val_accuracy: 0.9779 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.1103 - val_accuracy: 0.9771 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.1239 - val_accuracy: 0.9729 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.1190 - val_accuracy: 0.9794 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.1001 - val_accuracy: 0.9771 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.1078 - val_accuracy: 0.9771 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.97939\n",
            "191/191 - 14s - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.1153 - val_accuracy: 0.9763 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy improved from 0.97939 to 0.98053, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.1093 - val_accuracy: 0.9805 - lr: 0.0281 - 14s/epoch - 71ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0963 - val_accuracy: 0.9756 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0956 - val_accuracy: 0.9767 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0966 - val_accuracy: 0.9775 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.1010 - val_accuracy: 0.9771 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0951 - val_accuracy: 0.9771 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.0989 - val_accuracy: 0.9767 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.1018 - val_accuracy: 0.9779 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.1040 - val_accuracy: 0.9779 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.1034 - val_accuracy: 0.9786 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1022 - val_accuracy: 0.9763 - lr: 0.0267 - 14s/epoch - 71ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1035 - val_accuracy: 0.9786 - lr: 0.0253 - 14s/epoch - 71ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.1073 - val_accuracy: 0.9767 - lr: 0.0253 - 14s/epoch - 71ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1100 - val_accuracy: 0.9775 - lr: 0.0253 - 14s/epoch - 71ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.1199 - val_accuracy: 0.9729 - lr: 0.0253 - 14s/epoch - 71ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.1128 - val_accuracy: 0.9771 - lr: 0.0253 - 14s/epoch - 71ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.1019 - val_accuracy: 0.9786 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.1118 - val_accuracy: 0.9790 - lr: 0.0253 - 14s/epoch - 74ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.1092 - val_accuracy: 0.9767 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.1087 - val_accuracy: 0.9775 - lr: 0.0253 - 14s/epoch - 72ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1074 - val_accuracy: 0.9763 - lr: 0.0253 - 14s/epoch - 72ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.1144 - val_accuracy: 0.9767 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.1205 - val_accuracy: 0.9760 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.1144 - val_accuracy: 0.9771 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.1049 - val_accuracy: 0.9775 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.1036 - val_accuracy: 0.9775 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1092 - val_accuracy: 0.9786 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.1091 - val_accuracy: 0.9767 - lr: 0.0241 - 14s/epoch - 72ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.1107 - val_accuracy: 0.9767 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0994 - val_accuracy: 0.9798 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.98053\n",
            "191/191 - 14s - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.1238 - val_accuracy: 0.9714 - lr: 0.0241 - 14s/epoch - 73ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 01:29:08,054] Trial 11 finished with value: 0.981 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.04933917537856793, 'batch_size': 64, 'dropout_ratio': 0.1159855290918494, 'decay': 0.8011384502349994}. Best is trial 9 with value: 0.981.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_136 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_137 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_66 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_138 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_139 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 4 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.39580, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 15s - loss: 1.8429 - accuracy: 0.3339 - val_loss: 1.7877 - val_accuracy: 0.3958 - lr: 0.0493 - 15s/epoch - 79ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.39580 to 0.55954, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.4835 - accuracy: 0.4827 - val_loss: 1.2836 - val_accuracy: 0.5595 - lr: 0.0493 - 14s/epoch - 74ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.55954 to 0.63511, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.2732 - accuracy: 0.5626 - val_loss: 1.0765 - val_accuracy: 0.6351 - lr: 0.0493 - 14s/epoch - 74ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.63511 to 0.68588, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.1178 - accuracy: 0.6190 - val_loss: 0.9292 - val_accuracy: 0.6859 - lr: 0.0493 - 14s/epoch - 74ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.68588 to 0.73244, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.9586 - accuracy: 0.6686 - val_loss: 0.7868 - val_accuracy: 0.7324 - lr: 0.0493 - 14s/epoch - 74ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.73244\n",
            "191/191 - 14s - loss: 0.8531 - accuracy: 0.7093 - val_loss: 0.7926 - val_accuracy: 0.7290 - lr: 0.0493 - 14s/epoch - 73ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.73244 to 0.78397, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.7665 - accuracy: 0.7389 - val_loss: 0.6527 - val_accuracy: 0.7840 - lr: 0.0493 - 14s/epoch - 73ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.78397\n",
            "191/191 - 14s - loss: 0.6839 - accuracy: 0.7671 - val_loss: 0.6331 - val_accuracy: 0.7817 - lr: 0.0493 - 14s/epoch - 73ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.78397 to 0.82137, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.6375 - accuracy: 0.7826 - val_loss: 0.5259 - val_accuracy: 0.8214 - lr: 0.0493 - 14s/epoch - 73ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.82137\n",
            "191/191 - 14s - loss: 0.5664 - accuracy: 0.8087 - val_loss: 0.5706 - val_accuracy: 0.8126 - lr: 0.0493 - 14s/epoch - 73ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.82137 to 0.82977, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5075 - accuracy: 0.8297 - val_loss: 0.4882 - val_accuracy: 0.8298 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.82977 to 0.85725, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4748 - accuracy: 0.8394 - val_loss: 0.4381 - val_accuracy: 0.8573 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.85725 to 0.86794, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4311 - accuracy: 0.8542 - val_loss: 0.3926 - val_accuracy: 0.8679 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.86794 to 0.87710, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4157 - accuracy: 0.8615 - val_loss: 0.3705 - val_accuracy: 0.8771 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.87710\n",
            "191/191 - 14s - loss: 0.3749 - accuracy: 0.8741 - val_loss: 0.4279 - val_accuracy: 0.8641 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.87710 to 0.89046, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3598 - accuracy: 0.8784 - val_loss: 0.3359 - val_accuracy: 0.8905 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.89046 to 0.89313, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3320 - accuracy: 0.8862 - val_loss: 0.3096 - val_accuracy: 0.8931 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.89313\n",
            "191/191 - 14s - loss: 0.3100 - accuracy: 0.8927 - val_loss: 0.3795 - val_accuracy: 0.8782 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.89313\n",
            "191/191 - 14s - loss: 0.2816 - accuracy: 0.9039 - val_loss: 0.3009 - val_accuracy: 0.8905 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.89313 to 0.89504, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2682 - accuracy: 0.9097 - val_loss: 0.3195 - val_accuracy: 0.8950 - lr: 0.0468 - 14s/epoch - 73ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.89504 to 0.92252, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2462 - accuracy: 0.9170 - val_loss: 0.2352 - val_accuracy: 0.9225 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.92252\n",
            "191/191 - 14s - loss: 0.2344 - accuracy: 0.9200 - val_loss: 0.2509 - val_accuracy: 0.9134 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.92252 to 0.92290, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2340 - accuracy: 0.9197 - val_loss: 0.2447 - val_accuracy: 0.9229 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.92290 to 0.92557, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1999 - accuracy: 0.9301 - val_loss: 0.2189 - val_accuracy: 0.9256 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.92557 to 0.93244, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2089 - accuracy: 0.9312 - val_loss: 0.2255 - val_accuracy: 0.9324 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.93244\n",
            "191/191 - 14s - loss: 0.1925 - accuracy: 0.9355 - val_loss: 0.2105 - val_accuracy: 0.9290 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.93244 to 0.94618, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1736 - accuracy: 0.9413 - val_loss: 0.1695 - val_accuracy: 0.9462 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.94618\n",
            "191/191 - 14s - loss: 0.1613 - accuracy: 0.9451 - val_loss: 0.1724 - val_accuracy: 0.9458 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.94618\n",
            "191/191 - 14s - loss: 0.1666 - accuracy: 0.9440 - val_loss: 0.2017 - val_accuracy: 0.9351 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.94618\n",
            "191/191 - 14s - loss: 0.1583 - accuracy: 0.9461 - val_loss: 0.2148 - val_accuracy: 0.9351 - lr: 0.0445 - 14s/epoch - 73ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy improved from 0.94618 to 0.94885, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1428 - accuracy: 0.9524 - val_loss: 0.1638 - val_accuracy: 0.9489 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.94885\n",
            "191/191 - 14s - loss: 0.1321 - accuracy: 0.9547 - val_loss: 0.1563 - val_accuracy: 0.9477 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy improved from 0.94885 to 0.95534, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1351 - accuracy: 0.9533 - val_loss: 0.1453 - val_accuracy: 0.9553 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.95534\n",
            "191/191 - 14s - loss: 0.1390 - accuracy: 0.9535 - val_loss: 0.1742 - val_accuracy: 0.9458 - lr: 0.0423 - 14s/epoch - 72ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.95534 to 0.95611, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1188 - accuracy: 0.9616 - val_loss: 0.1371 - val_accuracy: 0.9561 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy improved from 0.95611 to 0.95763, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1211 - accuracy: 0.9625 - val_loss: 0.1302 - val_accuracy: 0.9576 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.95763\n",
            "191/191 - 14s - loss: 0.1074 - accuracy: 0.9670 - val_loss: 0.1662 - val_accuracy: 0.9500 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.95763\n",
            "191/191 - 14s - loss: 0.1159 - accuracy: 0.9620 - val_loss: 0.1377 - val_accuracy: 0.9519 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.95763\n",
            "191/191 - 14s - loss: 0.1371 - accuracy: 0.9577 - val_loss: 0.1728 - val_accuracy: 0.9447 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.95763\n",
            "191/191 - 14s - loss: 0.1095 - accuracy: 0.9630 - val_loss: 0.1451 - val_accuracy: 0.9550 - lr: 0.0423 - 14s/epoch - 73ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.95763\n",
            "191/191 - 14s - loss: 0.0871 - accuracy: 0.9717 - val_loss: 0.1559 - val_accuracy: 0.9557 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.95763 to 0.96145, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0951 - accuracy: 0.9674 - val_loss: 0.1267 - val_accuracy: 0.9615 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy improved from 0.96145 to 0.96450, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0783 - accuracy: 0.9757 - val_loss: 0.1195 - val_accuracy: 0.9645 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.96450\n",
            "191/191 - 14s - loss: 0.1213 - accuracy: 0.9614 - val_loss: 0.1842 - val_accuracy: 0.9458 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.96450\n",
            "191/191 - 14s - loss: 0.0936 - accuracy: 0.9696 - val_loss: 0.1423 - val_accuracy: 0.9550 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.96450\n",
            "191/191 - 14s - loss: 0.0790 - accuracy: 0.9739 - val_loss: 0.1455 - val_accuracy: 0.9584 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.96450\n",
            "191/191 - 14s - loss: 0.0778 - accuracy: 0.9763 - val_loss: 0.1398 - val_accuracy: 0.9595 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy improved from 0.96450 to 0.96947, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0754 - accuracy: 0.9749 - val_loss: 0.1113 - val_accuracy: 0.9695 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0805 - accuracy: 0.9730 - val_loss: 0.1378 - val_accuracy: 0.9622 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.1012 - accuracy: 0.9672 - val_loss: 0.1312 - val_accuracy: 0.9615 - lr: 0.0401 - 14s/epoch - 73ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0769 - accuracy: 0.9744 - val_loss: 0.1317 - val_accuracy: 0.9626 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy improved from 0.96947 to 0.97405, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0650 - accuracy: 0.9772 - val_loss: 0.1068 - val_accuracy: 0.9740 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0641 - accuracy: 0.9785 - val_loss: 0.1351 - val_accuracy: 0.9599 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0614 - accuracy: 0.9795 - val_loss: 0.1222 - val_accuracy: 0.9637 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0672 - accuracy: 0.9785 - val_loss: 0.1827 - val_accuracy: 0.9519 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0680 - accuracy: 0.9782 - val_loss: 0.1032 - val_accuracy: 0.9718 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0553 - accuracy: 0.9818 - val_loss: 0.1122 - val_accuracy: 0.9710 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0469 - accuracy: 0.9849 - val_loss: 0.1146 - val_accuracy: 0.9672 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.1157 - val_accuracy: 0.9676 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0517 - accuracy: 0.9837 - val_loss: 0.1212 - val_accuracy: 0.9691 - lr: 0.0381 - 14s/epoch - 73ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy improved from 0.97405 to 0.97443, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0431 - accuracy: 0.9871 - val_loss: 0.0984 - val_accuracy: 0.9744 - lr: 0.0362 - 14s/epoch - 73ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.97443\n",
            "191/191 - 14s - loss: 0.0496 - accuracy: 0.9838 - val_loss: 0.1099 - val_accuracy: 0.9691 - lr: 0.0362 - 14s/epoch - 73ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.97443\n",
            "191/191 - 14s - loss: 0.0525 - accuracy: 0.9829 - val_loss: 0.1308 - val_accuracy: 0.9710 - lr: 0.0362 - 14s/epoch - 73ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.97443\n",
            "191/191 - 14s - loss: 0.0396 - accuracy: 0.9879 - val_loss: 0.1133 - val_accuracy: 0.9721 - lr: 0.0362 - 14s/epoch - 73ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy improved from 0.97443 to 0.97672, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0422 - accuracy: 0.9867 - val_loss: 0.0979 - val_accuracy: 0.9767 - lr: 0.0362 - 14s/epoch - 73ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.97672\n",
            "191/191 - 14s - loss: 0.0434 - accuracy: 0.9869 - val_loss: 0.0943 - val_accuracy: 0.9721 - lr: 0.0362 - 14s/epoch - 73ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.97672\n",
            "191/191 - 14s - loss: 0.0500 - accuracy: 0.9837 - val_loss: 0.1005 - val_accuracy: 0.9721 - lr: 0.0362 - 14s/epoch - 73ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.97672\n",
            "191/191 - 14s - loss: 0.0507 - accuracy: 0.9846 - val_loss: 0.1136 - val_accuracy: 0.9695 - lr: 0.0362 - 14s/epoch - 73ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.97672\n",
            "191/191 - 14s - loss: 0.0494 - accuracy: 0.9837 - val_loss: 0.1083 - val_accuracy: 0.9763 - lr: 0.0362 - 14s/epoch - 72ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.97672\n",
            "191/191 - 14s - loss: 0.0550 - accuracy: 0.9841 - val_loss: 0.1120 - val_accuracy: 0.9718 - lr: 0.0362 - 14s/epoch - 72ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.97672\n",
            "191/191 - 14s - loss: 0.0348 - accuracy: 0.9896 - val_loss: 0.1032 - val_accuracy: 0.9748 - lr: 0.0344 - 14s/epoch - 73ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy improved from 0.97672 to 0.97748, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.0953 - val_accuracy: 0.9775 - lr: 0.0344 - 14s/epoch - 73ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0386 - accuracy: 0.9869 - val_loss: 0.1117 - val_accuracy: 0.9706 - lr: 0.0344 - 14s/epoch - 73ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0375 - accuracy: 0.9896 - val_loss: 0.1062 - val_accuracy: 0.9721 - lr: 0.0344 - 14s/epoch - 73ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0434 - accuracy: 0.9876 - val_loss: 0.1045 - val_accuracy: 0.9756 - lr: 0.0344 - 14s/epoch - 73ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.4139 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0344 - 13s/epoch - 69ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0344 - 13s/epoch - 66ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0344 - 13s/epoch - 66ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0344 - 13s/epoch - 66ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0344 - 13s/epoch - 67ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 67ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0327 - 13s/epoch - 66ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 67ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0311 - 13s/epoch - 66ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0295 - 13s/epoch - 67ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.97748\n",
            "191/191 - 13s - loss: nan - accuracy: 0.1145 - val_loss: nan - val_accuracy: 0.1145 - lr: 0.0295 - 13s/epoch - 66ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 01:52:17,526] Trial 12 finished with value: 0.977 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.04929052422144646, 'batch_size': 64, 'dropout_ratio': 0.12638908122105894, 'decay': 0.8512726832031003}. Best is trial 9 with value: 0.981.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_140 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_141 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_67 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_142 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_143 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 5 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.41832, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 15s - loss: 1.8596 - accuracy: 0.3305 - val_loss: 1.6042 - val_accuracy: 0.4183 - lr: 0.0404 - 15s/epoch - 79ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.41832 to 0.55534, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.5099 - accuracy: 0.4670 - val_loss: 1.2935 - val_accuracy: 0.5553 - lr: 0.0404 - 14s/epoch - 74ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.55534 to 0.60458, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.3344 - accuracy: 0.5438 - val_loss: 1.1752 - val_accuracy: 0.6046 - lr: 0.0404 - 14s/epoch - 74ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.60458 to 0.61947, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.1698 - accuracy: 0.6036 - val_loss: 1.0485 - val_accuracy: 0.6195 - lr: 0.0404 - 14s/epoch - 74ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.61947 to 0.70534, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.0351 - accuracy: 0.6466 - val_loss: 0.9044 - val_accuracy: 0.7053 - lr: 0.0404 - 14s/epoch - 74ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.70534\n",
            "191/191 - 14s - loss: 0.9404 - accuracy: 0.6822 - val_loss: 0.8627 - val_accuracy: 0.7019 - lr: 0.0404 - 14s/epoch - 73ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.70534 to 0.75076, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.8494 - accuracy: 0.7156 - val_loss: 0.7432 - val_accuracy: 0.7508 - lr: 0.0404 - 14s/epoch - 74ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.75076 to 0.77405, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.7823 - accuracy: 0.7366 - val_loss: 0.6812 - val_accuracy: 0.7740 - lr: 0.0404 - 14s/epoch - 74ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.77405 to 0.79809, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.7132 - accuracy: 0.7599 - val_loss: 0.6190 - val_accuracy: 0.7981 - lr: 0.0404 - 14s/epoch - 74ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.79809\n",
            "191/191 - 14s - loss: 0.6649 - accuracy: 0.7754 - val_loss: 0.7070 - val_accuracy: 0.7660 - lr: 0.0404 - 14s/epoch - 73ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.79809\n",
            "191/191 - 14s - loss: 0.6070 - accuracy: 0.7963 - val_loss: 0.6733 - val_accuracy: 0.7725 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.79809 to 0.83244, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5721 - accuracy: 0.8075 - val_loss: 0.5117 - val_accuracy: 0.8324 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.83244 to 0.84122, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5382 - accuracy: 0.8154 - val_loss: 0.4855 - val_accuracy: 0.8412 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.84122 to 0.86145, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5147 - accuracy: 0.8265 - val_loss: 0.4283 - val_accuracy: 0.8615 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.86145 to 0.86412, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4891 - accuracy: 0.8368 - val_loss: 0.4028 - val_accuracy: 0.8641 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.86412 to 0.88092, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4612 - accuracy: 0.8451 - val_loss: 0.3775 - val_accuracy: 0.8809 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.88092\n",
            "191/191 - 14s - loss: 0.4292 - accuracy: 0.8548 - val_loss: 0.3784 - val_accuracy: 0.8733 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.88092\n",
            "191/191 - 14s - loss: 0.4089 - accuracy: 0.8633 - val_loss: 0.4133 - val_accuracy: 0.8553 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.88092 to 0.90038, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4004 - accuracy: 0.8623 - val_loss: 0.3259 - val_accuracy: 0.9004 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.90038\n",
            "191/191 - 14s - loss: 0.3916 - accuracy: 0.8653 - val_loss: 0.3343 - val_accuracy: 0.8966 - lr: 0.0384 - 14s/epoch - 73ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.90038\n",
            "191/191 - 14s - loss: 0.3455 - accuracy: 0.8822 - val_loss: 0.3145 - val_accuracy: 0.8939 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.90038\n",
            "191/191 - 14s - loss: 0.3379 - accuracy: 0.8845 - val_loss: 0.2940 - val_accuracy: 0.8996 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.90038\n",
            "191/191 - 14s - loss: 0.3116 - accuracy: 0.8923 - val_loss: 0.3423 - val_accuracy: 0.8859 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.90038 to 0.90954, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3067 - accuracy: 0.8975 - val_loss: 0.2610 - val_accuracy: 0.9095 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.90954 to 0.91489, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3024 - accuracy: 0.8979 - val_loss: 0.2644 - val_accuracy: 0.9149 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.91489\n",
            "191/191 - 14s - loss: 0.2900 - accuracy: 0.9029 - val_loss: 0.2674 - val_accuracy: 0.9118 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.91489 to 0.92672, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2763 - accuracy: 0.9080 - val_loss: 0.2256 - val_accuracy: 0.9267 - lr: 0.0365 - 14s/epoch - 74ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.92672\n",
            "191/191 - 14s - loss: 0.2606 - accuracy: 0.9099 - val_loss: 0.2261 - val_accuracy: 0.9256 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.92672\n",
            "191/191 - 14s - loss: 0.2569 - accuracy: 0.9124 - val_loss: 0.2366 - val_accuracy: 0.9221 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.92672\n",
            "191/191 - 14s - loss: 0.2559 - accuracy: 0.9144 - val_loss: 0.2536 - val_accuracy: 0.9195 - lr: 0.0365 - 14s/epoch - 73ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.92672\n",
            "191/191 - 14s - loss: 0.2343 - accuracy: 0.9200 - val_loss: 0.2176 - val_accuracy: 0.9225 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy improved from 0.92672 to 0.92824, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2250 - accuracy: 0.9217 - val_loss: 0.2034 - val_accuracy: 0.9282 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.92824\n",
            "191/191 - 14s - loss: 0.2092 - accuracy: 0.9277 - val_loss: 0.2287 - val_accuracy: 0.9237 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.92824\n",
            "191/191 - 14s - loss: 0.2183 - accuracy: 0.9236 - val_loss: 0.2474 - val_accuracy: 0.9233 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.92824 to 0.93206, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2025 - accuracy: 0.9305 - val_loss: 0.1942 - val_accuracy: 0.9321 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy improved from 0.93206 to 0.94656, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1979 - accuracy: 0.9302 - val_loss: 0.1704 - val_accuracy: 0.9466 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.94656\n",
            "191/191 - 14s - loss: 0.1938 - accuracy: 0.9322 - val_loss: 0.1779 - val_accuracy: 0.9427 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.94656\n",
            "191/191 - 14s - loss: 0.1890 - accuracy: 0.9364 - val_loss: 0.1747 - val_accuracy: 0.9454 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.94656\n",
            "191/191 - 14s - loss: 0.1777 - accuracy: 0.9391 - val_loss: 0.1930 - val_accuracy: 0.9382 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.94656\n",
            "191/191 - 14s - loss: 0.1834 - accuracy: 0.9368 - val_loss: 0.1787 - val_accuracy: 0.9416 - lr: 0.0346 - 14s/epoch - 73ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.94656\n",
            "191/191 - 14s - loss: 0.1755 - accuracy: 0.9403 - val_loss: 0.1741 - val_accuracy: 0.9454 - lr: 0.0329 - 14s/epoch - 73ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.94656 to 0.95038, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1630 - accuracy: 0.9445 - val_loss: 0.1575 - val_accuracy: 0.9504 - lr: 0.0329 - 14s/epoch - 73ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.95038\n",
            "191/191 - 14s - loss: 0.1606 - accuracy: 0.9447 - val_loss: 0.1764 - val_accuracy: 0.9450 - lr: 0.0329 - 14s/epoch - 72ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy improved from 0.95038 to 0.95305, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1531 - accuracy: 0.9459 - val_loss: 0.1551 - val_accuracy: 0.9531 - lr: 0.0329 - 14s/epoch - 72ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.95305\n",
            "191/191 - 14s - loss: 0.1457 - accuracy: 0.9503 - val_loss: 0.1600 - val_accuracy: 0.9515 - lr: 0.0329 - 14s/epoch - 72ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.95305\n",
            "191/191 - 14s - loss: 0.1451 - accuracy: 0.9491 - val_loss: 0.1701 - val_accuracy: 0.9469 - lr: 0.0329 - 14s/epoch - 72ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy improved from 0.95305 to 0.95802, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1319 - accuracy: 0.9558 - val_loss: 0.1354 - val_accuracy: 0.9580 - lr: 0.0329 - 14s/epoch - 72ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.95802\n",
            "191/191 - 14s - loss: 0.1379 - accuracy: 0.9526 - val_loss: 0.1702 - val_accuracy: 0.9492 - lr: 0.0329 - 14s/epoch - 72ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.95802\n",
            "191/191 - 14s - loss: 0.1367 - accuracy: 0.9539 - val_loss: 0.1486 - val_accuracy: 0.9565 - lr: 0.0329 - 14s/epoch - 72ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.95802\n",
            "191/191 - 14s - loss: 0.1435 - accuracy: 0.9512 - val_loss: 0.1962 - val_accuracy: 0.9450 - lr: 0.0329 - 14s/epoch - 72ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy improved from 0.95802 to 0.96069, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1295 - accuracy: 0.9566 - val_loss: 0.1442 - val_accuracy: 0.9607 - lr: 0.0313 - 14s/epoch - 72ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy improved from 0.96069 to 0.96145, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1190 - accuracy: 0.9608 - val_loss: 0.1350 - val_accuracy: 0.9615 - lr: 0.0313 - 14s/epoch - 72ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1206 - accuracy: 0.9601 - val_loss: 0.1575 - val_accuracy: 0.9496 - lr: 0.0313 - 14s/epoch - 71ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1158 - accuracy: 0.9625 - val_loss: 0.1431 - val_accuracy: 0.9569 - lr: 0.0313 - 14s/epoch - 71ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1193 - accuracy: 0.9598 - val_loss: 0.1274 - val_accuracy: 0.9615 - lr: 0.0313 - 14s/epoch - 71ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1161 - accuracy: 0.9600 - val_loss: 0.1487 - val_accuracy: 0.9550 - lr: 0.0313 - 14s/epoch - 71ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1215 - accuracy: 0.9613 - val_loss: 0.1496 - val_accuracy: 0.9584 - lr: 0.0313 - 14s/epoch - 71ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1194 - accuracy: 0.9589 - val_loss: 0.1353 - val_accuracy: 0.9565 - lr: 0.0313 - 14s/epoch - 71ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1113 - accuracy: 0.9630 - val_loss: 0.1333 - val_accuracy: 0.9573 - lr: 0.0313 - 14s/epoch - 71ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1082 - accuracy: 0.9642 - val_loss: 0.1557 - val_accuracy: 0.9511 - lr: 0.0313 - 14s/epoch - 71ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.1089 - accuracy: 0.9627 - val_loss: 0.1328 - val_accuracy: 0.9553 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.96145\n",
            "191/191 - 14s - loss: 0.0946 - accuracy: 0.9669 - val_loss: 0.1370 - val_accuracy: 0.9576 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy improved from 0.96145 to 0.96832, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0968 - accuracy: 0.9692 - val_loss: 0.1136 - val_accuracy: 0.9683 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.96832\n",
            "191/191 - 14s - loss: 0.0878 - accuracy: 0.9698 - val_loss: 0.1220 - val_accuracy: 0.9656 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.96832\n",
            "191/191 - 14s - loss: 0.0929 - accuracy: 0.9688 - val_loss: 0.1151 - val_accuracy: 0.9653 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.96832\n",
            "191/191 - 14s - loss: 0.0822 - accuracy: 0.9740 - val_loss: 0.1150 - val_accuracy: 0.9653 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.96832\n",
            "191/191 - 14s - loss: 0.0881 - accuracy: 0.9701 - val_loss: 0.1141 - val_accuracy: 0.9679 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.96832\n",
            "191/191 - 14s - loss: 0.0892 - accuracy: 0.9696 - val_loss: 0.1119 - val_accuracy: 0.9626 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy improved from 0.96832 to 0.96985, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0917 - accuracy: 0.9688 - val_loss: 0.1043 - val_accuracy: 0.9698 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.96985\n",
            "191/191 - 14s - loss: 0.0794 - accuracy: 0.9724 - val_loss: 0.1119 - val_accuracy: 0.9668 - lr: 0.0297 - 14s/epoch - 71ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.96985\n",
            "191/191 - 14s - loss: 0.0907 - accuracy: 0.9698 - val_loss: 0.1212 - val_accuracy: 0.9615 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy improved from 0.96985 to 0.97061, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0897 - accuracy: 0.9713 - val_loss: 0.1130 - val_accuracy: 0.9706 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0765 - accuracy: 0.9742 - val_loss: 0.1125 - val_accuracy: 0.9687 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0804 - accuracy: 0.9728 - val_loss: 0.1133 - val_accuracy: 0.9676 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0760 - accuracy: 0.9741 - val_loss: 0.1122 - val_accuracy: 0.9672 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0706 - accuracy: 0.9772 - val_loss: 0.1079 - val_accuracy: 0.9702 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0693 - accuracy: 0.9771 - val_loss: 0.1200 - val_accuracy: 0.9676 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0862 - accuracy: 0.9735 - val_loss: 0.1223 - val_accuracy: 0.9702 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0885 - accuracy: 0.9714 - val_loss: 0.1120 - val_accuracy: 0.9691 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0677 - accuracy: 0.9753 - val_loss: 0.1110 - val_accuracy: 0.9683 - lr: 0.0282 - 14s/epoch - 71ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.97061\n",
            "191/191 - 14s - loss: 0.0725 - accuracy: 0.9764 - val_loss: 0.1086 - val_accuracy: 0.9706 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy improved from 0.97061 to 0.97176, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0625 - accuracy: 0.9789 - val_loss: 0.1039 - val_accuracy: 0.9718 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.97176\n",
            "191/191 - 14s - loss: 0.0736 - accuracy: 0.9754 - val_loss: 0.1236 - val_accuracy: 0.9683 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.97176\n",
            "191/191 - 14s - loss: 0.0687 - accuracy: 0.9776 - val_loss: 0.1107 - val_accuracy: 0.9698 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.97176\n",
            "191/191 - 14s - loss: 0.0675 - accuracy: 0.9776 - val_loss: 0.1387 - val_accuracy: 0.9626 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.97176\n",
            "191/191 - 14s - loss: 0.0658 - accuracy: 0.9785 - val_loss: 0.1237 - val_accuracy: 0.9695 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.97176\n",
            "191/191 - 14s - loss: 0.0745 - accuracy: 0.9750 - val_loss: 0.1048 - val_accuracy: 0.9687 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.97176\n",
            "191/191 - 14s - loss: 0.0803 - accuracy: 0.9736 - val_loss: 0.1359 - val_accuracy: 0.9611 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.97176\n",
            "191/191 - 14s - loss: 0.0846 - accuracy: 0.9703 - val_loss: 0.1208 - val_accuracy: 0.9672 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.97176\n",
            "191/191 - 14s - loss: 0.0727 - accuracy: 0.9764 - val_loss: 0.1029 - val_accuracy: 0.9706 - lr: 0.0268 - 14s/epoch - 71ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy improved from 0.97176 to 0.97214, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0571 - accuracy: 0.9819 - val_loss: 0.1021 - val_accuracy: 0.9721 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.97214\n",
            "191/191 - 14s - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.1077 - val_accuracy: 0.9706 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.97214\n",
            "191/191 - 14s - loss: 0.0614 - accuracy: 0.9807 - val_loss: 0.1003 - val_accuracy: 0.9718 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy improved from 0.97214 to 0.97405, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0514 - accuracy: 0.9831 - val_loss: 0.1046 - val_accuracy: 0.9740 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0550 - accuracy: 0.9829 - val_loss: 0.1034 - val_accuracy: 0.9725 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0541 - accuracy: 0.9826 - val_loss: 0.1036 - val_accuracy: 0.9718 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0494 - accuracy: 0.9845 - val_loss: 0.1015 - val_accuracy: 0.9721 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0571 - accuracy: 0.9818 - val_loss: 0.1111 - val_accuracy: 0.9718 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0614 - accuracy: 0.9798 - val_loss: 0.1525 - val_accuracy: 0.9603 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.97405\n",
            "191/191 - 14s - loss: 0.0539 - accuracy: 0.9821 - val_loss: 0.1066 - val_accuracy: 0.9725 - lr: 0.0255 - 14s/epoch - 71ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy improved from 0.97405 to 0.97595, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0468 - accuracy: 0.9845 - val_loss: 0.1069 - val_accuracy: 0.9760 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.1079 - val_accuracy: 0.9733 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.0942 - val_accuracy: 0.9740 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0445 - accuracy: 0.9865 - val_loss: 0.0975 - val_accuracy: 0.9760 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0466 - accuracy: 0.9845 - val_loss: 0.0988 - val_accuracy: 0.9725 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.1096 - val_accuracy: 0.9737 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.1127 - val_accuracy: 0.9740 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0442 - accuracy: 0.9850 - val_loss: 0.1013 - val_accuracy: 0.9752 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.1029 - val_accuracy: 0.9733 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.1172 - val_accuracy: 0.9672 - lr: 0.0242 - 14s/epoch - 71ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0494 - accuracy: 0.9836 - val_loss: 0.1042 - val_accuracy: 0.9733 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.1059 - val_accuracy: 0.9752 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.97595\n",
            "191/191 - 14s - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.1000 - val_accuracy: 0.9748 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.97595\n",
            "191/191 - 13s - loss: 0.0408 - accuracy: 0.9876 - val_loss: 0.1074 - val_accuracy: 0.9737 - lr: 0.0230 - 13s/epoch - 71ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy improved from 0.97595 to 0.97786, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.0964 - val_accuracy: 0.9779 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0425 - accuracy: 0.9858 - val_loss: 0.1174 - val_accuracy: 0.9725 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0422 - accuracy: 0.9860 - val_loss: 0.1011 - val_accuracy: 0.9760 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0430 - accuracy: 0.9862 - val_loss: 0.1003 - val_accuracy: 0.9725 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0453 - accuracy: 0.9861 - val_loss: 0.0972 - val_accuracy: 0.9748 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0419 - accuracy: 0.9863 - val_loss: 0.1018 - val_accuracy: 0.9740 - lr: 0.0230 - 14s/epoch - 71ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.1357 - val_accuracy: 0.9698 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.0990 - val_accuracy: 0.9756 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0348 - accuracy: 0.9890 - val_loss: 0.1032 - val_accuracy: 0.9756 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0348 - accuracy: 0.9898 - val_loss: 0.0989 - val_accuracy: 0.9748 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.1070 - val_accuracy: 0.9733 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0333 - accuracy: 0.9899 - val_loss: 0.1039 - val_accuracy: 0.9763 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.1020 - val_accuracy: 0.9763 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.1023 - val_accuracy: 0.9748 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0346 - accuracy: 0.9896 - val_loss: 0.0960 - val_accuracy: 0.9779 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0328 - accuracy: 0.9899 - val_loss: 0.1070 - val_accuracy: 0.9752 - lr: 0.0218 - 14s/epoch - 71ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0423 - accuracy: 0.9871 - val_loss: 0.1019 - val_accuracy: 0.9756 - lr: 0.0207 - 14s/epoch - 71ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0395 - accuracy: 0.9880 - val_loss: 0.0904 - val_accuracy: 0.9763 - lr: 0.0207 - 14s/epoch - 71ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0358 - accuracy: 0.9895 - val_loss: 0.0991 - val_accuracy: 0.9748 - lr: 0.0207 - 14s/epoch - 71ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.0997 - val_accuracy: 0.9752 - lr: 0.0207 - 14s/epoch - 71ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0963 - val_accuracy: 0.9775 - lr: 0.0207 - 14s/epoch - 71ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.0975 - val_accuracy: 0.9771 - lr: 0.0207 - 14s/epoch - 71ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.0934 - val_accuracy: 0.9760 - lr: 0.0207 - 14s/epoch - 71ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.1101 - val_accuracy: 0.9748 - lr: 0.0207 - 14s/epoch - 71ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.1025 - val_accuracy: 0.9763 - lr: 0.0207 - 14s/epoch - 72ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0265 - accuracy: 0.9918 - val_loss: 0.1081 - val_accuracy: 0.9744 - lr: 0.0207 - 14s/epoch - 73ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0332 - accuracy: 0.9894 - val_loss: 0.0987 - val_accuracy: 0.9740 - lr: 0.0197 - 14s/epoch - 74ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.1036 - val_accuracy: 0.9756 - lr: 0.0197 - 14s/epoch - 73ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.1152 - val_accuracy: 0.9756 - lr: 0.0197 - 14s/epoch - 72ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0265 - accuracy: 0.9922 - val_loss: 0.1002 - val_accuracy: 0.9767 - lr: 0.0197 - 14s/epoch - 72ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.97786\n",
            "191/191 - 14s - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0998 - val_accuracy: 0.9775 - lr: 0.0197 - 14s/epoch - 72ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 02:25:27,379] Trial 13 finished with value: 0.978 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.040412276844933835, 'batch_size': 64, 'dropout_ratio': 0.2961968226380338, 'decay': 0.8511753695907078}. Best is trial 9 with value: 0.981.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_144 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_145 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_68 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_146 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 6 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.41947, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 15s - loss: 1.8733 - accuracy: 0.3233 - val_loss: 1.6509 - val_accuracy: 0.4195 - lr: 0.0328 - 15s/epoch - 80ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.41947 to 0.53168, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.5058 - accuracy: 0.4694 - val_loss: 1.3251 - val_accuracy: 0.5317 - lr: 0.0328 - 14s/epoch - 75ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.53168 to 0.60229, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.2823 - accuracy: 0.5579 - val_loss: 1.1587 - val_accuracy: 0.6023 - lr: 0.0328 - 14s/epoch - 74ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.60229 to 0.61985, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.1362 - accuracy: 0.6076 - val_loss: 1.0734 - val_accuracy: 0.6198 - lr: 0.0328 - 14s/epoch - 74ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.61985 to 0.70458, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 1.0165 - accuracy: 0.6531 - val_loss: 0.8723 - val_accuracy: 0.7046 - lr: 0.0328 - 14s/epoch - 74ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.70458 to 0.70840, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.9021 - accuracy: 0.6903 - val_loss: 0.8519 - val_accuracy: 0.7084 - lr: 0.0328 - 14s/epoch - 74ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.70840 to 0.75649, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.8274 - accuracy: 0.7233 - val_loss: 0.7340 - val_accuracy: 0.7565 - lr: 0.0328 - 14s/epoch - 74ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.75649\n",
            "191/191 - 14s - loss: 0.7455 - accuracy: 0.7499 - val_loss: 0.7882 - val_accuracy: 0.7233 - lr: 0.0328 - 14s/epoch - 74ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.75649 to 0.77061, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.6887 - accuracy: 0.7655 - val_loss: 0.6738 - val_accuracy: 0.7706 - lr: 0.0328 - 14s/epoch - 74ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.77061\n",
            "191/191 - 14s - loss: 0.6368 - accuracy: 0.7826 - val_loss: 0.6463 - val_accuracy: 0.7698 - lr: 0.0328 - 14s/epoch - 73ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.77061 to 0.81336, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5748 - accuracy: 0.8059 - val_loss: 0.5611 - val_accuracy: 0.8134 - lr: 0.0311 - 14s/epoch - 73ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.81336 to 0.84198, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5360 - accuracy: 0.8189 - val_loss: 0.4765 - val_accuracy: 0.8420 - lr: 0.0311 - 14s/epoch - 73ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.84198 to 0.86107, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.5031 - accuracy: 0.8282 - val_loss: 0.4216 - val_accuracy: 0.8611 - lr: 0.0311 - 14s/epoch - 74ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.86107\n",
            "191/191 - 14s - loss: 0.4612 - accuracy: 0.8416 - val_loss: 0.4778 - val_accuracy: 0.8420 - lr: 0.0311 - 14s/epoch - 73ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.86107\n",
            "191/191 - 14s - loss: 0.4449 - accuracy: 0.8461 - val_loss: 0.4320 - val_accuracy: 0.8592 - lr: 0.0311 - 14s/epoch - 73ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.86107 to 0.87519, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.4043 - accuracy: 0.8621 - val_loss: 0.3870 - val_accuracy: 0.8752 - lr: 0.0311 - 14s/epoch - 73ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.87519 to 0.88397, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3874 - accuracy: 0.8697 - val_loss: 0.3526 - val_accuracy: 0.8840 - lr: 0.0311 - 14s/epoch - 73ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.88397 to 0.89160, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3637 - accuracy: 0.8766 - val_loss: 0.3370 - val_accuracy: 0.8916 - lr: 0.0311 - 14s/epoch - 72ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.89160\n",
            "191/191 - 14s - loss: 0.3388 - accuracy: 0.8868 - val_loss: 0.3711 - val_accuracy: 0.8775 - lr: 0.0311 - 14s/epoch - 72ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.89160 to 0.89504, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.3180 - accuracy: 0.8912 - val_loss: 0.3097 - val_accuracy: 0.8950 - lr: 0.0311 - 14s/epoch - 73ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.89504 to 0.91260, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2919 - accuracy: 0.9022 - val_loss: 0.2656 - val_accuracy: 0.9126 - lr: 0.0296 - 14s/epoch - 74ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.91260 to 0.92290, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2668 - accuracy: 0.9092 - val_loss: 0.2578 - val_accuracy: 0.9229 - lr: 0.0296 - 14s/epoch - 74ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.92290\n",
            "191/191 - 14s - loss: 0.2684 - accuracy: 0.9094 - val_loss: 0.2540 - val_accuracy: 0.9160 - lr: 0.0296 - 14s/epoch - 73ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.92290 to 0.92710, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2543 - accuracy: 0.9129 - val_loss: 0.2464 - val_accuracy: 0.9271 - lr: 0.0296 - 14s/epoch - 73ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.92710\n",
            "191/191 - 14s - loss: 0.2324 - accuracy: 0.9205 - val_loss: 0.2882 - val_accuracy: 0.9103 - lr: 0.0296 - 14s/epoch - 73ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.92710\n",
            "191/191 - 14s - loss: 0.2469 - accuracy: 0.9164 - val_loss: 0.3255 - val_accuracy: 0.8912 - lr: 0.0296 - 14s/epoch - 73ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.92710 to 0.92977, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2243 - accuracy: 0.9237 - val_loss: 0.2188 - val_accuracy: 0.9298 - lr: 0.0296 - 14s/epoch - 74ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.92977\n",
            "191/191 - 14s - loss: 0.2074 - accuracy: 0.9299 - val_loss: 0.2574 - val_accuracy: 0.9118 - lr: 0.0296 - 14s/epoch - 73ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy improved from 0.92977 to 0.93931, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.2069 - accuracy: 0.9314 - val_loss: 0.1984 - val_accuracy: 0.9393 - lr: 0.0296 - 14s/epoch - 74ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.93931\n",
            "191/191 - 14s - loss: 0.1995 - accuracy: 0.9301 - val_loss: 0.2222 - val_accuracy: 0.9233 - lr: 0.0296 - 14s/epoch - 73ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.93931\n",
            "191/191 - 14s - loss: 0.1783 - accuracy: 0.9386 - val_loss: 0.1994 - val_accuracy: 0.9385 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.93931\n",
            "191/191 - 14s - loss: 0.1701 - accuracy: 0.9431 - val_loss: 0.1944 - val_accuracy: 0.9393 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy improved from 0.93931 to 0.93969, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1606 - accuracy: 0.9457 - val_loss: 0.1882 - val_accuracy: 0.9397 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy improved from 0.93969 to 0.94656, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1529 - accuracy: 0.9494 - val_loss: 0.1824 - val_accuracy: 0.9466 - lr: 0.0281 - 14s/epoch - 74ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.94656 to 0.94885, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1538 - accuracy: 0.9485 - val_loss: 0.1702 - val_accuracy: 0.9489 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.94885\n",
            "191/191 - 14s - loss: 0.1486 - accuracy: 0.9520 - val_loss: 0.2072 - val_accuracy: 0.9286 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.94885\n",
            "191/191 - 14s - loss: 0.1423 - accuracy: 0.9531 - val_loss: 0.1785 - val_accuracy: 0.9447 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy improved from 0.94885 to 0.95076, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1331 - accuracy: 0.9536 - val_loss: 0.1638 - val_accuracy: 0.9508 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.95076\n",
            "191/191 - 14s - loss: 0.1396 - accuracy: 0.9534 - val_loss: 0.3358 - val_accuracy: 0.9145 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.95076\n",
            "191/191 - 14s - loss: 0.1287 - accuracy: 0.9572 - val_loss: 0.2041 - val_accuracy: 0.9370 - lr: 0.0281 - 14s/epoch - 73ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.95076\n",
            "191/191 - 14s - loss: 0.1119 - accuracy: 0.9637 - val_loss: 0.1971 - val_accuracy: 0.9382 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.95076\n",
            "191/191 - 14s - loss: 0.1150 - accuracy: 0.9637 - val_loss: 0.2012 - val_accuracy: 0.9385 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.95076\n",
            "191/191 - 14s - loss: 0.1039 - accuracy: 0.9662 - val_loss: 0.1737 - val_accuracy: 0.9469 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy improved from 0.95076 to 0.95725, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1091 - accuracy: 0.9634 - val_loss: 0.1482 - val_accuracy: 0.9573 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.95725\n",
            "191/191 - 14s - loss: 0.1039 - accuracy: 0.9662 - val_loss: 0.1404 - val_accuracy: 0.9569 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy improved from 0.95725 to 0.96336, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.1058 - accuracy: 0.9651 - val_loss: 0.1390 - val_accuracy: 0.9634 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.1009 - accuracy: 0.9658 - val_loss: 0.1550 - val_accuracy: 0.9515 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.1124 - accuracy: 0.9647 - val_loss: 0.1536 - val_accuracy: 0.9500 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.0961 - accuracy: 0.9695 - val_loss: 0.1490 - val_accuracy: 0.9553 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.1010 - accuracy: 0.9664 - val_loss: 0.1537 - val_accuracy: 0.9511 - lr: 0.0267 - 14s/epoch - 73ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.0923 - accuracy: 0.9708 - val_loss: 0.1354 - val_accuracy: 0.9595 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.0945 - accuracy: 0.9705 - val_loss: 0.1502 - val_accuracy: 0.9580 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.2918 - accuracy: 0.9340 - val_loss: 0.1791 - val_accuracy: 0.9458 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.1106 - accuracy: 0.9639 - val_loss: 0.1408 - val_accuracy: 0.9573 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.0953 - accuracy: 0.9677 - val_loss: 0.1645 - val_accuracy: 0.9511 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.0930 - accuracy: 0.9696 - val_loss: 0.1248 - val_accuracy: 0.9630 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.0828 - accuracy: 0.9742 - val_loss: 0.1317 - val_accuracy: 0.9618 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.0795 - accuracy: 0.9742 - val_loss: 0.1252 - val_accuracy: 0.9618 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.96336\n",
            "191/191 - 14s - loss: 0.0820 - accuracy: 0.9723 - val_loss: 0.1350 - val_accuracy: 0.9592 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy improved from 0.96336 to 0.96374, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0773 - accuracy: 0.9746 - val_loss: 0.1293 - val_accuracy: 0.9637 - lr: 0.0253 - 14s/epoch - 73ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy improved from 0.96374 to 0.96718, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0641 - accuracy: 0.9801 - val_loss: 0.1244 - val_accuracy: 0.9672 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.96718\n",
            "191/191 - 14s - loss: 0.0639 - accuracy: 0.9801 - val_loss: 0.1290 - val_accuracy: 0.9653 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.96718\n",
            "191/191 - 14s - loss: 0.0672 - accuracy: 0.9788 - val_loss: 0.1320 - val_accuracy: 0.9649 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.96718\n",
            "191/191 - 14s - loss: 0.0627 - accuracy: 0.9793 - val_loss: 0.1440 - val_accuracy: 0.9634 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy improved from 0.96718 to 0.96947, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0600 - accuracy: 0.9804 - val_loss: 0.1195 - val_accuracy: 0.9695 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0680 - accuracy: 0.9783 - val_loss: 0.1260 - val_accuracy: 0.9637 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0570 - accuracy: 0.9813 - val_loss: 0.1278 - val_accuracy: 0.9656 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0582 - accuracy: 0.9827 - val_loss: 0.1261 - val_accuracy: 0.9664 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0615 - accuracy: 0.9801 - val_loss: 0.1196 - val_accuracy: 0.9691 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0560 - accuracy: 0.9813 - val_loss: 0.1199 - val_accuracy: 0.9691 - lr: 0.0241 - 14s/epoch - 73ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0618 - accuracy: 0.9804 - val_loss: 0.1308 - val_accuracy: 0.9695 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.96947\n",
            "191/191 - 14s - loss: 0.0477 - accuracy: 0.9845 - val_loss: 0.1242 - val_accuracy: 0.9660 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy improved from 0.96947 to 0.97023, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.1221 - val_accuracy: 0.9702 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.97023\n",
            "191/191 - 14s - loss: 0.0511 - accuracy: 0.9846 - val_loss: 0.1281 - val_accuracy: 0.9698 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.97023\n",
            "191/191 - 14s - loss: 0.0481 - accuracy: 0.9845 - val_loss: 0.1367 - val_accuracy: 0.9649 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.97023\n",
            "191/191 - 14s - loss: 0.0558 - accuracy: 0.9831 - val_loss: 0.1292 - val_accuracy: 0.9668 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.97023\n",
            "191/191 - 14s - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.1289 - val_accuracy: 0.9653 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.97023\n",
            "191/191 - 14s - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.1225 - val_accuracy: 0.9683 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy improved from 0.97023 to 0.97099, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0442 - accuracy: 0.9866 - val_loss: 0.1123 - val_accuracy: 0.9710 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.97099\n",
            "191/191 - 14s - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.1160 - val_accuracy: 0.9702 - lr: 0.0229 - 14s/epoch - 73ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.97099\n",
            "191/191 - 14s - loss: 0.0502 - accuracy: 0.9854 - val_loss: 0.1259 - val_accuracy: 0.9656 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.97099\n",
            "191/191 - 14s - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.1188 - val_accuracy: 0.9698 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.97099\n",
            "191/191 - 14s - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.1245 - val_accuracy: 0.9695 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy improved from 0.97099 to 0.97214, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0352 - accuracy: 0.9898 - val_loss: 0.1149 - val_accuracy: 0.9721 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.97214\n",
            "191/191 - 14s - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.1265 - val_accuracy: 0.9679 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.97214\n",
            "191/191 - 14s - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.1127 - val_accuracy: 0.9702 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.97214\n",
            "191/191 - 14s - loss: 0.0403 - accuracy: 0.9863 - val_loss: 0.1465 - val_accuracy: 0.9672 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy improved from 0.97214 to 0.97481, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0461 - accuracy: 0.9853 - val_loss: 0.1056 - val_accuracy: 0.9748 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.97481\n",
            "191/191 - 14s - loss: 0.0328 - accuracy: 0.9891 - val_loss: 0.1345 - val_accuracy: 0.9698 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.97481\n",
            "191/191 - 14s - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.1231 - val_accuracy: 0.9710 - lr: 0.0217 - 14s/epoch - 73ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.97481\n",
            "191/191 - 14s - loss: 0.0351 - accuracy: 0.9888 - val_loss: 0.1199 - val_accuracy: 0.9695 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.97481\n",
            "191/191 - 14s - loss: 0.0394 - accuracy: 0.9882 - val_loss: 0.1138 - val_accuracy: 0.9733 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy improved from 0.97481 to 0.97748, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.1156 - val_accuracy: 0.9775 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0365 - accuracy: 0.9897 - val_loss: 0.1098 - val_accuracy: 0.9756 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.1252 - val_accuracy: 0.9698 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0385 - accuracy: 0.9867 - val_loss: 0.1341 - val_accuracy: 0.9725 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0349 - accuracy: 0.9900 - val_loss: 0.1156 - val_accuracy: 0.9740 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0363 - accuracy: 0.9890 - val_loss: 0.1161 - val_accuracy: 0.9763 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0436 - accuracy: 0.9868 - val_loss: 0.1312 - val_accuracy: 0.9698 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0374 - accuracy: 0.9892 - val_loss: 0.1257 - val_accuracy: 0.9737 - lr: 0.0206 - 14s/epoch - 73ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.1086 - val_accuracy: 0.9744 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0320 - accuracy: 0.9909 - val_loss: 0.1032 - val_accuracy: 0.9748 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.1109 - val_accuracy: 0.9744 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.1187 - val_accuracy: 0.9737 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.1130 - val_accuracy: 0.9721 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.1175 - val_accuracy: 0.9763 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.1134 - val_accuracy: 0.9752 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.1206 - val_accuracy: 0.9737 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.1115 - val_accuracy: 0.9767 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.1183 - val_accuracy: 0.9725 - lr: 0.0196 - 14s/epoch - 73ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.1129 - val_accuracy: 0.9721 - lr: 0.0186 - 14s/epoch - 73ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.1134 - val_accuracy: 0.9760 - lr: 0.0186 - 14s/epoch - 73ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.1159 - val_accuracy: 0.9760 - lr: 0.0186 - 14s/epoch - 73ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.1134 - val_accuracy: 0.9737 - lr: 0.0186 - 14s/epoch - 73ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.1123 - val_accuracy: 0.9756 - lr: 0.0186 - 14s/epoch - 73ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.1206 - val_accuracy: 0.9706 - lr: 0.0186 - 14s/epoch - 73ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.1098 - val_accuracy: 0.9756 - lr: 0.0186 - 14s/epoch - 72ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.97748\n",
            "191/191 - 14s - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.1163 - val_accuracy: 0.9756 - lr: 0.0186 - 14s/epoch - 72ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy improved from 0.97748 to 0.97824, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.1014 - val_accuracy: 0.9782 - lr: 0.0186 - 14s/epoch - 73ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0238 - accuracy: 0.9929 - val_loss: 0.1123 - val_accuracy: 0.9744 - lr: 0.0186 - 14s/epoch - 73ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.1122 - val_accuracy: 0.9775 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.97824\n",
            "191/191 - 14s - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.1107 - val_accuracy: 0.9771 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy improved from 0.97824 to 0.97901, saving model to saved_models/best_fcn.keras\n",
            "191/191 - 14s - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.1094 - val_accuracy: 0.9790 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.1091 - val_accuracy: 0.9752 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0244 - accuracy: 0.9931 - val_loss: 0.1194 - val_accuracy: 0.9744 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.1073 - val_accuracy: 0.9760 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.1153 - val_accuracy: 0.9763 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.1213 - val_accuracy: 0.9744 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.1125 - val_accuracy: 0.9752 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.1178 - val_accuracy: 0.9756 - lr: 0.0177 - 14s/epoch - 73ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.1103 - val_accuracy: 0.9767 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.1176 - val_accuracy: 0.9756 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.1126 - val_accuracy: 0.9775 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.1155 - val_accuracy: 0.9775 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.1088 - val_accuracy: 0.9779 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.1109 - val_accuracy: 0.9786 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.1155 - val_accuracy: 0.9763 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.1138 - val_accuracy: 0.9740 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.1234 - val_accuracy: 0.9725 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.1236 - val_accuracy: 0.9752 - lr: 0.0168 - 14s/epoch - 73ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.1192 - val_accuracy: 0.9779 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.1197 - val_accuracy: 0.9748 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.1255 - val_accuracy: 0.9748 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.1321 - val_accuracy: 0.9744 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.1225 - val_accuracy: 0.9752 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.1272 - val_accuracy: 0.9740 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.1234 - val_accuracy: 0.9756 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.1237 - val_accuracy: 0.9763 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.1165 - val_accuracy: 0.9782 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.1261 - val_accuracy: 0.9767 - lr: 0.0160 - 14s/epoch - 73ms/step\n",
            "Epoch 151/250\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.1273 - val_accuracy: 0.9775 - lr: 0.0152 - 14s/epoch - 73ms/step\n",
            "Epoch 152/250\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.1217 - val_accuracy: 0.9782 - lr: 0.0152 - 14s/epoch - 73ms/step\n",
            "Epoch 153/250\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.97901\n",
            "191/191 - 14s - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.1229 - val_accuracy: 0.9744 - lr: 0.0152 - 14s/epoch - 73ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 03:01:04,137] Trial 14 finished with value: 0.979 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.032750155923148554, 'batch_size': 64, 'dropout_ratio': 0.13212517844447466, 'decay': 0.8024115657993454}. Best is trial 9 with value: 0.981.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_148 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_149 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_69 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_150 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_151 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 7 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.37863, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 16s - loss: 1.8220 - accuracy: 0.3455 - val_loss: 1.6827 - val_accuracy: 0.3786 - lr: 0.0486 - 16s/epoch - 41ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.37863 to 0.61031, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 1.4083 - accuracy: 0.5054 - val_loss: 1.1483 - val_accuracy: 0.6103 - lr: 0.0486 - 14s/epoch - 38ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.61031 to 0.64313, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 1.1504 - accuracy: 0.6048 - val_loss: 0.9910 - val_accuracy: 0.6431 - lr: 0.0486 - 14s/epoch - 38ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.64313 to 0.70458, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.9843 - accuracy: 0.6659 - val_loss: 0.8727 - val_accuracy: 0.7046 - lr: 0.0486 - 14s/epoch - 37ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.70458 to 0.74160, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.8620 - accuracy: 0.7067 - val_loss: 0.7453 - val_accuracy: 0.7416 - lr: 0.0486 - 14s/epoch - 37ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.74160 to 0.77176, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.7632 - accuracy: 0.7413 - val_loss: 0.6752 - val_accuracy: 0.7718 - lr: 0.0486 - 14s/epoch - 37ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.77176 to 0.80038, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.6841 - accuracy: 0.7692 - val_loss: 0.5862 - val_accuracy: 0.8004 - lr: 0.0486 - 14s/epoch - 37ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.80038 to 0.83359, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.6162 - accuracy: 0.7943 - val_loss: 0.5179 - val_accuracy: 0.8336 - lr: 0.0486 - 14s/epoch - 37ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.83359\n",
            "382/382 - 14s - loss: 0.5697 - accuracy: 0.8089 - val_loss: 0.4992 - val_accuracy: 0.8298 - lr: 0.0486 - 14s/epoch - 37ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.83359 to 0.85649, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.5201 - accuracy: 0.8253 - val_loss: 0.4586 - val_accuracy: 0.8565 - lr: 0.0486 - 14s/epoch - 37ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.85649 to 0.86641, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.4836 - accuracy: 0.8358 - val_loss: 0.4305 - val_accuracy: 0.8664 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.86641 to 0.87710, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.4392 - accuracy: 0.8508 - val_loss: 0.3748 - val_accuracy: 0.8771 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.87710 to 0.88664, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.4341 - accuracy: 0.8547 - val_loss: 0.3303 - val_accuracy: 0.8866 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.88664 to 0.90420, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.3941 - accuracy: 0.8659 - val_loss: 0.3096 - val_accuracy: 0.9042 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.90420\n",
            "382/382 - 14s - loss: 0.3793 - accuracy: 0.8700 - val_loss: 0.3001 - val_accuracy: 0.8977 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.90420\n",
            "382/382 - 14s - loss: 0.3620 - accuracy: 0.8780 - val_loss: 0.3333 - val_accuracy: 0.8935 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.90420 to 0.91832, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.3439 - accuracy: 0.8858 - val_loss: 0.2595 - val_accuracy: 0.9183 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.91832\n",
            "382/382 - 14s - loss: 0.3193 - accuracy: 0.8890 - val_loss: 0.3076 - val_accuracy: 0.9031 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.91832\n",
            "382/382 - 14s - loss: 0.3198 - accuracy: 0.8945 - val_loss: 0.2767 - val_accuracy: 0.9107 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.91832 to 0.92099, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.2850 - accuracy: 0.9025 - val_loss: 0.2347 - val_accuracy: 0.9210 - lr: 0.0462 - 14s/epoch - 37ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.92099 to 0.92443, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.2613 - accuracy: 0.9115 - val_loss: 0.2382 - val_accuracy: 0.9244 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.92443 to 0.93321, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.2553 - accuracy: 0.9132 - val_loss: 0.2020 - val_accuracy: 0.9332 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.93321\n",
            "382/382 - 14s - loss: 0.2532 - accuracy: 0.9132 - val_loss: 0.2430 - val_accuracy: 0.9218 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.93321\n",
            "382/382 - 14s - loss: 0.2453 - accuracy: 0.9193 - val_loss: 0.2327 - val_accuracy: 0.9172 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.93321\n",
            "382/382 - 14s - loss: 0.2317 - accuracy: 0.9209 - val_loss: 0.2117 - val_accuracy: 0.9298 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.93321 to 0.94237, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.2218 - accuracy: 0.9227 - val_loss: 0.1763 - val_accuracy: 0.9424 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.94237\n",
            "382/382 - 14s - loss: 0.2040 - accuracy: 0.9318 - val_loss: 0.1965 - val_accuracy: 0.9302 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.94237\n",
            "382/382 - 14s - loss: 0.2083 - accuracy: 0.9272 - val_loss: 0.1835 - val_accuracy: 0.9393 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.94237\n",
            "382/382 - 14s - loss: 0.2048 - accuracy: 0.9313 - val_loss: 0.1980 - val_accuracy: 0.9382 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.94237 to 0.95000, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1950 - accuracy: 0.9324 - val_loss: 0.1564 - val_accuracy: 0.9500 - lr: 0.0438 - 14s/epoch - 37ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy improved from 0.95000 to 0.95267, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1800 - accuracy: 0.9403 - val_loss: 0.1528 - val_accuracy: 0.9527 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.95267\n",
            "382/382 - 14s - loss: 0.1824 - accuracy: 0.9370 - val_loss: 0.1771 - val_accuracy: 0.9443 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy improved from 0.95267 to 0.95305, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1707 - accuracy: 0.9416 - val_loss: 0.1585 - val_accuracy: 0.9531 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.95305\n",
            "382/382 - 14s - loss: 0.1896 - accuracy: 0.9372 - val_loss: 0.1644 - val_accuracy: 0.9511 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.95305\n",
            "382/382 - 14s - loss: 0.1866 - accuracy: 0.9363 - val_loss: 0.2204 - val_accuracy: 0.9317 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.95305\n",
            "382/382 - 14s - loss: 0.1528 - accuracy: 0.9466 - val_loss: 0.1521 - val_accuracy: 0.9515 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.95305\n",
            "382/382 - 14s - loss: 0.1531 - accuracy: 0.9504 - val_loss: 0.1568 - val_accuracy: 0.9496 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.95305\n",
            "382/382 - 14s - loss: 0.1460 - accuracy: 0.9502 - val_loss: 0.1676 - val_accuracy: 0.9485 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.95305\n",
            "382/382 - 14s - loss: 0.1478 - accuracy: 0.9497 - val_loss: 0.1719 - val_accuracy: 0.9527 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.95305\n",
            "382/382 - 14s - loss: 0.1363 - accuracy: 0.9544 - val_loss: 0.1690 - val_accuracy: 0.9477 - lr: 0.0417 - 14s/epoch - 37ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.95305 to 0.95992, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1533 - accuracy: 0.9493 - val_loss: 0.1413 - val_accuracy: 0.9599 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.95992 to 0.96031, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1261 - accuracy: 0.9571 - val_loss: 0.1404 - val_accuracy: 0.9603 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.96031\n",
            "382/382 - 14s - loss: 0.1146 - accuracy: 0.9604 - val_loss: 0.1404 - val_accuracy: 0.9595 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.96031\n",
            "382/382 - 14s - loss: 0.1227 - accuracy: 0.9566 - val_loss: 0.1436 - val_accuracy: 0.9538 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy improved from 0.96031 to 0.96527, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1124 - accuracy: 0.9623 - val_loss: 0.1218 - val_accuracy: 0.9653 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.96527\n",
            "382/382 - 14s - loss: 0.1118 - accuracy: 0.9639 - val_loss: 0.1330 - val_accuracy: 0.9584 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.96527\n",
            "382/382 - 14s - loss: 0.1400 - accuracy: 0.9549 - val_loss: 0.1383 - val_accuracy: 0.9576 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.96527\n",
            "382/382 - 14s - loss: 0.1158 - accuracy: 0.9612 - val_loss: 0.1432 - val_accuracy: 0.9592 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.96527\n",
            "382/382 - 14s - loss: 0.1213 - accuracy: 0.9589 - val_loss: 0.1249 - val_accuracy: 0.9645 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.96527\n",
            "382/382 - 14s - loss: 0.1132 - accuracy: 0.9620 - val_loss: 0.1221 - val_accuracy: 0.9653 - lr: 0.0396 - 14s/epoch - 37ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy improved from 0.96527 to 0.96870, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0978 - accuracy: 0.9658 - val_loss: 0.1078 - val_accuracy: 0.9687 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.96870\n",
            "382/382 - 14s - loss: 0.0994 - accuracy: 0.9674 - val_loss: 0.1228 - val_accuracy: 0.9668 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy improved from 0.96870 to 0.96985, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1007 - accuracy: 0.9677 - val_loss: 0.1158 - val_accuracy: 0.9698 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy improved from 0.96985 to 0.97214, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.1078 - accuracy: 0.9632 - val_loss: 0.1076 - val_accuracy: 0.9721 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0896 - accuracy: 0.9703 - val_loss: 0.1189 - val_accuracy: 0.9630 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0993 - accuracy: 0.9675 - val_loss: 0.1240 - val_accuracy: 0.9653 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0819 - accuracy: 0.9723 - val_loss: 0.1139 - val_accuracy: 0.9676 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0768 - accuracy: 0.9735 - val_loss: 0.1229 - val_accuracy: 0.9679 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0851 - accuracy: 0.9729 - val_loss: 0.1279 - val_accuracy: 0.9660 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0837 - accuracy: 0.9722 - val_loss: 0.1169 - val_accuracy: 0.9656 - lr: 0.0376 - 14s/epoch - 37ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0705 - accuracy: 0.9765 - val_loss: 0.0978 - val_accuracy: 0.9706 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0670 - accuracy: 0.9764 - val_loss: 0.1064 - val_accuracy: 0.9718 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0668 - accuracy: 0.9787 - val_loss: 0.1181 - val_accuracy: 0.9706 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0813 - accuracy: 0.9736 - val_loss: 0.1017 - val_accuracy: 0.9706 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0744 - accuracy: 0.9758 - val_loss: 0.1188 - val_accuracy: 0.9676 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0704 - accuracy: 0.9782 - val_loss: 0.1404 - val_accuracy: 0.9637 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0885 - accuracy: 0.9726 - val_loss: 0.1148 - val_accuracy: 0.9687 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0676 - accuracy: 0.9773 - val_loss: 0.1352 - val_accuracy: 0.9618 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.1123 - accuracy: 0.9661 - val_loss: 0.1128 - val_accuracy: 0.9676 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0852 - accuracy: 0.9735 - val_loss: 0.1335 - val_accuracy: 0.9634 - lr: 0.0357 - 14s/epoch - 37ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.97214\n",
            "382/382 - 14s - loss: 0.0668 - accuracy: 0.9777 - val_loss: 0.1389 - val_accuracy: 0.9672 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy improved from 0.97214 to 0.97290, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0657 - accuracy: 0.9770 - val_loss: 0.1023 - val_accuracy: 0.9729 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy improved from 0.97290 to 0.97672, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0579 - accuracy: 0.9819 - val_loss: 0.1059 - val_accuracy: 0.9767 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0674 - accuracy: 0.9779 - val_loss: 0.1199 - val_accuracy: 0.9691 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0659 - accuracy: 0.9766 - val_loss: 0.1081 - val_accuracy: 0.9733 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0763 - accuracy: 0.9757 - val_loss: 0.1286 - val_accuracy: 0.9672 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0605 - accuracy: 0.9793 - val_loss: 0.1122 - val_accuracy: 0.9706 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0546 - accuracy: 0.9823 - val_loss: 0.1126 - val_accuracy: 0.9725 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.1130 - val_accuracy: 0.9748 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0576 - accuracy: 0.9812 - val_loss: 0.1150 - val_accuracy: 0.9721 - lr: 0.0339 - 14s/epoch - 37ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0497 - accuracy: 0.9840 - val_loss: 0.1019 - val_accuracy: 0.9714 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0438 - accuracy: 0.9842 - val_loss: 0.1014 - val_accuracy: 0.9733 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0464 - accuracy: 0.9832 - val_loss: 0.1170 - val_accuracy: 0.9744 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.1166 - val_accuracy: 0.9683 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0698 - accuracy: 0.9793 - val_loss: 0.1028 - val_accuracy: 0.9737 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0543 - accuracy: 0.9827 - val_loss: 0.1282 - val_accuracy: 0.9714 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0554 - accuracy: 0.9818 - val_loss: 0.1080 - val_accuracy: 0.9733 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0461 - accuracy: 0.9847 - val_loss: 0.1184 - val_accuracy: 0.9706 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0481 - accuracy: 0.9845 - val_loss: 0.1291 - val_accuracy: 0.9664 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0517 - accuracy: 0.9849 - val_loss: 0.1072 - val_accuracy: 0.9733 - lr: 0.0322 - 14s/epoch - 37ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.1143 - val_accuracy: 0.9748 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.1114 - accuracy: 0.9693 - val_loss: 0.1406 - val_accuracy: 0.9656 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.97672\n",
            "382/382 - 14s - loss: 0.0742 - accuracy: 0.9763 - val_loss: 0.1147 - val_accuracy: 0.9725 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy improved from 0.97672 to 0.97710, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0511 - accuracy: 0.9841 - val_loss: 0.1049 - val_accuracy: 0.9771 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.97710\n",
            "382/382 - 14s - loss: 0.0420 - accuracy: 0.9858 - val_loss: 0.1146 - val_accuracy: 0.9714 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.97710\n",
            "382/382 - 14s - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.1139 - val_accuracy: 0.9725 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.97710\n",
            "382/382 - 14s - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.1039 - val_accuracy: 0.9752 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.97710\n",
            "382/382 - 14s - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.1187 - val_accuracy: 0.9744 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.97710\n",
            "382/382 - 14s - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.1129 - val_accuracy: 0.9725 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.97710\n",
            "382/382 - 14s - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.1131 - val_accuracy: 0.9729 - lr: 0.0306 - 14s/epoch - 37ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.97710\n",
            "382/382 - 14s - loss: 0.0410 - accuracy: 0.9867 - val_loss: 0.1051 - val_accuracy: 0.9760 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy improved from 0.97710 to 0.97786, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.1057 - val_accuracy: 0.9779 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0350 - accuracy: 0.9887 - val_loss: 0.1201 - val_accuracy: 0.9752 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.0960 - val_accuracy: 0.9763 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.1131 - val_accuracy: 0.9767 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0485 - accuracy: 0.9848 - val_loss: 0.1208 - val_accuracy: 0.9748 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.1075 - val_accuracy: 0.9767 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0335 - accuracy: 0.9897 - val_loss: 0.0985 - val_accuracy: 0.9733 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0382 - accuracy: 0.9885 - val_loss: 0.1055 - val_accuracy: 0.9748 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.1055 - val_accuracy: 0.9763 - lr: 0.0291 - 14s/epoch - 37ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.1146 - val_accuracy: 0.9775 - lr: 0.0276 - 14s/epoch - 37ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.1034 - val_accuracy: 0.9779 - lr: 0.0276 - 14s/epoch - 37ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.97786\n",
            "382/382 - 14s - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.1191 - val_accuracy: 0.9763 - lr: 0.0276 - 14s/epoch - 37ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy improved from 0.97786 to 0.97939, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.1078 - val_accuracy: 0.9794 - lr: 0.0276 - 14s/epoch - 37ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.97939\n",
            "382/382 - 14s - loss: 0.0356 - accuracy: 0.9894 - val_loss: 0.1147 - val_accuracy: 0.9737 - lr: 0.0276 - 14s/epoch - 37ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.97939\n",
            "382/382 - 14s - loss: 0.0342 - accuracy: 0.9892 - val_loss: 0.1377 - val_accuracy: 0.9748 - lr: 0.0276 - 14s/epoch - 37ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.97939\n",
            "382/382 - 14s - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.1126 - val_accuracy: 0.9733 - lr: 0.0276 - 14s/epoch - 36ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.97939\n",
            "382/382 - 14s - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.1179 - val_accuracy: 0.9756 - lr: 0.0276 - 14s/epoch - 36ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy improved from 0.97939 to 0.97977, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.1089 - val_accuracy: 0.9798 - lr: 0.0276 - 14s/epoch - 36ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0347 - accuracy: 0.9894 - val_loss: 0.1211 - val_accuracy: 0.9756 - lr: 0.0276 - 14s/epoch - 36ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0282 - accuracy: 0.9914 - val_loss: 0.1149 - val_accuracy: 0.9756 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.1230 - val_accuracy: 0.9718 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.1251 - val_accuracy: 0.9763 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.1307 - val_accuracy: 0.9721 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.1098 - val_accuracy: 0.9771 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0230 - accuracy: 0.9917 - val_loss: 0.1203 - val_accuracy: 0.9760 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.1250 - val_accuracy: 0.9740 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0239 - accuracy: 0.9935 - val_loss: 0.1056 - val_accuracy: 0.9786 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1105 - val_accuracy: 0.9786 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.1347 - val_accuracy: 0.9767 - lr: 0.0263 - 14s/epoch - 36ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.1169 - val_accuracy: 0.9771 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.1145 - val_accuracy: 0.9756 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.1025 - val_accuracy: 0.9790 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.1085 - val_accuracy: 0.9760 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.1078 - val_accuracy: 0.9794 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0222 - accuracy: 0.9935 - val_loss: 0.1068 - val_accuracy: 0.9771 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.1200 - val_accuracy: 0.9771 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.1153 - val_accuracy: 0.9767 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.1215 - val_accuracy: 0.9779 - lr: 0.0249 - 14s/epoch - 36ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.1011 - val_accuracy: 0.9775 - lr: 0.0249 - 14s/epoch - 37ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.1033 - val_accuracy: 0.9760 - lr: 0.0237 - 14s/epoch - 37ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.1066 - val_accuracy: 0.9767 - lr: 0.0237 - 14s/epoch - 37ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.1110 - val_accuracy: 0.9760 - lr: 0.0237 - 14s/epoch - 37ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.1180 - val_accuracy: 0.9752 - lr: 0.0237 - 14s/epoch - 36ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.97977\n",
            "382/382 - 14s - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.1100 - val_accuracy: 0.9790 - lr: 0.0237 - 14s/epoch - 36ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy improved from 0.97977 to 0.98015, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.1045 - val_accuracy: 0.9802 - lr: 0.0237 - 14s/epoch - 36ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.1077 - val_accuracy: 0.9790 - lr: 0.0237 - 14s/epoch - 36ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.1123 - val_accuracy: 0.9771 - lr: 0.0237 - 14s/epoch - 36ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.1235 - val_accuracy: 0.9760 - lr: 0.0237 - 14s/epoch - 36ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.1094 - val_accuracy: 0.9794 - lr: 0.0237 - 14s/epoch - 36ms/step\n",
            "Epoch 151/250\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.1066 - val_accuracy: 0.9775 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 152/250\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.1174 - val_accuracy: 0.9771 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 153/250\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1118 - val_accuracy: 0.9782 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 154/250\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.1331 - val_accuracy: 0.9767 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 155/250\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.1068 - val_accuracy: 0.9779 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 156/250\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.1117 - val_accuracy: 0.9782 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 157/250\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.1169 - val_accuracy: 0.9782 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 158/250\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.1101 - val_accuracy: 0.9790 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 159/250\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.1331 - val_accuracy: 0.9752 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 160/250\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.98015\n",
            "382/382 - 14s - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.1091 - val_accuracy: 0.9786 - lr: 0.0225 - 14s/epoch - 36ms/step\n",
            "Epoch 161/250\n",
            "\n",
            "Epoch 161: val_accuracy improved from 0.98015 to 0.98053, saving model to saved_models/best_fcn.keras\n",
            "382/382 - 14s - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.1171 - val_accuracy: 0.9805 - lr: 0.0214 - 14s/epoch - 36ms/step\n",
            "Epoch 162/250\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.1127 - val_accuracy: 0.9794 - lr: 0.0214 - 14s/epoch - 36ms/step\n",
            "Epoch 163/250\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.1169 - val_accuracy: 0.9798 - lr: 0.0214 - 14s/epoch - 36ms/step\n",
            "Epoch 164/250\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.1198 - val_accuracy: 0.9775 - lr: 0.0214 - 14s/epoch - 36ms/step\n",
            "Epoch 165/250\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.1185 - val_accuracy: 0.9802 - lr: 0.0214 - 14s/epoch - 36ms/step\n",
            "Epoch 166/250\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.1238 - val_accuracy: 0.9775 - lr: 0.0214 - 14s/epoch - 36ms/step\n",
            "Epoch 167/250\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.1253 - val_accuracy: 0.9782 - lr: 0.0214 - 14s/epoch - 36ms/step\n",
            "Epoch 168/250\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.1127 - val_accuracy: 0.9790 - lr: 0.0214 - 14s/epoch - 36ms/step\n",
            "Epoch 169/250\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.1150 - val_accuracy: 0.9798 - lr: 0.0214 - 14s/epoch - 37ms/step\n",
            "Epoch 170/250\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.1261 - val_accuracy: 0.9771 - lr: 0.0214 - 14s/epoch - 37ms/step\n",
            "Epoch 171/250\n",
            "\n",
            "Epoch 171: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.1249 - val_accuracy: 0.9771 - lr: 0.0203 - 14s/epoch - 37ms/step\n",
            "Epoch 172/250\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.1199 - val_accuracy: 0.9790 - lr: 0.0203 - 14s/epoch - 37ms/step\n",
            "Epoch 173/250\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.1131 - val_accuracy: 0.9790 - lr: 0.0203 - 14s/epoch - 36ms/step\n",
            "Epoch 174/250\n",
            "\n",
            "Epoch 174: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.1250 - val_accuracy: 0.9790 - lr: 0.0203 - 14s/epoch - 36ms/step\n",
            "Epoch 175/250\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.1140 - val_accuracy: 0.9794 - lr: 0.0203 - 14s/epoch - 36ms/step\n",
            "Epoch 176/250\n",
            "\n",
            "Epoch 176: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.1173 - val_accuracy: 0.9790 - lr: 0.0203 - 14s/epoch - 36ms/step\n",
            "Epoch 177/250\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.1248 - val_accuracy: 0.9782 - lr: 0.0203 - 14s/epoch - 36ms/step\n",
            "Epoch 178/250\n",
            "\n",
            "Epoch 178: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.1226 - val_accuracy: 0.9767 - lr: 0.0203 - 14s/epoch - 36ms/step\n",
            "Epoch 179/250\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.1196 - val_accuracy: 0.9767 - lr: 0.0203 - 14s/epoch - 36ms/step\n",
            "Epoch 180/250\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.1110 - val_accuracy: 0.9786 - lr: 0.0203 - 14s/epoch - 36ms/step\n",
            "Epoch 181/250\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.1169 - val_accuracy: 0.9782 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 182/250\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1123 - val_accuracy: 0.9782 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 183/250\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1148 - val_accuracy: 0.9786 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 184/250\n",
            "\n",
            "Epoch 184: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1192 - val_accuracy: 0.9790 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 185/250\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.1276 - val_accuracy: 0.9775 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 186/250\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1270 - val_accuracy: 0.9779 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 187/250\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.1156 - val_accuracy: 0.9775 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 188/250\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.1181 - val_accuracy: 0.9767 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 189/250\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0184 - accuracy: 0.9952 - val_loss: 0.1191 - val_accuracy: 0.9760 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 190/250\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.1096 - val_accuracy: 0.9790 - lr: 0.0193 - 14s/epoch - 36ms/step\n",
            "Epoch 191/250\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.98053\n",
            "382/382 - 14s - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.1085 - val_accuracy: 0.9786 - lr: 0.0183 - 14s/epoch - 36ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 03:45:41,250] Trial 15 finished with value: 0.981 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.04858207421349849, 'batch_size': 32, 'dropout_ratio': 0.35244668692755876, 'decay': 0.8405449244790214}. Best is trial 9 with value: 0.981.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_152 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_153 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_70 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_154 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_155 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 8 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.39504, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 15s - loss: 1.9436 - accuracy: 0.2965 - val_loss: 1.7219 - val_accuracy: 0.3950 - lr: 0.0398 - 15s/epoch - 156ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.39504 to 0.46679, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.6559 - accuracy: 0.4158 - val_loss: 1.5136 - val_accuracy: 0.4668 - lr: 0.0398 - 14s/epoch - 144ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.46679\n",
            "96/96 - 14s - loss: 1.4780 - accuracy: 0.4862 - val_loss: 1.6797 - val_accuracy: 0.3847 - lr: 0.0398 - 14s/epoch - 144ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.46679 to 0.55229, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.3452 - accuracy: 0.5317 - val_loss: 1.2519 - val_accuracy: 0.5523 - lr: 0.0398 - 14s/epoch - 144ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.55229\n",
            "96/96 - 14s - loss: 1.2397 - accuracy: 0.5713 - val_loss: 1.3927 - val_accuracy: 0.4992 - lr: 0.0398 - 14s/epoch - 144ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.55229 to 0.57290, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.1643 - accuracy: 0.5964 - val_loss: 1.2328 - val_accuracy: 0.5729 - lr: 0.0398 - 14s/epoch - 146ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.57290 to 0.58015, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.0858 - accuracy: 0.6331 - val_loss: 1.1904 - val_accuracy: 0.5802 - lr: 0.0398 - 14s/epoch - 148ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.58015\n",
            "96/96 - 14s - loss: 1.0037 - accuracy: 0.6495 - val_loss: 1.1910 - val_accuracy: 0.5767 - lr: 0.0398 - 14s/epoch - 146ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.58015 to 0.67023, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.9567 - accuracy: 0.6722 - val_loss: 0.9620 - val_accuracy: 0.6702 - lr: 0.0398 - 14s/epoch - 145ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.67023 to 0.74733, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.8863 - accuracy: 0.6984 - val_loss: 0.7899 - val_accuracy: 0.7473 - lr: 0.0398 - 14s/epoch - 145ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.74733\n",
            "96/96 - 14s - loss: 0.8172 - accuracy: 0.7244 - val_loss: 0.8040 - val_accuracy: 0.7374 - lr: 0.0378 - 14s/epoch - 145ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.74733 to 0.77748, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.7795 - accuracy: 0.7358 - val_loss: 0.7024 - val_accuracy: 0.7775 - lr: 0.0378 - 14s/epoch - 146ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.77748\n",
            "96/96 - 14s - loss: 0.7627 - accuracy: 0.7498 - val_loss: 0.7257 - val_accuracy: 0.7607 - lr: 0.0378 - 14s/epoch - 145ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.77748\n",
            "96/96 - 14s - loss: 0.6864 - accuracy: 0.7707 - val_loss: 0.7672 - val_accuracy: 0.7321 - lr: 0.0378 - 14s/epoch - 144ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.77748\n",
            "96/96 - 14s - loss: 0.6751 - accuracy: 0.7746 - val_loss: 0.6719 - val_accuracy: 0.7775 - lr: 0.0378 - 14s/epoch - 143ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.77748\n",
            "96/96 - 14s - loss: 0.6246 - accuracy: 0.7890 - val_loss: 0.7015 - val_accuracy: 0.7653 - lr: 0.0378 - 14s/epoch - 143ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.77748 to 0.80038, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.5943 - accuracy: 0.8024 - val_loss: 0.5782 - val_accuracy: 0.8004 - lr: 0.0378 - 14s/epoch - 144ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.80038 to 0.81565, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.5532 - accuracy: 0.8163 - val_loss: 0.5451 - val_accuracy: 0.8156 - lr: 0.0378 - 14s/epoch - 144ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.81565 to 0.81908, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.5669 - accuracy: 0.8095 - val_loss: 0.5331 - val_accuracy: 0.8191 - lr: 0.0378 - 14s/epoch - 144ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.81908 to 0.83359, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.5040 - accuracy: 0.8287 - val_loss: 0.5233 - val_accuracy: 0.8336 - lr: 0.0378 - 14s/epoch - 143ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.83359 to 0.83588, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.4877 - accuracy: 0.8374 - val_loss: 0.4748 - val_accuracy: 0.8359 - lr: 0.0359 - 14s/epoch - 143ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.83588\n",
            "96/96 - 14s - loss: 0.4582 - accuracy: 0.8420 - val_loss: 0.5227 - val_accuracy: 0.8282 - lr: 0.0359 - 14s/epoch - 142ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.83588 to 0.83779, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.4428 - accuracy: 0.8514 - val_loss: 0.4968 - val_accuracy: 0.8378 - lr: 0.0359 - 14s/epoch - 143ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.83779\n",
            "96/96 - 14s - loss: 0.4287 - accuracy: 0.8520 - val_loss: 0.5371 - val_accuracy: 0.8221 - lr: 0.0359 - 14s/epoch - 143ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.83779\n",
            "96/96 - 14s - loss: 0.4021 - accuracy: 0.8640 - val_loss: 0.4907 - val_accuracy: 0.8282 - lr: 0.0359 - 14s/epoch - 143ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.83779 to 0.86298, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.3920 - accuracy: 0.8676 - val_loss: 0.4189 - val_accuracy: 0.8630 - lr: 0.0359 - 14s/epoch - 143ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.86298 to 0.88550, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.3801 - accuracy: 0.8694 - val_loss: 0.3502 - val_accuracy: 0.8855 - lr: 0.0359 - 14s/epoch - 143ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.88550 to 0.89313, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.3550 - accuracy: 0.8800 - val_loss: 0.3382 - val_accuracy: 0.8931 - lr: 0.0359 - 14s/epoch - 142ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.89313\n",
            "96/96 - 14s - loss: 0.3374 - accuracy: 0.8877 - val_loss: 0.4468 - val_accuracy: 0.8496 - lr: 0.0359 - 14s/epoch - 142ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.89313\n",
            "96/96 - 14s - loss: 0.3377 - accuracy: 0.8838 - val_loss: 0.3262 - val_accuracy: 0.8916 - lr: 0.0359 - 14s/epoch - 142ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy improved from 0.89313 to 0.90802, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.3133 - accuracy: 0.8946 - val_loss: 0.3056 - val_accuracy: 0.9080 - lr: 0.0341 - 14s/epoch - 143ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.90802\n",
            "96/96 - 14s - loss: 0.3110 - accuracy: 0.8953 - val_loss: 0.3543 - val_accuracy: 0.8809 - lr: 0.0341 - 14s/epoch - 142ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.90802\n",
            "96/96 - 14s - loss: 0.2907 - accuracy: 0.9009 - val_loss: 0.3057 - val_accuracy: 0.8962 - lr: 0.0341 - 14s/epoch - 142ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.90802\n",
            "96/96 - 14s - loss: 0.2787 - accuracy: 0.9053 - val_loss: 0.5048 - val_accuracy: 0.8332 - lr: 0.0341 - 14s/epoch - 142ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.90802 to 0.91603, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.2769 - accuracy: 0.9095 - val_loss: 0.2661 - val_accuracy: 0.9160 - lr: 0.0341 - 14s/epoch - 143ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.91603\n",
            "96/96 - 14s - loss: 0.2606 - accuracy: 0.9121 - val_loss: 0.2926 - val_accuracy: 0.9008 - lr: 0.0341 - 14s/epoch - 146ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.91603\n",
            "96/96 - 14s - loss: 0.2525 - accuracy: 0.9143 - val_loss: 0.2645 - val_accuracy: 0.9122 - lr: 0.0341 - 14s/epoch - 146ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.91603\n",
            "96/96 - 14s - loss: 0.2371 - accuracy: 0.9196 - val_loss: 0.3200 - val_accuracy: 0.8935 - lr: 0.0341 - 14s/epoch - 144ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.91603\n",
            "96/96 - 14s - loss: 0.2246 - accuracy: 0.9265 - val_loss: 0.2862 - val_accuracy: 0.9092 - lr: 0.0341 - 14s/epoch - 144ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy improved from 0.91603 to 0.92710, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.2539 - accuracy: 0.9155 - val_loss: 0.2266 - val_accuracy: 0.9271 - lr: 0.0341 - 14s/epoch - 144ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.92710\n",
            "96/96 - 14s - loss: 0.2149 - accuracy: 0.9326 - val_loss: 0.2241 - val_accuracy: 0.9263 - lr: 0.0324 - 14s/epoch - 144ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.92710 to 0.92748, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.2176 - accuracy: 0.9265 - val_loss: 0.2284 - val_accuracy: 0.9275 - lr: 0.0324 - 14s/epoch - 145ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.92748\n",
            "96/96 - 14s - loss: 0.2081 - accuracy: 0.9301 - val_loss: 0.3133 - val_accuracy: 0.8908 - lr: 0.0324 - 14s/epoch - 144ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.92748\n",
            "96/96 - 14s - loss: 0.1966 - accuracy: 0.9344 - val_loss: 0.2412 - val_accuracy: 0.9210 - lr: 0.0324 - 14s/epoch - 144ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.92748\n",
            "96/96 - 14s - loss: 0.1948 - accuracy: 0.9342 - val_loss: 0.2432 - val_accuracy: 0.9252 - lr: 0.0324 - 14s/epoch - 144ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.92748\n",
            "96/96 - 14s - loss: 0.1912 - accuracy: 0.9378 - val_loss: 0.2572 - val_accuracy: 0.9195 - lr: 0.0324 - 14s/epoch - 144ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.92748\n",
            "96/96 - 14s - loss: 0.1710 - accuracy: 0.9445 - val_loss: 0.4120 - val_accuracy: 0.8691 - lr: 0.0324 - 14s/epoch - 144ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.92748\n",
            "96/96 - 14s - loss: 0.1805 - accuracy: 0.9415 - val_loss: 0.2691 - val_accuracy: 0.9034 - lr: 0.0324 - 14s/epoch - 144ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.92748\n",
            "96/96 - 14s - loss: 0.1701 - accuracy: 0.9431 - val_loss: 0.2427 - val_accuracy: 0.9260 - lr: 0.0324 - 14s/epoch - 144ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy improved from 0.92748 to 0.93779, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1758 - accuracy: 0.9427 - val_loss: 0.1913 - val_accuracy: 0.9378 - lr: 0.0324 - 14s/epoch - 145ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.93779\n",
            "96/96 - 14s - loss: 0.1490 - accuracy: 0.9522 - val_loss: 0.2092 - val_accuracy: 0.9294 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.93779\n",
            "96/96 - 14s - loss: 0.1697 - accuracy: 0.9432 - val_loss: 0.1918 - val_accuracy: 0.9366 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.93779\n",
            "96/96 - 14s - loss: 0.1570 - accuracy: 0.9494 - val_loss: 0.2335 - val_accuracy: 0.9191 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.93779\n",
            "96/96 - 14s - loss: 0.1461 - accuracy: 0.9496 - val_loss: 0.2436 - val_accuracy: 0.9187 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy improved from 0.93779 to 0.95153, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1417 - accuracy: 0.9545 - val_loss: 0.1579 - val_accuracy: 0.9515 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.95153\n",
            "96/96 - 14s - loss: 0.1389 - accuracy: 0.9544 - val_loss: 0.1741 - val_accuracy: 0.9435 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.95153\n",
            "96/96 - 14s - loss: 0.1318 - accuracy: 0.9571 - val_loss: 0.1943 - val_accuracy: 0.9309 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.95153\n",
            "96/96 - 14s - loss: 0.1247 - accuracy: 0.9581 - val_loss: 0.3158 - val_accuracy: 0.9019 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.95153\n",
            "96/96 - 14s - loss: 0.1324 - accuracy: 0.9540 - val_loss: 0.1432 - val_accuracy: 0.9504 - lr: 0.0308 - 14s/epoch - 144ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy improved from 0.95153 to 0.95802, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1158 - accuracy: 0.9612 - val_loss: 0.1312 - val_accuracy: 0.9580 - lr: 0.0308 - 14s/epoch - 145ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.1147 - accuracy: 0.9634 - val_loss: 0.1478 - val_accuracy: 0.9561 - lr: 0.0292 - 14s/epoch - 144ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.1159 - accuracy: 0.9630 - val_loss: 0.1370 - val_accuracy: 0.9573 - lr: 0.0292 - 14s/epoch - 144ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.1180 - accuracy: 0.9606 - val_loss: 0.1955 - val_accuracy: 0.9378 - lr: 0.0292 - 14s/epoch - 144ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.1201 - accuracy: 0.9599 - val_loss: 0.2172 - val_accuracy: 0.9290 - lr: 0.0292 - 14s/epoch - 144ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.1096 - accuracy: 0.9661 - val_loss: 0.1872 - val_accuracy: 0.9424 - lr: 0.0292 - 14s/epoch - 144ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.1240 - accuracy: 0.9580 - val_loss: 0.1967 - val_accuracy: 0.9351 - lr: 0.0292 - 14s/epoch - 144ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.1026 - accuracy: 0.9679 - val_loss: 0.1583 - val_accuracy: 0.9515 - lr: 0.0292 - 14s/epoch - 144ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.0996 - accuracy: 0.9678 - val_loss: 0.1879 - val_accuracy: 0.9447 - lr: 0.0292 - 14s/epoch - 144ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.0988 - accuracy: 0.9677 - val_loss: 0.1616 - val_accuracy: 0.9508 - lr: 0.0292 - 14s/epoch - 143ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.0940 - accuracy: 0.9689 - val_loss: 0.1573 - val_accuracy: 0.9523 - lr: 0.0292 - 14s/epoch - 143ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.0900 - accuracy: 0.9702 - val_loss: 0.1460 - val_accuracy: 0.9546 - lr: 0.0278 - 14s/epoch - 144ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.95802\n",
            "96/96 - 14s - loss: 0.0929 - accuracy: 0.9689 - val_loss: 0.1512 - val_accuracy: 0.9511 - lr: 0.0278 - 14s/epoch - 144ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy improved from 0.95802 to 0.96565, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1007 - accuracy: 0.9670 - val_loss: 0.1171 - val_accuracy: 0.9656 - lr: 0.0278 - 14s/epoch - 145ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0867 - accuracy: 0.9723 - val_loss: 0.1426 - val_accuracy: 0.9523 - lr: 0.0278 - 14s/epoch - 144ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0811 - accuracy: 0.9742 - val_loss: 0.1175 - val_accuracy: 0.9637 - lr: 0.0278 - 14s/epoch - 143ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0914 - accuracy: 0.9715 - val_loss: 0.1501 - val_accuracy: 0.9546 - lr: 0.0278 - 14s/epoch - 144ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0829 - accuracy: 0.9748 - val_loss: 0.1278 - val_accuracy: 0.9626 - lr: 0.0278 - 14s/epoch - 144ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0765 - accuracy: 0.9773 - val_loss: 0.1115 - val_accuracy: 0.9641 - lr: 0.0278 - 14s/epoch - 144ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0753 - accuracy: 0.9743 - val_loss: 0.1356 - val_accuracy: 0.9588 - lr: 0.0278 - 14s/epoch - 144ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0741 - accuracy: 0.9764 - val_loss: 0.1322 - val_accuracy: 0.9576 - lr: 0.0278 - 14s/epoch - 144ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0720 - accuracy: 0.9769 - val_loss: 0.1104 - val_accuracy: 0.9656 - lr: 0.0264 - 14s/epoch - 143ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0726 - accuracy: 0.9767 - val_loss: 0.1168 - val_accuracy: 0.9634 - lr: 0.0264 - 14s/epoch - 144ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0714 - accuracy: 0.9782 - val_loss: 0.1605 - val_accuracy: 0.9462 - lr: 0.0264 - 14s/epoch - 144ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0722 - accuracy: 0.9775 - val_loss: 0.1510 - val_accuracy: 0.9546 - lr: 0.0264 - 14s/epoch - 144ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.96565\n",
            "96/96 - 14s - loss: 0.0691 - accuracy: 0.9779 - val_loss: 0.1986 - val_accuracy: 0.9435 - lr: 0.0264 - 14s/epoch - 144ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy improved from 0.96565 to 0.96603, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0775 - accuracy: 0.9749 - val_loss: 0.1160 - val_accuracy: 0.9660 - lr: 0.0264 - 14s/epoch - 144ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy improved from 0.96603 to 0.96641, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0735 - accuracy: 0.9780 - val_loss: 0.1081 - val_accuracy: 0.9664 - lr: 0.0264 - 14s/epoch - 144ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy improved from 0.96641 to 0.97023, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0678 - accuracy: 0.9777 - val_loss: 0.1092 - val_accuracy: 0.9702 - lr: 0.0264 - 14s/epoch - 145ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy improved from 0.97023 to 0.97061, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.1018 - val_accuracy: 0.9706 - lr: 0.0264 - 14s/epoch - 145ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.97061\n",
            "96/96 - 14s - loss: 0.0633 - accuracy: 0.9794 - val_loss: 0.1069 - val_accuracy: 0.9656 - lr: 0.0264 - 14s/epoch - 144ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.97061\n",
            "96/96 - 14s - loss: 0.0554 - accuracy: 0.9823 - val_loss: 0.1090 - val_accuracy: 0.9653 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.97061\n",
            "96/96 - 14s - loss: 0.0558 - accuracy: 0.9826 - val_loss: 0.1243 - val_accuracy: 0.9622 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy improved from 0.97061 to 0.97443, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0531 - accuracy: 0.9839 - val_loss: 0.0951 - val_accuracy: 0.9744 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0556 - accuracy: 0.9834 - val_loss: 0.0994 - val_accuracy: 0.9687 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.1184 - val_accuracy: 0.9637 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0541 - accuracy: 0.9833 - val_loss: 0.0915 - val_accuracy: 0.9702 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0598 - accuracy: 0.9819 - val_loss: 0.0944 - val_accuracy: 0.9740 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.1074 - val_accuracy: 0.9687 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.1235 - val_accuracy: 0.9641 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.0999 - val_accuracy: 0.9683 - lr: 0.0251 - 14s/epoch - 144ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0530 - accuracy: 0.9835 - val_loss: 0.0945 - val_accuracy: 0.9740 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0585 - accuracy: 0.9823 - val_loss: 0.1050 - val_accuracy: 0.9683 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0576 - accuracy: 0.9829 - val_loss: 0.0971 - val_accuracy: 0.9725 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0487 - accuracy: 0.9859 - val_loss: 0.1134 - val_accuracy: 0.9687 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0497 - accuracy: 0.9840 - val_loss: 0.0915 - val_accuracy: 0.9718 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0498 - accuracy: 0.9852 - val_loss: 0.1477 - val_accuracy: 0.9561 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0480 - accuracy: 0.9862 - val_loss: 0.1037 - val_accuracy: 0.9714 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0497 - accuracy: 0.9836 - val_loss: 0.3725 - val_accuracy: 0.9099 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.1000 - val_accuracy: 0.9695 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0446 - accuracy: 0.9858 - val_loss: 0.0955 - val_accuracy: 0.9737 - lr: 0.0238 - 14s/epoch - 144ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0427 - accuracy: 0.9876 - val_loss: 0.1020 - val_accuracy: 0.9725 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.1213 - val_accuracy: 0.9653 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0433 - accuracy: 0.9875 - val_loss: 0.1566 - val_accuracy: 0.9588 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0494 - accuracy: 0.9848 - val_loss: 0.1094 - val_accuracy: 0.9710 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.0922 - val_accuracy: 0.9740 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0454 - accuracy: 0.9867 - val_loss: 0.0975 - val_accuracy: 0.9733 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0450 - accuracy: 0.9865 - val_loss: 0.1274 - val_accuracy: 0.9615 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0476 - accuracy: 0.9845 - val_loss: 0.1169 - val_accuracy: 0.9649 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy improved from 0.97443 to 0.97595, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0400 - accuracy: 0.9875 - val_loss: 0.0918 - val_accuracy: 0.9760 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.97595\n",
            "96/96 - 14s - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.1081 - val_accuracy: 0.9691 - lr: 0.0226 - 14s/epoch - 144ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.97595\n",
            "96/96 - 14s - loss: 0.0418 - accuracy: 0.9872 - val_loss: 0.1067 - val_accuracy: 0.9706 - lr: 0.0215 - 14s/epoch - 144ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.97595\n",
            "96/96 - 14s - loss: 0.0361 - accuracy: 0.9898 - val_loss: 0.0870 - val_accuracy: 0.9760 - lr: 0.0215 - 14s/epoch - 144ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy improved from 0.97595 to 0.97710, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0833 - val_accuracy: 0.9771 - lr: 0.0215 - 14s/epoch - 144ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0383 - accuracy: 0.9892 - val_loss: 0.1118 - val_accuracy: 0.9710 - lr: 0.0215 - 14s/epoch - 143ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0390 - accuracy: 0.9885 - val_loss: 0.0838 - val_accuracy: 0.9767 - lr: 0.0215 - 14s/epoch - 144ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0903 - val_accuracy: 0.9752 - lr: 0.0215 - 14s/epoch - 144ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0873 - val_accuracy: 0.9767 - lr: 0.0215 - 14s/epoch - 144ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0993 - val_accuracy: 0.9744 - lr: 0.0215 - 14s/epoch - 144ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0384 - accuracy: 0.9876 - val_loss: 0.0829 - val_accuracy: 0.9767 - lr: 0.0215 - 14s/epoch - 143ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0351 - accuracy: 0.9901 - val_loss: 0.0936 - val_accuracy: 0.9752 - lr: 0.0215 - 14s/epoch - 144ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0369 - accuracy: 0.9892 - val_loss: 0.0826 - val_accuracy: 0.9760 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0336 - accuracy: 0.9902 - val_loss: 0.0865 - val_accuracy: 0.9771 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.0889 - val_accuracy: 0.9760 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0316 - accuracy: 0.9902 - val_loss: 0.0975 - val_accuracy: 0.9760 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.97710\n",
            "96/96 - 14s - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.0879 - val_accuracy: 0.9752 - lr: 0.0204 - 14s/epoch - 143ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy improved from 0.97710 to 0.97939, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.0798 - val_accuracy: 0.9794 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.97939\n",
            "96/96 - 14s - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.0887 - val_accuracy: 0.9767 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.97939\n",
            "96/96 - 14s - loss: 0.0353 - accuracy: 0.9899 - val_loss: 0.0942 - val_accuracy: 0.9752 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.97939\n",
            "96/96 - 14s - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.0903 - val_accuracy: 0.9771 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.97939\n",
            "96/96 - 14s - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.0938 - val_accuracy: 0.9733 - lr: 0.0204 - 14s/epoch - 144ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.97939\n",
            "96/96 - 14s - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.0852 - val_accuracy: 0.9767 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.97939\n",
            "96/96 - 14s - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.0868 - val_accuracy: 0.9775 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy improved from 0.97939 to 0.97977, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.0948 - val_accuracy: 0.9798 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.97977\n",
            "96/96 - 14s - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0949 - val_accuracy: 0.9767 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.97977\n",
            "96/96 - 14s - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.0831 - val_accuracy: 0.9786 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.97977\n",
            "96/96 - 14s - loss: 0.0309 - accuracy: 0.9906 - val_loss: 0.0834 - val_accuracy: 0.9775 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.97977\n",
            "96/96 - 14s - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.0810 - val_accuracy: 0.9775 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.97977\n",
            "96/96 - 14s - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.0777 - val_accuracy: 0.9790 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.97977\n",
            "96/96 - 14s - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.1065 - val_accuracy: 0.9698 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy improved from 0.97977 to 0.98053, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.0858 - val_accuracy: 0.9805 - lr: 0.0194 - 14s/epoch - 144ms/step\n",
            "Epoch 151/250\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0943 - val_accuracy: 0.9752 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 152/250\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.0899 - val_accuracy: 0.9775 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 153/250\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0257 - accuracy: 0.9924 - val_loss: 0.0812 - val_accuracy: 0.9775 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 154/250\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0249 - accuracy: 0.9929 - val_loss: 0.0804 - val_accuracy: 0.9786 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 155/250\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0944 - val_accuracy: 0.9775 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 156/250\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.1042 - val_accuracy: 0.9687 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 157/250\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.0890 - val_accuracy: 0.9767 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 158/250\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.0933 - val_accuracy: 0.9760 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 159/250\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0247 - accuracy: 0.9930 - val_loss: 0.0912 - val_accuracy: 0.9756 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 160/250\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.0825 - val_accuracy: 0.9771 - lr: 0.0184 - 14s/epoch - 144ms/step\n",
            "Epoch 161/250\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0814 - val_accuracy: 0.9802 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 162/250\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.0868 - val_accuracy: 0.9767 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 163/250\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.0863 - val_accuracy: 0.9740 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 164/250\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0863 - val_accuracy: 0.9790 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 165/250\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.0779 - val_accuracy: 0.9786 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 166/250\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0249 - accuracy: 0.9934 - val_loss: 0.1036 - val_accuracy: 0.9744 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 167/250\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.0863 - val_accuracy: 0.9782 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 168/250\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0810 - val_accuracy: 0.9802 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 169/250\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.0821 - val_accuracy: 0.9794 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 170/250\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0251 - accuracy: 0.9935 - val_loss: 0.0875 - val_accuracy: 0.9782 - lr: 0.0175 - 14s/epoch - 144ms/step\n",
            "Epoch 171/250\n",
            "\n",
            "Epoch 171: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0898 - val_accuracy: 0.9775 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 172/250\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.0814 - val_accuracy: 0.9779 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 173/250\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.98053\n",
            "96/96 - 14s - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.0847 - val_accuracy: 0.9786 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 174/250\n",
            "\n",
            "Epoch 174: val_accuracy improved from 0.98053 to 0.98168, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0791 - val_accuracy: 0.9817 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 175/250\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.0840 - val_accuracy: 0.9767 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 176/250\n",
            "\n",
            "Epoch 176: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0875 - val_accuracy: 0.9790 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 177/250\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.0828 - val_accuracy: 0.9798 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 178/250\n",
            "\n",
            "Epoch 178: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.0895 - val_accuracy: 0.9775 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 179/250\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.0998 - val_accuracy: 0.9737 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 180/250\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0901 - val_accuracy: 0.9786 - lr: 0.0166 - 14s/epoch - 144ms/step\n",
            "Epoch 181/250\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0199 - accuracy: 0.9944 - val_loss: 0.0827 - val_accuracy: 0.9794 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 182/250\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.0874 - val_accuracy: 0.9786 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 183/250\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0806 - val_accuracy: 0.9786 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 184/250\n",
            "\n",
            "Epoch 184: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0838 - val_accuracy: 0.9775 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 185/250\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0887 - val_accuracy: 0.9798 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 186/250\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.0895 - val_accuracy: 0.9805 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 187/250\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.0894 - val_accuracy: 0.9763 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 188/250\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.0880 - val_accuracy: 0.9790 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 189/250\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.0925 - val_accuracy: 0.9771 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 190/250\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.0985 - val_accuracy: 0.9752 - lr: 0.0158 - 14s/epoch - 144ms/step\n",
            "Epoch 191/250\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.0853 - val_accuracy: 0.9798 - lr: 0.0150 - 14s/epoch - 144ms/step\n",
            "Epoch 192/250\n",
            "\n",
            "Epoch 192: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0844 - val_accuracy: 0.9798 - lr: 0.0150 - 14s/epoch - 144ms/step\n",
            "Epoch 193/250\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0933 - val_accuracy: 0.9794 - lr: 0.0150 - 14s/epoch - 144ms/step\n",
            "Epoch 194/250\n",
            "\n",
            "Epoch 194: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0172 - accuracy: 0.9956 - val_loss: 0.0845 - val_accuracy: 0.9767 - lr: 0.0150 - 14s/epoch - 143ms/step\n",
            "Epoch 195/250\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0831 - val_accuracy: 0.9805 - lr: 0.0150 - 14s/epoch - 143ms/step\n",
            "Epoch 196/250\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.1052 - val_accuracy: 0.9706 - lr: 0.0150 - 14s/epoch - 143ms/step\n",
            "Epoch 197/250\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0988 - val_accuracy: 0.9733 - lr: 0.0150 - 14s/epoch - 143ms/step\n",
            "Epoch 198/250\n",
            "\n",
            "Epoch 198: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.0859 - val_accuracy: 0.9794 - lr: 0.0150 - 14s/epoch - 143ms/step\n",
            "Epoch 199/250\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.1023 - val_accuracy: 0.9771 - lr: 0.0150 - 14s/epoch - 143ms/step\n",
            "Epoch 200/250\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.0960 - val_accuracy: 0.9779 - lr: 0.0150 - 14s/epoch - 144ms/step\n",
            "Epoch 201/250\n",
            "\n",
            "Epoch 201: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0879 - val_accuracy: 0.9805 - lr: 0.0143 - 14s/epoch - 144ms/step\n",
            "Epoch 202/250\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.0821 - val_accuracy: 0.9798 - lr: 0.0143 - 14s/epoch - 144ms/step\n",
            "Epoch 203/250\n",
            "\n",
            "Epoch 203: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.0843 - val_accuracy: 0.9790 - lr: 0.0143 - 14s/epoch - 144ms/step\n",
            "Epoch 204/250\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.98168\n",
            "96/96 - 14s - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0902 - val_accuracy: 0.9771 - lr: 0.0143 - 14s/epoch - 144ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 04:32:41,378] Trial 16 finished with value: 0.982 and parameters: {'optimizer': 'SGD', 'learning_rate': 0.03975771983403553, 'batch_size': 128, 'dropout_ratio': 0.12175087285280539, 'decay': 0.8750989791052}. Best is trial 16 with value: 0.982.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_156 (Conv2D)         (None, 38, 171, 32)       288       \n",
            "                                                                 \n",
            " conv2d_157 (Conv2D)         (None, 37, 168, 64)       16448     \n",
            "                                                                 \n",
            " max_pooling2d_71 (MaxPooli  (None, 18, 84, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_158 (Conv2D)         (None, 17, 81, 128)       65664     \n",
            "                                                                 \n",
            " conv2d_159 (Conv2D)         (None, 16, 78, 256)       262400    \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 256)               0         \n",
            " 9 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347370 (1.33 MB)\n",
            "Trainable params: 347370 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.32137, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 15s - loss: 2.0428 - accuracy: 0.2433 - val_loss: 1.8779 - val_accuracy: 0.3214 - lr: 0.0242 - 15s/epoch - 157ms/step\n",
            "Epoch 2/250\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.32137 to 0.38702, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.7795 - accuracy: 0.3671 - val_loss: 1.7002 - val_accuracy: 0.3870 - lr: 0.0242 - 14s/epoch - 147ms/step\n",
            "Epoch 3/250\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.38702 to 0.41985, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.6340 - accuracy: 0.4255 - val_loss: 1.6211 - val_accuracy: 0.4198 - lr: 0.0242 - 14s/epoch - 147ms/step\n",
            "Epoch 4/250\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.41985 to 0.43168, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.5153 - accuracy: 0.4706 - val_loss: 1.5346 - val_accuracy: 0.4317 - lr: 0.0242 - 14s/epoch - 147ms/step\n",
            "Epoch 5/250\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.43168 to 0.51183, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.4108 - accuracy: 0.5127 - val_loss: 1.3715 - val_accuracy: 0.5118 - lr: 0.0242 - 14s/epoch - 147ms/step\n",
            "Epoch 6/250\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.51183\n",
            "96/96 - 14s - loss: 1.3262 - accuracy: 0.5435 - val_loss: 1.3414 - val_accuracy: 0.5065 - lr: 0.0242 - 14s/epoch - 146ms/step\n",
            "Epoch 7/250\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.51183 to 0.52290, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.2551 - accuracy: 0.5652 - val_loss: 1.4085 - val_accuracy: 0.5229 - lr: 0.0242 - 14s/epoch - 146ms/step\n",
            "Epoch 8/250\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.52290 to 0.53817, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.1945 - accuracy: 0.5920 - val_loss: 1.2096 - val_accuracy: 0.5382 - lr: 0.0242 - 14s/epoch - 146ms/step\n",
            "Epoch 9/250\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.53817 to 0.61527, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.1264 - accuracy: 0.6128 - val_loss: 1.0501 - val_accuracy: 0.6153 - lr: 0.0242 - 14s/epoch - 146ms/step\n",
            "Epoch 10/250\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.61527 to 0.63053, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.0626 - accuracy: 0.6352 - val_loss: 1.0678 - val_accuracy: 0.6305 - lr: 0.0242 - 14s/epoch - 146ms/step\n",
            "Epoch 11/250\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.63053 to 0.65840, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 1.0102 - accuracy: 0.6527 - val_loss: 0.9930 - val_accuracy: 0.6584 - lr: 0.0230 - 14s/epoch - 146ms/step\n",
            "Epoch 12/250\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.65840 to 0.69466, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.9634 - accuracy: 0.6765 - val_loss: 0.8898 - val_accuracy: 0.6947 - lr: 0.0230 - 14s/epoch - 146ms/step\n",
            "Epoch 13/250\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.69466\n",
            "96/96 - 14s - loss: 0.9220 - accuracy: 0.6868 - val_loss: 0.9302 - val_accuracy: 0.6870 - lr: 0.0230 - 14s/epoch - 145ms/step\n",
            "Epoch 14/250\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.69466\n",
            "96/96 - 14s - loss: 0.8734 - accuracy: 0.7002 - val_loss: 1.0411 - val_accuracy: 0.6225 - lr: 0.0230 - 14s/epoch - 145ms/step\n",
            "Epoch 15/250\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.69466 to 0.72672, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.8398 - accuracy: 0.7210 - val_loss: 0.7774 - val_accuracy: 0.7267 - lr: 0.0230 - 14s/epoch - 145ms/step\n",
            "Epoch 16/250\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.72672 to 0.75191, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.8100 - accuracy: 0.7268 - val_loss: 0.7341 - val_accuracy: 0.7519 - lr: 0.0230 - 14s/epoch - 145ms/step\n",
            "Epoch 17/250\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.75191 to 0.76527, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.7741 - accuracy: 0.7445 - val_loss: 0.7023 - val_accuracy: 0.7653 - lr: 0.0230 - 14s/epoch - 145ms/step\n",
            "Epoch 18/250\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.76527\n",
            "96/96 - 14s - loss: 0.7506 - accuracy: 0.7460 - val_loss: 0.7688 - val_accuracy: 0.7412 - lr: 0.0230 - 14s/epoch - 144ms/step\n",
            "Epoch 19/250\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.76527 to 0.78511, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.7134 - accuracy: 0.7600 - val_loss: 0.6586 - val_accuracy: 0.7851 - lr: 0.0230 - 14s/epoch - 145ms/step\n",
            "Epoch 20/250\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.78511 to 0.79008, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.7027 - accuracy: 0.7657 - val_loss: 0.6416 - val_accuracy: 0.7901 - lr: 0.0230 - 14s/epoch - 145ms/step\n",
            "Epoch 21/250\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.79008\n",
            "96/96 - 14s - loss: 0.6625 - accuracy: 0.7759 - val_loss: 0.6747 - val_accuracy: 0.7718 - lr: 0.0218 - 14s/epoch - 144ms/step\n",
            "Epoch 22/250\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.79008 to 0.81298, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.6349 - accuracy: 0.7858 - val_loss: 0.5583 - val_accuracy: 0.8130 - lr: 0.0218 - 14s/epoch - 145ms/step\n",
            "Epoch 23/250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.81298\n",
            "96/96 - 14s - loss: 0.6115 - accuracy: 0.7973 - val_loss: 0.5806 - val_accuracy: 0.7912 - lr: 0.0218 - 14s/epoch - 145ms/step\n",
            "Epoch 24/250\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.81298 to 0.82252, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.5974 - accuracy: 0.7994 - val_loss: 0.5384 - val_accuracy: 0.8225 - lr: 0.0218 - 14s/epoch - 145ms/step\n",
            "Epoch 25/250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.82252\n",
            "96/96 - 14s - loss: 0.5779 - accuracy: 0.8062 - val_loss: 0.5627 - val_accuracy: 0.8050 - lr: 0.0218 - 14s/epoch - 144ms/step\n",
            "Epoch 26/250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.82252\n",
            "96/96 - 14s - loss: 0.5599 - accuracy: 0.8132 - val_loss: 0.5947 - val_accuracy: 0.7901 - lr: 0.0218 - 14s/epoch - 144ms/step\n",
            "Epoch 27/250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.82252\n",
            "96/96 - 14s - loss: 0.5433 - accuracy: 0.8189 - val_loss: 0.5671 - val_accuracy: 0.8107 - lr: 0.0218 - 14s/epoch - 145ms/step\n",
            "Epoch 28/250\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.82252 to 0.82328, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.5309 - accuracy: 0.8186 - val_loss: 0.5308 - val_accuracy: 0.8233 - lr: 0.0218 - 14s/epoch - 145ms/step\n",
            "Epoch 29/250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.82328\n",
            "96/96 - 14s - loss: 0.5168 - accuracy: 0.8246 - val_loss: 0.6241 - val_accuracy: 0.7782 - lr: 0.0218 - 14s/epoch - 145ms/step\n",
            "Epoch 30/250\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.82328 to 0.85076, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.5036 - accuracy: 0.8310 - val_loss: 0.4391 - val_accuracy: 0.8508 - lr: 0.0218 - 14s/epoch - 145ms/step\n",
            "Epoch 31/250\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.85076\n",
            "96/96 - 14s - loss: 0.4757 - accuracy: 0.8429 - val_loss: 0.4848 - val_accuracy: 0.8366 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 32/250\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.85076\n",
            "96/96 - 14s - loss: 0.4667 - accuracy: 0.8426 - val_loss: 0.4695 - val_accuracy: 0.8462 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 33/250\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.85076\n",
            "96/96 - 14s - loss: 0.4555 - accuracy: 0.8453 - val_loss: 0.5402 - val_accuracy: 0.8069 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 34/250\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.85076\n",
            "96/96 - 14s - loss: 0.4458 - accuracy: 0.8499 - val_loss: 0.4548 - val_accuracy: 0.8466 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 35/250\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.85076 to 0.87443, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.4394 - accuracy: 0.8532 - val_loss: 0.3878 - val_accuracy: 0.8744 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 36/250\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.87443\n",
            "96/96 - 14s - loss: 0.4287 - accuracy: 0.8564 - val_loss: 0.4029 - val_accuracy: 0.8725 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 37/250\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.87443\n",
            "96/96 - 14s - loss: 0.4089 - accuracy: 0.8608 - val_loss: 0.4988 - val_accuracy: 0.8252 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 38/250\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.87443\n",
            "96/96 - 14s - loss: 0.4110 - accuracy: 0.8623 - val_loss: 0.3811 - val_accuracy: 0.8725 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 39/250\n",
            "\n",
            "Epoch 39: val_accuracy improved from 0.87443 to 0.88130, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.4039 - accuracy: 0.8620 - val_loss: 0.3703 - val_accuracy: 0.8813 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 40/250\n",
            "\n",
            "Epoch 40: val_accuracy improved from 0.88130 to 0.88359, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.3890 - accuracy: 0.8671 - val_loss: 0.3595 - val_accuracy: 0.8836 - lr: 0.0207 - 14s/epoch - 145ms/step\n",
            "Epoch 41/250\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.88359 to 0.89885, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.3738 - accuracy: 0.8746 - val_loss: 0.3191 - val_accuracy: 0.8989 - lr: 0.0197 - 14s/epoch - 145ms/step\n",
            "Epoch 42/250\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.89885 to 0.90076, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.3656 - accuracy: 0.8766 - val_loss: 0.3199 - val_accuracy: 0.9008 - lr: 0.0197 - 14s/epoch - 145ms/step\n",
            "Epoch 43/250\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.90076\n",
            "96/96 - 14s - loss: 0.3504 - accuracy: 0.8823 - val_loss: 0.3588 - val_accuracy: 0.8805 - lr: 0.0197 - 14s/epoch - 144ms/step\n",
            "Epoch 44/250\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.90076\n",
            "96/96 - 14s - loss: 0.3448 - accuracy: 0.8829 - val_loss: 0.3448 - val_accuracy: 0.8901 - lr: 0.0197 - 14s/epoch - 144ms/step\n",
            "Epoch 45/250\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.90076\n",
            "96/96 - 14s - loss: 0.3395 - accuracy: 0.8819 - val_loss: 0.3214 - val_accuracy: 0.8966 - lr: 0.0197 - 14s/epoch - 144ms/step\n",
            "Epoch 46/250\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.90076\n",
            "96/96 - 14s - loss: 0.3248 - accuracy: 0.8883 - val_loss: 0.3714 - val_accuracy: 0.8718 - lr: 0.0197 - 14s/epoch - 144ms/step\n",
            "Epoch 47/250\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.90076\n",
            "96/96 - 14s - loss: 0.3253 - accuracy: 0.8880 - val_loss: 0.3331 - val_accuracy: 0.8863 - lr: 0.0197 - 14s/epoch - 144ms/step\n",
            "Epoch 48/250\n",
            "\n",
            "Epoch 48: val_accuracy improved from 0.90076 to 0.90305, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.3217 - accuracy: 0.8883 - val_loss: 0.3117 - val_accuracy: 0.9031 - lr: 0.0197 - 14s/epoch - 145ms/step\n",
            "Epoch 49/250\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.90305\n",
            "96/96 - 14s - loss: 0.3119 - accuracy: 0.8953 - val_loss: 0.2998 - val_accuracy: 0.8985 - lr: 0.0197 - 14s/epoch - 144ms/step\n",
            "Epoch 50/250\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.90305\n",
            "96/96 - 14s - loss: 0.3014 - accuracy: 0.8976 - val_loss: 0.3296 - val_accuracy: 0.8901 - lr: 0.0197 - 14s/epoch - 144ms/step\n",
            "Epoch 51/250\n",
            "\n",
            "Epoch 51: val_accuracy improved from 0.90305 to 0.91756, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.2970 - accuracy: 0.8991 - val_loss: 0.2634 - val_accuracy: 0.9176 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 52/250\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.91756\n",
            "96/96 - 14s - loss: 0.2803 - accuracy: 0.9047 - val_loss: 0.2818 - val_accuracy: 0.9000 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 53/250\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.91756\n",
            "96/96 - 14s - loss: 0.2837 - accuracy: 0.9016 - val_loss: 0.2631 - val_accuracy: 0.9076 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 54/250\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.91756\n",
            "96/96 - 14s - loss: 0.2782 - accuracy: 0.9044 - val_loss: 0.2657 - val_accuracy: 0.9107 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 55/250\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.91756\n",
            "96/96 - 14s - loss: 0.2735 - accuracy: 0.9060 - val_loss: 0.2736 - val_accuracy: 0.9057 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 56/250\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.91756\n",
            "96/96 - 14s - loss: 0.2647 - accuracy: 0.9105 - val_loss: 0.2750 - val_accuracy: 0.9092 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 57/250\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.91756\n",
            "96/96 - 14s - loss: 0.2624 - accuracy: 0.9095 - val_loss: 0.3054 - val_accuracy: 0.8962 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 58/250\n",
            "\n",
            "Epoch 58: val_accuracy improved from 0.91756 to 0.92901, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.2592 - accuracy: 0.9090 - val_loss: 0.2290 - val_accuracy: 0.9290 - lr: 0.0187 - 14s/epoch - 145ms/step\n",
            "Epoch 59/250\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.92901\n",
            "96/96 - 14s - loss: 0.2508 - accuracy: 0.9142 - val_loss: 0.2488 - val_accuracy: 0.9183 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 60/250\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.92901\n",
            "96/96 - 14s - loss: 0.2486 - accuracy: 0.9162 - val_loss: 0.2254 - val_accuracy: 0.9240 - lr: 0.0187 - 14s/epoch - 144ms/step\n",
            "Epoch 61/250\n",
            "\n",
            "Epoch 61: val_accuracy improved from 0.92901 to 0.93397, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.2511 - accuracy: 0.9147 - val_loss: 0.2100 - val_accuracy: 0.9340 - lr: 0.0178 - 14s/epoch - 145ms/step\n",
            "Epoch 62/250\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.93397\n",
            "96/96 - 14s - loss: 0.2332 - accuracy: 0.9200 - val_loss: 0.2628 - val_accuracy: 0.9118 - lr: 0.0178 - 14s/epoch - 144ms/step\n",
            "Epoch 63/250\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.93397\n",
            "96/96 - 14s - loss: 0.2271 - accuracy: 0.9223 - val_loss: 0.2586 - val_accuracy: 0.9130 - lr: 0.0178 - 14s/epoch - 144ms/step\n",
            "Epoch 64/250\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.93397\n",
            "96/96 - 14s - loss: 0.2397 - accuracy: 0.9184 - val_loss: 0.2840 - val_accuracy: 0.9084 - lr: 0.0178 - 14s/epoch - 144ms/step\n",
            "Epoch 65/250\n",
            "\n",
            "Epoch 65: val_accuracy improved from 0.93397 to 0.93702, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.2299 - accuracy: 0.9205 - val_loss: 0.2056 - val_accuracy: 0.9370 - lr: 0.0178 - 14s/epoch - 145ms/step\n",
            "Epoch 66/250\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.93702\n",
            "96/96 - 14s - loss: 0.2302 - accuracy: 0.9244 - val_loss: 0.2330 - val_accuracy: 0.9244 - lr: 0.0178 - 14s/epoch - 144ms/step\n",
            "Epoch 67/250\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.93702\n",
            "96/96 - 14s - loss: 0.2103 - accuracy: 0.9265 - val_loss: 0.2557 - val_accuracy: 0.9164 - lr: 0.0178 - 14s/epoch - 144ms/step\n",
            "Epoch 68/250\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.93702\n",
            "96/96 - 14s - loss: 0.2191 - accuracy: 0.9265 - val_loss: 0.2100 - val_accuracy: 0.9355 - lr: 0.0178 - 14s/epoch - 144ms/step\n",
            "Epoch 69/250\n",
            "\n",
            "Epoch 69: val_accuracy improved from 0.93702 to 0.93893, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.2144 - accuracy: 0.9264 - val_loss: 0.2063 - val_accuracy: 0.9389 - lr: 0.0178 - 14s/epoch - 144ms/step\n",
            "Epoch 70/250\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.93893\n",
            "96/96 - 14s - loss: 0.2072 - accuracy: 0.9291 - val_loss: 0.2041 - val_accuracy: 0.9366 - lr: 0.0178 - 14s/epoch - 144ms/step\n",
            "Epoch 71/250\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.93893\n",
            "96/96 - 14s - loss: 0.1968 - accuracy: 0.9358 - val_loss: 0.1829 - val_accuracy: 0.9385 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 72/250\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.93893\n",
            "96/96 - 14s - loss: 0.1967 - accuracy: 0.9328 - val_loss: 0.1983 - val_accuracy: 0.9385 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 73/250\n",
            "\n",
            "Epoch 73: val_accuracy improved from 0.93893 to 0.94008, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1901 - accuracy: 0.9343 - val_loss: 0.1875 - val_accuracy: 0.9401 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 74/250\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.94008\n",
            "96/96 - 14s - loss: 0.1935 - accuracy: 0.9337 - val_loss: 0.1966 - val_accuracy: 0.9389 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 75/250\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.94008\n",
            "96/96 - 14s - loss: 0.1894 - accuracy: 0.9357 - val_loss: 0.2041 - val_accuracy: 0.9282 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 76/250\n",
            "\n",
            "Epoch 76: val_accuracy improved from 0.94008 to 0.94198, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1901 - accuracy: 0.9350 - val_loss: 0.1718 - val_accuracy: 0.9420 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 77/250\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.94198\n",
            "96/96 - 14s - loss: 0.1865 - accuracy: 0.9381 - val_loss: 0.2886 - val_accuracy: 0.9061 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 78/250\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.94198\n",
            "96/96 - 14s - loss: 0.1825 - accuracy: 0.9371 - val_loss: 0.1995 - val_accuracy: 0.9340 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 79/250\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.94198\n",
            "96/96 - 14s - loss: 0.1828 - accuracy: 0.9382 - val_loss: 0.2039 - val_accuracy: 0.9275 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 80/250\n",
            "\n",
            "Epoch 80: val_accuracy improved from 0.94198 to 0.94580, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1850 - accuracy: 0.9385 - val_loss: 0.1815 - val_accuracy: 0.9458 - lr: 0.0169 - 14s/epoch - 144ms/step\n",
            "Epoch 81/250\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.94580\n",
            "96/96 - 14s - loss: 0.1755 - accuracy: 0.9400 - val_loss: 0.1819 - val_accuracy: 0.9401 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 82/250\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.94580\n",
            "96/96 - 14s - loss: 0.1672 - accuracy: 0.9445 - val_loss: 0.1705 - val_accuracy: 0.9439 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 83/250\n",
            "\n",
            "Epoch 83: val_accuracy improved from 0.94580 to 0.94695, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1705 - accuracy: 0.9437 - val_loss: 0.1693 - val_accuracy: 0.9469 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 84/250\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.94695\n",
            "96/96 - 14s - loss: 0.1635 - accuracy: 0.9458 - val_loss: 0.2195 - val_accuracy: 0.9267 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 85/250\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.94695\n",
            "96/96 - 14s - loss: 0.1662 - accuracy: 0.9427 - val_loss: 0.1776 - val_accuracy: 0.9462 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 86/250\n",
            "\n",
            "Epoch 86: val_accuracy improved from 0.94695 to 0.94771, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1609 - accuracy: 0.9450 - val_loss: 0.1631 - val_accuracy: 0.9477 - lr: 0.0160 - 14s/epoch - 145ms/step\n",
            "Epoch 87/250\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.94771\n",
            "96/96 - 14s - loss: 0.1586 - accuracy: 0.9467 - val_loss: 0.1636 - val_accuracy: 0.9462 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 88/250\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.94771\n",
            "96/96 - 14s - loss: 0.1646 - accuracy: 0.9461 - val_loss: 0.2131 - val_accuracy: 0.9282 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 89/250\n",
            "\n",
            "Epoch 89: val_accuracy improved from 0.94771 to 0.94962, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1586 - accuracy: 0.9463 - val_loss: 0.1541 - val_accuracy: 0.9496 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 90/250\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.94962\n",
            "96/96 - 14s - loss: 0.1538 - accuracy: 0.9485 - val_loss: 0.1682 - val_accuracy: 0.9431 - lr: 0.0160 - 14s/epoch - 144ms/step\n",
            "Epoch 91/250\n",
            "\n",
            "Epoch 91: val_accuracy improved from 0.94962 to 0.95153, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1460 - accuracy: 0.9523 - val_loss: 0.1565 - val_accuracy: 0.9515 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 92/250\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.95153\n",
            "96/96 - 14s - loss: 0.1490 - accuracy: 0.9500 - val_loss: 0.1583 - val_accuracy: 0.9511 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 93/250\n",
            "\n",
            "Epoch 93: val_accuracy improved from 0.95153 to 0.95191, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1435 - accuracy: 0.9518 - val_loss: 0.1502 - val_accuracy: 0.9519 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 94/250\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.95191\n",
            "96/96 - 14s - loss: 0.1419 - accuracy: 0.9526 - val_loss: 0.1571 - val_accuracy: 0.9492 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 95/250\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.95191\n",
            "96/96 - 14s - loss: 0.1457 - accuracy: 0.9513 - val_loss: 0.1582 - val_accuracy: 0.9492 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 96/250\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.95191\n",
            "96/96 - 14s - loss: 0.1440 - accuracy: 0.9508 - val_loss: 0.1641 - val_accuracy: 0.9500 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 97/250\n",
            "\n",
            "Epoch 97: val_accuracy improved from 0.95191 to 0.95687, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1434 - accuracy: 0.9518 - val_loss: 0.1487 - val_accuracy: 0.9569 - lr: 0.0152 - 14s/epoch - 145ms/step\n",
            "Epoch 98/250\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.95687\n",
            "96/96 - 14s - loss: 0.1432 - accuracy: 0.9537 - val_loss: 0.1467 - val_accuracy: 0.9569 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 99/250\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.95687\n",
            "96/96 - 14s - loss: 0.1379 - accuracy: 0.9539 - val_loss: 0.1524 - val_accuracy: 0.9492 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 100/250\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.95687\n",
            "96/96 - 14s - loss: 0.1339 - accuracy: 0.9553 - val_loss: 0.1676 - val_accuracy: 0.9489 - lr: 0.0152 - 14s/epoch - 144ms/step\n",
            "Epoch 101/250\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.95687\n",
            "96/96 - 14s - loss: 0.1325 - accuracy: 0.9552 - val_loss: 0.1433 - val_accuracy: 0.9561 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 102/250\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.95687\n",
            "96/96 - 14s - loss: 0.1349 - accuracy: 0.9548 - val_loss: 0.1445 - val_accuracy: 0.9550 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 103/250\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.95687\n",
            "96/96 - 14s - loss: 0.1230 - accuracy: 0.9592 - val_loss: 0.2282 - val_accuracy: 0.9263 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 104/250\n",
            "\n",
            "Epoch 104: val_accuracy improved from 0.95687 to 0.96069, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1341 - accuracy: 0.9548 - val_loss: 0.1393 - val_accuracy: 0.9607 - lr: 0.0145 - 14s/epoch - 145ms/step\n",
            "Epoch 105/250\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1265 - accuracy: 0.9591 - val_loss: 0.1747 - val_accuracy: 0.9466 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 106/250\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1195 - accuracy: 0.9605 - val_loss: 0.1574 - val_accuracy: 0.9561 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 107/250\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1232 - accuracy: 0.9599 - val_loss: 0.1312 - val_accuracy: 0.9584 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 108/250\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1207 - accuracy: 0.9587 - val_loss: 0.1418 - val_accuracy: 0.9584 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 109/250\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1236 - accuracy: 0.9608 - val_loss: 0.1504 - val_accuracy: 0.9466 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 110/250\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1235 - accuracy: 0.9584 - val_loss: 0.1326 - val_accuracy: 0.9588 - lr: 0.0145 - 14s/epoch - 144ms/step\n",
            "Epoch 111/250\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1185 - accuracy: 0.9629 - val_loss: 0.1500 - val_accuracy: 0.9557 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 112/250\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1154 - accuracy: 0.9609 - val_loss: 0.1489 - val_accuracy: 0.9481 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 113/250\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1109 - accuracy: 0.9639 - val_loss: 0.1490 - val_accuracy: 0.9561 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 114/250\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.96069\n",
            "96/96 - 14s - loss: 0.1166 - accuracy: 0.9608 - val_loss: 0.1577 - val_accuracy: 0.9523 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 115/250\n",
            "\n",
            "Epoch 115: val_accuracy improved from 0.96069 to 0.96107, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1124 - accuracy: 0.9635 - val_loss: 0.1241 - val_accuracy: 0.9611 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 116/250\n",
            "\n",
            "Epoch 116: val_accuracy improved from 0.96107 to 0.96298, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1097 - accuracy: 0.9634 - val_loss: 0.1253 - val_accuracy: 0.9630 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 117/250\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.96298\n",
            "96/96 - 14s - loss: 0.1092 - accuracy: 0.9647 - val_loss: 0.1341 - val_accuracy: 0.9595 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 118/250\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.96298\n",
            "96/96 - 14s - loss: 0.1082 - accuracy: 0.9625 - val_loss: 0.1752 - val_accuracy: 0.9389 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 119/250\n",
            "\n",
            "Epoch 119: val_accuracy improved from 0.96298 to 0.96374, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1107 - accuracy: 0.9647 - val_loss: 0.1281 - val_accuracy: 0.9637 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 120/250\n",
            "\n",
            "Epoch 120: val_accuracy improved from 0.96374 to 0.96450, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.1093 - accuracy: 0.9649 - val_loss: 0.1223 - val_accuracy: 0.9645 - lr: 0.0137 - 14s/epoch - 144ms/step\n",
            "Epoch 121/250\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.96450\n",
            "96/96 - 14s - loss: 0.1013 - accuracy: 0.9665 - val_loss: 0.1295 - val_accuracy: 0.9637 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 122/250\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.96450\n",
            "96/96 - 14s - loss: 0.1058 - accuracy: 0.9635 - val_loss: 0.1402 - val_accuracy: 0.9626 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 123/250\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.96450\n",
            "96/96 - 14s - loss: 0.1017 - accuracy: 0.9655 - val_loss: 0.1339 - val_accuracy: 0.9576 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 124/250\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.96450\n",
            "96/96 - 14s - loss: 0.1016 - accuracy: 0.9670 - val_loss: 0.1307 - val_accuracy: 0.9599 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 125/250\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.96450\n",
            "96/96 - 14s - loss: 0.1022 - accuracy: 0.9670 - val_loss: 0.1247 - val_accuracy: 0.9630 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 126/250\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.96450\n",
            "96/96 - 14s - loss: 0.1021 - accuracy: 0.9664 - val_loss: 0.1170 - val_accuracy: 0.9634 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 127/250\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.96450\n",
            "96/96 - 14s - loss: 0.0976 - accuracy: 0.9678 - val_loss: 0.1374 - val_accuracy: 0.9580 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 128/250\n",
            "\n",
            "Epoch 128: val_accuracy improved from 0.96450 to 0.96527, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0993 - accuracy: 0.9665 - val_loss: 0.1133 - val_accuracy: 0.9653 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 129/250\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.96527\n",
            "96/96 - 14s - loss: 0.0971 - accuracy: 0.9690 - val_loss: 0.1255 - val_accuracy: 0.9615 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 130/250\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.96527\n",
            "96/96 - 14s - loss: 0.1001 - accuracy: 0.9671 - val_loss: 0.1203 - val_accuracy: 0.9618 - lr: 0.0131 - 14s/epoch - 144ms/step\n",
            "Epoch 131/250\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.96527\n",
            "96/96 - 14s - loss: 0.0974 - accuracy: 0.9680 - val_loss: 0.1289 - val_accuracy: 0.9599 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 132/250\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.96527\n",
            "96/96 - 14s - loss: 0.0903 - accuracy: 0.9707 - val_loss: 0.1309 - val_accuracy: 0.9630 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 133/250\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.96527\n",
            "96/96 - 14s - loss: 0.0975 - accuracy: 0.9692 - val_loss: 0.1215 - val_accuracy: 0.9653 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 134/250\n",
            "\n",
            "Epoch 134: val_accuracy improved from 0.96527 to 0.97023, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0980 - accuracy: 0.9675 - val_loss: 0.1105 - val_accuracy: 0.9702 - lr: 0.0124 - 14s/epoch - 145ms/step\n",
            "Epoch 135/250\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0898 - accuracy: 0.9711 - val_loss: 0.1178 - val_accuracy: 0.9664 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 136/250\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0891 - accuracy: 0.9716 - val_loss: 0.1121 - val_accuracy: 0.9698 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 137/250\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0899 - accuracy: 0.9691 - val_loss: 0.1119 - val_accuracy: 0.9683 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 138/250\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0831 - accuracy: 0.9717 - val_loss: 0.1154 - val_accuracy: 0.9683 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 139/250\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0913 - accuracy: 0.9693 - val_loss: 0.1182 - val_accuracy: 0.9668 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 140/250\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0956 - accuracy: 0.9673 - val_loss: 0.1114 - val_accuracy: 0.9676 - lr: 0.0124 - 14s/epoch - 144ms/step\n",
            "Epoch 141/250\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0829 - accuracy: 0.9724 - val_loss: 0.1135 - val_accuracy: 0.9679 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 142/250\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0853 - accuracy: 0.9729 - val_loss: 0.1170 - val_accuracy: 0.9664 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 143/250\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0843 - accuracy: 0.9736 - val_loss: 0.1155 - val_accuracy: 0.9679 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 144/250\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0901 - accuracy: 0.9707 - val_loss: 0.1172 - val_accuracy: 0.9653 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 145/250\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0775 - accuracy: 0.9755 - val_loss: 0.1220 - val_accuracy: 0.9676 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 146/250\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0802 - accuracy: 0.9732 - val_loss: 0.1102 - val_accuracy: 0.9687 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 147/250\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0804 - accuracy: 0.9748 - val_loss: 0.1163 - val_accuracy: 0.9664 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 148/250\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0860 - accuracy: 0.9723 - val_loss: 0.1507 - val_accuracy: 0.9508 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 149/250\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0767 - accuracy: 0.9737 - val_loss: 0.1147 - val_accuracy: 0.9672 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 150/250\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0842 - accuracy: 0.9725 - val_loss: 0.1136 - val_accuracy: 0.9653 - lr: 0.0118 - 14s/epoch - 144ms/step\n",
            "Epoch 151/250\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0797 - accuracy: 0.9748 - val_loss: 0.1119 - val_accuracy: 0.9683 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 152/250\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0732 - accuracy: 0.9777 - val_loss: 0.1115 - val_accuracy: 0.9687 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 153/250\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0774 - accuracy: 0.9749 - val_loss: 0.1031 - val_accuracy: 0.9683 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 154/250\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0805 - accuracy: 0.9735 - val_loss: 0.1105 - val_accuracy: 0.9687 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 155/250\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0751 - accuracy: 0.9751 - val_loss: 0.1112 - val_accuracy: 0.9664 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 156/250\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0746 - accuracy: 0.9745 - val_loss: 0.1179 - val_accuracy: 0.9695 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 157/250\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.97023\n",
            "96/96 - 14s - loss: 0.0727 - accuracy: 0.9751 - val_loss: 0.1078 - val_accuracy: 0.9687 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 158/250\n",
            "\n",
            "Epoch 158: val_accuracy improved from 0.97023 to 0.97176, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0771 - accuracy: 0.9740 - val_loss: 0.1060 - val_accuracy: 0.9718 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 159/250\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.97176\n",
            "96/96 - 14s - loss: 0.0721 - accuracy: 0.9777 - val_loss: 0.1048 - val_accuracy: 0.9714 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 160/250\n",
            "\n",
            "Epoch 160: val_accuracy improved from 0.97176 to 0.97252, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0749 - accuracy: 0.9764 - val_loss: 0.1030 - val_accuracy: 0.9725 - lr: 0.0112 - 14s/epoch - 144ms/step\n",
            "Epoch 161/250\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0684 - accuracy: 0.9786 - val_loss: 0.1124 - val_accuracy: 0.9702 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 162/250\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0744 - accuracy: 0.9755 - val_loss: 0.1029 - val_accuracy: 0.9725 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 163/250\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0706 - accuracy: 0.9772 - val_loss: 0.1097 - val_accuracy: 0.9679 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 164/250\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0723 - accuracy: 0.9766 - val_loss: 0.1103 - val_accuracy: 0.9676 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 165/250\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0731 - accuracy: 0.9782 - val_loss: 0.1123 - val_accuracy: 0.9626 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 166/250\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0714 - accuracy: 0.9773 - val_loss: 0.1079 - val_accuracy: 0.9691 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 167/250\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0722 - accuracy: 0.9759 - val_loss: 0.1105 - val_accuracy: 0.9660 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 168/250\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0717 - accuracy: 0.9782 - val_loss: 0.1128 - val_accuracy: 0.9630 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 169/250\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0678 - accuracy: 0.9783 - val_loss: 0.1050 - val_accuracy: 0.9706 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 170/250\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0714 - accuracy: 0.9769 - val_loss: 0.1163 - val_accuracy: 0.9676 - lr: 0.0106 - 14s/epoch - 144ms/step\n",
            "Epoch 171/250\n",
            "\n",
            "Epoch 171: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0696 - accuracy: 0.9766 - val_loss: 0.1078 - val_accuracy: 0.9660 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 172/250\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0721 - accuracy: 0.9766 - val_loss: 0.1213 - val_accuracy: 0.9687 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 173/250\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0671 - accuracy: 0.9786 - val_loss: 0.1060 - val_accuracy: 0.9702 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 174/250\n",
            "\n",
            "Epoch 174: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0680 - accuracy: 0.9773 - val_loss: 0.1112 - val_accuracy: 0.9668 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 175/250\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0664 - accuracy: 0.9797 - val_loss: 0.1081 - val_accuracy: 0.9725 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 176/250\n",
            "\n",
            "Epoch 176: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0693 - accuracy: 0.9783 - val_loss: 0.1247 - val_accuracy: 0.9634 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 177/250\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0667 - accuracy: 0.9781 - val_loss: 0.1088 - val_accuracy: 0.9641 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 178/250\n",
            "\n",
            "Epoch 178: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0635 - accuracy: 0.9795 - val_loss: 0.0978 - val_accuracy: 0.9714 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 179/250\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.97252\n",
            "96/96 - 14s - loss: 0.0680 - accuracy: 0.9794 - val_loss: 0.1565 - val_accuracy: 0.9573 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 180/250\n",
            "\n",
            "Epoch 180: val_accuracy improved from 0.97252 to 0.97290, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0642 - accuracy: 0.9797 - val_loss: 0.1025 - val_accuracy: 0.9729 - lr: 0.0101 - 14s/epoch - 144ms/step\n",
            "Epoch 181/250\n",
            "\n",
            "Epoch 181: val_accuracy improved from 0.97290 to 0.97405, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0634 - accuracy: 0.9807 - val_loss: 0.0970 - val_accuracy: 0.9740 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 182/250\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.97405\n",
            "96/96 - 14s - loss: 0.0636 - accuracy: 0.9812 - val_loss: 0.0977 - val_accuracy: 0.9725 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 183/250\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.97405\n",
            "96/96 - 14s - loss: 0.0612 - accuracy: 0.9806 - val_loss: 0.1032 - val_accuracy: 0.9695 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 184/250\n",
            "\n",
            "Epoch 184: val_accuracy did not improve from 0.97405\n",
            "96/96 - 14s - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.1066 - val_accuracy: 0.9691 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 185/250\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.97405\n",
            "96/96 - 14s - loss: 0.0647 - accuracy: 0.9789 - val_loss: 0.1082 - val_accuracy: 0.9725 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 186/250\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.97405\n",
            "96/96 - 14s - loss: 0.0665 - accuracy: 0.9791 - val_loss: 0.1049 - val_accuracy: 0.9691 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 187/250\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.97405\n",
            "96/96 - 14s - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.1019 - val_accuracy: 0.9733 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 188/250\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.97405\n",
            "96/96 - 14s - loss: 0.0636 - accuracy: 0.9796 - val_loss: 0.1048 - val_accuracy: 0.9725 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 189/250\n",
            "\n",
            "Epoch 189: val_accuracy improved from 0.97405 to 0.97443, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0611 - accuracy: 0.9800 - val_loss: 0.0952 - val_accuracy: 0.9744 - lr: 0.0096 - 14s/epoch - 145ms/step\n",
            "Epoch 190/250\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0568 - accuracy: 0.9819 - val_loss: 0.1018 - val_accuracy: 0.9733 - lr: 0.0096 - 14s/epoch - 144ms/step\n",
            "Epoch 191/250\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0595 - accuracy: 0.9809 - val_loss: 0.1044 - val_accuracy: 0.9740 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 192/250\n",
            "\n",
            "Epoch 192: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0564 - accuracy: 0.9813 - val_loss: 0.1181 - val_accuracy: 0.9691 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 193/250\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.97443\n",
            "96/96 - 14s - loss: 0.0605 - accuracy: 0.9806 - val_loss: 0.1112 - val_accuracy: 0.9698 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 194/250\n",
            "\n",
            "Epoch 194: val_accuracy improved from 0.97443 to 0.97481, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0627 - accuracy: 0.9794 - val_loss: 0.0981 - val_accuracy: 0.9748 - lr: 0.0091 - 14s/epoch - 145ms/step\n",
            "Epoch 195/250\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0595 - accuracy: 0.9815 - val_loss: 0.1011 - val_accuracy: 0.9714 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 196/250\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0601 - accuracy: 0.9810 - val_loss: 0.0982 - val_accuracy: 0.9748 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 197/250\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0587 - accuracy: 0.9822 - val_loss: 0.1075 - val_accuracy: 0.9698 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 198/250\n",
            "\n",
            "Epoch 198: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0536 - accuracy: 0.9826 - val_loss: 0.1026 - val_accuracy: 0.9721 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 199/250\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.0985 - val_accuracy: 0.9740 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 200/250\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0564 - accuracy: 0.9818 - val_loss: 0.1018 - val_accuracy: 0.9737 - lr: 0.0091 - 14s/epoch - 144ms/step\n",
            "Epoch 201/250\n",
            "\n",
            "Epoch 201: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0578 - accuracy: 0.9809 - val_loss: 0.0997 - val_accuracy: 0.9737 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 202/250\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0584 - accuracy: 0.9804 - val_loss: 0.1037 - val_accuracy: 0.9695 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 203/250\n",
            "\n",
            "Epoch 203: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0530 - accuracy: 0.9835 - val_loss: 0.1069 - val_accuracy: 0.9718 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 204/250\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0506 - accuracy: 0.9836 - val_loss: 0.0973 - val_accuracy: 0.9721 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 205/250\n",
            "\n",
            "Epoch 205: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0511 - accuracy: 0.9840 - val_loss: 0.1028 - val_accuracy: 0.9729 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 206/250\n",
            "\n",
            "Epoch 206: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0579 - accuracy: 0.9821 - val_loss: 0.1044 - val_accuracy: 0.9721 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 207/250\n",
            "\n",
            "Epoch 207: val_accuracy did not improve from 0.97481\n",
            "96/96 - 14s - loss: 0.0558 - accuracy: 0.9825 - val_loss: 0.1037 - val_accuracy: 0.9714 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 208/250\n",
            "\n",
            "Epoch 208: val_accuracy improved from 0.97481 to 0.97557, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0570 - accuracy: 0.9812 - val_loss: 0.0992 - val_accuracy: 0.9756 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 209/250\n",
            "\n",
            "Epoch 209: val_accuracy did not improve from 0.97557\n",
            "96/96 - 14s - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.1092 - val_accuracy: 0.9725 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 210/250\n",
            "\n",
            "Epoch 210: val_accuracy did not improve from 0.97557\n",
            "96/96 - 14s - loss: 0.0550 - accuracy: 0.9820 - val_loss: 0.1093 - val_accuracy: 0.9714 - lr: 0.0087 - 14s/epoch - 144ms/step\n",
            "Epoch 211/250\n",
            "\n",
            "Epoch 211: val_accuracy did not improve from 0.97557\n",
            "96/96 - 14s - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.0975 - val_accuracy: 0.9737 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 212/250\n",
            "\n",
            "Epoch 212: val_accuracy did not improve from 0.97557\n",
            "96/96 - 14s - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.1087 - val_accuracy: 0.9714 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 213/250\n",
            "\n",
            "Epoch 213: val_accuracy did not improve from 0.97557\n",
            "96/96 - 14s - loss: 0.0537 - accuracy: 0.9837 - val_loss: 0.1018 - val_accuracy: 0.9721 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 214/250\n",
            "\n",
            "Epoch 214: val_accuracy improved from 0.97557 to 0.97595, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0520 - accuracy: 0.9845 - val_loss: 0.0938 - val_accuracy: 0.9760 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 215/250\n",
            "\n",
            "Epoch 215: val_accuracy did not improve from 0.97595\n",
            "96/96 - 14s - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.0969 - val_accuracy: 0.9744 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 216/250\n",
            "\n",
            "Epoch 216: val_accuracy improved from 0.97595 to 0.97672, saving model to saved_models/best_fcn.keras\n",
            "96/96 - 14s - loss: 0.0544 - accuracy: 0.9819 - val_loss: 0.0952 - val_accuracy: 0.9767 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 217/250\n",
            "\n",
            "Epoch 217: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0540 - accuracy: 0.9828 - val_loss: 0.1018 - val_accuracy: 0.9721 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 218/250\n",
            "\n",
            "Epoch 218: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0530 - accuracy: 0.9829 - val_loss: 0.0980 - val_accuracy: 0.9740 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 219/250\n",
            "\n",
            "Epoch 219: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0953 - val_accuracy: 0.9733 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 220/250\n",
            "\n",
            "Epoch 220: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0988 - val_accuracy: 0.9740 - lr: 0.0082 - 14s/epoch - 144ms/step\n",
            "Epoch 221/250\n",
            "\n",
            "Epoch 221: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.0973 - val_accuracy: 0.9710 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 222/250\n",
            "\n",
            "Epoch 222: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0462 - accuracy: 0.9856 - val_loss: 0.1002 - val_accuracy: 0.9740 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 223/250\n",
            "\n",
            "Epoch 223: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0511 - accuracy: 0.9826 - val_loss: 0.0979 - val_accuracy: 0.9756 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 224/250\n",
            "\n",
            "Epoch 224: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.0967 - val_accuracy: 0.9760 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 225/250\n",
            "\n",
            "Epoch 225: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0490 - accuracy: 0.9846 - val_loss: 0.0973 - val_accuracy: 0.9748 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 226/250\n",
            "\n",
            "Epoch 226: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0464 - accuracy: 0.9861 - val_loss: 0.0952 - val_accuracy: 0.9729 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 227/250\n",
            "\n",
            "Epoch 227: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0973 - val_accuracy: 0.9763 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 228/250\n",
            "\n",
            "Epoch 228: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0481 - accuracy: 0.9845 - val_loss: 0.0932 - val_accuracy: 0.9748 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 229/250\n",
            "\n",
            "Epoch 229: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0920 - val_accuracy: 0.9760 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 230/250\n",
            "\n",
            "Epoch 230: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.0923 - val_accuracy: 0.9752 - lr: 0.0078 - 14s/epoch - 144ms/step\n",
            "Epoch 231/250\n",
            "\n",
            "Epoch 231: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0476 - accuracy: 0.9844 - val_loss: 0.0979 - val_accuracy: 0.9729 - lr: 0.0074 - 14s/epoch - 144ms/step\n",
            "Epoch 232/250\n",
            "\n",
            "Epoch 232: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0516 - accuracy: 0.9829 - val_loss: 0.0895 - val_accuracy: 0.9740 - lr: 0.0074 - 14s/epoch - 144ms/step\n",
            "Epoch 233/250\n",
            "\n",
            "Epoch 233: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0508 - accuracy: 0.9849 - val_loss: 0.0987 - val_accuracy: 0.9767 - lr: 0.0074 - 14s/epoch - 144ms/step\n",
            "Epoch 234/250\n",
            "\n",
            "Epoch 234: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.0921 - val_accuracy: 0.9763 - lr: 0.0074 - 14s/epoch - 144ms/step\n",
            "Epoch 235/250\n",
            "\n",
            "Epoch 235: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0471 - accuracy: 0.9859 - val_loss: 0.0962 - val_accuracy: 0.9760 - lr: 0.0074 - 14s/epoch - 144ms/step\n",
            "Epoch 236/250\n",
            "\n",
            "Epoch 236: val_accuracy did not improve from 0.97672\n",
            "96/96 - 14s - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.0909 - val_accuracy: 0.9744 - lr: 0.0074 - 14s/epoch - 144ms/step\n",
            "Epoch 237/250\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    OPTIMIZER = trial.suggest_categorical(\n",
        "        'optimizer', [\"Adam\",\"RMSprop\",\"SGD\"])\n",
        "    LEARNING_RATE = trial.suggest_float('learning_rate', 5e-4, 0.05)\n",
        "    BATCH_SIZE = trial.suggest_categorical(\n",
        "        'batch_size', [16, 32, 64, 128, 256, 512])\n",
        "    EPOCHS = 250\n",
        "    PATIENCE = 30\n",
        "    DROPOUT = trial.suggest_float('dropout_ratio', 0.01, 0.5)\n",
        "    DECAY = trial.suggest_float('decay', 0.8, 1)\n",
        "    # RS = 1\n",
        "\n",
        "    model = reimproved_model(\n",
        "        input_shape=X_train.shape[1:], dropout_ratio=DROPOUT)\n",
        "    _ = model(X_train[:1])\n",
        "\n",
        "    trained_model, history = launch_training(\n",
        "        model, X_train, y_train, X_val, y_val, lr=LEARNING_RATE, bs=BATCH_SIZE, epochs=EPOCHS, patience=PATIENCE, decay=DECAY, optimizer=OPTIMIZER, verbose=2)\n",
        "    best_val_accuracy = round(max(history.history['val_accuracy']), 3)\n",
        "    return best_val_accuracy\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    study = optuna.create_study(\n",
        "        storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
        "        study_name=\"audio-recognize01\",\n",
        "        direction=\"maximize\"\n",
        "    )\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = get_data(\n",
        "    \"extracted.csv\", random_state=1)\n",
        "\n",
        "study.optimize(objective, n_trials=50, n_jobs=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71VdLtq-EAZh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}